{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jychen630/dl-fall22-mini-project/blob/main/Gustavo_Mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM4tmSSp0cPb",
        "outputId": "2f8b7307-616e-447b-d592-691b95cc65e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "SsNWB9qNNKka"
      },
      "outputs": [],
      "source": [
        "#!pip install -e git+https://github.com/marcoancona/TorchPruner.git#egg=torchpruner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "GXI-w576XzT_"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "def set_up_ssl():\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "set_up_ssl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "wTLc4fVcQ857"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "import humanize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "jQeGvfSCRM4i"
      },
      "outputs": [],
      "source": [
        "term_width = 5\n",
        "TOTAL_BAR_LENGTH = 7\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "wTCFIHn0XzUL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # pruning model parameters in the first convolution layer\n",
        "\n",
        "        # prune.random_unstructured(self.conv1, name='weight', amount=0.6)\n",
        "        # prune.remove(self.conv1, 'weight')\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # pruning model parameters in the second convolution layer\n",
        "\n",
        "        # prune.random_unstructured(self.conv2, name='weight', amount=0.6)\n",
        "        # prune.remove(self.conv2, 'weight')\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        # prune.random_unstructured(self.conv1, name='weight', amount=0.5)\n",
        "        # prune.remove(self.conv1, 'weight')\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        \n",
        "        # prune.random_unstructured(self.conv2, name='weight', amount=0.5)\n",
        "        # prune.remove(self.conv2, 'weight')\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        \n",
        "        # prune.random_unstructured(self.conv3, name='weight', amount=0.5)\n",
        "        # prune.remove(self.conv3, 'weight')\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        #out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        \n",
        "        # prune.random_unstructured(self.conv1, name='weight', amount=0.5)\n",
        "        # prune.remove(self.conv1, 'weight')\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=4)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "        # prune.random_unstructured(self.linear, name='weight', amount=0.5)\n",
        "        # prune.remove(self.linear, 'weight')\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        #out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "#seems not used\n",
        "# def test():\n",
        "#     net = ResNet18()\n",
        "#     y = net(torch.randn(1, 3, 32, 32))\n",
        "#     print(y.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_K9-VkFRsiL",
        "outputId": "1a7bff1d-c624-4b8e-d1d0-4ddcbfbdccf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "The length of a train set is  45000\n",
            "The length of a validation set is  5000\n",
            "The length of a test set is  10000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "LOCAL_M1 = False\n",
        "\n",
        "if LOCAL_M1:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
        "else:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    #transforms.RandomErasing()\n",
        "  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# constructing validation set\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)\n",
        "print(\"The length of a train set is \", len(train_ds))\n",
        "print(\"The length of a validation set is \", len(val_ds))\n",
        "print(\"The length of a test set is \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = ResNet18() # 11.2 params\n",
        "#net.fc = nn.Identity()\n",
        "#net = ResNet50() # 23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzjCm0gOElC",
        "outputId": "7abfda57-f519-4fbe-fdc7-71d18b3da2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(4, 4), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "layers = list(net.children())\n",
        "\n",
        "print(len(layers))\n",
        "\n",
        "print(net)\n",
        "# print(\"layers[0]: \", layers[0])\n",
        "# print(\"layers[1]: \", layers[1])\n",
        "# print(\"layers[2]: \", layers[2])\n",
        "# print(\"layers[3]: \", layers[3])\n",
        "# print(\"layers[4]: \", layers[4])\n",
        "# print(\"layers[5]: \", layers[5])\n",
        "# print(\"layers[6]: \", layers[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "kgQPV3H4ZTxA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def print_params(model):\n",
        "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkbs0btThnx",
        "outputId": "db1abe29-75fe-475f-9582-30de71975d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters is \n",
            "Number of parameters  2.8 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "nTqr1gYtVHgE"
      },
      "outputs": [],
      "source": [
        "# from torchsummary import summary\n",
        "\n",
        "# def print_model_summary(model):\n",
        "#   print(summary(model.to(device), (3, 32, 32)))\n",
        "\n",
        "# print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "tejFfYvQJxR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67aa219e-f5dc-4a45-9e41-63011af58c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([64, 3, 3, 3])\n",
            "bn1.weight torch.Size([64])\n",
            "bn1.bias torch.Size([64])\n",
            "layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([64])\n",
            "layer1.0.bn1.bias torch.Size([64])\n",
            "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([64])\n",
            "layer1.0.bn2.bias torch.Size([64])\n",
            "layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([64])\n",
            "layer1.1.bn1.bias torch.Size([64])\n",
            "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([64])\n",
            "layer1.1.bn2.bias torch.Size([64])\n",
            "layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([128])\n",
            "layer2.0.bn1.bias torch.Size([128])\n",
            "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([128])\n",
            "layer2.0.bn2.bias torch.Size([128])\n",
            "layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])\n",
            "layer2.0.shortcut.1.weight torch.Size([128])\n",
            "layer2.0.shortcut.1.bias torch.Size([128])\n",
            "layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([128])\n",
            "layer2.1.bn1.bias torch.Size([128])\n",
            "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([128])\n",
            "layer2.1.bn2.bias torch.Size([128])\n",
            "layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([256])\n",
            "layer3.0.bn1.bias torch.Size([256])\n",
            "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([256])\n",
            "layer3.0.bn2.bias torch.Size([256])\n",
            "layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])\n",
            "layer3.0.shortcut.1.weight torch.Size([256])\n",
            "layer3.0.shortcut.1.bias torch.Size([256])\n",
            "layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([256])\n",
            "layer3.1.bn1.bias torch.Size([256])\n",
            "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([256])\n",
            "layer3.1.bn2.bias torch.Size([256])\n",
            "linear.weight torch.Size([10, 256])\n",
            "linear.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "def print_model_layers(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "print_model_layers(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "iod4A6RJVzBb"
      },
      "outputs": [],
      "source": [
        "def freeze_layer(layer_name):\n",
        "  for param_name, param in net.named_parameters():\n",
        "    if layer_name in param_name:\n",
        "      param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "D4CjYR_cLnDx"
      },
      "outputs": [],
      "source": [
        "# freeze_layer(\"layer3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "WDYLyuksFbiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3eb930e-cc9d-45c2-982d-2dee9f63ccd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 4, 4]             512\n",
            "           Conv2d-27            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 4, 4]             512\n",
            "           Conv2d-29            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 4, 4]             512\n",
            "       BasicBlock-31            [-1, 256, 4, 4]               0\n",
            "           Conv2d-32            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 4, 4]             512\n",
            "           Conv2d-34            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 4, 4]             512\n",
            "       BasicBlock-36            [-1, 256, 4, 4]               0\n",
            "           Linear-37                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 2,777,674\n",
            "Trainable params: 2,777,674\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.38\n",
            "Params size (MB): 10.60\n",
            "Estimated Total Size (MB): 19.98\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "a3kWtBzVWg3Y"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "lr = 0.1\n",
        "lr = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                       momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "save_loss = {'train':[], 'test':[]}\n",
        "save_acc = {'train':[], 'test':[]}\n",
        "\n",
        "train_acc_array, train_loss_array = [], [] # for plotting\n",
        "val_acc_array, val_loss_array = [], [] # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "CIzJObnOWz2d"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_acc = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_acc=100.*correct/total\n",
        "        progress_bar(batch_idx, len(trainloader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    train_acc_array.append(train_acc) # for plottting\n",
        "    train_loss_array.append(train_loss) # for plottting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "0CHlPBF6uIhT"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch): # validation\n",
        "   \n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(val_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
        "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    valid_acc = 100.*correct/total\n",
        "    if valid_acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net_state_dict': net.state_dict(),\n",
        "            'acc': valid_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = valid_acc\n",
        "    val_acc_array.append(valid_acc) # for plottting\n",
        "    val_loss_array.append(valid_loss) # for plottting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "G5i2dqetBgXp"
      },
      "outputs": [],
      "source": [
        "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
        "def test(): \n",
        "   \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    net.load_state_dict(checkpoint['net_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_acc = checkpoint['acc']\n",
        "    net.eval()\n",
        "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs) \n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "Qyuhb-GrXzUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb15632-d976-4b03-fb49-de6d8881a46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "79HcWh5aXzUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249f912a-05a3-4932-9e1b-ef781f73dfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  2.8 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "jJcMkrBzW7o7",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71ed424-df6d-42db-d1f6-064d04d999e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 234ms | Tot: 38s867ms | Train Loss: 1.747 | Train Acc: 35.927% (16167/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 40ms | Tot: 3s136ms | Valid Loss: 1.609 | Valid Acc: 40.900% (2045/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 42ms | Tot: 34s435ms | Train Loss: 1.309 | Train Acc: 53.044% (23870/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 3s135ms | Valid Loss: 1.301 | Valid Acc: 53.760% (2688/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 45ms | Tot: 34s620ms | Train Loss: 1.098 | Train Acc: 60.900% (27405/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s73ms | Valid Loss: 1.165 | Valid Acc: 60.380% (3019/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 40ms | Tot: 33s745ms | Train Loss: 0.964 | Train Acc: 65.931% (29669/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s104ms | Valid Loss: 0.981 | Valid Acc: 65.740% (3287/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 41ms | Tot: 33s901ms | Train Loss: 0.872 | Train Acc: 69.371% (31217/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s108ms | Valid Loss: 0.950 | Valid Acc: 66.520% (3326/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 44ms | Tot: 34s207ms | Train Loss: 0.810 | Train Acc: 71.384% (32123/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s160ms | Valid Loss: 0.915 | Valid Acc: 68.280% (3414/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 40ms | Tot: 34s21ms | Train Loss: 0.759 | Train Acc: 73.411% (33035/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s144ms | Valid Loss: 0.890 | Valid Acc: 69.540% (3477/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 41ms | Tot: 34s382ms | Train Loss: 0.721 | Train Acc: 74.880% (33696/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s177ms | Valid Loss: 0.836 | Valid Acc: 71.600% (3580/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 43ms | Tot: 34s93ms | Train Loss: 0.684 | Train Acc: 76.180% (34281/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s118ms | Valid Loss: 0.714 | Valid Acc: 75.260% (3763/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 40ms | Tot: 34s217ms | Train Loss: 0.661 | Train Acc: 76.902% (34606/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s138ms | Valid Loss: 0.816 | Valid Acc: 70.980% (3549/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 43ms | Tot: 34s198ms | Train Loss: 0.632 | Train Acc: 77.991% (35096/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s202ms | Valid Loss: 0.706 | Valid Acc: 75.260% (3763/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 42ms | Tot: 34s403ms | Train Loss: 0.605 | Train Acc: 78.740% (35433/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s116ms | Valid Loss: 0.691 | Valid Acc: 76.740% (3837/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 45ms | Tot: 34s648ms | Train Loss: 0.589 | Train Acc: 79.580% (35811/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s134ms | Valid Loss: 0.756 | Valid Acc: 74.380% (3719/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 38ms | Tot: 33s938ms | Train Loss: 0.575 | Train Acc: 80.080% (36036/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s143ms | Valid Loss: 0.657 | Valid Acc: 76.540% (3827/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 44ms | Tot: 33s840ms | Train Loss: 0.559 | Train Acc: 80.640% (36288/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s66ms | Valid Loss: 0.681 | Valid Acc: 76.600% (3830/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 41ms | Tot: 34s134ms | Train Loss: 0.539 | Train Acc: 81.258% (36566/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s200ms | Valid Loss: 0.636 | Valid Acc: 77.700% (3885/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 43ms | Tot: 33s870ms | Train Loss: 0.521 | Train Acc: 81.627% (36732/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 15ms | Tot: 3s144ms | Valid Loss: 0.642 | Valid Acc: 78.040% (3902/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 42ms | Tot: 33s530ms | Train Loss: 0.519 | Train Acc: 81.918% (36863/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s89ms | Valid Loss: 0.617 | Valid Acc: 78.680% (3934/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 42ms | Tot: 33s776ms | Train Loss: 0.497 | Train Acc: 82.593% (37167/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s93ms | Valid Loss: 0.565 | Valid Acc: 80.360% (4018/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 40ms | Tot: 33s870ms | Train Loss: 0.482 | Train Acc: 83.162% (37423/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s129ms | Valid Loss: 0.613 | Valid Acc: 79.140% (3957/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 20\n",
            " [======>]  Step: 41ms | Tot: 34s54ms | Train Loss: 0.477 | Train Acc: 83.464% (37559/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s96ms | Valid Loss: 0.557 | Valid Acc: 80.040% (4002/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 21\n",
            " [======>]  Step: 44ms | Tot: 34s86ms | Train Loss: 0.462 | Train Acc: 83.927% (37767/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s181ms | Valid Loss: 0.520 | Valid Acc: 81.500% (4075/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 22\n",
            " [======>]  Step: 41ms | Tot: 34s215ms | Train Loss: 0.455 | Train Acc: 84.124% (37856/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s163ms | Valid Loss: 0.550 | Valid Acc: 80.280% (4014/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 23\n",
            " [======>]  Step: 40ms | Tot: 35s136ms | Train Loss: 0.442 | Train Acc: 84.633% (38085/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s184ms | Valid Loss: 0.554 | Valid Acc: 80.840% (4042/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 24\n",
            " [======>]  Step: 45ms | Tot: 35s227ms | Train Loss: 0.429 | Train Acc: 85.042% (38269/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s309ms | Valid Loss: 0.551 | Valid Acc: 80.400% (4020/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 25\n",
            " [======>]  Step: 42ms | Tot: 34s861ms | Train Loss: 0.428 | Train Acc: 85.011% (38255/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s264ms | Valid Loss: 0.553 | Valid Acc: 80.600% (4030/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 26\n",
            " [======>]  Step: 46ms | Tot: 34s949ms | Train Loss: 0.420 | Train Acc: 85.284% (38378/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s231ms | Valid Loss: 0.533 | Valid Acc: 81.760% (4088/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [======>]  Step: 43ms | Tot: 35s70ms | Train Loss: 0.412 | Train Acc: 85.589% (38515/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s208ms | Valid Loss: 0.577 | Valid Acc: 80.460% (4023/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 28\n",
            " [======>]  Step: 41ms | Tot: 35s55ms | Train Loss: 0.406 | Train Acc: 85.769% (38596/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s165ms | Valid Loss: 0.500 | Valid Acc: 82.260% (4113/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 29\n",
            " [======>]  Step: 40ms | Tot: 34s541ms | Train Loss: 0.393 | Train Acc: 86.171% (38777/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s114ms | Valid Loss: 0.527 | Valid Acc: 82.100% (4105/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 30\n",
            " [======>]  Step: 43ms | Tot: 34s692ms | Train Loss: 0.389 | Train Acc: 86.462% (38908/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 14ms | Tot: 3s68ms | Valid Loss: 0.518 | Valid Acc: 81.880% (4094/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 31\n",
            " [======>]  Step: 40ms | Tot: 34s401ms | Train Loss: 0.384 | Train Acc: 86.644% (38990/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s330ms | Valid Loss: 0.519 | Valid Acc: 83.400% (4170/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 32\n",
            " [======>]  Step: 41ms | Tot: 34s319ms | Train Loss: 0.376 | Train Acc: 86.929% (39118/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s183ms | Valid Loss: 0.516 | Valid Acc: 82.780% (4139/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 33\n",
            " [======>]  Step: 43ms | Tot: 34s328ms | Train Loss: 0.372 | Train Acc: 87.140% (39213/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 3s137ms | Valid Loss: 0.492 | Valid Acc: 83.200% (4160/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 34\n",
            " [======>]  Step: 43ms | Tot: 34s682ms | Train Loss: 0.369 | Train Acc: 87.120% (39204/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s236ms | Valid Loss: 0.510 | Valid Acc: 83.000% (4150/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 35\n",
            " [======>]  Step: 44ms | Tot: 34s708ms | Train Loss: 0.363 | Train Acc: 87.260% (39267/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s291ms | Valid Loss: 0.466 | Valid Acc: 83.860% (4193/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 36\n",
            " [======>]  Step: 41ms | Tot: 34s459ms | Train Loss: 0.357 | Train Acc: 87.513% (39381/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s216ms | Valid Loss: 0.550 | Valid Acc: 81.660% (4083/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 37\n",
            " [======>]  Step: 44ms | Tot: 34s899ms | Train Loss: 0.352 | Train Acc: 87.764% (39494/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s163ms | Valid Loss: 0.522 | Valid Acc: 82.020% (4101/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 38\n",
            " [======>]  Step: 42ms | Tot: 34s665ms | Train Loss: 0.347 | Train Acc: 87.822% (39520/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s213ms | Valid Loss: 0.476 | Valid Acc: 83.580% (4179/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 39\n",
            " [======>]  Step: 44ms | Tot: 35s132ms | Train Loss: 0.343 | Train Acc: 88.140% (39663/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s165ms | Valid Loss: 0.496 | Valid Acc: 83.300% (4165/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 40\n",
            " [======>]  Step: 44ms | Tot: 34s712ms | Train Loss: 0.338 | Train Acc: 88.287% (39729/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s217ms | Valid Loss: 0.533 | Valid Acc: 82.560% (4128/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 41\n",
            " [======>]  Step: 40ms | Tot: 34s321ms | Train Loss: 0.339 | Train Acc: 88.287% (39729/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s162ms | Valid Loss: 0.488 | Valid Acc: 84.200% (4210/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            " [======>]  Step: 43ms | Tot: 34s384ms | Train Loss: 0.332 | Train Acc: 88.407% (39783/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s186ms | Valid Loss: 0.481 | Valid Acc: 83.660% (4183/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 43\n",
            " [======>]  Step: 43ms | Tot: 34s116ms | Train Loss: 0.330 | Train Acc: 88.591% (39866/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s152ms | Valid Loss: 0.472 | Valid Acc: 84.200% (4210/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 44\n",
            " [======>]  Step: 45ms | Tot: 34s929ms | Train Loss: 0.323 | Train Acc: 88.836% (39976/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 3s101ms | Valid Loss: 0.523 | Valid Acc: 82.620% (4131/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 45\n",
            " [======>]  Step: 43ms | Tot: 37s611ms | Train Loss: 0.316 | Train Acc: 88.973% (40038/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 14ms | Tot: 5s314ms | Valid Loss: 0.454 | Valid Acc: 84.140% (4207/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 46\n",
            " [======>]  Step: 44ms | Tot: 35s23ms | Train Loss: 0.318 | Train Acc: 88.807% (39963/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 3s188ms | Valid Loss: 0.533 | Valid Acc: 81.920% (4096/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 47\n",
            " [======>]  Step: 42ms | Tot: 34s244ms | Train Loss: 0.314 | Train Acc: 89.022% (40060/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s169ms | Valid Loss: 0.425 | Valid Acc: 85.240% (4262/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 48\n",
            " [======>]  Step: 38ms | Tot: 34s318ms | Train Loss: 0.310 | Train Acc: 89.176% (40129/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s201ms | Valid Loss: 0.448 | Valid Acc: 84.540% (4227/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 49\n",
            " [======>]  Step: 43ms | Tot: 34s372ms | Train Loss: 0.309 | Train Acc: 89.249% (40162/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s184ms | Valid Loss: 0.466 | Valid Acc: 84.220% (4211/5000)\b\b\b\b 40/40 \n",
            "---------------------------------------- Testing Model... ----------------------------------------\n",
            "Best validation acc: 85.240% at Epoch 47\n",
            " [======>]  Step: 25ms | Tot: 3s310ms | Test Loss: 0.291 | Test Acc: 90.670% (9067/10000)\b\b\b\b 100/100 \n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 50\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "outputId": "3e735733-06c5-46af-bfc3-9d635dcd42d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SBpSbX6bWVRb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 50\n",
            " [======>]  Step: 41ms | Tot: 34s952ms | Train Loss: 0.308 | Train Acc: 89.311% (40190/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s65ms | Valid Loss: 0.470 | Valid Acc: 84.700% (4235/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 51\n",
            " [======>]  Step: 42ms | Tot: 34s886ms | Train Loss: 0.307 | Train Acc: 89.409% (40234/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s204ms | Valid Loss: 0.464 | Valid Acc: 84.900% (4245/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 52\n",
            " [======>]  Step: 46ms | Tot: 34s454ms | Train Loss: 0.306 | Train Acc: 89.244% (40160/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s191ms | Valid Loss: 0.472 | Valid Acc: 84.420% (4221/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 53\n",
            " [======>]  Step: 46ms | Tot: 34s470ms | Train Loss: 0.293 | Train Acc: 89.882% (40447/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 13ms | Tot: 3s191ms | Valid Loss: 0.422 | Valid Acc: 85.260% (4263/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            " [======>]  Step: 41ms | Tot: 34s497ms | Train Loss: 0.295 | Train Acc: 89.744% (40385/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s167ms | Valid Loss: 0.445 | Valid Acc: 84.820% (4241/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 55\n",
            " [======>]  Step: 44ms | Tot: 34s443ms | Train Loss: 0.290 | Train Acc: 89.984% (40493/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s196ms | Valid Loss: 0.457 | Valid Acc: 84.940% (4247/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 56\n",
            " [======>]  Step: 41ms | Tot: 34s524ms | Train Loss: 0.289 | Train Acc: 89.887% (40449/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s187ms | Valid Loss: 0.522 | Valid Acc: 83.100% (4155/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 57\n",
            " [======>]  Step: 46ms | Tot: 34s368ms | Train Loss: 0.285 | Train Acc: 90.022% (40510/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s177ms | Valid Loss: 0.432 | Valid Acc: 85.360% (4268/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 58\n",
            " [======>]  Step: 40ms | Tot: 34s248ms | Train Loss: 0.276 | Train Acc: 90.413% (40686/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 13ms | Tot: 3s169ms | Valid Loss: 0.435 | Valid Acc: 85.320% (4266/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 59\n",
            " [======>]  Step: 44ms | Tot: 34s431ms | Train Loss: 0.286 | Train Acc: 90.029% (40513/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 3s188ms | Valid Loss: 0.435 | Valid Acc: 84.680% (4234/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 60\n",
            " [======>]  Step: 43ms | Tot: 34s467ms | Train Loss: 0.275 | Train Acc: 90.338% (40652/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s181ms | Valid Loss: 0.432 | Valid Acc: 85.460% (4273/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 61\n",
            " [======>]  Step: 45ms | Tot: 34s311ms | Train Loss: 0.280 | Train Acc: 90.278% (40625/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 3s199ms | Valid Loss: 0.434 | Valid Acc: 85.180% (4259/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 62\n",
            " [======>]  Step: 43ms | Tot: 34s276ms | Train Loss: 0.274 | Train Acc: 90.696% (40813/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 3s195ms | Valid Loss: 0.421 | Valid Acc: 85.660% (4283/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 63\n",
            " [======>]  Step: 41ms | Tot: 33s942ms | Train Loss: 0.269 | Train Acc: 90.598% (40769/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 3s302ms | Valid Loss: 0.440 | Valid Acc: 84.980% (4249/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-171-7baf2f93ad5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-61fc0d5999fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 50\n",
        "\n",
        "for epoch in range(start_epoch + NUM_EPOCHS, start_epoch + NUM_EPOCHS +30):\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "8F9l3iSKXzUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a5f45a-04e2-4351-84b7-12f361ff7b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  2.8 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "DRtpQiLSWkIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ee3a68-cc8a-4aa2-ba86-2adacad907da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f1648a45550>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "net.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "6z_TwWP4Xkca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86fb033-87db-462d-ea38-5c7539d3ea1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[35.92666666666667,\n",
              " 53.044444444444444,\n",
              " 60.9,\n",
              " 65.93111111111111,\n",
              " 69.3711111111111,\n",
              " 71.38444444444444,\n",
              " 73.41111111111111,\n",
              " 74.88,\n",
              " 76.18,\n",
              " 76.90222222222222,\n",
              " 77.99111111111111,\n",
              " 78.74,\n",
              " 79.58,\n",
              " 80.08,\n",
              " 80.64,\n",
              " 81.25777777777778,\n",
              " 81.62666666666667,\n",
              " 81.91777777777777,\n",
              " 82.59333333333333,\n",
              " 83.16222222222223,\n",
              " 83.46444444444444,\n",
              " 83.92666666666666,\n",
              " 84.12444444444445,\n",
              " 84.63333333333334,\n",
              " 85.04222222222222,\n",
              " 85.0111111111111,\n",
              " 85.28444444444445,\n",
              " 85.58888888888889,\n",
              " 85.7688888888889,\n",
              " 86.17111111111112,\n",
              " 86.46222222222222,\n",
              " 86.64444444444445,\n",
              " 86.92888888888889,\n",
              " 87.14,\n",
              " 87.12,\n",
              " 87.26,\n",
              " 87.51333333333334,\n",
              " 87.76444444444445,\n",
              " 87.82222222222222,\n",
              " 88.14,\n",
              " 88.28666666666666,\n",
              " 88.28666666666666,\n",
              " 88.40666666666667,\n",
              " 88.5911111111111,\n",
              " 88.83555555555556,\n",
              " 88.97333333333333,\n",
              " 88.80666666666667,\n",
              " 89.02222222222223,\n",
              " 89.17555555555556,\n",
              " 89.24888888888889]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "train_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "JHKohhBDJRIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "6880a362-fe39-4acb-9bab-c4d1fb23c030"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAGDCAYAAAAvXp2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zV5fn/8dedvTcJkATZEFaYiuIAcSEg4AAV3Fq1VVpt+xX91aqts7V+rR0q/aq1KiDugROqgorKMAzZI0BYGWSSnXP//rhPGBogAZKTkPfz8TiPsz7jOsfxyXXu675uY61FREREREREpLnx83UAIiIiIiIiInVRwioiIiIiIiLNkhJWERERERERaZaUsIqIiIiIiEizpIRVREREREREmiUlrCIiIiIiItIsKWEVERERERGRZkkJq4iPGGM+N8bkG2OCfR2LiIiI1I8xJtMYc46v4xBpLZSwiviAMaYjcAZggYua8LwBTXUuEREREZFjpYRVxDeuBr4B/g1cU/uiMSbVGPOmMSbHGJNnjPn7Ae/dZIxZbYwpNsasMsYM9L5ujTFdD9ju38aYB72PhxtjsowxdxljdgEvGGNijTHve8+R732c4t3+MmPMkgMDNcbcaYx5pxG/CxERkRbNGBNsjHnSGLPDe3uytoLKGJPgvdYWGGP2GGMWGGP8vO/dZYzZ7r22rzXGjPTtJxFpfpSwivjG1cAr3tv5xpgkY4w/8D6wBegIJAOzwCWSwP3e/aJwo7J59TxXWyAOOAn4Ge6/+xe8zzsAZUBtYvwu0MkYk3bA/lcB/zmKzygiItJa/D9gKNAfSAdOBn7nfe/XQBbQBkgC7gGsMaYHcBswxFobCZwPZDZt2CLNnxJWkSZmjDkdlyzOttYuATYCV+Iubu2B31pr91pry621X3p3uxH4k7V2kXU2WGu31POUHuA+a22FtbbMWptnrX3DWltqrS0GHgLOArDWVgCvAlO8sfbGJc/vH4/PLiIicoKaDPzBWpttrc0BHsD94AtQBbQDTrLWVllrF1hrLVADBAO9jDGB1tpMa+1Gn0Qv0owpYRVpetcAn1hrc73PZ3hfSwW2WGur69gnFZfYHo0ca2157RNjTJgx5lljzBZjTBEwH4jxjvACvAhcaYwxuIvtbG8iKyIiInVrj6uQqrXF+xrAn4ENwCfGmE3GmGkA1toNwK9wFVTZxphZxpj2iMhBlLCKNCFjTCgwETjLGLPLO6/0Dlz50G6gwyEaI20DuhzisKVA2AHP2/7offuj578GegCnWGujgDNrwwOw1n4DVOKaQl0JvFSPjyYiItKa7cBVT9Xq4H0Na22xtfbX1trOuCk9d9bOVbXWzrDW1lZeWeCxpg1bpPlTwirStMbjSoB64ea59AfSgAXe93YCjxpjwo0xIcaYYd79/g/4jTFmkHG6GmNqL4wZuBFRf2PMBXjLew8jEjdvtcAYEwfcV8c2/8HNa606oCxZREREnEDvdTrEGBMCzAR+Z4xpY4xJAH4PvAxgjBnjvW4boBD3d4DHGNPDGHO2tzlTOe7a7PHNxxFpvpSwijSta4AXrLVbrbW7am+45PAKYCzQFdiKa9AwCcBa+xpurukMoBh4G9dICeCX3v0KcHNo3j5CDE8CoUAurlPxR3Vs8xLQB+/FVkRERA7yAS7BrL2FAIuB5cAKYCnwoHfbbsBcoARYCPzTWvsZbv7qo7jr8S4gEbi76T6CSMtg3JxvEZH9vKXL2cBAa+16X8cjIiIiIq2TRlhFpC63AouUrIqIiIiIL9XV3EVEWjFjTCauAdN4H4ciIiIiIq2cSoJFRERERESkWVJJsIiIiIiIiDRLSlhFRERERESkWWoRc1gTEhJsx44dfR2GiIicIJYsWZJrrW3j6zhaMl2bRUTkeDrUtblFJKwdO3Zk8eLFvg5DREROEMaYLb6OoaXTtVlERI6nQ12bVRIsIiIiIiIizZISVhEREREREWmWlLCKiIiIiIhIs9Qi5rCKiLRGVVVVZGVlUV5e7utQWqyQkBBSUlIIDAz0dSgiItLC6bp8fDT02qyEVUSkmcrKyiIyMpKOHTtijPF1OC2OtZa8vDyysrLo1KmTr8MREZEWTtflY3c01+ZGLQk2xvzSGLPSGPODMeZX3tfijDGfGmPWe+9jGzMGEZGWqry8nPj4eF0Uj5Ixhvj4eP0SLiIix4Wuy8fuaK7NjZawGmP6ADcBJwPpwBhjTFdgGjDPWtsNmOd9LiIiddBF8djo+xMRkeNJ15Vj19DvsDFHWNOAb621pdbaauAL4GJgHPCid5sXgfGNGIOIiBylvLw8+vfvT//+/Wnbti3Jycn7nldWVh5238WLFzN16tQGnzMjIwNjDB999NHRhi0iInJCKigo4J///OdR7XvhhRdSUFBQ7+3vv/9+Hn/88aM61/HWmAnrSuAMY0y8MSYMuBBIBZKstTu92+wCkura2RjzM2PMYmPM4pycnEYMU0RE6hIfH09GRgYZGRnccsst3HHHHfueBwUFUV1dfch9Bw8ezFNPPdXgc86cOZPTTz+dmTNnHkvoIiIiJ5zDJayHuyYDfPDBB8TExDRGWI2u0RJWa+1q4DHgE+AjIAOo+dE2FrCH2H+6tXawtXZwmzZtGitMERFpgGuvvZZbbrmFU045hf/5n//hu+++49RTT2XAgAGcdtpprF27FoDPP/+cMWPGAO5X2uuvv57hw4fTuXPnQyay1lpee+01/v3vf/Ppp58eNL/lscceo2/fvqSnpzNtmptJsmHDBs455xzS09MZOHAgGzdubORPLyIi4jvTpk1j48aN9O/fn9/+9rd8/vnnnHHGGVx00UX06tULgPHjxzNo0CB69+7N9OnT9+3bsWNHcnNzyczMJC0tjZtuuonevXtz3nnnUVZWdtjzZmRkMHToUPr168eECRPIz88H4KmnnqJXr17069ePyy+/HIAvvvhiXzXWgAEDKC4uPubP3ahdgq21zwHPARhjHgaygN3GmHbW2p3GmHZAdmPGICJyInjgvR9YtaPouB6zV/so7hvbu8H7ZWVl8fXXX+Pv709RURELFiwgICCAuXPncs899/DGG2/8ZJ81a9bw2WefUVxcTI8ePbj11lt/0s7+66+/plOnTnTp0oXhw4czZ84cLrnkEj788EPeeecdvv32W8LCwtizZw8AkydPZtq0aUyYMIHy8nI8Hs/RfREiIiIN5Ivr8qOPPsrKlSvJyMgA3I/DS5cuZeXKlfs67j7//PPExcVRVlbGkCFDuOSSS4iPjz/oOOvXr2fmzJn861//YuLEibzxxhtMmTLlkOe9+uqr+dvf/sZZZ53F73//ex544AGefPJJHn30UTZv3kxwcPC+cuPHH3+cf/zjHwwbNoySkhJCQkKO9Wtp9C7Bid77Drj5qzOAd4FrvJtcA7zTmDGIiMjxddlll+Hv7w9AYWEhl112GX369OGOO+7ghx9+qHOf0aNHExwcTEJCAomJiezevfsn28ycOZPLL78cay0TJ07ilRkzqKiq4aOPP+GKKVdT4+cS3Li4OIqLi9m+fTsTJkwA3JpuYWFhjfSJpbFszStl3uqf/rsgIiL1c/LJJx+0PMxTTz1Feno6Q4cOZdu2baxfv/4n+3Tq1In+/fsDMGjQIDIzMw95/MLCQgoKCjjrrLMAuOaaa5g/fz4A/fr1Y/Lkybz88ssEBLhx0GHDhnHnnXfy1FNPUVBQsO/1Y9HY67C+YYyJB6qAX1hrC4wxjwKzjTE3AFuAiY0cg4hIi3c0I6GNJTw8fN/je++9lxEjRvDWW2+RmZnJ8OHD69wnODgYay01Houfnz/5JWWEllRQWeOhqsZSXlnFq6+9zutvvs39f/gj1loK8vNZunEH+aVV5JZUsCWvlD7J0U30KaUpvLE0i6f+u551D44i0L9Rf0MXETmumst1+cBr8ueff87cuXNZuHAhYWFhDB8+vM7lY4KDg/c99vf3P2JJ8KHMmTOH+fPn89577/HQQw+xYsUKpk2bxujRo/nggw8YNmwYH3/8MT179jyq49dq1KuDtfYMa20va226tXae97U8a+1Ia203a+051to9jRmDiIg0jLWWqhoPZZXVFJVVkbe3gpKKagpKKykpr2Z3UTnb80vJLi4nd08+CYltqarx8MILL+zbv7KmhuoaS05xOYVlLuFctbOIVTuLqKiuISu/jO0FZeQWV1JaUc3X8z+nV+8+LFm1niUr15Kxej0XjRtPxoJPGT/6Aj56cxbtwl0b/D179hAZGUlKSgpvv/02ABUVFZSWlvrsO5OjkxgVjLWQW1Lh61BERJq9yMjIw84JLSwsJDY2lrCwMNasWcM333xzzOeMjo4mNjaWBQsWAPDSSy9x1lln4fF42LZtGyNGjOCxxx6jsLCQkpISNm7cSN++fbnrrrsYMmQIa9asOeYYGnuEVUREmrGqGg/lVTWUV7n7sqoaKqo9uJ54++2tqMYEevBYi8djKSirosZjmXTDL7j7jp/zhwcf5MyR51NVY1m5o4hte8oorapmZ2E5ldUeQoCY0ECCAvwJ8vejY3wYXdtFEeBnMMbw2Idvc8XES0mOCd13zisvn8jTTz/Nhx9+yLrVKznjtKEEBQVx4YUX8vDDD/PSSy9x88038/vf/57AwEBee+01Onfu3MTfoByLxEg3tym7qIJ20aFH2FpEpHWLj49n2LBh9OnTh1GjRjF69OiD3r/gggt45plnSEtLo0ePHgwdOvS4nPfFF1/klltuobS0lM6dO/PCCy9QU1PDlClTKCwsxFrL1KlTiYmJ4d577+Wzzz7Dz8+P3r17M2rUqGM+v/nxHyXN0eDBg+3ixYt9HYaISJNavXo1aWlpx3wcj8dSWeOhstqz7742Sa0+oFFRoL8fIYH+hAT6EejvR6C/IcDPPQ7wN/j9aKHvGo8bia09bpW3vDfQ3xAc4E9wgB/BAX4E+LjUs67v0RizxFo72EchnRCOx7V5eVYBF/39K/519WDO7VXnKnciIs3G8bouS8OuzRphFRFpoWrnhFZ7LNU1HnfvfVxVsz9Jrao5uHuunzEEB/gRGRJASKA/oYEuUW1oYunvZ/D38yck0P94fiw5TowxMcD/AX1wS8hdD6wFXgU6ApnARGttvjHGAH/FrZleClxrrV3a2DHuG2Et/ukcKxEREVDCKiLiM8XlVWzdU8quwnJ2Fpazq7CcXUXl3udl3HNaFJ4dhYfc3+MBW8dS1gZDgL8h0N+PiOAAggL83M3f3deW4coJ76/AR9baS40xQUAYcA8wz1r7qDFmGjANuAsYBXTz3k4BnvbeN6qEiCCMgd1FmsMqIiJ1U8IqItJEdhaWsTgzn8WZe/guM581u4o4cFaGv58hMTKYttEhdE+KJCzIn9iwoEMez89AgJ8r1w3wMwT4u2TUXwlpq2eMiQbOBK4FsNZWApXGmHHAcO9mLwKf4xLWccB/rJsn9I0xJqZ2zfTGjDPA34/48CByNMIqIiKHoIRVROQY1HgsJRXVlFXWUFpZTWmla1xUWllDWWU1OSWVLN2Sz6LMPWTlu7bxYUH+DOwQy69GdqdH2wjaRofSLjqEhIhg/P32J5qrV6+mfYwa0chR6QTkAC8YY9KBJcAvgaQDktBdQO3E0WRg2wH7Z3lfa9SEFVxZcLZGWEVE5BCUsIqI1FNReRVrdhazakchq3cWs3pXEWt3FVNR7TnsfgkRwZzcKZbrh3ViSMc40tpF+rwRkZzwAoCBwO3W2m+NMX/Flf/uY621xpgGdV40xvwM+BlAhw4djkugiVHBZBcrYRURkbopYRUR+RFrLdsLyli1w60bumpHEat3uaVaasWFB5HWLpKrhp5E2+gQQoP8CQvyJzQwgLDax0H+xIQF0T46RCW60tSygCxr7bfe56/jEtbdtaW+xph2QLb3/e1A6gH7p3hfO4i1djowHVyX4OMRaGJkMKt2FB2PQ4mIyAlICauItFo1HkteSQU7C8tZt7uYVTuLWO1NUIvKqwEwBjrFh9MvJYbLh3SgV7so0tpFkRQVfMInoSNGjGDatGmcf/75+1578sknWbt2LU8//XSd+wwfPpzHH3+cwYMHc+GFFzJjxgxiYmIO2ub+++8nIiKC3/zmN3Ueo3///vTs2ZNZs2Ydvw/Tylhrdxljthljelhr1wIjgVXe2zXAo977d7y7vAvcZoyZhWu2VNjY81drJUaGkFtSQY3HHlQSLyIixy4iIoKSkhJ27NjB1KlTef3113+yzYHX7vq83tSUsIpIi1VYWsXG3BI2ZpewOXcvldUe/L0NiPz99jcgCvAzVNV42F1Uwe6icu+tghzvH8m1QgL96Nk2ijHp7enVLope7aPo2TaSsKDW+b/KK664glmzZh2UsM6aNYs//elP9dr/gw8+aPA5V69eTU1NDQsWLGDv3r2Eh4c3+Biyz+3AK94OwZuA6wA/YLYx5gZgCzDRu+0HuCVtNuCWtbmuqYJMigrGYyFvb8W+ZW5EROT4at++fZ3JakvQOv8KE5EWpbi8ihXbC1m1o4iNOXvZmFPCppwScksq920T6G8I8vej2rN/bdIfiw4NpG1UCIlRwXRLiqRtVAhJUcEkRoXQpU0EnRLCNcJzgEsvvZTf/e53VFZWEhQURGZmJjt27OCMM87g1ltvZdGiRZSVlXHppZfywAMP/GT/jh07snjxYhISEnjooYd48cUXSUxMJDU1lUGDBtV5zpkzZ3LVVVexevVq3nnnHa688koAFi1axC9/+Uv27t1LcHAw8+bNIywsjLvuuouPPvoIPz8/brrpJm6//fZG/U5aEmttBlDXz+Ij69jWAr9o9KDq0KZ2LdYiJawiIoczbdo0UlNT+cUv3P+uayuWbrnlFsaNG0d+fj5VVVU8+OCDjBs37qB9MzMzGTNmDCtXrqSsrIzrrruOZcuW0bNnT8rKyuo63UFmzpzJww8/jLWW0aNH89hjj1FTU8MNN9zA4sWLMcZw/fXXc8cdd/DUU0/xzDPPEBAQQK9evY65YkoJq4g0KxXVNazZWczyrAIythWyLKuAjTkl+5Z/iQkLpGubCEb2TKJLYjhd2kTQpU0EKbGhBzUystbisVDt8VDjsfgZQ0igv48+1XHw4TTYteL4HrNtXxj16CHfjouL4+STT+bDDz9k3LhxzJo1i4kTJ2KM4aGHHiIuLo6amhpGjhzJ8uXL6devX53HWbJkCbNmzSIjI4Pq6moGDhx4yIT11Vdf5dNPP2XNmjX87W9/48orr6SyspJJkybx6quvMmTIEIqKiggNDWX69OlkZmaSkZFBQEAAe/bsOS5fizStxKhgALKLy4Fo3wYjIlJfPrguT5o0iV/96lf7EtbZs2fz8ccfExISwltvvUVUVBS5ubkMHTqUiy666JBTl55++mnCwsJYvXo1y5cvZ+DAgYcNa8eOHdx1110sWbKE2NhYzjvvPN5++21SU1PZvn07K1euBKCgoACARx99lM2bNxMcHLzvtWOhhFVEmlyNx7KrqJyteaVs3bOXrXtK2ZLnbmt3FVNZ47ruJkQEkZ4Sw0Xp7emXEk2f5GgSIoLrdQ5jDP4G/P1acJLaDNSWBdcmrM899xzgLpLTp0+nurqanTt3smrVqkMmrAsWLGDChAmEhYUBcNFFF9W5Xe1obIcOHUhOTub6669nz549bN++nXbt2jFkyBAAoqKiAJg7dy633HILAQHuUhYXF3dcP7s0jcRIb8KqpW1ERA5rwIABZGdns2PHDnJycoiNjSU1NZWqqiruuece5s+fj5+fH9u3b2f37t20bdu2zuPMnz+fqVOnAtCvX79DXr9rLVq0iOHDh9OmTRsAJk+ezPz587n33nvZtGkTt99+O6NHj+a8887bd8zJkyczfvx4xo8ff8yfWwmriDSq0spqVmQVkrGtgIxtBazdVUxWftm+pBQgwM+QHBtKh7gwrhvWkfTUGNJTY9Rd90CH+cW1MY0bN4477riDpUuXUlpayqBBg9i8eTOPP/44ixYtIjY2lmuvvZby8vJjPtfMmTNZs2YNHTt2BKCoqIg33niDoUOHHvOxpflqU5uwamkbEWlJfHRdvuyyy3j99dfZtWsXkyZNAuCVV14hJyeHJUuWEBgYSMeOHY/LdflIYmNjWbZsGR9//DHPPPMMs2fP5vnnn2fOnDnMnz+f9957j4ceeogVK1bs+3H5aChhFZHjxlrLxpwSlm4p4Htvgrpud/G+xkapcaH0aR/Neb3b0iEujA5xYZwUH0a76BCtS9pMRUREMGLECK6//nquuOIKwCWS4eHhREdHs3v3bj788EOGDx9+yGOceeaZXHvttdx9991UV1fz3nvvcfPNNx+0jcfjYfbs2axYsYL27dsD8Nlnn/HHP/6Ra665hp07d7Jo0SKGDBlCcXExoaGhnHvuuTz77LOMGDFiX0mwRllbnuAAf2LDAr0lwSIicjiTJk3ipptuIjc3ly+++AKAwsJCEhMTCQwM5LPPPmPLli2HPcaZZ57JjBkzOPvss1m5ciXLly8/7PYnn3wyU6dOJTc3l9jYWGbOnMntt99Obm4uQUFBXHLJJfTo0YMpU6bg8XjYtm0bI0aM4PTTT2fWrFmUlJT8ZMWAhlDCKiLHpLyqhm825fHfNdnMW53N9gI3cT8yJID+qTGck9aF/qkx9E+NIb6e5bzSvFxxxRVMmDBhX9OE9PR0BgwYQM+ePUlNTWXYsGGH3X/gwIFMmjSJ9PR0EhMT95X2HmjBggUkJyfvS1bBXVBXrVpFXl4er776KrfffjtlZWWEhoYyd+5cbrzxRtatW0e/fv0IDAzkpptu4rbbbju+H16aRGJkiEqCRUTqoXfv3hQXF5OcnEy7du0AV6I7duxY+vbty+DBg+nZs+dhj3Hrrbdy3XXXkZaWRlpa2iH7StRq164djz76KCNGjNjXdGncuHEsW7aM6667Do/HVc098sgj1NTUMGXKFAoLC7HWMnXq1GNKVgGMtcdl3e9GNXjwYLt48WJfhyEiXtlF5Xy21iWoX27IpbSyhpBAP07v2oazeyZycqc4OieE46eOu8dk9erVpKWl+TqMFq+u79EYs8Ra69uF5Vq443ltvuq5bykqr+adXxz+xw8REV/Sdfn4aci1WSOsIlKnwtIqtu4pPei27YDHAO2jQ7hkYApnpyVyauf4lt2FV0R8pk1kMBuzS3wdhoiINENKWEWE4vIqlm0rZMmWfJZuzWdZVgEFpVUHbRMfHkRqXBj9U2OYNCSVkWmJ9EiKVFMkETlmSVEh5JRUYK3V/1NEROQgSlhFWhmPx7I5by8ZWwtYsjWfpVvyWbu7GGvBGOieGMkFvdvSpU0Eqd6mSKlxYUQE638XItI4EiODqaqx5JdWERce5OtwRESkGdFfoCInMGstW/JKWb69kBVZBazYXsjK7UWUVFQDEBkcQP8OMVzQpy0DO8TSv0MMUSGBPo5aDnRCjTgV74TSfIhIhLB49wtJI2sJfRrENV0C2F1UroRVRJq1E+q67CMNvTYrYRVpQay1rN5ZzLzVu5m3JpvsonICA/wI9K+9mX33NR7Lml3FFJe75DQowI9e7aKYMCCZvinRpKfE0C0xQo2RmrGQkBDy8vKIj49v+RdHTw2U5AAWCrdBSTZEtoXQ2EZLXK215OXlERIS0ijHl+MnMWr/Wqxp7XwcjIjIIZxQ12UfOZprsxJWkWauorqGbzbtcUmqd9kYYyA9JYbTuiZQXeOhqsZSWeOhqvZW7X65Gpvenn7J0fRNiaZ7UiSBWuu0RUlJSSErK4ucnBxfh3LsKkugdA9EJIG1UL4baraBfyCERENgWKOcNiQkhJSUlEY5thw/Sd4R1uwircUqIs3XCXVd9qGGXpuVsIo0Q5XVHv67Jpt3MrYzf10OeytrCA305/RuCUwd2ZURPRP3ldDJiSswMJBOnTr5OozjY/pwqCqHny90I6oeD6x6Cz57BPLWQ7v+cPbvoOs5TVIqLM3LgSOsIiLN1Ql1XW5BlLCKNBPWWn7YUcTrS7J4J2M7+aVVtIkMZtyAZM5JS+S0LglaNkZapu1LYcf3MOrP+5NRPz/ocwmkjYMVs+HzR+CVSyE0DjoMhQ6nulu7dAjQnMYTXUigP5EhARphFRGRn1DCKuJjuSUVvP39dl5fksWaXcUE+ftxbu8kLh2UwhldEwhQGa/UpXSPuw+LO7p9jXHzR5vC4uddyW/6pJ++5x8A/a+EPpfCD2/B5vmwdSGs/cC9HxAKKYO9CexQ6Dwc/PTDzYkoMTJYI6wiIvITSlhFmkhltYete0rJzN3L5ty9bM7by6acEhZn5lPtsaSnRPPHcb0Zm96emDCNKMlhFO+Gf41wjYvSxsKga6HjGW7U8lA8Htj8BSz5N6yZ4+aS3jTPNT6qL2th3h+gNBfGPlW/0t2yAlj5BvS91M1VPZSAIJfQ1ia1xbth2zewZaFLYBc8DkERcFdm/eOVFiUpKkQJq4iI/IQSVpFGsruonDnLdzJ/fQ6bcvaSlV+K54Au3jFhgXRKCOf60ztx6aAUuidF+i7Y1m7nMojtBCFRvo7kyKrK4dXJUJYPA6a4Uckf3oS4zjDwGug/GSLa7N++eDdkvAJLX4T8TDeqOvAqWDYLZl4O186BoPD6nXv+4/DlE+5x5+GupPdIls+GqlIYfH3DPmdkEvQa524AFcWQt0GjqyewxMhglmzN93UYIiLSzChhFTmOcksq+HDlLt5ftoPvMvdgLXRLjKBfSjTj+7enY0I4nbw3jaI2AyU58PHdsOI11+xn8uvNu+GPtfD+ryBrEUz8j0vmLngEVr3rRk7n3gf/fRB6jobuF7iy2rUfgKcaThoGI37nRmQDQ6DruTDrSnjzZ+5YR0oEv38ZPnsQ+k2CnLXw0T3uGIdL8q2Fxc9B+4HQfsCxffbgyGM/hjRriVEh7C6q0BqHIiJyECWsIscof28ln6zaxXvLdvL1xlw8FromRvCrkd0Zk96OLm0ifB2i/Ji1sGwmfHwPVJRAl7Nhw1xY9Q70Hn/8zpO1GL78X4jtCMkDXeIW2/Hok+Kv/+biHn7P/pHHwND9pbQ5a13imjEDVr3tGhidcosbeW3T/YW9UNQAACAASURBVOBj9bzQJbsfTYNPfw/nP3To867/FN6dCp1HwEV/h90r4F8jXaOkCx459H5bF0LOGrePyBEkRgZTWe2hqKya6LBAX4cjIiLNhBJWkQbweCzrs0tYujWfpVvyWbo1n405ewE4KT6Mnw/vypj0dvRIitQIQUOV5cOcX7uusIOuPfx8x2ORtxHev8PN50w9xc3FjO8K/xrukreuI91o3vE4zyuXga1xCV+Nd25eaJwbKUz2jjp2PKN+pcjrPnaJZa/xcNb/1L1Nmx4ugRx5H+xaDm37udHUQznlFhfnwr9DfJe6y3a3L4HZV0NSb5j0kptrmjzIbfvtM5B+BbTrV/fxFz0HwdHQ5+Ijfz5p9dpE1i5tU66EVURE9lHCKnIEG7KLeW/ZTpZuzSdjawHFFdUAxIYFMrBDLBcPTOGMbgn0TY5Wknq0qsph5pWuyc7KN+CLP8Pga+GUWyE6+Qj7lsHGz2DjPAgIccln7S2y7f7RzJoqN0L5xWPgHwSj/wKDrt/fqGjMk/B/58BnDx9+1LA+9ubCy975nTd9BtGpkL0Kdizdv8TLgidcMhsaC2f+FobcCAHBdR8vew28foNLDMc/feQR2sAQSD35yHEaAxc86ua2zvkNxHRwpdG19myCVyZCeIIrlz4wkR95rxuRnnMnXP/JTxs+leS494fcUP85stKqJUW5H1eyiyvopjn9IiLipYRVpA7VNR7mrs7mPwsz+XpjHn4GuidFMrZ/ewZ2iGVghxg6JYQrQT0ePDXw1s9g69dw6QuuedDXT8HCf8I3z0Dfy+C02yGp1/599ubBuo/c/MwN86C6zHWQranaP5IJEBgO8Z1d8pq7HnavhJ5j4MI/Q1T7g+NIGQyDr/OOGl7uRnqPRlUZzLwCinbANe+5kUuA9v3drXYUs7LUjV4u+IsrTf72GTcy2vvig5O/0j2uOVJgKFw+A4LCji6uQ/EPgMtegOcvgNnXwg0fu9HUkhx46WKXVE950zVBOlBoLJz3ILx9C3z/Egy65uD3M14GTxUMuu74xisnrMQDRlhFRERqKWEVOUBuSQWvLtrGK99sYUdhOckxofzPBT2YNDiV+IhDjH7J0bMWPrrbjcSd/8j+0tFLn3fJ2zf/hKX/gWUzXIOfk05zc023LgTrgahk1/G2x4WuqZBfABRtd91k8za4cte8DbAjw40mTnrZNR06lJG/h9Xvwft3wg2fHn6ZmLp4PPDWLZD1HVz2InQ45dDbBoVBpzPcbcM8+PQ+eOMGNwp83h+h05kuAZ99tUt+r50D0SkNi6e+giPhytnwr7NhxiS45l03olu80yXdCd3q3i/9cvfPZ+597oeA8Hj3uscDi1+Ak06HxJ6NE7OccBK9I6y7i7S0jYiI7KeEVQTI2FbAi19nMmf5TiprPJzeNYH7L+rNyLQk/P00itpovn4KvnsWTr0NTv35we/FngSjHoOz7nKdZr99FjZ8Ckl94IzfuE647dJ/Wh4bk+puXUY0PJ7QWDjvITfiu/TfDV+KZd79rtnRuX9sWPOmriPdMjHLZ7suvy+OhW7nQ2gMZC6ACc9C6pCGxdJQ0clw5Sx44UL4xymus/CkVw5fWmyMK61+9gyXtI7zNlfa9F8o2OJ+ABCpp4jgAMKC/MlWwioiIgdQwiqt2pIt+fx13nrmr8shIjiAK0/pwJShJ9E1UZ19G93y2a6JUJ9LXIJ3KGFxbo7nqbdDeYGbl9qY+k10Ja5z73ejhhGJ9dtv0XPw1V9h8A2uhLmh/Pyh/xUu0f32WTfHtaIQhv3SjWQ2hfYD4JLn4M2bYNSfXCfhI0nqBUN/7n58GHCVG1Ve9DyEJRx+NFukDklRISoJFhGRgyhhlVZpyZZ8npy7jgXrc4kLD+LuUT2ZPPQkIoL1n8QR5W+BzC/diFx0qivLPVwn2rps/Aze/rnrkDv+6fqV3gaGQGAjJ6vgHTV8Ap4+DT65Fy5+9sj7rPsEPvgNdDvPJXrHMrc5MBRO/xUMvNp9zz1HH/2xjkbPC+GuLW5ua32ddZdrljXnTjfPdt2HLtE+VBMpkUNoExlMdrFGWEVEZD/9dS6typIte3hy7vqDEtUpQ08iXIlq/ZRkw3PnQcmug18PT3TzK6NTXKfZ+K5uiZU2Pd0I6YF2LodXr4KE7nD5K80zqWnT3SWN8/8MAya7+aSHsnMZvHatK1W+9IWGJXqHExYHvS46PsdqqIZ+huAI12149lWuO7K1bmkikQZKjAxm5fZCX4chIiLNiP5KlxOax2PZlFvC91sLeHfZDhaszyU+PIh7LnSJaliQ/hOoN0+NKxUtL4Cr3nYNjgqzvLet7j5njVtztLps/37hbSChh0tg47vCV0+6NVanvN54a60eD2f8Gla85how3frV/sS6psotTbPpc3fL+g4i2rqmRcGtuJQ8baxrjLXhU3cf29HXEUkLlBgZQnZxtq/DEBGRZkR/rcsJJbekgoytBWRsc7dlWQUUl7t1UxMilKju8/0rUFPplnGprwV/cQna2KcO39DI44GiLMhZ672tcfcrXndzMkNi4Pp3f7qsTHMTGAoX/gVeuQTmPuBGjjd97sp0K4sB45apOe12N5oY1c7HAfuYMXDhn+ClCTBsqq+jkRYqKSqY0soaSiqqNUVDREQAJazSwhWWVbFwYy7z1+fy1YZctuSVAuDvZ+iRFMnY9Pb0T41hQGoMXdpE4NfUHX+thZLdjd8oqL5qquHju+G76e554TY4+94jz7ncPB8+fwT6TXJzKw/Hz88ldzEdoNu5+1+v/S4CwyAk6tg+R1Ppdg70Ggff/MM9j+0EfS91HX07nfnTcufWLq4z/HKZr6OQFiwxyrsWa1E5EW1accWCiIjso4RVWpTqGg8Z2wpYsD6XBetzyNhWgMe65RCGdo5n8ikd6J8aS9/kaEKD/H0brLXw/h2w5AU478Gj6xx7PFUUw+vXw/pP3DIyFcVu1LSqDM5/+NBJa/FutyZnfFfXjOhoGwoZ03wS94YY+1foOdYtK6MyV5FGlRi5fy3WzkpYRUQEJazSQmzILuG5Lzfx/rKdFFdU42egX0oMt43oyhnd29A/NYZA/3p0mm1K8/7gktX4bvDJ76B4l1u+pT4dcY+3wu0wYxJkr3JJ55AbXEIdGAbf/NMlraOf+Glsnhp480aX3F79TuucoxkaC/0u83UUIq1CYqR3hFVL24iIiJcSVmm2rLUsysxn+vyNzF2dTXCAH2PT2zOyZyKndUkgOizQ1yEe2td/gy+fcHMbRz8BH90NC//uuuyO+wcEBDVdLDsyYOblUFECk2dD13Pc68bABY+4uZpfPuGS1nH/OLhD7Bd/cuXAF/3drbcpItKIEqPcCGuOlrYREREvJazS7NR4LJ/8sItn528iY1sBsWGBTB3ZjatPPYmEiGa4BMqPLX3Jjaj2nuAdtfSHUY9BZJIbdS3NhYn/geDIwx9n+1KXLJ50GiQPPrqR2bUfujLg0Di44WNI6n3w+8bAOfdBUBj890GoLoeL/+US6k2fwxePQfoVMGBKw88tItJAUSEBBAf4aS1WERHZRwmrNBt7K6p5c2kWz325mcy8UjrEhfHHcb25dFCq7+ej1teqd+G9qdDlbJgw3SWr4BLDM37tlj9593b49xiY/DpEtDl4/6oyWPkmLPo/2LF0/+uR7SFtDKRd5BJYvyN8H+WF+xPn9v3hilmHnz965m8hIBQ++X9QXeES7DdudGuljv7L0c9bFRFpAGMMiVHB7C5SSbCIiDiNmrAaY+4AbgQssAK4DmgHzALigSXAVdbaysaMQ5q3dbuLefmbLby5dDslFdWkp8bwzwt6cn7vtvg3dVffY7Hpc3jjBjcaOunlust+B0yG8ASYfQ08dy5c9abrrJq3ERY/D9+/7NY5TegBo/4EPS6ErQth1Tuw9D+uu29Ywv7kNao95G044LbR3fZ61zHsOQYung5B4UeO/7TbIDAE5vzafRZj4Jr36reviMhxkhgZQnaRRlhFRMRptITVGJMMTAV6WWvLjDGzgcuBC4H/tdbOMsY8A9wAPN1YcUjzVFnt4ZNVu3hp4Ra+3byHIH8/xvRrx+ShJzGwQwymKUf0KvfCGzdBh1PgtKlHN5qYtQRmXuk66V756uGTvO7nu0RwxmXw3HnQti9s/C/4BbgEc8iN0PH0/XHEpEK/iW4O6oZPXfK6/DVY8u+Djxue6M7f/XyI7wJt0tyyMkcajT3QkBtdI6b374Qx/wuJaQ3+KkREjkVSVDBrdxX7OgwREWkmGrskOAAINcZUAWHATuBs4Erv+y8C96OEtdXYXlDGq99tZeaibeQUV5AaF8rdo3py2eBU4sKbsBFRLWvhnV/A2jnuVrDNlcM2JMnLXgOvXOLKe696q35rc6YOges/cftlr4bh97j1TaPaHXqf4Ag3L7b3BFc6vOlzl8TGd3G3kOj6x3w4/a+EvpeBfzNuaiUiJ6zEyBAWrM/1dRgiItJMNFrCaq3dbox5HNgKlAGf4EqAC6y11d7NsoDkxopBmoeSimo+XLGTN5duZ+GmPIyBs3skMuXUkzirWxv8fFn2+9WT8MNbMPI+KMuHr59y5bQTprvy2CP54S1XQusfBFe93bB1Rtt0h9uWuOS4IQkyuM6+PUY1bJ+GULIqIj7SJjKY4vJqyiprWk7/AhERaTSNWRIcC4wDOgEFwGvABQ3Y/2fAzwA6dOjQGCFKI6rxWBZuzOONpVl8tHIXZVU1dIwP485zuzNhQDKpcWG+DhHWfwpzH4DeF8Ppd7gS3Mi28PE9sDcPLn8FQmPq3rckBz74tSvPbT/AddaN69TwGJpyeRsRkRbgwLVYT4rXHHoRkdauMUuCzwE2W2tzAIwxbwLDgBhjTIB3lDUF2F7Xztba6cB0gMGDB9tGjFOOo6LyKqZ/sYk3lmaxs7CcyJAAxg9I5tJByQzsENu0c1MPJ28jvH4DJPWBcX/fP1/01F9ARBK8dQu8cCFMeePgMl1r3ajqB7+BimI3Mnva1IPXLhURkaNWuxZrdnGFElYREWnUhHUrMNQYE4YrCR4JLAY+Ay7FdQq+BninEWOQJmKt5f3lO/nD+6vILalgePc2/L/RaZyTlkRIYDMr6aoohplXuDLcy1/5aYOkvpe6eaivXuU6+U5505XvlmS78t/V70L7gTD+aUjs6ZvPICJyBMaYTKAYqAGqrbWDjTFxwKtARyATmGitzTfu18S/4hojlgLXWmuX1nXcxpYU5R1hVadgERGhceewfmuMeR1YClQD3+NGTOcAs4wxD3pfe66xYpCmsSVvL/e+8wPz1+XQJzmK564ZTL+UQ5TS+prH40ZP8za4BkmxJ9W9XZez4dr34ZXL4PnzYdhU+OopqCyBc+6HU2/XqKqItAQjrLUHdjCaBsyz1j5qjJnmfX4XMAro5r2dgmuGeEpTBwuu6RK4kmAREZFG/YvbWnsfcN+PXt4EnNyY55WmUVntYfr8jfztvxsI9PfjvrG9uPrUjs177dT5f4I178MFj0Lnsw6/bfsBcMMn8NLFMPd+t77quH9oVFVEWrJxwHDv4xeBz3EJ6zjgP9ZaC3xjjIkxxrSz1u5s6gBjwwIJ9Dfs1giriIjQ+MvayAnqm015/O7tlWzILmFUn7bcN7Y3baPr0VXXl9bMgc8fgfQr4JRb6rdPXGe4cS5kfglpYxvezVdExHcs8IkxxgLPentDJB2QhO4CkryPk4FtB+xb28X/oIS1KRoiGmNoExGsEVYREQGUsEoDbS8o4/GP1/LW99tJjgnl+WsHc3bPpCPv6GubF8CbP3OjpmP+d3+TpfoIT4De4xsvNhGRxnG6d4m5ROBTY8yaA9+01lpvMltvTdUQMTEqhJxijbCKiIgSVqmnovIqnv58I899uRmAW4d34fazuxIW1Iz/FbLWLV3z5ROwdSFEJcOkV9wapiIiJzhr7XbvfbYx5i3cdJzdtaW+xph2QLZ38+1A6gG7H7KLf1NIjAxmS16pr04vIiLNSDPONqQ5qKrxMPO7rTw5dz179lYyYUAyvz6vOymxzWAd1UPx1LilZ758EnavgOhUGPUnGHAVBDXjuEVEjhNjTDjgZ60t9j4+D/gD8C6uQ/+jHNyp/13gNmPMLFyzpUJfzF+tlRgVzHeZe3x1ehERaUaUsEqdrLV8smo3j324hk25exnaOY7/d2Ev+qZE+zq0Q6uugIwZ8NVfIX8zJHR3S8/0vQz8A30dnYhIU0oC3vKufR0AzLDWfmSMWQTMNsbcAGwBJnq3/wC3pM0G3LI21zV9yPslRoZQUFpFRXUNwQHqHSAi0popYZWf2LanlF+/tozvNu+hS5twnrtmMGf3TMQ0ZN5nU7AWcta4hkiZC9w81bI9bo3U8/4IPUaDn5+voxQRaXLW2k1Aeh2v5+HWRf/x6xb4RROEVi+1a7HmFFc074oeERFpdEpY5SBfb8jlFzOWUu2xPDShD5MGpxLg30ySPmshZ61LTjMXQOZXUOpdXjA6FbqfD/0mQefhDWuqJCIizcr+tViVsIqItHZKWAVwJcDPf5XJwx+spnNCONOvHkynhHBfh7VfeaHr8rvuI/c8KgW6nQsdT3e3mJOUpIqInCDaRLoR1uwiLW0jItLaKWEVyqtquOfNFbz5/XbO65XEE5P6ExHcjP7VyF0PM69w81JH3ge9J0BsRyWoIiInqERvSXC2lrYREWn1mlFWIr6wo6CMm19aworthdx5bnduG9EVP79mlAiu/xRevwH8A+Dqd6HjMF9HJCIijSw+PBh/P0N2kRJWEZHWTglrK/btpjx+/spSKqo9/OvqwZzbK8nXIe1nrev2O/d+aNsHLp8BMR18HZWIiDQBfz9DQkQQ2cUqCRYRae2UsLZC5VU1PP/VZp74ZB0d4sKYfvVguiZG+Dqs/SpL4d3bYeXrrvx33D8gqBnNpxURkUaXGBmikmAREVHC2ppU13h4c+l2/nfuOnYWlnNeryQen5hOVEgD1yj9/hXYmwOn/+r4B1mwDV6dDDuXw8jfw+l3aq6qiEgrlBgZzI5CjbCKiLR2SlhbAWstH/+wm8c/WcuG7BLSU2P4y2XpnNY1oeEHy5gB7/zcPe4w1N0aYtsiWPwcVBRDVakbTa3cC1V73X1ZPvgHwxWzoMcFDY9PREROCIlRwSzLKvB1GCIi4mNKWE9w32zK47GP1vD91gI6twnnmSkDOb93W8zRjFqu/QjeuQ06nQm5G+DDu+Cmz8Cvnuu0lhXArCuhpgKikiEwDILCICxu/+PgKBh0LSR0a3h8IiJywkiMDCFvbyXVNZ7msx64iIg0OSWsJ6js4nL+5/XlfL42h7ZRITx6cV8uHZRy9Bf9LQvhtWugbV/XAGnth/DmTbBsJgyYXL9jzL0fSnPhZ59Du/Sji0NERFqFxKhgrIXckkraRof4OhwREfERJawnoB0FZUz+v2/ZVVjO3aN6cs1pHQkJ9D/6A+5aCTMmQXQKTHkDgiOh72Xw3XSY9wD0usi9djhbv4UlL8CptylZFRGRI0qMdEnq7qJyJawiIq2YamxOMFvzSpn47EJyiyt4+caTufmsLseWrOZnwsuXuHLdq96CcO+8V2PggkehZDcseOLwx6iuhPd+CdGpMPzuo49FRERajcTIYAB1ChYRaeWUsJ5ANmSXMPHZhZRUVDPjpqEMOinu2A5YkgMvTYDqcpes/ngd1JTB0G8SLPyHS2wPZeHfIGc1XPg4BDej5XNERKTZSopyo6pai1VEpHVTwnqCWL2ziMunL6Ta42HWz4bSNyX62A5YXgQvXwxFO2Hya5CYVvd259wPfv7wyb11v79nE3zxJ0i7SF1/RUSk3hIigjAGdmtpGxGRVk0J6wlgeVYBl0//hgA/P169+VR6to1yZbhL/u3uG6qmynXzzV4Fk16C1JMPvW1Uezj9Dlj9LmR+efB71sL7d4JfIIz6U8PjEBGRVivA349O8eGs2VXs61BERMSHlLC2cIsz9zD5X98SGRLA7JtPpUsbb8ntsplu3ujKNxp+0PWfQuYCGP0EdDv3yNufdrubn/rhNPDU7H99xWuw6TM45z6IatfwOEREpFXrmxLNiu2Fvg5DRER8SAlrC/b1hlyueu472kQGM/vmU+kQH7b/zWUz3f2a9xt+4DXvQ0g09L+yftsHhsK5D8DuFfD9S+610j3w0d2QPBgGX9/wGEREpNXrmxzNzsJyzWMVEWnFlLC2UEu35nPDi4tJjQtl1s1DaR8Tuv/NPZtg60IIjoYN86CytP4Hrql2a6x2vwD8A+u/X++LocOpMO+PUF4In/4eyvJh7JNujquIiEgD9UuJAWBFlkZZRURaKyWsLdC63cVc98IiEqOCefnGU/atVbfPslcBA6Meg+oy2Div/gff+jWU7YGeYxoWlDFwwSNQmgevXetGWk/9BbTt27DjiIiIePVuH4WfgeVKWEVEWi0lrC3Mtj2lXPXctwQH+PHyDXUkqx6PKwfudCb0vQxCY2F1A8qCV78PASHQdWTDg2s/wJURb/wvRHeA4dMafgwRERGv8OAAuiZGaB6riEgrpoS1BckpruCq576lrLKG/9xwMqlxYT/daNs3ULDFJY7+AdB9FKz70HX+PRJrYc0c6DISgsKPLsiRv4eOZ8D4fxz9MURERLz6JsewPKsQa62vQxERER9QwtpCFJVXce0L37GrqJwXrhvilq6pS8YMCAyHtLHuec/Rbk7pj5ecqcuO76EoC9IaWA58oMi2cO37boRXRETkGKWnRpNbUsFOrccqItIqKWFtAcqrarjpxcWs3VXM01MGMeikuLo3rCyFH96GXuP2j252ORsCQuvXLXjN+2D8XcMlERGRZqBvcjSgeawiIq2VEtZmrrrGw+0zv+e7zD38ZWI6I3okHnrjNXOgshj6X7H/taAwNx91zRw3v/VwVr8PHYdB2CESYhERkSaW1i6KAD/Diu0Fvg5FRER8QAlrM2atZdqbK/h01W7uH9ubcf2TD7/DspkQnQonnX7w62ljoXgn7Fh66H1z10Pu2oZ3BxYREWlEIYH+9GgbqRFWEZFWSglrM/b8V5m8viSLX53TjWtO63j4jYt2wqbPoN8k8PvRP9bu54NfAKx+79D7177Xc/QxxSwiInK89UuJVuMlEZFWSglrM7U5dy9//ngNZ/dM5Jcjux15h+WvgvVA+hU/fS80Fjqe7uaoHupiv+Z9tyxNdMqxBS4iInKc9U2OobCsim17ynwdioiINDElrM1Qjcfy29eWEeTvxyMX98UYc/gdrHXlwCknQ0LXurfpOQbyNkDO2p++V7QDti9RObCIiDRL/VJc46VlWZrHKiLS2ihhbYZe+Gozi7fkc9/Y3iRFhRx5h50ZkLPm4GZLP1Zb6rumjrLgNXPcfe1SOCIiIs1I96RIggL8WLFd81hFRFobJazNzKacEv788VpG9kzk4oFHaLJUK2Mm+AdD7wmH3iaqPSQPdp2Af2z1uxDfDdr0OLqgRUREGlFQgB9p7aJYrhFWEZFWRwlrM1Ljsfz29eUEB/jxcH1KgQGqK2HFa9BjlJurejhpY9xobMG2/a+V7oHMr9x7IiIizVR6SjQrtxfh8ajxkohIa6KEtRl54avNLNmSz/0X1bMUGGDDp1C2B/pfeeRte3pLfmtLgAHWfQS2Zv97IiIizVDf5GhKKqrZlLvX16GIiEgTUsLaTGz0lgKfk5bIhAH1LAUGyJgB4W2gy9lH3jahK7Tp6ToC11r9PkS2dx2CRUREmql+KTEArNiusmARkdZECWszUNsVOCTQn4cn1LMUGFw577qPoe9E8A+s3z49x8CWr2BvHlTuhY3zXEOmH6/dKiIi0ox0TYwgNNCfZdvUeElEpDVRltIMPP/lZpZuLeD+i3qRWN9SYICVb4Cn6vDdgX8sbYxbr3Xdh7BhHlSXa/6qiIg0e/5+hj7JUeoULCLSyihh9bGNOSU8/slazklLYnz/BpQCV1fAd9MhqQ+07Vv//dr1h+hUVwq85n0IiYGThjU8cBERkSbWNzmGH3YUUl3j8XUoIiLSRJSw+tDBpcB96l8KDDD/z5C7Dkbe17CTGuNKgDf+F9Z+5LoL17ecWERExIfSU6Mpr/KwPrvE16GIiEgTUcLqQ/+3YBNLtxbwwEW9G1YKvHMZLHgC0q+A7uc1/MQ9x0BNBVQUusciIiItQN/kaABWZKksWESktVDC6iPrdxfzl0/XcX7vJMb1b1//HWuq4O1fQHgCnP/w0Z28w6kQGgcBofXrLiwiItIMdIwPJzI4gOXqFCwi0moE+DqA1qi6xsNvXltGeJA/D45vQFdggC+fhN0rYNIrEBZ3dAH4B8DwaVBZAkFhR3cMERGRJubnZ+ibEs1yjbCKiLQaSlh94Nn5m1iWVcg/rhxIm8jg+u+YvRq+eAx6X3zsnX1PufnY9hcREfGBvinRPP/lZiqqawgO8Pd1OCIi0sgarSTYGPP/2bvzODnqOv/jr0/33Pc9k0wmd0hIAgQIN3KFSxESL0QXQUVZ1HW9F/S367Xq4rorHuCBoIIXSFZEEEEI4ZCbBJKQi0xCrrkz93319/dH1SSTMEk6MD3VM/1+Ph716Krqqu5PF0mad3+/9f3ONbNXhi1tZvZZMysws0fMbIv/mB+rGuLRpto2fvDoa1xy7CQuOXZS9CcODsCfPwlpOfCO78WuQBERmRDMLGxmL5vZA/72DDN73swqzexuM0vx96f625X+89ODrPtwji3Po3/Q8VqtBl4SEUkEMQuszrnNzrlFzrlFwIlAF3AvcAOwwjk3B1jhbyeE/sEIX/jjGnLTk/nPpQuP7OTnboHq1V5YzSyKTYEiIjKRfAbYOGz7u8BNzrnZQDNwjb//GqDZ33+Tf1zcOnaKN/DSmt26j1VEJBGM1aBLS4CtzrkdwFLgDn//HcCyMaohcD9ZuZX11W18a9kxFGSm/tJwsQAAIABJREFURH/ini3w2Le9EX0XvDt2BYqIyIRgZlOAS4Db/G0DzgOW+4cM//4d/r28HFhiRzS4wtiakp9OfkayRgoWEUkQYxVYrwD+4K+XOudq/PVaoHSMagjU+upWfvzYFpYumszFC8uiPzEyCPf9CySnwSX/682jKiIicmg/AP4NiPjbhUCLc27A394NlPvr5cAuAP/5Vv/4NzCza83sJTN7qaGhIVa1H5KZccyUPNZWKbCKiCSCmAdW/x6Zy4B7DnzOOecAd5DzAv9SHC19A15X4PzMFL5x2YIjO/mFX8Cu5+DiGyH7CIKuiIgkJDN7J1DvnFs12q/tnLvVObfYObe4uLh4tF8+asdNyeW1una6+wYDq0FERMbGWLSwvh1Y7Zyr87frzGwSgP9YP9JJ8fKlOBpufmwLm2rb+a93HUNexhF0Ba7bACu+AbMvgOM+ELsCRURkIjkDuMzMtgN34XUF/iGQZ2ZDswNMAar89SqgAsB/PhdoHMuCj9Qx5bkMRhwbatqCLkVERGJsLALrB9jXHRjgL8DV/vrVwH1jUENgNlS3ccvjW3nPCVM4f/4R9H7evQp+/Q5IzYZLf6CuwCIiEhXn3Jedc1Occ9Pxbsl5zDn3T8BK4L3+YcO/f4d/L7/XP37E3k/x4tgpeQCs08BLIiITXkwDq5llAhcAfxq2+0bgAjPbApzvb09Yv3r6ddKSQnz1nfOjP2nbE3DnZZCaAx99GHKnxK5AERFJFNcDnzezSrx7VG/3998OFPr7P884GL2/LDeNkuxU1mrgJRGRCS/p8Ie8ec65Tg4YuME514g3avCE197TzwNra1h2/GRyM5KjO2njA7D8I1A4G678E+QcwVytIiIiwzjnHgce99e3ASePcEwP8L4xLWwUHDslVwMviYgkgLEaJTgh/WVNNd39g1xx0tToTnjl9/DHD0HZsfDhvyqsioiIHMQx5Xlsbeigtas/6FJERCSGFFhj6K4XdjGvLHvvJOeH9NxP4c+fgBlnwVX3QUZB7AsUEREZp846qgjnYMWmusMfLCIi45YCa4y8WtXKuqpWPnDyVA45/7pzsPI78NANcPSl8ME/QmrW2BUqIiIyDh03JY+ynDQeerU26FJERCSGFFhj5K4Xd5KaFGLZovJDH/j3f4cnvgvHXwnv/TUkpY5JfSIiIuNZKGRctKCUJ15roKtvIOhyREQkRhRYY6Crb4D7Xq7mkmMmHXqwpVf+AM/eDCd9HC67GcIxHQNLRERkQrloYRm9AxGe2NwQdCkiIhIjCqwx8OC6Wtp7B7ji5EMMtlS3Hh74HEx/G1x8o+ZZFREROUInTy+gIDOFh9arW7CIyESlwBoDd72wk5nFmZw0PX/kA3pa4e4PQVouvOd2tayKiIi8CUnhEBccXcpjG+vpHRgMuhwREYkBBdZRtqWunZd2NHPFSRUjD7bkHNz3KWjeDu/7FWSXjnmNIiIiE8XFC8to7x3gma2NQZciIiIxoMA6yu56cRfJYeM9J0wZ+YBnb4GN98P5X4dpp49laSIiIhPO6bMLyUpN4mGNFiwiMiEpsI6i3oFB/rR6NxfOL6Mwa4TRfnc8C498Fea9E07/9NgXKCIiMsGkJoU5b14Jf99Qx2DEBV2OiIiMMgXWUfT39XU0d/Xz/pMq3vhkRz3c82HInwbLfqJBlkREREbJxQvLaOrs48XtTUGXIiIio0yBdRTd9eJOpuSnc+bsov2fGByA5R+Fnha4/E5vsCUREREZFWcfVUxqUoiH1C1YRGTCUWAdJTsaO3m6spH3L64gFDqg9XTlt2H7U3DJ96HsmGAKFBERmaAyU5M466hiHl5fS0TdgkVEJhQF1lFy94u7CBm8b/Gw7sB9nfDYt+Ef34cTroLj/ym4AkVERCawixeUUdPaw9qq1qBLERGRUaQJQEfBwGCEe1bt5rx5JZTlpnlT16xb7g2w1F4NC98Lb/9e0GWKiIhMWEuOLiEpZDz0ai2LKvKCLkdEREbJYVtYzexSM1NL7CE8tqmehvZe3n/SVKhaBb+8CP70Mcgqho88BO+9HZLTgi5TRERkwsrLSOG0WYU89GoNzqlbsIjIRBFNEH0/sMXM/tvM5sW6oPHorhd3MT+7iyWbvw6/OA+aXofLboaPPw7TTgu6PBERkYRw0YIytjd28VpdR9CliIjIKDlsYHXOXQkcD2wFfm1mz5rZtWaWHfPqxoHO3gEmVd7FvYP/SujV5XDGZ+DTq+CED0FIDdMiIiJj5cIFpZih0YJFRCaQqBKVc64NWA7cBUwC3gWsNrNPx7C2ceHFymr+I3wHPYXz4ZPPwQXfhLScoMsSERFJOCXZaSyels9D6xVYRUQmimjuYb3MzO4FHgeSgZOdc28HjgO+ENvy4t/2NU+SZv2kn/N5KJwVdDkiIiIJ7aIFZWysaWNHY2fQpYiIyCiIpoX1PcBNzrljnHPfc87VAzjnuoBrYlrdOBDa/hQRQqTMPCPoUkRERBLeRQvKAHhYrawiIhNCNIH168ALQxtmlm5m0wGccytiUtU4UdfWw9yeV2jMngvpGkJfREQkaBUFGSwsz9F9rCIiE0Q0gfUeIDJse9Dfl/Ce2bSbRVaJzTgr6FJERETEd/GCMlbvbKGurSfoUkRE5C2KJrAmOef6hjb89ZTYlTR+VL/6JKk2QMGCJUGXIiIiIr6LF6pbsIjIRBFNYG0ws8uGNsxsKbAndiWND8450nY/zSAhQpprVUREJG7MLslmXlk2v31uB5GIC7ocERF5C6IJrNcBXzGznWa2C7ge+OfYlhX/Nte1c8zAOlryFmgaGxERkTjzz2fP5LW6DlZurg+6FBEReQsOG1idc1udc6cC84GjnXOnO+cqY19afHt20y4WWSUps88OuhQRERE5wDuPnUx5Xjo/fXxr0KWIiMhbkBTNQWZ2CbAASDMzAJxz34xhXXGvYf2TpNggKXPPDboUERGZwMwsE+h2zkXM7ChgHvA351x/wKXFteRwiGvPmsnX/rKeF7c3cdL0gqBLEhGRN+GwLaxm9jPg/cCnAQPeB0yLcV1xrXdgkNy6ZxkkDFNPDbocERGZ2J7E+8G4HPg78CHg14FWNE5cvriCgswUtbKKiIxj0dzDerpz7iqg2Tn3DeA04KjYlhXfVu1oZjEbaC88BlKzgi5HREQmNnPOdQHvBn7inHsfXq8nOYz0lDAfOX06j22qZ2NNW9DliIjImxBNYB2axKzLzCYD/cCk2JUU/17YvJNjbRvpR50TdCkiIjLxmZmdBvwT8Fd/XzjAesaVq06bTmZKmJ8/oVZWEZHxKJrAer+Z5QHfA1YD24Hfx7KoeNey6UmSbZBUDbgkIiKx91ngy8C9zrn1ZjYTWBlwTeNGbkYyHzxlKvevrWFXU1fQ5YiIyBE6ZGA1sxCwwjnX4pz7P7x7V+c55746JtXFoZauPkqbXmLQkqDilKDLERGRCc4594Rz7jLn3Hf97+U9zrl/Dbqu8eSaM2cSMrjtqW1BlyIiIkfokIHVORcBbhm23euca415VXHsma2NnBbaQHfxIkjJDLocERGZ4Mzs92aW448W/Cqwwcy+FHRd40lZbhrvPn4Kd724iz0dvUGXIyIiRyCaLsErzOw9NjSfTYJ7YdMOFtrrun9VRETGynznXBuwDPgbMANvpGA5AteePZO+wQh3PLM96FJEROQIRBNY/xm4B+g1szYzazezhB1qr7PyKZIsQnjm24IuRUREEkOymSXjBda/+POvuoBrGndmFWdx0fwy7nhmOx29A0GXIyIiUTpsYHXOZTvnQs65FOdcjr+dMxbFxZsdjZ3M7nyZQUvW/asiIjJWfo434GEm8KSZTQMS9ofjt+K6c2bR1jPAH57fGXQpIiISpaTDHWBmZ4203zn35OiXE9+e2rKH00Ib6Jt0IunJ6UGXIyIiCcA59yPgR8N27TCzc4OqZzxbVJHH6bMKue0f27jq9GmkJml2IBGReBdNl+AvDVv+A7gf+HoMa4pbqzdvZ0FoB2mzR8zwIiIio87Mcs3s+2b2kr/8L15rq7wJnzhnFnVtvfz55aqgSxERkShE0yX40mHLBcBCoDn2pcWXwYhj4PWnCRPBZiiwiojImPkl0A5c7i9twK8CrWgcO3N2EQvLc/j5E9sYjOhWYBGReBdNC+uBdgNHj3Yh8W5dVSvHDqxlMJQCU04KuhwREUkcs5xzX3PObfOXbwAzD3WCmaWZ2QtmtsbM1pvZN/z9M8zseTOrNLO7zSzF35/qb1f6z0+P+acKiJnxL+fOYdueTn72xNagyxERkcM4bGA1sx+b2Y/85WbgKWB17EuLL//Y0sCpoY1Eyk+C5LSgyxERkcTRbWZnDm2Y2RlA92HO6QXOc84dBywCLjazU4HvAjc552bj9Za6xj/+GqDZ33+Tf9yEddGCUt557CRueuQ11u5uCbocERE5hGhaWF8CVvnLs8D1zrkrY1pVHFq9+XXmh3aQPOvsoEsREZHEch1wi5ltN7PtwM14U84dlPN0+JvJ/uKA84Dl/v478KbKAVjqb+M/v2Qiz79uZnx72TEUZ6fy2btfobtvMOiSRETkIKIJrMuB3zrn7nDO/Q54zswyYlxXXOnsHSC16llCOJih+VdFRGTsOOfW+C2lxwLHOueOxwueh2RmYTN7BagHHgG2Ai3OuaFJSHcD5f56ObDLf78BoBUoHNUPEmdyM5L5n/cdx7aGTr7z4MagyxERkYOIJrCuAIbP4ZIOPBqbcuLTC683cTLrGQynQvmJQZcjIiIJyDnX5pwbmn/181EcP+icWwRMAU4G5r3VGszs2qHRihsaGt7qywXujNlFfOzMGfzmuR2s3FQfdDkiIjKCaAJr2rBuRfjrCdXC+vKuFk4NbYSKUyEpNehyREREou6u65xrAVYCpwF5ZjY0B/sUYGhulyqgAsB/PhdoHOG1bnXOLXbOLS4uLn4L5cePL140l3ll2Xxp+VoaO3qDLkdERA4QTWDtNLMThjbM7EQOP9jDhFJVtZujQzsJz1R3YBERiQuHnI/FzIrNLM9fTwcuADbiBdf3+oddDdznr//F38Z//jHnXELM+ZKWHOYHVyyirbufG/60jgT52CIi40bS4Q/hs8A9ZlaN94tuGfD+aF7c/7K8DW/uVgd8FNgM3A1MB7YDlzvn4npe16za572V6QqsIiIyNsysnZGDqbH/rTojmQTcYWZhvB+n/+ice8DMNgB3mdm3gJeB2/3jbwd+Y2aVQBNwxWh8hvFiXlkO/3bxXL71143c/eIurjh5atAliYiI77CB1Tn3opnNA+b6uzY75/qjfP0fAg85597rz/WWAXwFWOGcu9HMbgBuAK5/E7WPiZ7+Qco71jGQnEzS5BMOf4KIiMgocM5lv4Vz1wLHj7B/G979rAfu7wHe92bfbyL46BkzeGxTPd98YAOnzixkelFm0CWJiAjRzcP6KSDTOfeqc+5VIMvMPhnFebnAWfi/3jrn+vz7aIYPnT98SP24VFnfwTH2Oh158yApJehyREREJAZCIeN/Lz+OpJDx2btfYWAwEnRJIiJCdPewftwPmgD43Xc/HsV5M4AG4Fdm9rKZ3WZmmUCpc67GP6YWKB3p5HgZifC12lYWhl6HcrWuioiITGSTctP59ruO4ZVdLfzg0S1BlyMiIkQXWMPDJw/374eJpqkxCTgB+Kk/Z1wnXvffvfwBHUYc3SBeRiJs2LGebOsma8ZJgdUgIiIiY+PS4yZz+eIp3LyykvvXVAddjohIwosmsD4E3G1mS8xsCfAH4G9RnLcb2O2c80csYjlegK0zs0kA/mNcT3xmVS8DkDRFLawiIiKJ4D+XLWTxtHy+eM8a1uxqOfwJIiISM9EE1uuBx4Dr/GUdhx+dEOdcLbDLzIYGa1oCbGD/ofOHD6kfl/JaXqXX0qBo7uEPFhERkXEvNSnMzz90IsXZqXz8zpeoaU2o2fxEROLKYQOrcy4CPI83Bc3JwHl4c7lF49PA78xsLbAI+A5wI3CBmW0Bzve341JbTz8z+7fQlD0XwtHMACQiIiITQWFWKrdffRKdvQN8/M6X6OobCLokEZGEdNDAamZHmdnXzGwT8GNgJ4Bz7lzn3M3RvLhz7hX/PtRjnXPLnHPNzrlG59wS59wc59z5zrmm0fkoo29LTTMLbDv9pYuCLkVERETG2NyybH78weNZX93GF/64hkhkxGE3REQkhg7VwroJrzX1nc65M51zPwYGx6as+FBXuYZ06yNTAy6JiIgkpPPmlfL/3nE0f3u1lpsefS3ockREEs6hAuu7gRpgpZn9wh9wyQ5x/ITTv2s1APmzTwm4EhEREQnKNWfO4IqTKvjxY5Xc90pV0OWIiCSUgwZW59yfnXNXAPOAlcBngRIz+6mZXThWBQYpY89aOi2DUNHsoEsRERGRgJgZ31y6kFNmFPCl5WtZvbM56JJERBJGNIMudTrnfu+cuxSYAryMN3LwhDe5ayM1GfMgFM1gyiIiIjJRpSSF+NmVJzIpN41r71zFlrr2oEsSEUkIR5TE/EGTbnXOLYlVQfFiT0sbc9x2uoqOCboUERERiQP5mSncfvVJmMF7fvoMz21rDLokEZEJT02HB1G1eRUpNkjK1MVBlyIiIiJxYnZJFvd+8nRKctK46vYX+Mua6qBLEhGZ0BRYD6Lj9RcBKJ57asCViIiISDyZkp/B/113Ooum5vGvf3iZnz2xFec05Y2ISCwosB5ESt0rNJNNwWQNuCQiIiL7y81I5jfXnMw7j53EjX/bxFfvW8+g5mkVERl1SUEXEK+K2jeyI/Uo8jXgkoiIiIwgNSnMj644nvK8dH7+5DZqWnv48QeOJz0lHHRpIiIThtLYCFxfJxX922nNWxh0KSIiIhLHQiHjy+84mm8uXcCKTXVc8Yvn2NPRG3RZIiIThgLrCBoqV5FkESg/IehSREREZBy46rTp/OzKE9lU08a7fvI0lfWa9kZEZDQosI6gpfJ5APJmnRxwJSIiIjJeXLSgjLuuPZXuvkHe9ZNneLpyT9AliYiMewqsI3BVL1Pv8pg+QwMuiYiISPSOn5rPvZ88g0m5aVz9yxe4+8WdQZckIjKuKbCOILf5VTaHZ5ObkRJ0KSIiIjLOVBRksPwTp3ParEKu/7913Pi3TUQ0grCIyJuiwHqg3nZK+nbSkD0/6EpERERknMpJS+ZXHz6JfzplKj97Yiuf+v1quvsGgy5LRGTcUWA9wEDVK4RwDJQuCroUERERGceSwiG+tWwh/37J0Ty0vpYrbn2W+vaeoMsSERlXFFgPMDTgUsb0xQFXIiIiIuOdmfGxt83k51eeyGt1HSy7+WkeXl+Lc+oiLCISDQXWA/TtXMVuV8T0adODLkVEREQmiAsXlHHPdaeRlhzmn3+zinf95Bme0SjCIiKHpcB6gIw9a1kXmcnskqygSxEREZEJZGF5Ln//3Fl89z3HUNfWwwdve54rb3ueNbtagi5NRCRuKbAO191MXs9udqXPJS05HHQ1IiIiMsEkhUO8/6SprPziOfz7JUezoaaNpbc8zSd+u4rK+vagyxMRiTsKrMNVvwxAZ+ExARciIiIiE1lacpiPvW0mT3zpHD57/hye2rKHC296kv937zo6egeCLk9EJG4osA7Tv2s1ACkVJwRciYiIiCSC7LRkPnv+UTz5b+dy9enT+cMLO7n4B0/y7NbGoEsTEYkLCqzDdG9/idcjpUybUh50KSIiIpJACjJT+NqlC7jnutNIChkf+MVzfOP+9Zq7VUQSngLrMEl1L7POzWReWXbQpYiIiEgCOnFaAQ9+5m1cfdo0fvX0di750VOs3tkcdFkiIoFRYB3SUU9Gdy3rmc20wsygqxEREZEElZGSxDeWLuR3HzuFnv5B3vvTZ/jew5voHVBrq4gkHgXWIdWvANCYO5/ksC6LiIiIBOuM2UU89LmzeM8JU7hl5VaW3vw0a3drChwRSSxKZkOqVxPBCE06LuhKRERERADISUvme+87jtuvXkxTZx/Lbnmar/9lPe09/UGXJiIyJhRYfQO7VlEZmcy0yaVBlyIiIiKynyVHl/LoF87mylOnccez2zn/+0/wt3U1OOeCLk1EJKYUWH2R6ldY52Ywt1QDLomIiEj8yUlL5ptLF3LvJ8+gIDOVT/xuNdfc8RK7mrqCLk1EJGYUWAH6u0nprmdbZDJzNUKwiIiIxLFFFXnc/y9n8O+XHM2zWxu58KYn+fkTW+kfjARdmojIqFNgBWivAaA5XEh5XnrAxYiIiIgcWlI4xMfeNpNHv3A2Z8wu5L/+tonzv/8Et6yspK6tJ+jyRERGjQIrQJsXWJPyywmFLOBiRERERKJTnpfOL65azK0fOpHSnDS+9/BmTvuvFXz01y/y0Ks19A2o1VVExrekoAuIC34La25xRcCFiIiIiBwZM+PCBWVcuKCM1/d0snzVLpav2s11v62nMDOFdx1fzuUnVXCUxukQkXFIgRUYbK0iDGQUKbCKiIjI+DWjKJMvXTSPz51/FE9t2cMfX9rFHc9u57Z/vM5RpVlcvKCMixaWMX9SDmbqVSYi8U+BFeht2g0ulcycgqBLERERecvMrAK4EygFHHCrc+6HZlYA3A1MB7YDlzvnms1LLj8E3gF0AR92zq0OonYZHUnhEOfOK+HceSU0dvRy/5pqHlpfy80rK/nRY5VMyU/n4gVlXLywjBOm5uuWKBGJWwqswEBrDXtcPvmZqUGXIiIiMhoGgC8451abWTawysweAT4MrHDO3WhmNwA3ANcDbwfm+MspwE/9R5kACrNS+fAZM/jwGTNo7Ojl0Y11PLy+jjuf3cFt/3idoqxULl5YytJF5Zyo8CoicUaBFaCtmjpXQGFmStCViIiIvGXOuRqgxl9vN7ONQDmwFDjHP+wO4HG8wLoUuNM554DnzCzPzCb5ryMTSGFWKu8/aSrvP2kq7T39PL65gYdereX/VlXx2+d2Up6XzrLjJ7NsUTlzdM+riMQBBVYgqbOWWqYzT4FVREQmGDObDhwPPA+UDguhtXhdhsELs7uGnbbb37dfYDWza4FrAaZOnRqzmmVsZKclc+lxk7n0uMl09g7w9w21/Pnlan72xDZuWbmV+ZNyWHb8ZC47rpyy3LSgyxWRBKVpbZwjtbueOldAgQKriIhMIGaWBfwf8FnnXNvw5/zWVHckr+ecu9U5t9g5t7i4uHgUK5WgZaYm8a7jp3DHR0/muS8v4WuXzic5KcR3HtzEaTeu4LrfrGLNrpagyxSRBKQW1q5Gwq6fWpdPXkZy0NWIiIiMCjNLxgurv3PO/cnfXTfU1dfMJgH1/v4qYPhQ+VP8fZKAirNT+cgZM/jIGTP2TpPzm2d38ND6Wk6fVcgnz5nNGbMLNcqwiIwJtbC2VQPQmlREalI44GJERETeOn/U39uBjc657w976i/A1f761cB9w/ZfZZ5TgVbdvyqwb5qcZ768hK+8Yx6V9R1cefvzXHbz0zy4robByBE10ouIHDG1sLZ738fdaaWHOVBERGTcOAP4ELDOzF7x930FuBH4o5ldA+wALvefexBvSptKvGltPjK25Uq8y0pN4tqzZnH16dO5d3UVP3tiK5/83WpmFGXy8bfNZNnxk8lI0f9Wisjo078sfgtrf2ZZwIWIiIiMDufcP4CD9ddcMsLxDvhUTIuSCSE1KcwVJ0/lfYsreOjVWn76RCVfuXcd//W3jbz3xClceeo0ZhVnBV2miEwgCqztNUQwLKsk6EpERERExoVwyLjk2Em845gyXtzezG+f28Fvn9vBr57ezumzCvnQqdM4f34pyWHdfSYib40Ca1s1TeSSm5UZdCUiIiIi44qZcfKMAk6eUUBD+3z++NIufv/8Tj7xu9WU5qRyxUlTWVieS3ZakrekJu9dT1KYFZEoKLC211DrCijI1AjBIiIiIm9WcXYqnzp3NtedPYuVm+r5zXM7+OGKLQc9Pj05TEVBOh9/20zedXy5AqyIjCimgdXMtgPtwCAw4JxbbGYFwN3AdGA7cLlzrjmWdRxKpLWamkg++ZqDVUREROQtC4eM8+eXcv78Uurbeqht66G9Z8Bf+uno3bf+zNZGvrR8LTevrOTT581h2aLJCq4isp+xaGE91zm3Z9j2DcAK59yNZnaDv339GNQxItdeQ607kYIMBVYRERGR0VSSk0ZJTtpBn3fO8ejGen7w6Gt88Z41/PixLQquIrKfIP4lWArc4a/fASwLoAZPfzfhnma/S7ACq4iIiMhYMjMumF/KA58+k19ctZis1CS+eM8alnz/CZav2k3/YCToEkUkYLEOrA74u5mtMrNr/X2lwyYjrwWCmwDVn4O1jnwFVhEREZGAHCy4nvKdFXz1vldZvbMZb/YlEUk0se4SfKZzrsrMSoBHzGzT8Cedc87MRvzXxw+41wJMnTo1NtW1eYG11hXoHlYRERGRgA0F1/OPLuHxzQ0sX72bu1/cxZ3P7mBaYQZLF5WzbNFkZmquV5GEEdPA6pyr8h/rzexe4GSgzswmOedqzGwSUH+Qc28FbgVYvHhxbH5Sax8KrPm6h1VEREQkTpgZ584r4dx5JbT19PPQq7Xc90oVP35sCz9asYXjpuRy8cJJTCvMYFJuGpNy0ynOTiUcsqBLF5FRFrPAamaZQMg51+6vXwh8E/gLcDVwo/94X6xqOKy2agAaKCA3XdPaiIiIiMSbnLRkLl9cweWLK6ht7eH+NdXc+3IV331ov457hENGaXYqk/LSKctN46Rp+bzj2EmUZB980CcRiX+xbGEtBe41s6H3+b1z7iEzexH4o5ldA+wALo9hDYfWXkNvKJ2k9FxC+kVOREREJK6V5abx8bNm8vGzZtLU2UdNazc1LT3UtPVQ09JNbWsPNa09rNnVwl/X1vDNBzZwyoxCLj1uMm9fWKZbwETGoZgFVufcNuC4EfY3Akti9b5/WW4uAAAgAElEQVRHpK2alnAh+empQVciIiIiIkegIDOFgswUFkzOHfH5LXXt3L+2hgfWVPOVe9fx1fte5cw5RVx67GQuWFBKTpp614mMB2MxD2v8aq+hwQp1/6qIiIjIBDOnNJvPX5DN586fw/rqNh5YW8P9a6r5wj1rCC2H6YWZzCnN4qjSbOaUZnNUaRYzi7JISdL8ryLxJLEDa1sNtW6GprQRERERmaDMjIXluSwsz+X6i+fy8q4WHt9Uz2t1HbxW184jG+qI+MN7JoWM6UWZLJ6WzwXzSzljdhFpyeFgP4BIgkvcwBqJQHsNVe543c8gIiIikgDMjBOm5nPC1Py9+3r6B9nW0MmW+nZeq2tnc207D6yt4a4Xd5GREuasOcVcuKCU8+aVkKdeeSJjLnEDa1cjRPrZMZBHQabuYRARERFJRGnJYeZPzmH+5Jy9+3oHBnluWxN/X1/LoxvreGh9LeGQcfL0Ai6Y74XX6UWZAVYtkjgSN7D6c7BWR/JZrF/LRERERMSXmhTm7KOKOfuoYv5z6ULWVrXyyIZa/r6+jm8+sIFvPrCBGUWZnDO3mHPnlnDyjAJ1HRaJkYQPrHUun8IsBVYREREReaNQyFhUkceiijy+dNE8djR28vjmBlZuruf3z+/kV09vJz05zBmzCzlnbglHT8omNSlMWnKYtOSQ/xgmLSlEUlgDOokcqcQNrG3VANS6AvLVwioiIiIiUZhWmMnVp2dy9enT6e4b5LltjazcXM9jm+p5dGP9Ic9NSQoxozCT2aVZzCnJYk6JNzrxtMJMjU4schCJG1jba3AYDeRqlGAREREROWLpKWHOnVfCufNK+MZljm17Otnd3E1P/yA9/YP09kfoGRj0tyO09/SzraGTdbtbeXBdDe6A0YnnlmYzf3IOC/x7akuy04L9gCJxIHEDa1s1PamFDPQkqYVVRERERN4SM2NWcRazirOiOr67b5CtDR1U1nf4IxR3sLaqhb+uq9l7THF2KguGAuykXGYUZTK1MIOs1MT9X3hJPIn7p729hvbkYgDdwyoiIiIiYyo9Jbx3ftjhWrv72VDdxvrqVjZUt7Ghpo2ntuxhcGiyWKAwM4WKggymFWYwtSCDioIM5k/ygq2ZjfVHEYmpxA2sbTW0JBWRmhQiXaO6iYiIiEgcyE1P5rRZhZw2q3Dvvp7+QSrrO9jR2MXOpi52NnWys6mLVTuauX9NNUNZdlJuGucfXcr580s5dWYBqUn6f1wZ/xI3sLZXsydtDgWZKfolSkRERETiVlryyK2xAP2DEaqau3lxexOPbKhj+ard/Oa5HWSlJnH2UcWcP7+Ec+eWkKdb4GScSszA2t8N3c3Upubr/lURERERGbeSwyGmF2UyvSiT9y2uoKd/kGe27uGRDfU8urGOv66rwQwKM1MpyU6lJMd/zE7bt56TRllOGsXZqSRr6h2JM4kZWP05WHcP5lGYp8AqIiIiIhNDWnKY8+aVct68Ur4dWcjaqlaefK2B6pZu6tt7qW/vYUN1G3s6ehl2WyzA3mBblptKWU4aJTlpTMpJY05pNgvLcyjPS1fPRBlziRlY27zAuqM/Vy2sIiIiIjIhhULGooo8FlXkveG5wYijsbOX+jYvxNa29lLX1kNdWw+1bT1UtfSwemcLTZ19e8/Jy0hm4eRcFpTnsHCy10V5WkEGoZBCrMROYgZWv4W1sieH4zUHq4iIiIgkmHDIvG7B2WnAG++NHdLdN8jmunZerWplfXUr66pa+eU/Xqd/0GueTQmHKMxKoSgrdb/HYv8xLyOF3PTk/RZ1O5YjkZiBta0agG09OZynFlYRERERkRGlp4Tf0ErbNxDhtbp21le3sm1PJ40dfezp6KWxo4/Nte00dvTRNxg56GtmpoTJTU+mMCuVaYUZzCjKZHqhdx/ujKJM8jOS1fVY9krMwNpeQyQ5g/aedAo0B6uIiIiISNRSkkIHHbUYwDlHW88AjR29tHT309rVT2v3G5f69l7WVbXy4Lqa/e6nzUlLYkZRJtMKM5lW6M0zO60gg2mFmZRkp6oLcoJJzMDaVk1/Rhm0GwVqYRURERERGTVmtrf7bzT6BiLsau5i+55OXt/TyfbGTrbv6eLlXc38dV0Ng8PSbGpSiIqCDKYWZFCel055fvrexyl56RRlKdBONIkZWNtr6EkrASA/M7q/SCIiIiIiMvpSkkLMKs5iVnHWG57rH4xQ3dLNjsYudjb5i7++akczrd39b3ityblplOenMzk3ncnDQu3kvHQm5aaRlhweq48moyAxA2tbDe05iwAo0KBLIiIiIiJxKTkc8rsGZ474fEfvAFXN3VS1dFHV3M3ulm5/u5sntzRQ396LO2D6nsLMFIqzU/dfsvatl/rz0mamJmZUijeJ918hEoH2GloKlgAKrCIiIiIi41VWahJzy7KZW5Y94vN9AxHq2nrY3dxNdYu/tPbQ0N5LQ0cv2xo6aWjvHXGQqOzUJEpz0/w5ab25aYuyUok4x0DEMTAYoW/QexyIOPoHI+SlpzCrJJPZJVlML8xUa+4oSLzA2tUIkX72WCGA5mEVEREREZmgUvx7XisKMg56jHOOtu4BGjp6qG/rpa69h7q2Xmpb981L+9zWDurbexmIuDecnxQyksJGcihER9/A3hbdkEFFQQazirP2BtiCzGSy05LJSUsmOy2JnHTvUVP9HFziBdZ2b0qbOlegPxwiIiIiIgnOzMjNSCY3I5nZJSO31AIMRhxt3f2EQkZKOERS2EgK2X5T8HT3DbJtTwdbGzqprO9ga0MHW+s7+EflHvoGDj7VT3pymNKc1L3hdlZxFrNKsphdnEVuRmKPuZN4gbWtBoDdg3nqDiwiIiIiIlEJh4z8w+SH9JQwCybnsmDy/lP+DEYctW09tHb109bTT3vPAG3d/bT39NPmr9e09lBZ38FTW/bs10W5KCuVWcWZ+wXZWcWZTM5NT4gRkRMvsPotrDv6chRYRUREREQk5sIh86bfyUs/7LGDEceupi62NnRQWe8vDR3cv6aatp6BvcelJ4eZWZzJrOIsCjJT6B0YpKc/Qk//oL9E6BkYpG8gQm56MkVZqd6SnUJRljfQVGGWNwBVYWYqKUnx2fM08QJrWw1gvN6TRUmeAquIiIiIiMSPcMiYXpTJ9KJMlhxdune/c47Gzj621ntdjocC7aodzbT39JOWHCY1OURaUpi05DBpySGyUpNISjdau/t5ZVcLezp66eobHPF98zKS946WXDTsMSMlTGpSiNTkECnh4esh0lPCHDslL6bXI/ECa3s1ZJWwpzvC3HIFVhERERERiX9mtreV9JSZhW/6dbr6BtjT3seezl72+KMl72nvY09H797Rk9fsbqGh/eDhdkhuejJrvnbhm64lGokXWNtqcNmTaNrVpy7BIiIyIZnZL4F3AvXOuYX+vgLgbmA6sB243DnXbN5oIT8E3gF0AR92zq0Oom4REYm9jJQkphYmMbXw4CMnD+nqG6C7b5C+wQi9/RF6ByL0DUToHRikdyDyhjluYyHxAmt7LYO5FfQORBRYRURkovo1cDNw57B9NwArnHM3mtkN/vb1wNuBOf5yCvBT/1FERBJcRkoSGSnBRsb4vLM2ltqr6Unz+oIXaA5WERGZgJxzTwJNB+xeCtzhr98BLBu2/07neQ7IM7NJY1OpiIjIoSVWYO3vhu5mOlKKAQ47LLWIiMgEUuqcq/HXa4GhkTzKgV3Djtvt7xMREQlcYgXWdu97uiWpCICCzMSehFdERBKTc84BR3znkZlda2YvmdlLDQ0NMahMRERkf4kVWNu8wLrHvFG1CjJTg6xGRERkLNUNdfX1H+v9/VVAxbDjpvj73sA5d6tzbrFzbnFxcXFMixUREYFEC6x+C2utywd0D6uIiCSUvwBX++tXA/cN23+VeU4FWod1HRYREQlUYo0S3FYNQFUkn3Conuy0xPr4IiKSGMzsD8A5QJGZ7Qa+BtwI/NHMrgF2AJf7hz+IN6VNJd60Nh8Z84JFREQOIrESW3sNJGdS25NCfkYyoZAFXZGIiMioc8594CBPLRnhWAd8KrYViYiIvDmJ1SW4rRpyJtHU1ac5WEVEREREROJcYgXW9hrInkRzZz/5un9VREREREQkriVWYG2rgZzJamEVEREREREZBxInsEYiw1pY+8hXYBUREREREYlriRNYuxoh0k8kexLNXX0UKrCKiIiIiIjEtcQJrO3elDZdqSVEHLqHVUREREREJM4lTmBt8+ZAb0kqAtA9rCIiIiIiInEucQKr38LaGCoE0D2sIiIiIiIicS6BAmstWIi6SC6A7mEVERERERGJc4kTWM++Hr6wmabuCKAWVhERERERkXgX88BqZmEze9nMHvC3Z5jZ82ZWaWZ3m9nYJMdQGLJKaOrqA6BAgy6JiIiIiIjEtbFoYf0MsHHY9neBm5xzs4Fm4JoxqGGv5s4+0pJDpKeEx/JtRURE5EDdLbD1saCrEBGROBbTwGpmU4BLgNv8bQPOA5b7h9wBLItlDQdq6uynMDN1LN9SRERERvLEd+E374anvg/OBV2NiIjEoVi3sP4A+Dcg4m8XAi3OuQF/ezdQPtKJZnatmb1kZi81NDSMWkFNnb3kZyaP2uuJiIjIm3Tef8CCd8GKb8Dyj0JfV9AViYhInIlZYDWzdwL1zrlVb+Z859ytzrnFzrnFxcXFo1ZXU1c/+bp/VUREJHgpGfDeX8L5X4f198IvL4SWnUFXJSIicSSWLaxnAJeZ2XbgLryuwD8E8swsyT9mClAVwxreoLmzjwKNECwiIhIfzODMz8EH/wjNO+HWc2D7P4KuSkRE4kTMAqtz7svOuSnOuenAFcBjzrl/AlYC7/UPuxq4L1Y1jESBVUREJA4ddSF8fAWkF8CdS+GFX+i+VhERCWQe1uuBz5tZJd49rbeP1Rv3DgzS3jugKW1ERETiUdEcL7TOWgIPfhHu/1fo7wm6KhERCVDS4Q9565xzjwOP++vbgJPH4n0P1NLVD0C+WlhFRETiU1oufOAPsPLb8NT/wsb7YcG74dj3Q8XJXhdiERFJGGMSWONFU2cfgLoEi4iIxLNQGJZ8FWaeA6vugFd+Dy/dDnnTvOB67OVea6yIiEx4CRVYmxVYRURExo8ZZ3lLbztsfADW3g1P/Q88+d8w+QRY9EFvSckMulIREYmRIO5hDUyjAquIiMj4k5oNiz4AV/0ZPrcBLvwWRPq9+1x/cIzXdbinLegqRUQkBhIqsDZ3eYFV87CKiIiMUzmT4PRPw3X/gI8+7LW0rvgm/GAhrPwOdDUFXaGIiIyihAqsQ/ew5mUkB1yJiIiIvGVTT4Url8O1j3tdh5/4Lty0EP7+H9BeF3R1IiIyChLuHtbc9GSSwwmV00VERCa2ycfD+38LdRvgH9+HZ2+GF271Wl8zCiCzCDKKIKPQX/cfM0sgsxjCCfW/QyIi40pC/Qvd2Nmn+1dFREQmqtL58J7b4Jwvw3M/gfpN0FgJu56HrkZwkRFOMi/UZpV64TWrFLJKvH1peZCet/9jWp439Y5CrojImEiof22bu/rIV3dgERGRia1wFlzyv/vvi0Sgp8ULrp17oLMBOuuhowE66rztjjov3HbUw0D3wV/fQpBb4b1Pwaz9H/OmQlj/ryEiMloSKrA2dfZTnpcWdBkiIiIy1kIhr9U0oyC6OVz7u6G7xQu5Pa371rtboGsPNG2Dxq2w+yXoHTZCcSgJyo6Foy+Foy+DotmHfy/nYM9rsO1xwGD2Ei/8iohIYgXW5s4+jinPCboMERERiXfJ6d6SM+nQxznntdo2boWmrV4X5G2Pw4pveEvx0X54facXZM288zrqveO2rvQe26v3f93C2TDnQm+Zdjokpb65zzHQB41boOl1KDkaCmbuq0FEZBxImMDqnKOps4983cMqIiIio8XMH8CpCKae4u1b8lVo3Q2b/gob74en/gee/G+vu/C0M6FmDdSv945Nz4cZZ8Osc2Hmud59tlsegS0Pw4u3e/fipmTBzHO8Y7JK/TCdAUlp3uNQuO5phfqN/rLBe2zaCpGBffXmVnjvN/Ns7zG7dKyvmIjIEUmYwNrZN0jfYIQCzcEqIiIisZY7BU75Z2/p3AObH/TC6+a/wqTjYMnXvABadpzXXXm4U671lr4ueP1J2PJ3b9n0QJRvbpA/3WtRPfqdUDIf8qZB7RqvNXfTA/DKb71Di4/2wmvRUV7X5jd0g26F3navK3Vuhfe58iogd+q+9dRs77Wcg8igF5CHFhfxQ7VuyRKRNydhAmuzPwerWlhFRERkTGUWwQlXecuRSMmAuRd7i3PQsgN62rz7a/u7YKDHe+zv9paUTCieB8VzvfUDVZwEJ33MC5W1a2HbE/D6E7Dqjn2DTIWSh42InOu1AOdN9bo9734RNvx5/xZbgHCK95pu8OCfJZzqv57/ukOvn1EIBTMgf4bXXTl/2sG7P/d1QstOb2neAb2t3nlDg16l6bYvkYkoYQJrkx9YCxVYRUREZLwxv9V0NITC3ty1k4+HMz8LA73Q1eQFyOT0Q9/jGhn0RlNu3e0Fx9bd0N3kBd1Qkr+E961bCPo792+x7fEHrmqs9EZn7usY/kEhp9wPsdP9kLrDe6/OhkN/rswS797fQn/E5twKyC6D7EleV+rUrEN8rmGjSHc1ej8AuEHvhwIX8QN5ZN9i5n22NywGDsDtOxf/0TnvvVIyITXHa5lOzfIekzO9lvZIxPucrbuh1b++Q0tnAxTOgcmLvDmGSxckbst1ex00b/d/9CjwfljR6NwTVsIFVrWwioiIiAyTlHr4waWGhMKQM9lbKk5+6+/tnNdluvl1b2Copm371l972At0eVNh7ju8x/zp3mPeVC/0NW/3gu/QgFeN27zzOuvf+F4pWV6AzSrzWnq7m/dNc9TddJB5eseKecF1oAcG+/Z/KiXLC98ZhfDaQ/u6c4eSvO7eQz8+ZJd5n+nApavJ+6HAQl5reDjZfxy2Hgr7gdrtC9bD1/cL6OH9t8MpI7eeDy2RAe9Hib5Ofxm27pz3Zy9nitfFPLP4jV3kB3qhZq3Xwr/7RW9k7tadb7yEqTlecE3P90Js9qQDurFXeD+GjBTyBwegrx16O7z6Ovd4P8y010JHrTdIWnutt6+n1fsBJHfKAa/vb6fl+T/YhN74PtHqafP+bA9fOuq8rv2lC7yleN7Bf7Bor4Wq1VC1CqpXQ8NmKDsGZp8Pcy4YvR+/xkjCBVbdwyoiIiISJ8wgq9hb3kwALp3vLQfqaYO2amiv2Rc8hsJHe60XjNPzvXt3p57mhcHMIu8xo8Br8RwKZKHhQW2oFXUo3A1rdR26h3cozGFgDFsPeef0dXr3Bfe2e/cN93bsWw+neGE8d8q+JS1vX6u3c9BW5YWR6pe9ZcN9sPqOA65ryDtvqPUxo8A7d7DPC4C97TDY720P9vl149dp+BvD1t3+n3P45x7o8a43jrcslOz9GJI7xQvgzTu87utDIT5nite1/dTrvNbm3rb9g3l3k/fY1Qj1m7z//gfWlVniBeP+Li+c9nYcet7lcKo3OFlWmTclVmqO92eqsdIb5bu/c+TzLOR9nvCw3gcH+8FgaL2n1Qun3U37v1Z6vheSK1fsq9XCXo+CoQBr5ofU1ftGHbew96NGxSlecH3tIW9/4RwvuM65AKadsX83fOe8a9PT5t/D3ub9eRn+Y8Pe7U7vx46Lvh3Nf903LWECa3OXWlhFREREEkJajreUzAu6ktFlti/Izr/M2+ec1yrd3QzpfkBNzXlrLXxHKhLxWigPHLRrKISnZPpL1v7rQwG8rWpf1+e2Kmit8lpSc8rhlOtgykkwZbEXZo/EQJ8X3lp2+a+/y1s69+yrITXLu15D6ylZ3g8X2WVeSEzLPXg3eee86z6863Zvq/cDwGA/RPq91ttIv9fSPNjnbQ/9ULD3R4N+Lwym5cKCZV4L6NCSN81rvQbvdZteh7pXoW69t1StgvV/8p4vmAXTz/C6jJef4E2llZKxr9bGrVD5iDcS+dAo5MkZXhf63nYvpPa2vfE+9ZFYyLtWWaUKrKOlODuVM2YXkpOWMB9ZRERERCY6M2/AqiCFQvu6ADPtyM7NLIRJx8akLJJS9gW/WDDzWq8zCmL3GYYLhaFotrcsWLZvf0+b19o9FGwPVuvQuad+whuFfPtTXnht2QnFuf4PPblegN+7nrsvyA8P+UlpYzanc8Kkt6WLylm6qDzoMkREREREREbPmxkhOyUDjrrIW+LcGPYVEBEREREREYmeAquIiIiIiIjEJQVWERERERERiUsKrCIiIoKZXWxmm82s0sxuCLoeERERUGAVERFJeGYWBm4B3g7MBz5gZiNMbikiIjK2FFhFRETkZKDSObfNOdcH3AUsDbgmERERBVYRERGhHNg1bHu3v28/Znatmb1kZi81NDSMWXEiIpK4FFhFREQkKs65W51zi51zi4uLi4MuR0REEoACq4iIiFQBFcO2p/j7REREAqXAKiIiIi8Cc8xshpmlAFcAfwm4JhEREZKCLkBERESC5ZwbMLN/AR4GwsAvnXPrAy5LREREgVVERETAOfcg8GDQdYiIiAynLsEiIiIiIiISl8w5F3QNh2VmDcCOKA8vAvbEsJyJRNcqerpWR0bXK3q6VtEbzWs1zTmnYW7fAn03x4yuVfR0rY6Mrlf0dK2iF/Pv5nERWI+Emb3knFscdB3jga5V9HStjoyuV/R0raKnazV+6b9d9HStoqdrdWR0vaKnaxW9sbhW6hIsIiIiIiIicUmBVUREREREROLSRAystwZdwDiiaxU9Xasjo+sVPV2r6OlajV/6bxc9Xavo6VodGV2v6OlaRS/m12rC3cMqIiIiIiIiE8NEbGEVERERERGRCWDCBFYzu9jMNptZpZndEHQ98cbMfmlm9Wb26rB9BWb2iJlt8R/zg6wxXphZhZmtNLMNZrbezD7j79f1OoCZpZnZC2a2xr9W3/D3zzCz5/2/j3ebWUrQtcYLMwub2ctm9oC/rWt1EGa23czWmdkrZvaSv09/D8cRfTcfmr6bo6fv5ujpu/nI6bs5ekF8N0+IwGpmYeAW4O3AfOADZjY/2Krizq+Biw/YdwOwwjk3B1jhbwsMAF9wzs0HTgU+5f950vV6o17gPOfcccAi4GIzOxX4LnCTc2420AxcE2CN8eYzwMZh27pWh3auc27RsCHz9fdwnNB3c1R+jb6bo6Xv5ujpu/nI6bv5yIzpd/OECKzAyUClc26bc64PuAtYGnBNccU59yTQdMDupcAd/vodwLIxLSpOOedqnHOr/fV2vH/AytH1egPn6fA3k/3FAecBy/39ulY+M5sCXALc5m8bulZHSn8Pxw99Nx+Gvpujp+/m6Om7+cjou3lUxPTv4UQJrOXArmHbu/19cmilzrkaf70WKA2ymHhkZtOB44Hn0fUakd+N5hWgHngE2Aq0OOf+fzv3EmpVFcdx/PvraiAZPbQisJBICKKyiKDHQIIaVDQp0jCICCIHPQaV1iSInDSIspoUFUEvgtIcSaESQkEivR+jsIFU5sBCCCn7NzjLPKjX+8Du3uf2/cDl7L3OYd21F2ff311r77X/ah/xfDzkGeAR4O+2vwD76lgK+CDJjiT3tDLPw9FhNk+P3/EJmM0TM5unxGyemhnP5jnHszKNrqqqJD4yekiS+cC7wINV9ftgwm3A/jqkqg4AS5OcCqwHLui4Sb2U5CZgd1XtSLKs6/aMiGuqaleSM4EPk3w//KbnoWY7v+NHMpsnx2yeHLN5WmY8m2fLFdZdwDlD+4tamY7tlyRnA7TX3R23pzeSzGUQiG9U1Xut2P46hqraC2wFrgROTXJwQszzceBq4OYkOxncGnkt8Cz21biqald73c3gH64r8DwcJWbz9PgdH4fZPHVm84TM5inqIptny4B1O7CkPdHrRGAFsLHjNo2CjcCdbftO4P0O29Ibbe3Cy8B3VfX00Fv212GSnNFmb0kyD7iOwbqircCt7WP2FVBVj1bVoqpazOBv1JaqWol9dVRJTkpy8sFt4HrgazwPR4nZPD1+x4/CbJ48s3nyzOap6SqbUzU77pxIcgODe9DHgFeqam3HTeqVJG8By4CFwC/A48AG4B3gXOBH4LaqOvzhD/87Sa4BtgFfcWg9w2MM1srYX0OSXMxgcf0Ygwmwd6rqiSTnMZipPB34DLijqvZ319J+abcdPVRVN9lXR9f6ZX3bnQO8WVVrkyzA83BkmM3HZjZPntk8eWbz9JjNE+sqm2fNgFWSJEmSNLvMlluCJUmSJEmzjANWSZIkSVIvOWCVJEmSJPWSA1ZJkiRJUi85YJUkSZIk9ZIDVqknkhxI8vnQz5rjWPfiJF8fr/okSfo/MJul7s3pugGS/vVHVS3tuhGSJOlfZrPUMa+wSj2XZGeSp5J8leTTJOe38sVJtiT5MsnmJOe28rOSrE/yRfu5qlU1luSlJN8k+SDJvPb5+5N82+p5u6PDlCRpZJjN0sxxwCr1x7zDbjtaPvTeb1V1EfA88Ewrew54raouBt4A1rXydcBHVXUJcBnwTStfArxQVRcCe4FbWvka4NJWz73/1cFJkjSCzGapY6mqrtsgCUiyr6rmH6V8J3BtVf2QZC7wc1UtSLIHOLuq/mzlP1XVwiS/Aouqav9QHYuBD6tqSdtfDcytqieTbAL2ARuADVW17z8+VEmSRoLZLHXPK6zSaKhxtqdi/9D2AQ6tYb8ReIHBjO/2JK5tlyRpYmazNAMcsEqjYfnQ6ydt+2NgRdteCWxr25uBVQBJxpKcMl6lSU4AzqmqrcBq4BTgiJlkSZJ0BLNZmgHO1kj9MS/J50P7m6rq4OPzT0vyJYOZ2Ntb2X3Aq0keBn4F7mrlDwAvJrmbwWztKuCncX7nGPB6C84A66pq73E7IkmSRpvZLHXMNUeFGsYAAABeSURBVKxSz7V1MpdX1Z6u2yJJksxmaSZ5S7AkSZIkqZe8wipJkiRJ6iWvsEqSJEmSeskBqyRJkiSplxywSpIkSZJ6yQGrJEmSJKmXHLBKkiRJknrJAaskSZIkqZf+AXU/fW/A4+J4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),train_acc_array)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),val_acc_array)\n",
        "plt.title(\"Accuray\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),train_loss_array)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),val_loss_array)\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "JX1dmdIIuPOo"
      },
      "outputs": [],
      "source": [
        "# can you create a subset of params exclusing pruned weights ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPceEp-MM1Jf"
      },
      "execution_count": 170,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}