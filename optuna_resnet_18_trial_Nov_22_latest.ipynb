{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaBEihcdtk8",
        "outputId": "a02db347-e397-4df0-af5f-9c3d07c4e794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXI-w576XzT_"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "import torch as torch\n",
        "\n",
        "\n",
        "def set_up_ssl():\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "set_up_ssl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC88owTK4XJj"
      },
      "outputs": [],
      "source": [
        "LOCAL_M1 = False\n",
        "\n",
        "if LOCAL_M1:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
        "else:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbtvE4s14XJj",
        "outputId": "c1d65db3-e2ca-42f6-8013-ed432078c882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTLc4fVcQ857"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "import humanize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAU4PYGddva",
        "outputId": "d3653024-bd73-4844-a600-f237e68073cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Tensorboard writer object\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating Tensorboard writer object\")\n",
        "\n",
        "TENSOR_BOARD_DIR = \"runs/resnet_18\"\n",
        "\n",
        "writer = SummaryWriter(TENSOR_BOARD_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQeGvfSCRM4i"
      },
      "outputs": [],
      "source": [
        "term_width = 5\n",
        "TOTAL_BAR_LENGTH = 7\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTCFIHn0XzUL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate3 = trial.suggest_float(\"dropout_rate3\", 0, 0.1,\n",
        "                                                step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate3)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, trial=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], trial,\n",
        "                                       stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], trial,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], trial,\n",
        "                                       stride=2)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], trial,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, trial, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, trial))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(trial=None):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet34(trial=None):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet50(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet101(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet152(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], trial=trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "3df2267cf8d54d74aaa803ab0a7f39d5",
            "a4fd0e91c384433c9e4e86677551a5eb",
            "75fb31bd9ee64e3c8fe52490f031d917",
            "c411225fe7b9462bbbef20d707e9b184",
            "ae4f75575c494f9aa028a84b27b35718",
            "f0361accc5944588b1f28e440421b32d",
            "0a3dee7be8734ab99425179b2d0a37d2",
            "1346132be0c544bdb53d0985afeb9db0",
            "91f2e2b1de884cfe875db6b983566fb3",
            "b432d075aafa47cb8121b097d421733e",
            "fcfc666db5a6422b95ae3115185ae4af"
          ]
        },
        "id": "N_K9-VkFRsiL",
        "outputId": "e3b5e70f-f7dc-4249-aee9-1bf89dd153a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3df2267cf8d54d74aaa803ab0a7f39d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "The length of a train set is  45000\n",
            "The length of a validation set is  5000\n",
            "The length of a test set is  10000\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# constructing validation set\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)\n",
        "print(\"The length of a train set is \", len(train_ds))\n",
        "print(\"The length of a validation set is \", len(val_ds))\n",
        "print(\"The length of a test set is \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = ResNet18() # 11.2 params\n",
        "#net = ResNet50() # 23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzjCm0gOElC",
        "outputId": "f1783bbc-f083-4252-a342-5d6745ee7501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "layers[0]:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "layers[1]:  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "layers[2]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[3]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[4]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[5]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[6]:  Linear(in_features=512, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "layers = list(net.children())\n",
        "\n",
        "print(len(layers))\n",
        "\n",
        "print(\"layers[0]: \", layers[0])\n",
        "print(\"layers[1]: \", layers[1])\n",
        "print(\"layers[2]: \", layers[2])\n",
        "print(\"layers[3]: \", layers[3])\n",
        "print(\"layers[4]: \", layers[4])\n",
        "print(\"layers[5]: \", layers[5])\n",
        "print(\"layers[6]: \", layers[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhtblo5n4uKQ",
        "outputId": "73870da1-5fce-4c9f-e69c-4098585c48af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-0.2.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch_pruning) (4.1.1)\n",
            "Installing collected packages: torch-pruning\n",
            "Successfully installed torch-pruning-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M1xDV4-VaKG"
      },
      "outputs": [],
      "source": [
        "import torch_pruning as tp\n",
        "\n",
        "def prune_model(model):\n",
        "    model.cpu()\n",
        "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 3, 32, 32) )\n",
        "    def prune_conv(conv, amount=0.2):\n",
        "        strategy = tp.strategy.L1Strategy()\n",
        "        pruning_index = strategy(conv.weight, amount=amount)\n",
        "        plan = DG.get_pruning_plan(conv, tp.prune_conv_out_channel, pruning_index)\n",
        "        plan.exec()\n",
        "    \n",
        "    block_prune_probs = [0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3]\n",
        "    blk_id = 0\n",
        "    for m in model.modules():\n",
        "        if isinstance( m, BasicBlock):\n",
        "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
        "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
        "            blk_id+=1\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgQPV3H4ZTxA"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def print_params(model):\n",
        "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkbs0btThnx",
        "outputId": "6071538e-8b91-47d6-b424-ee87adeebd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters before pruning is \n",
            "Number of parameters  11.2 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters before pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duOPOJDMV2Vn",
        "outputId": "9122f6c8-4135-489c-d3ba-5b31c96e7a28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(53, 83, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(83, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(83, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(83, 164, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(164, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(164, 359, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(164, 252, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(252, 359, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=252, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "prune_model(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAZTZsHwTyOK",
        "outputId": "6e5e7d5b-e1f5-4168-ce0a-d771e54bbeb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters after pruning is \n",
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters after pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqr1gYtVHgE",
        "outputId": "ce483cee-21fd-48ed-b051-c4a2d4430ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 53, 32, 32]           1,431\n",
            "       BatchNorm2d-2           [-1, 53, 32, 32]             106\n",
            "            Conv2d-3           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-4           [-1, 58, 32, 32]             116\n",
            "            Conv2d-5           [-1, 53, 32, 32]          27,666\n",
            "       BatchNorm2d-6           [-1, 53, 32, 32]             106\n",
            "        BasicBlock-7           [-1, 53, 32, 32]               0\n",
            "            Conv2d-8           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-9           [-1, 58, 32, 32]             116\n",
            "           Conv2d-10           [-1, 53, 32, 32]          27,666\n",
            "      BatchNorm2d-11           [-1, 53, 32, 32]             106\n",
            "       BasicBlock-12           [-1, 53, 32, 32]               0\n",
            "           Conv2d-13          [-1, 103, 16, 16]          49,131\n",
            "      BatchNorm2d-14          [-1, 103, 16, 16]             206\n",
            "           Conv2d-15           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-16           [-1, 83, 16, 16]             166\n",
            "           Conv2d-17           [-1, 83, 16, 16]           4,399\n",
            "      BatchNorm2d-18           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-19           [-1, 83, 16, 16]               0\n",
            "           Conv2d-20          [-1, 103, 16, 16]          76,941\n",
            "      BatchNorm2d-21          [-1, 103, 16, 16]             206\n",
            "           Conv2d-22           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-23           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-24           [-1, 83, 16, 16]               0\n",
            "           Conv2d-25            [-1, 205, 8, 8]         153,135\n",
            "      BatchNorm2d-26            [-1, 205, 8, 8]             410\n",
            "           Conv2d-27            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-28            [-1, 164, 8, 8]             328\n",
            "           Conv2d-29            [-1, 164, 8, 8]          13,612\n",
            "      BatchNorm2d-30            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-31            [-1, 164, 8, 8]               0\n",
            "           Conv2d-32            [-1, 205, 8, 8]         302,580\n",
            "      BatchNorm2d-33            [-1, 205, 8, 8]             410\n",
            "           Conv2d-34            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-35            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-36            [-1, 164, 8, 8]               0\n",
            "           Conv2d-37            [-1, 359, 4, 4]         529,884\n",
            "      BatchNorm2d-38            [-1, 359, 4, 4]             718\n",
            "           Conv2d-39            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-40            [-1, 252, 4, 4]             504\n",
            "           Conv2d-41            [-1, 252, 4, 4]          41,328\n",
            "      BatchNorm2d-42            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-43            [-1, 252, 4, 4]               0\n",
            "           Conv2d-44            [-1, 359, 4, 4]         814,212\n",
            "      BatchNorm2d-45            [-1, 359, 4, 4]             718\n",
            "           Conv2d-46            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-47            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-48            [-1, 252, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 4,493,525\n",
            "Trainable params: 4,493,525\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 8.69\n",
            "Params size (MB): 17.14\n",
            "Estimated Total Size (MB): 25.84\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def print_model_summary(model):\n",
        "  print(summary(model.to(device), (3, 32, 32)))\n",
        "\n",
        "print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tejFfYvQJxR5",
        "outputId": "9e109609-cb8d-4dd6-9671-e27c13d6482b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([53, 3, 3, 3])\n",
            "bn1.weight torch.Size([53])\n",
            "bn1.bias torch.Size([53])\n",
            "layer1.0.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([58])\n",
            "layer1.0.bn1.bias torch.Size([58])\n",
            "layer1.0.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([53])\n",
            "layer1.0.bn2.bias torch.Size([53])\n",
            "layer1.1.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([58])\n",
            "layer1.1.bn1.bias torch.Size([58])\n",
            "layer1.1.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([53])\n",
            "layer1.1.bn2.bias torch.Size([53])\n",
            "layer2.0.conv1.weight torch.Size([103, 53, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([103])\n",
            "layer2.0.bn1.bias torch.Size([103])\n",
            "layer2.0.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([83])\n",
            "layer2.0.bn2.bias torch.Size([83])\n",
            "layer2.0.shortcut.0.weight torch.Size([83, 53, 1, 1])\n",
            "layer2.0.shortcut.1.weight torch.Size([83])\n",
            "layer2.0.shortcut.1.bias torch.Size([83])\n",
            "layer2.1.conv1.weight torch.Size([103, 83, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([103])\n",
            "layer2.1.bn1.bias torch.Size([103])\n",
            "layer2.1.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([83])\n",
            "layer2.1.bn2.bias torch.Size([83])\n",
            "layer3.0.conv1.weight torch.Size([205, 83, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([205])\n",
            "layer3.0.bn1.bias torch.Size([205])\n",
            "layer3.0.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([164])\n",
            "layer3.0.bn2.bias torch.Size([164])\n",
            "layer3.0.shortcut.0.weight torch.Size([164, 83, 1, 1])\n",
            "layer3.0.shortcut.1.weight torch.Size([164])\n",
            "layer3.0.shortcut.1.bias torch.Size([164])\n",
            "layer3.1.conv1.weight torch.Size([205, 164, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([205])\n",
            "layer3.1.bn1.bias torch.Size([205])\n",
            "layer3.1.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([164])\n",
            "layer3.1.bn2.bias torch.Size([164])\n",
            "layer4.0.conv1.weight torch.Size([359, 164, 3, 3])\n",
            "layer4.0.bn1.weight torch.Size([359])\n",
            "layer4.0.bn1.bias torch.Size([359])\n",
            "layer4.0.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([252])\n",
            "layer4.0.bn2.bias torch.Size([252])\n",
            "layer4.0.shortcut.0.weight torch.Size([252, 164, 1, 1])\n",
            "layer4.0.shortcut.1.weight torch.Size([252])\n",
            "layer4.0.shortcut.1.bias torch.Size([252])\n",
            "layer4.1.conv1.weight torch.Size([359, 252, 3, 3])\n",
            "layer4.1.bn1.weight torch.Size([359])\n",
            "layer4.1.bn1.bias torch.Size([359])\n",
            "layer4.1.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([252])\n",
            "layer4.1.bn2.bias torch.Size([252])\n",
            "linear.weight torch.Size([10, 252])\n",
            "linear.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "def print_model_layers(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "print_model_layers(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3kWtBzVWg3Y"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "lr = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                       momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "lr = 0.0008781984559717051\n",
        "\n",
        "momentum = 0.26582732909111395\n",
        "\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=lr,\n",
        "                       momentum = momentum)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "\n",
        "# # test \n",
        "\n",
        "# optimizer = optim.RMSprop(net.parameters(), lr=0.001988661747922797,\n",
        "#                        momentum=0.6758665503145822)\n",
        "# # test\n",
        "\n",
        "# writing data to TensorBoard\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid, 0)\n",
        "writer.add_graph(net, images)\n",
        "writer.close()\n",
        "\n",
        "# --------------------------------------- # \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "save_loss = {'train':[], 'test':[]}\n",
        "save_acc = {'train':[], 'test':[]}\n",
        "\n",
        "train_acc_array, train_loss_array = [], [] # for plotting\n",
        "val_acc_array, val_loss_array = [], [] # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIzJObnOWz2d"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch, model=net, train_loader=trainloader):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_acc = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_acc=100.*correct/total\n",
        "        progress_bar(batch_idx, len(train_loader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    train_acc_array.append(train_acc) # for plottting\n",
        "    train_loss_array.append(train_loss) # for plottting\n",
        "    writer.add_scalar('training loss', train_loss)\n",
        "    writer.add_scalar('training accuracy', train_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CHlPBF6uIhT"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch, model=net, validation_loader=val_loader): # validation\n",
        "   \n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(validation_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(validation_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
        "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    valid_acc = 100.*correct/total\n",
        "    if valid_acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net_state_dict': model.state_dict(),\n",
        "            'acc': valid_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = valid_acc\n",
        "    val_acc_array.append(valid_acc) # for plottting\n",
        "    val_loss_array.append(valid_loss) # for plottting\n",
        "    writer.add_scalar('validation loss', valid_loss)\n",
        "    writer.add_scalar('validation accuracy', valid_acc)\n",
        "    return valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5i2dqetBgXp"
      },
      "outputs": [],
      "source": [
        "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
        "def test(model=net):\n",
        "   \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_acc = checkpoint['acc']\n",
        "    model.eval()\n",
        "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyuhb-GrXzUo",
        "outputId": "9854b62d-39a7-41ef-9665-94bf96d39a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HcWh5aXzUq",
        "outputId": "784216fd-bad3-4fec-e328-439915c4a414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcMkrBzW7o7",
        "outputId": "27f61c7a-0bae-496a-a9b7-9637e1f1346d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 50ms | Tot: 28s665ms | Train Loss: 1.111 | Train Acc: 60.824% (27371/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 1.031 | Valid Acc: 63.080% (3154/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 48ms | Tot: 28s759ms | Train Loss: 0.947 | Train Acc: 66.471% (29912/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s22ms | Valid Loss: 1.005 | Valid Acc: 63.840% (3192/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.857 | Train Acc: 70.096% (31543/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.932 | Valid Acc: 67.060% (3353/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 50ms | Tot: 28s522ms | Train Loss: 0.774 | Train Acc: 72.878% (32795/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s14ms | Valid Loss: 0.810 | Valid Acc: 71.040% (3552/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 48ms | Tot: 28s418ms | Train Loss: 0.717 | Train Acc: 74.871% (33692/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s182ms | Valid Loss: 0.743 | Valid Acc: 74.080% (3704/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 51ms | Tot: 28s571ms | Train Loss: 0.674 | Train Acc: 76.378% (34370/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 0.792 | Valid Acc: 73.040% (3652/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.633 | Train Acc: 78.022% (35110/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s974ms | Valid Loss: 0.804 | Valid Acc: 72.920% (3646/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 49ms | Tot: 28s574ms | Train Loss: 0.600 | Train Acc: 79.091% (35591/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s28ms | Valid Loss: 0.687 | Valid Acc: 75.840% (3792/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 52ms | Tot: 28s506ms | Train Loss: 0.580 | Train Acc: 80.016% (36007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s9ms | Valid Loss: 0.685 | Valid Acc: 76.740% (3837/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.545 | Train Acc: 81.111% (36500/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s54ms | Valid Loss: 0.637 | Valid Acc: 78.360% (3918/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 50ms | Tot: 28s456ms | Train Loss: 0.521 | Train Acc: 81.704% (36767/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.684 | Valid Acc: 76.480% (3824/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 49ms | Tot: 28s505ms | Train Loss: 0.499 | Train Acc: 82.687% (37209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.602 | Valid Acc: 78.900% (3945/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 50ms | Tot: 28s536ms | Train Loss: 0.482 | Train Acc: 83.049% (37372/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.584 | Valid Acc: 79.780% (3989/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 49ms | Tot: 28s491ms | Train Loss: 0.471 | Train Acc: 83.607% (37623/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.609 | Valid Acc: 79.140% (3957/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 48ms | Tot: 28s447ms | Train Loss: 0.450 | Train Acc: 84.411% (37985/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s5ms | Valid Loss: 0.613 | Valid Acc: 78.460% (3923/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.435 | Train Acc: 84.836% (38176/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s38ms | Valid Loss: 0.577 | Valid Acc: 80.200% (4010/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 50ms | Tot: 28s473ms | Train Loss: 0.423 | Train Acc: 85.196% (38338/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s991ms | Valid Loss: 0.536 | Valid Acc: 81.340% (4067/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 50ms | Tot: 28s765ms | Train Loss: 0.408 | Train Acc: 85.740% (38583/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s4ms | Valid Loss: 0.539 | Valid Acc: 81.700% (4085/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 49ms | Tot: 28s482ms | Train Loss: 0.406 | Train Acc: 85.764% (38594/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s10ms | Valid Loss: 0.537 | Valid Acc: 81.480% (4074/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 52ms | Tot: 28s565ms | Train Loss: 0.388 | Train Acc: 86.364% (38864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.556 | Valid Acc: 81.540% (4077/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 20\n",
            " [======>]  Step: 50ms | Tot: 28s479ms | Train Loss: 0.372 | Train Acc: 86.860% (39087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.525 | Valid Acc: 82.720% (4136/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [======>]  Step: 53ms | Tot: 28s451ms | Train Loss: 0.366 | Train Acc: 87.129% (39208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s363ms | Valid Loss: 0.519 | Valid Acc: 82.360% (4118/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 22\n",
            " [======>]  Step: 51ms | Tot: 28s453ms | Train Loss: 0.359 | Train Acc: 87.496% (39373/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 13ms | Tot: 2s76ms | Valid Loss: 0.508 | Valid Acc: 82.600% (4130/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 23\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.353 | Train Acc: 87.642% (39439/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s989ms | Valid Loss: 0.530 | Valid Acc: 82.180% (4109/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 24\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.344 | Train Acc: 87.833% (39525/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s44ms | Valid Loss: 0.534 | Valid Acc: 81.860% (4093/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 25\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.340 | Train Acc: 88.120% (39654/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s981ms | Valid Loss: 0.537 | Valid Acc: 82.220% (4111/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 26\n",
            " [======>]  Step: 50ms | Tot: 28s569ms | Train Loss: 0.331 | Train Acc: 88.502% (39826/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.503 | Valid Acc: 82.940% (4147/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.319 | Train Acc: 88.809% (39964/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s972ms | Valid Loss: 0.488 | Valid Acc: 83.240% (4162/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 28\n",
            " [======>]  Step: 51ms | Tot: 28s526ms | Train Loss: 0.312 | Train Acc: 89.100% (40095/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s952ms | Valid Loss: 0.481 | Valid Acc: 84.220% (4211/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 29\n",
            " [======>]  Step: 50ms | Tot: 28s527ms | Train Loss: 0.307 | Train Acc: 89.258% (40166/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.486 | Valid Acc: 84.440% (4222/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            " [======>]  Step: 51ms | Tot: 28s444ms | Train Loss: 0.302 | Train Acc: 89.658% (40346/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s970ms | Valid Loss: 0.480 | Valid Acc: 83.540% (4177/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 31\n",
            " [======>]  Step: 51ms | Tot: 28s530ms | Train Loss: 0.295 | Train Acc: 89.702% (40366/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s969ms | Valid Loss: 0.460 | Valid Acc: 84.760% (4238/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 32\n",
            " [======>]  Step: 52ms | Tot: 28s478ms | Train Loss: 0.292 | Train Acc: 89.962% (40483/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s989ms | Valid Loss: 0.464 | Valid Acc: 85.220% (4261/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 33\n",
            " [======>]  Step: 51ms | Tot: 28s456ms | Train Loss: 0.283 | Train Acc: 90.127% (40557/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s996ms | Valid Loss: 0.467 | Valid Acc: 84.860% (4243/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 34\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.282 | Train Acc: 90.104% (40547/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s932ms | Valid Loss: 0.521 | Valid Acc: 84.020% (4201/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 35\n",
            " [======>]  Step: 52ms | Tot: 28s466ms | Train Loss: 0.276 | Train Acc: 90.360% (40662/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s24ms | Valid Loss: 0.493 | Valid Acc: 84.380% (4219/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 36\n",
            " [======>]  Step: 48ms | Tot: 28s541ms | Train Loss: 0.272 | Train Acc: 90.544% (40745/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s995ms | Valid Loss: 0.472 | Valid Acc: 84.360% (4218/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 37\n",
            " [======>]  Step: 52ms | Tot: 28s482ms | Train Loss: 0.263 | Train Acc: 90.896% (40903/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s972ms | Valid Loss: 0.469 | Valid Acc: 84.660% (4233/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 38\n",
            " [======>]  Step: 49ms | Tot: 28s391ms | Train Loss: 0.264 | Train Acc: 90.831% (40874/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s263ms | Valid Loss: 0.480 | Valid Acc: 84.480% (4224/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 39\n",
            " [======>]  Step: 50ms | Tot: 28s508ms | Train Loss: 0.259 | Train Acc: 90.858% (40886/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s962ms | Valid Loss: 0.476 | Valid Acc: 85.020% (4251/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 40\n",
            " [======>]  Step: 52ms | Tot: 28s546ms | Train Loss: 0.256 | Train Acc: 91.071% (40982/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s935ms | Valid Loss: 0.477 | Valid Acc: 84.580% (4229/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 41\n",
            " [======>]  Step: 51ms | Tot: 28s573ms | Train Loss: 0.245 | Train Acc: 91.404% (41132/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s963ms | Valid Loss: 0.447 | Valid Acc: 86.200% (4310/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.248 | Train Acc: 91.451% (41153/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s999ms | Valid Loss: 0.500 | Valid Acc: 85.340% (4267/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 43\n",
            " [======>]  Step: 54ms | Tot: 28s511ms | Train Loss: 0.245 | Train Acc: 91.331% (41099/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s295ms | Valid Loss: 0.477 | Valid Acc: 85.320% (4266/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 44\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.241 | Train Acc: 91.576% (41209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s924ms | Valid Loss: 0.435 | Valid Acc: 85.440% (4272/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 45\n",
            " [======>]  Step: 50ms | Tot: 28s476ms | Train Loss: 0.235 | Train Acc: 91.836% (41326/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.475 | Valid Acc: 85.660% (4283/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 46\n",
            " [======>]  Step: 52ms | Tot: 28s576ms | Train Loss: 0.230 | Train Acc: 92.040% (41418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s971ms | Valid Loss: 0.439 | Valid Acc: 86.300% (4315/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 47\n",
            " [======>]  Step: 51ms | Tot: 28s477ms | Train Loss: 0.223 | Train Acc: 92.176% (41479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s960ms | Valid Loss: 0.453 | Valid Acc: 85.500% (4275/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 48\n",
            " [======>]  Step: 50ms | Tot: 28s576ms | Train Loss: 0.223 | Train Acc: 92.371% (41567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.432 | Valid Acc: 86.480% (4324/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            " [======>]  Step: 49ms | Tot: 28s480ms | Train Loss: 0.218 | Train Acc: 92.413% (41586/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s15ms | Valid Loss: 0.444 | Valid Acc: 86.060% (4303/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 50\n",
            " [======>]  Step: 51ms | Tot: 28s466ms | Train Loss: 0.217 | Train Acc: 92.320% (41544/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s973ms | Valid Loss: 0.451 | Valid Acc: 85.840% (4292/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 51\n",
            " [======>]  Step: 51ms | Tot: 28s525ms | Train Loss: 0.212 | Train Acc: 92.591% (41666/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s161ms | Valid Loss: 0.444 | Valid Acc: 86.180% (4309/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 52\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.215 | Train Acc: 92.513% (41631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.466 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 53\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.204 | Train Acc: 92.889% (41800/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.473 | Valid Acc: 86.520% (4326/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            " [======>]  Step: 52ms | Tot: 28s525ms | Train Loss: 0.207 | Train Acc: 92.693% (41712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.460 | Valid Acc: 85.900% (4295/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 55\n",
            " [======>]  Step: 50ms | Tot: 28s462ms | Train Loss: 0.206 | Train Acc: 92.784% (41753/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s51ms | Valid Loss: 0.455 | Valid Acc: 85.980% (4299/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 56\n",
            " [======>]  Step: 51ms | Tot: 28s540ms | Train Loss: 0.195 | Train Acc: 93.007% (41853/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s31ms | Valid Loss: 0.482 | Valid Acc: 85.420% (4271/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 57\n",
            " [======>]  Step: 51ms | Tot: 28s457ms | Train Loss: 0.196 | Train Acc: 93.393% (42027/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s998ms | Valid Loss: 0.470 | Valid Acc: 86.680% (4334/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 58\n",
            " [======>]  Step: 50ms | Tot: 28s578ms | Train Loss: 0.194 | Train Acc: 93.309% (41989/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s952ms | Valid Loss: 0.468 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 59\n",
            " [======>]  Step: 50ms | Tot: 28s689ms | Train Loss: 0.193 | Train Acc: 93.324% (41996/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s999ms | Valid Loss: 0.473 | Valid Acc: 86.900% (4345/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 60\n",
            " [======>]  Step: 49ms | Tot: 28s470ms | Train Loss: 0.190 | Train Acc: 93.351% (42008/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s85ms | Valid Loss: 0.452 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 61\n",
            " [======>]  Step: 51ms | Tot: 28s524ms | Train Loss: 0.190 | Train Acc: 93.542% (42094/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s17ms | Valid Loss: 0.409 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 62\n",
            " [======>]  Step: 48ms | Tot: 28s463ms | Train Loss: 0.184 | Train Acc: 93.631% (42134/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s993ms | Valid Loss: 0.414 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 63\n",
            " [======>]  Step: 51ms | Tot: 28s744ms | Train Loss: 0.184 | Train Acc: 93.653% (42144/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s961ms | Valid Loss: 0.408 | Valid Acc: 87.560% (4378/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 64\n",
            " [======>]  Step: 52ms | Tot: 28s463ms | Train Loss: 0.180 | Train Acc: 93.756% (42190/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s928ms | Valid Loss: 0.413 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 65\n",
            " [======>]  Step: 51ms | Tot: 28s594ms | Train Loss: 0.180 | Train Acc: 93.851% (42233/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s240ms | Valid Loss: 0.434 | Valid Acc: 86.660% (4333/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 66\n",
            " [======>]  Step: 52ms | Tot: 28s465ms | Train Loss: 0.176 | Train Acc: 93.924% (42266/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s987ms | Valid Loss: 0.411 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 67\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.177 | Train Acc: 93.918% (42263/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s32ms | Valid Loss: 0.417 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 68\n",
            " [======>]  Step: 51ms | Tot: 28s577ms | Train Loss: 0.172 | Train Acc: 93.971% (42287/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.466 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 69\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.175 | Train Acc: 93.867% (42240/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s977ms | Valid Loss: 0.454 | Valid Acc: 86.980% (4349/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 70\n",
            " [======>]  Step: 51ms | Tot: 28s523ms | Train Loss: 0.166 | Train Acc: 94.107% (42348/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s963ms | Valid Loss: 0.437 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [======>]  Step: 51ms | Tot: 28s474ms | Train Loss: 0.167 | Train Acc: 94.164% (42374/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s992ms | Valid Loss: 0.444 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 72\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.163 | Train Acc: 94.398% (42479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s973ms | Valid Loss: 0.426 | Valid Acc: 87.620% (4381/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 73\n",
            " [======>]  Step: 52ms | Tot: 28s561ms | Train Loss: 0.163 | Train Acc: 94.242% (42409/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.434 | Valid Acc: 87.700% (4385/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 74\n",
            " [======>]  Step: 51ms | Tot: 28s568ms | Train Loss: 0.161 | Train Acc: 94.502% (42526/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s995ms | Valid Loss: 0.448 | Valid Acc: 86.860% (4343/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 75\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.163 | Train Acc: 94.367% (42465/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s958ms | Valid Loss: 0.430 | Valid Acc: 87.540% (4377/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 76\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.159 | Train Acc: 94.596% (42568/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s51ms | Valid Loss: 0.408 | Valid Acc: 87.660% (4383/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 77\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.155 | Train Acc: 94.616% (42577/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.429 | Valid Acc: 87.260% (4363/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 78\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.154 | Train Acc: 94.591% (42566/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s56ms | Valid Loss: 0.426 | Valid Acc: 87.300% (4365/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 79\n",
            " [======>]  Step: 51ms | Tot: 28s447ms | Train Loss: 0.158 | Train Acc: 94.369% (42466/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s21ms | Valid Loss: 0.455 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 80\n",
            " [======>]  Step: 50ms | Tot: 28s534ms | Train Loss: 0.154 | Train Acc: 94.553% (42549/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s987ms | Valid Loss: 0.434 | Valid Acc: 88.500% (4425/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 81\n",
            " [======>]  Step: 52ms | Tot: 28s490ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s944ms | Valid Loss: 0.445 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 82\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s963ms | Valid Loss: 0.416 | Valid Acc: 88.160% (4408/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 83\n",
            " [======>]  Step: 49ms | Tot: 28s553ms | Train Loss: 0.146 | Train Acc: 94.922% (42715/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s960ms | Valid Loss: 0.417 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 84\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.146 | Train Acc: 95.029% (42763/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s966ms | Valid Loss: 0.473 | Valid Acc: 87.600% (4380/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 85\n",
            " [======>]  Step: 51ms | Tot: 28s555ms | Train Loss: 0.144 | Train Acc: 94.998% (42749/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s973ms | Valid Loss: 0.431 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 86\n",
            " [======>]  Step: 50ms | Tot: 28s554ms | Train Loss: 0.145 | Train Acc: 94.984% (42743/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s937ms | Valid Loss: 0.441 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 87\n",
            " [======>]  Step: 49ms | Tot: 28s520ms | Train Loss: 0.140 | Train Acc: 95.062% (42778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s54ms | Valid Loss: 0.406 | Valid Acc: 88.560% (4428/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 88\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.138 | Train Acc: 95.376% (42919/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s55ms | Valid Loss: 0.432 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 89\n",
            " [======>]  Step: 52ms | Tot: 28s505ms | Train Loss: 0.140 | Train Acc: 95.207% (42843/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s988ms | Valid Loss: 0.447 | Valid Acc: 87.680% (4384/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 90\n",
            " [======>]  Step: 52ms | Tot: 28s566ms | Train Loss: 0.136 | Train Acc: 95.249% (42862/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s931ms | Valid Loss: 0.408 | Valid Acc: 88.440% (4422/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 91\n",
            " [======>]  Step: 51ms | Tot: 28s499ms | Train Loss: 0.140 | Train Acc: 95.231% (42854/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s971ms | Valid Loss: 0.399 | Valid Acc: 88.480% (4424/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 92\n",
            " [======>]  Step: 51ms | Tot: 28s529ms | Train Loss: 0.137 | Train Acc: 95.244% (42860/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s120ms | Valid Loss: 0.416 | Valid Acc: 88.040% (4402/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 93\n",
            " [======>]  Step: 49ms | Tot: 28s555ms | Train Loss: 0.134 | Train Acc: 95.398% (42929/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s943ms | Valid Loss: 0.413 | Valid Acc: 88.580% (4429/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.132 | Train Acc: 95.362% (42913/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s992ms | Valid Loss: 0.457 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 95\n",
            " [======>]  Step: 51ms | Tot: 28s572ms | Train Loss: 0.131 | Train Acc: 95.518% (42983/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s968ms | Valid Loss: 0.434 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 96\n",
            " [======>]  Step: 52ms | Tot: 28s559ms | Train Loss: 0.132 | Train Acc: 95.422% (42940/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.431 | Valid Acc: 88.320% (4416/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 97\n",
            " [======>]  Step: 50ms | Tot: 28s503ms | Train Loss: 0.134 | Train Acc: 95.409% (42934/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s173ms | Valid Loss: 0.400 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 98\n",
            " [======>]  Step: 49ms | Tot: 28s578ms | Train Loss: 0.130 | Train Acc: 95.571% (43007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s8ms | Valid Loss: 0.419 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 99\n",
            " [======>]  Step: 51ms | Tot: 28s502ms | Train Loss: 0.131 | Train Acc: 95.609% (43024/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s968ms | Valid Loss: 0.382 | Valid Acc: 88.300% (4415/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 100\n",
            " [======>]  Step: 50ms | Tot: 28s563ms | Train Loss: 0.127 | Train Acc: 95.644% (43040/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 0.427 | Valid Acc: 88.140% (4407/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 101\n",
            " [======>]  Step: 51ms | Tot: 28s486ms | Train Loss: 0.126 | Train Acc: 95.702% (43066/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s968ms | Valid Loss: 0.399 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [======>]  Step: 52ms | Tot: 28s589ms | Train Loss: 0.123 | Train Acc: 95.749% (43087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.426 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 103\n",
            " [======>]  Step: 53ms | Tot: 28s495ms | Train Loss: 0.123 | Train Acc: 95.769% (43096/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s7ms | Valid Loss: 0.429 | Valid Acc: 88.680% (4434/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 104\n",
            " [======>]  Step: 49ms | Tot: 28s538ms | Train Loss: 0.123 | Train Acc: 95.753% (43089/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.418 | Valid Acc: 88.620% (4431/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 105\n",
            " [======>]  Step: 48ms | Tot: 28s571ms | Train Loss: 0.120 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s980ms | Valid Loss: 0.381 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 106\n",
            " [======>]  Step: 50ms | Tot: 28s472ms | Train Loss: 0.121 | Train Acc: 95.733% (43080/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.438 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 107\n",
            " [======>]  Step: 47ms | Tot: 28s553ms | Train Loss: 0.118 | Train Acc: 95.993% (43197/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s960ms | Valid Loss: 0.389 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 108\n",
            " [======>]  Step: 50ms | Tot: 28s483ms | Train Loss: 0.118 | Train Acc: 95.929% (43168/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.413 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 109\n",
            " [======>]  Step: 49ms | Tot: 28s519ms | Train Loss: 0.116 | Train Acc: 95.982% (43192/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s78ms | Valid Loss: 0.403 | Valid Acc: 89.220% (4461/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [======>]  Step: 48ms | Tot: 28s528ms | Train Loss: 0.117 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.434 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 111\n",
            " [======>]  Step: 52ms | Tot: 28s518ms | Train Loss: 0.114 | Train Acc: 96.084% (43238/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.415 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 112\n",
            " [======>]  Step: 52ms | Tot: 28s603ms | Train Loss: 0.112 | Train Acc: 96.204% (43292/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s40ms | Valid Loss: 0.425 | Valid Acc: 88.420% (4421/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 113\n",
            " [======>]  Step: 50ms | Tot: 28s519ms | Train Loss: 0.113 | Train Acc: 96.067% (43230/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s1ms | Valid Loss: 0.374 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.115 | Train Acc: 96.011% (43205/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 6ms | Tot: 1s947ms | Valid Loss: 0.380 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 115\n",
            " [======>]  Step: 48ms | Tot: 28s488ms | Train Loss: 0.115 | Train Acc: 96.018% (43208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s18ms | Valid Loss: 0.390 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 116\n",
            " [======>]  Step: 51ms | Tot: 28s482ms | Train Loss: 0.106 | Train Acc: 96.309% (43339/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s954ms | Valid Loss: 0.436 | Valid Acc: 88.780% (4439/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 117\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.106 | Train Acc: 96.313% (43341/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s924ms | Valid Loss: 0.413 | Valid Acc: 89.080% (4454/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 118\n",
            " [======>]  Step: 51ms | Tot: 28s515ms | Train Loss: 0.108 | Train Acc: 96.276% (43324/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s916ms | Valid Loss: 0.403 | Valid Acc: 89.280% (4464/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 119\n",
            " [======>]  Step: 52ms | Tot: 28s535ms | Train Loss: 0.105 | Train Acc: 96.344% (43355/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s941ms | Valid Loss: 0.405 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 120\n",
            " [======>]  Step: 53ms | Tot: 28s484ms | Train Loss: 0.108 | Train Acc: 96.233% (43305/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s964ms | Valid Loss: 0.401 | Valid Acc: 89.320% (4466/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 121\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.111 | Train Acc: 96.249% (43312/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s315ms | Valid Loss: 0.391 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 122\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.106 | Train Acc: 96.304% (43337/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s4ms | Valid Loss: 0.437 | Valid Acc: 89.000% (4450/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 123\n",
            " [======>]  Step: 49ms | Tot: 28s593ms | Train Loss: 0.105 | Train Acc: 96.351% (43358/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.400 | Valid Acc: 89.200% (4460/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 124\n",
            " [======>]  Step: 50ms | Tot: 28s593ms | Train Loss: 0.101 | Train Acc: 96.422% (43390/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s984ms | Valid Loss: 0.418 | Valid Acc: 88.860% (4443/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 125\n",
            " [======>]  Step: 51ms | Tot: 28s681ms | Train Loss: 0.099 | Train Acc: 96.484% (43418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s57ms | Valid Loss: 0.401 | Valid Acc: 89.260% (4463/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 126\n",
            " [======>]  Step: 51ms | Tot: 28s538ms | Train Loss: 0.097 | Train Acc: 96.684% (43508/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s6ms | Valid Loss: 0.387 | Valid Acc: 89.480% (4474/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 127\n",
            " [======>]  Step: 50ms | Tot: 28s532ms | Train Loss: 0.101 | Train Acc: 96.467% (43410/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s979ms | Valid Loss: 0.420 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 128\n",
            " [======>]  Step: 51ms | Tot: 28s492ms | Train Loss: 0.102 | Train Acc: 96.411% (43385/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s984ms | Valid Loss: 0.397 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 129\n",
            " [======>]  Step: 51ms | Tot: 28s463ms | Train Loss: 0.095 | Train Acc: 96.707% (43518/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s968ms | Valid Loss: 0.415 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 130\n",
            " [======>]  Step: 49ms | Tot: 28s533ms | Train Loss: 0.100 | Train Acc: 96.516% (43432/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s962ms | Valid Loss: 0.400 | Valid Acc: 89.440% (4472/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 131\n",
            " [======>]  Step: 47ms | Tot: 28s492ms | Train Loss: 0.099 | Train Acc: 96.509% (43429/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s931ms | Valid Loss: 0.394 | Valid Acc: 89.720% (4486/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 132\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.094 | Train Acc: 96.807% (43563/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s530ms | Valid Loss: 0.392 | Valid Acc: 89.560% (4478/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 133\n",
            " [======>]  Step: 52ms | Tot: 28s461ms | Train Loss: 0.099 | Train Acc: 96.627% (43482/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s949ms | Valid Loss: 0.390 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [======>]  Step: 52ms | Tot: 28s521ms | Train Loss: 0.092 | Train Acc: 96.756% (43540/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s967ms | Valid Loss: 0.432 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 135\n",
            " [======>]  Step: 49ms | Tot: 28s511ms | Train Loss: 0.094 | Train Acc: 96.736% (43531/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.398 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 136\n",
            " [======>]  Step: 50ms | Tot: 28s524ms | Train Loss: 0.088 | Train Acc: 96.947% (43626/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s960ms | Valid Loss: 0.410 | Valid Acc: 89.700% (4485/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 137\n",
            " [======>]  Step: 51ms | Tot: 28s489ms | Train Loss: 0.094 | Train Acc: 96.784% (43553/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s897ms | Valid Loss: 0.403 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 138\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.094 | Train Acc: 96.816% (43567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s213ms | Valid Loss: 0.386 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 139\n",
            " [======>]  Step: 51ms | Tot: 28s478ms | Train Loss: 0.091 | Train Acc: 96.878% (43595/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s929ms | Valid Loss: 0.411 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 140\n",
            " [======>]  Step: 50ms | Tot: 28s489ms | Train Loss: 0.088 | Train Acc: 96.958% (43631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.389 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 141\n",
            " [======>]  Step: 48ms | Tot: 28s538ms | Train Loss: 0.091 | Train Acc: 96.767% (43545/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s928ms | Valid Loss: 0.397 | Valid Acc: 89.360% (4468/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 142\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.091 | Train Acc: 96.822% (43570/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s11ms | Valid Loss: 0.389 | Valid Acc: 89.960% (4498/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 143\n",
            " [======>]  Step: 51ms | Tot: 28s467ms | Train Loss: 0.090 | Train Acc: 96.927% (43617/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.388 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 144\n",
            " [======>]  Step: 49ms | Tot: 28s689ms | Train Loss: 0.087 | Train Acc: 96.962% (43633/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s936ms | Valid Loss: 0.375 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 145\n",
            " [======>]  Step: 50ms | Tot: 28s637ms | Train Loss: 0.091 | Train Acc: 96.916% (43612/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s939ms | Valid Loss: 0.391 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 146\n",
            " [======>]  Step: 49ms | Tot: 28s666ms | Train Loss: 0.089 | Train Acc: 96.933% (43620/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.398 | Valid Acc: 89.660% (4483/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 147\n",
            " [======>]  Step: 49ms | Tot: 28s587ms | Train Loss: 0.089 | Train Acc: 96.856% (43585/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s27ms | Valid Loss: 0.382 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 148\n",
            " [======>]  Step: 49ms | Tot: 28s623ms | Train Loss: 0.086 | Train Acc: 96.978% (43640/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s940ms | Valid Loss: 0.409 | Valid Acc: 89.500% (4475/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 149\n",
            " [======>]  Step: 50ms | Tot: 28s595ms | Train Loss: 0.086 | Train Acc: 97.042% (43669/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s908ms | Valid Loss: 0.367 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 150\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.088 | Train Acc: 96.944% (43625/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.403 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 151\n",
            " [======>]  Step: 49ms | Tot: 28s462ms | Train Loss: 0.084 | Train Acc: 97.120% (43704/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s935ms | Valid Loss: 0.411 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 152\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.088 | Train Acc: 96.989% (43645/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.379 | Valid Acc: 90.100% (4505/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 153\n",
            " [======>]  Step: 50ms | Tot: 28s481ms | Train Loss: 0.083 | Train Acc: 97.064% (43679/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.397 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 154\n",
            " [======>]  Step: 51ms | Tot: 28s501ms | Train Loss: 0.085 | Train Acc: 97.098% (43694/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.406 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 155\n",
            " [======>]  Step: 50ms | Tot: 28s512ms | Train Loss: 0.082 | Train Acc: 97.180% (43731/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s937ms | Valid Loss: 0.414 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 156\n",
            " [======>]  Step: 49ms | Tot: 28s490ms | Train Loss: 0.085 | Train Acc: 97.007% (43653/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s948ms | Valid Loss: 0.368 | Valid Acc: 90.440% (4522/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 157\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.085 | Train Acc: 97.051% (43673/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.394 | Valid Acc: 90.220% (4511/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 158\n",
            " [======>]  Step: 47ms | Tot: 28s500ms | Train Loss: 0.083 | Train Acc: 97.082% (43687/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s922ms | Valid Loss: 0.411 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 159\n",
            " [======>]  Step: 50ms | Tot: 28s535ms | Train Loss: 0.083 | Train Acc: 97.138% (43712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s988ms | Valid Loss: 0.416 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 160\n",
            " [======>]  Step: 51ms | Tot: 28s552ms | Train Loss: 0.085 | Train Acc: 97.118% (43703/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s911ms | Valid Loss: 0.421 | Valid Acc: 90.080% (4504/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 161\n",
            " [======>]  Step: 49ms | Tot: 28s492ms | Train Loss: 0.081 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s912ms | Valid Loss: 0.379 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 162\n",
            " [======>]  Step: 51ms | Tot: 28s553ms | Train Loss: 0.083 | Train Acc: 97.076% (43684/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.375 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 163\n",
            " [======>]  Step: 49ms | Tot: 28s501ms | Train Loss: 0.079 | Train Acc: 97.129% (43708/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.380 | Valid Acc: 90.380% (4519/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 164\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.079 | Train Acc: 97.327% (43797/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s929ms | Valid Loss: 0.392 | Valid Acc: 89.880% (4494/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 165\n",
            " [======>]  Step: 50ms | Tot: 28s506ms | Train Loss: 0.082 | Train Acc: 97.216% (43747/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s932ms | Valid Loss: 0.373 | Valid Acc: 90.560% (4528/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 166\n",
            " [======>]  Step: 51ms | Tot: 28s534ms | Train Loss: 0.082 | Train Acc: 97.080% (43686/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s957ms | Valid Loss: 0.419 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 167\n",
            " [======>]  Step: 49ms | Tot: 28s507ms | Train Loss: 0.078 | Train Acc: 97.289% (43780/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s997ms | Valid Loss: 0.385 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.078 | Train Acc: 97.280% (43776/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s912ms | Valid Loss: 0.386 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 169\n",
            " [======>]  Step: 51ms | Tot: 28s556ms | Train Loss: 0.080 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s938ms | Valid Loss: 0.371 | Valid Acc: 90.360% (4518/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 170\n",
            " [======>]  Step: 52ms | Tot: 28s723ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s985ms | Valid Loss: 0.364 | Valid Acc: 90.700% (4535/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 171\n",
            " [======>]  Step: 49ms | Tot: 28s748ms | Train Loss: 0.080 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.392 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 172\n",
            " [======>]  Step: 52ms | Tot: 28s792ms | Train Loss: 0.079 | Train Acc: 97.307% (43788/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s999ms | Valid Loss: 0.366 | Valid Acc: 90.540% (4527/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 173\n",
            " [======>]  Step: 49ms | Tot: 28s701ms | Train Loss: 0.078 | Train Acc: 97.200% (43740/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s4ms | Valid Loss: 0.389 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 174\n",
            " [======>]  Step: 51ms | Tot: 28s685ms | Train Loss: 0.080 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.369 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 175\n",
            " [======>]  Step: 52ms | Tot: 28s693ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 0.404 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 176\n",
            " [======>]  Step: 52ms | Tot: 28s797ms | Train Loss: 0.076 | Train Acc: 97.398% (43829/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s950ms | Valid Loss: 0.367 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 177\n",
            " [======>]  Step: 51ms | Tot: 28s666ms | Train Loss: 0.077 | Train Acc: 97.367% (43815/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s11ms | Valid Loss: 0.380 | Valid Acc: 90.520% (4526/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 178\n",
            " [======>]  Step: 50ms | Tot: 28s650ms | Train Loss: 0.076 | Train Acc: 97.351% (43808/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s39ms | Valid Loss: 0.374 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 179\n",
            " [======>]  Step: 52ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s27ms | Valid Loss: 0.389 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 180\n",
            " [======>]  Step: 51ms | Tot: 28s595ms | Train Loss: 0.078 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s29ms | Valid Loss: 0.407 | Valid Acc: 90.760% (4538/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 181\n",
            " [======>]  Step: 53ms | Tot: 28s799ms | Train Loss: 0.075 | Train Acc: 97.378% (43820/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.391 | Valid Acc: 90.340% (4517/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 182\n",
            " [======>]  Step: 51ms | Tot: 28s714ms | Train Loss: 0.074 | Train Acc: 97.364% (43814/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s3ms | Valid Loss: 0.353 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 183\n",
            " [======>]  Step: 48ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.406 | Valid Acc: 89.940% (4497/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 184\n",
            " [======>]  Step: 52ms | Tot: 28s714ms | Train Loss: 0.077 | Train Acc: 97.338% (43802/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s63ms | Valid Loss: 0.381 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 185\n",
            " [======>]  Step: 49ms | Tot: 28s678ms | Train Loss: 0.077 | Train Acc: 97.344% (43805/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s940ms | Valid Loss: 0.349 | Valid Acc: 91.180% (4559/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 186\n",
            " [======>]  Step: 50ms | Tot: 28s714ms | Train Loss: 0.076 | Train Acc: 97.416% (43837/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s45ms | Valid Loss: 0.397 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 187\n",
            " [======>]  Step: 52ms | Tot: 28s770ms | Train Loss: 0.079 | Train Acc: 97.271% (43772/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.419 | Valid Acc: 90.120% (4506/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 188\n",
            " [======>]  Step: 50ms | Tot: 28s669ms | Train Loss: 0.079 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s983ms | Valid Loss: 0.356 | Valid Acc: 90.860% (4543/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 189\n",
            " [======>]  Step: 51ms | Tot: 28s679ms | Train Loss: 0.078 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s8ms | Valid Loss: 0.388 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 190\n",
            " [======>]  Step: 52ms | Tot: 28s718ms | Train Loss: 0.074 | Train Acc: 97.353% (43809/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s60ms | Valid Loss: 0.382 | Valid Acc: 90.000% (4500/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 191\n",
            " [======>]  Step: 50ms | Tot: 28s720ms | Train Loss: 0.076 | Train Acc: 97.482% (43867/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s987ms | Valid Loss: 0.358 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 192\n",
            " [======>]  Step: 50ms | Tot: 28s706ms | Train Loss: 0.075 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s974ms | Valid Loss: 0.364 | Valid Acc: 90.600% (4530/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 193\n",
            " [======>]  Step: 47ms | Tot: 28s697ms | Train Loss: 0.079 | Train Acc: 97.287% (43779/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s17ms | Valid Loss: 0.405 | Valid Acc: 89.980% (4499/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 194\n",
            " [======>]  Step: 50ms | Tot: 28s760ms | Train Loss: 0.079 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s35ms | Valid Loss: 0.384 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 195\n",
            " [======>]  Step: 47ms | Tot: 28s685ms | Train Loss: 0.078 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.376 | Valid Acc: 90.320% (4516/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 196\n",
            " [======>]  Step: 51ms | Tot: 28s671ms | Train Loss: 0.077 | Train Acc: 97.273% (43773/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s963ms | Valid Loss: 0.345 | Valid Acc: 91.020% (4551/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 197\n",
            " [======>]  Step: 51ms | Tot: 28s817ms | Train Loss: 0.075 | Train Acc: 97.476% (43864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.370 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 198\n",
            " [======>]  Step: 52ms | Tot: 28s707ms | Train Loss: 0.076 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.363 | Valid Acc: 90.780% (4539/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 199\n",
            " [======>]  Step: 50ms | Tot: 28s719ms | Train Loss: 0.075 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s13ms | Valid Loss: 0.381 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "---------------------------------------- Testing Model... ----------------------------------------\n",
            "Best validation acc: 91.180% at Epoch 185\n",
            " [======>]  Step: 21ms | Tot: 2s360ms | Test Loss: 0.348 | Test Acc: 93.820% (9382/10000)\b\b\b\b 100/100 \n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 200\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9l3iSKXzUs",
        "outputId": "b8c1f4be-717f-434e-9fce-be69987cb5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z_TwWP4Xkca",
        "outputId": "4f984e49-30b1-4465-9d01-eba30dbbdcf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24.788888888888888,\n",
              " 38.593333333333334,\n",
              " 51.28,\n",
              " 10.171830484330485,\n",
              " 10.211894586894587,\n",
              " 10.249732905982906,\n",
              " 10.1696047008547,\n",
              " 10.122863247863247,\n",
              " 10.27199074074074,\n",
              " 10.225249287749287,\n",
              " 10.243055555555555,\n",
              " 10.145121082621083,\n",
              " 10.109508547008547,\n",
              " 9.866071428571429,\n",
              " 10.0,\n",
              " 10.071428571428571,\n",
              " 9.908482142857142,\n",
              " 9.977678571428571,\n",
              " 9.964285714285714,\n",
              " 9.959821428571429,\n",
              " 9.890625,\n",
              " 9.991071428571429,\n",
              " 9.915178571428571,\n",
              " 9.452902421652421,\n",
              " 9.428418803418804,\n",
              " 9.437321937321938,\n",
              " 9.41951566951567,\n",
              " 9.339387464387464,\n",
              " 9.486289173789174,\n",
              " 9.524127492877493,\n",
              " 9.51522435897436,\n",
              " 9.346064814814815,\n",
              " 9.479611823361823,\n",
              " 10.024928774928775,\n",
              " 9.991542022792023,\n",
              " 10.011574074074074,\n",
              " 10.009348290598291,\n",
              " 60.824444444444445,\n",
              " 66.47111111111111,\n",
              " 70.09555555555555,\n",
              " 72.87777777777778,\n",
              " 74.8711111111111,\n",
              " 76.37777777777778,\n",
              " 78.02222222222223,\n",
              " 79.0911111111111,\n",
              " 80.01555555555555,\n",
              " 81.11111111111111,\n",
              " 81.70444444444445,\n",
              " 82.68666666666667,\n",
              " 83.04888888888888,\n",
              " 83.60666666666667,\n",
              " 84.41111111111111,\n",
              " 84.83555555555556,\n",
              " 85.19555555555556,\n",
              " 85.74,\n",
              " 85.76444444444445,\n",
              " 86.36444444444444,\n",
              " 86.86,\n",
              " 87.1288888888889,\n",
              " 87.49555555555555,\n",
              " 87.64222222222222,\n",
              " 87.83333333333333,\n",
              " 88.12,\n",
              " 88.50222222222222,\n",
              " 88.80888888888889,\n",
              " 89.1,\n",
              " 89.25777777777778,\n",
              " 89.65777777777778,\n",
              " 89.70222222222222,\n",
              " 89.96222222222222,\n",
              " 90.12666666666667,\n",
              " 90.10444444444444,\n",
              " 90.36,\n",
              " 90.54444444444445,\n",
              " 90.89555555555556,\n",
              " 90.83111111111111,\n",
              " 90.85777777777778,\n",
              " 91.07111111111111,\n",
              " 91.40444444444445,\n",
              " 91.45111111111112,\n",
              " 91.33111111111111,\n",
              " 91.57555555555555,\n",
              " 91.83555555555556,\n",
              " 92.04,\n",
              " 92.17555555555556,\n",
              " 92.3711111111111,\n",
              " 92.41333333333333,\n",
              " 92.32,\n",
              " 92.5911111111111,\n",
              " 92.51333333333334,\n",
              " 92.88888888888889,\n",
              " 92.69333333333333,\n",
              " 92.78444444444445,\n",
              " 93.00666666666666,\n",
              " 93.39333333333333,\n",
              " 93.30888888888889,\n",
              " 93.32444444444444,\n",
              " 93.35111111111111,\n",
              " 93.54222222222222,\n",
              " 93.63111111111111,\n",
              " 93.65333333333334,\n",
              " 93.75555555555556,\n",
              " 93.85111111111111,\n",
              " 93.92444444444445,\n",
              " 93.91777777777777,\n",
              " 93.97111111111111,\n",
              " 93.86666666666666,\n",
              " 94.10666666666667,\n",
              " 94.16444444444444,\n",
              " 94.39777777777778,\n",
              " 94.24222222222222,\n",
              " 94.50222222222222,\n",
              " 94.36666666666666,\n",
              " 94.59555555555555,\n",
              " 94.61555555555556,\n",
              " 94.5911111111111,\n",
              " 94.36888888888889,\n",
              " 94.55333333333333,\n",
              " 94.77777777777777,\n",
              " 94.77777777777777,\n",
              " 94.92222222222222,\n",
              " 95.02888888888889,\n",
              " 94.99777777777778,\n",
              " 94.98444444444445,\n",
              " 95.06222222222222,\n",
              " 95.37555555555555,\n",
              " 95.20666666666666,\n",
              " 95.24888888888889,\n",
              " 95.2311111111111,\n",
              " 95.24444444444444,\n",
              " 95.39777777777778,\n",
              " 95.36222222222223,\n",
              " 95.51777777777778,\n",
              " 95.42222222222222,\n",
              " 95.4088888888889,\n",
              " 95.57111111111111,\n",
              " 95.60888888888888,\n",
              " 95.64444444444445,\n",
              " 95.70222222222222,\n",
              " 95.74888888888889,\n",
              " 95.7688888888889,\n",
              " 95.75333333333333,\n",
              " 95.89111111111112,\n",
              " 95.73333333333333,\n",
              " 95.99333333333334,\n",
              " 95.92888888888889,\n",
              " 95.98222222222222,\n",
              " 95.89111111111112,\n",
              " 96.08444444444444,\n",
              " 96.20444444444445,\n",
              " 96.06666666666666,\n",
              " 96.0111111111111,\n",
              " 96.01777777777778,\n",
              " 96.30888888888889,\n",
              " 96.31333333333333,\n",
              " 96.27555555555556,\n",
              " 96.34444444444445,\n",
              " 96.23333333333333,\n",
              " 96.24888888888889,\n",
              " 96.30444444444444,\n",
              " 96.35111111111111,\n",
              " 96.42222222222222,\n",
              " 96.48444444444445,\n",
              " 96.68444444444444,\n",
              " 96.46666666666667,\n",
              " 96.41111111111111,\n",
              " 96.70666666666666,\n",
              " 96.51555555555555,\n",
              " 96.50888888888889,\n",
              " 96.80666666666667,\n",
              " 96.62666666666667,\n",
              " 96.75555555555556,\n",
              " 96.73555555555555,\n",
              " 96.94666666666667,\n",
              " 96.78444444444445,\n",
              " 96.81555555555556,\n",
              " 96.87777777777778,\n",
              " 96.95777777777778,\n",
              " 96.76666666666667,\n",
              " 96.82222222222222,\n",
              " 96.92666666666666,\n",
              " 96.96222222222222,\n",
              " 96.91555555555556,\n",
              " 96.93333333333334,\n",
              " 96.85555555555555,\n",
              " 96.97777777777777,\n",
              " 97.04222222222222,\n",
              " 96.94444444444444,\n",
              " 97.12,\n",
              " 96.9888888888889,\n",
              " 97.06444444444445,\n",
              " 97.09777777777778,\n",
              " 97.18,\n",
              " 97.00666666666666,\n",
              " 97.05111111111111,\n",
              " 97.08222222222223,\n",
              " 97.13777777777777,\n",
              " 97.11777777777777,\n",
              " 97.20222222222222,\n",
              " 97.07555555555555,\n",
              " 97.1288888888889,\n",
              " 97.32666666666667,\n",
              " 97.21555555555555,\n",
              " 97.08,\n",
              " 97.28888888888889,\n",
              " 97.28,\n",
              " 97.20222222222222,\n",
              " 97.27777777777777,\n",
              " 97.30444444444444,\n",
              " 97.30666666666667,\n",
              " 97.2,\n",
              " 97.22222222222223,\n",
              " 97.27777777777777,\n",
              " 97.39777777777778,\n",
              " 97.36666666666666,\n",
              " 97.35111111111111,\n",
              " 97.28444444444445,\n",
              " 97.22222222222223,\n",
              " 97.37777777777778,\n",
              " 97.36444444444444,\n",
              " 97.34666666666666,\n",
              " 97.33777777777777,\n",
              " 97.34444444444445,\n",
              " 97.41555555555556,\n",
              " 97.27111111111111,\n",
              " 97.30444444444444,\n",
              " 97.32888888888888,\n",
              " 97.35333333333334,\n",
              " 97.48222222222222,\n",
              " 97.31333333333333,\n",
              " 97.28666666666666,\n",
              " 97.28444444444445,\n",
              " 97.34666666666666,\n",
              " 97.27333333333333,\n",
              " 97.47555555555556,\n",
              " 97.31333333333333,\n",
              " 97.32888888888888]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "JHKohhBDJRIP",
        "outputId": "8ea9358a-2b3f-46ae-d0b0-1ce551d0ed9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc_array shape  237\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x576 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABrgAAAI4CAYAAAAxqel1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5ycVd3//9dn2vaWbHpIljSSCCQQihIkAfFGQxMbINK95VaxgCjeeitw28CCgH5VuP0hRUUERYoUEQi9RhPppJKezWazm+1tzu+P69rkmtmZ3Zntm7yfj8c8MteZc53rzMw1m5nrc87nmHMOERERERERERERERERkZEiNNQdEBEREREREREREREREcmGAlwiIiIiIiIiIiIiIiIyoijAJSIiIiIiIiIiIiIiIiOKAlwiIiIiIiIiIiIiIiIyoijAJSIiIiIiIiIiIiIiIiOKAlwiIiIiIiIiIiIiIiIyoijAJSK9ZmZLzcz5t3VD3Z99WeB9cGZ2Sw911wXqLh2g/ixO6tN5A3GcwZLN6ysiIiIiIiIiIiIDTwEukT4ys4qki98DcbtyqJ/nSGZmeWbWEHg9zzaz+sB23Mym9tOxnkh6787oj3ZFRjoz+0fSZ6PDzPYb6n6JiIiIiIiIiMjIpACXiOwLjgfy/futwF+BPwceN+Dsvh7EzKYAiwJFtf6xZIhptuHQ8gNZxyYVh4BPD0F3RERERET2KSkG5q4b6j6JiIj0BwW4RGRfcHLg/lLnXB1wa1KdPge4/DYssP0n51xzP7QrMtKdTervHOcOdkdERERERERERGTvEBnqDojsBTYC+2dY94/AkYHtM4EXMtivJttOicfMDDgpUHS//+8TwHpgir89y8yOdM692IfDJQfJkoNoIvuqdIGsA/rhcyciIiIiIiIiIvsgBbhE+sg51w6sy6SumSXP5tnqnMto3+HIObd4qPuQgcOBCYHt+wCcc87Mbge+FXjsbKBXF9rN7EjggEDRaufcs71pa6A55yqGug8jjXPOeq4lqZjZe4FZgaKHgA8Hts+ll587ERERERERERHZdylFoYjs7YLpCVc459YHtm9LqnuGmUV7eZxzkraT2xbZVyXP3vo68Hpg+wwziw1if0REREREREREZC+gAJeI7O1OCdy/P/iAc+4d4PlA0WhgSbYH8C/Onx5sGgW4RDCzHBI/Gyucc68BtwfKykgMRIuIiIiIiIiIiPRIKQpFRigzOxCYi5d+rwBY55z7Qzf1C4AD8dLolQN5QC2wHXjFObd6wDvdDTObBhwK7AeEgW3As865NX1ocwpwcKDovhTVbgXeF9g+B7g3y0OdiBcc6/RUd6knzWwM3nsxEyjFe747gc3A88657Vkef1CZ2cHAfLxzrw5vHbpnnXM7+qn9YX2u9oaZFQPvBybhnSt1eOf4i0mzCvvjWGXA0XifpWKgClgOLHPOuf48VgZOwQtgdfqd/+8fgB8CnakfzwX+3NeDmVkpcBTeuVnuF1cDbwHLnXN1w6ndwWRmhXjnxSRgLNAIPOQH+tPtMw3v/5mpeOdSO97zXgu84Jxr7Ke+hYEFeH8Tx+D9n1aHl/53hXPu3f44joiIiIiIiIjsXRTgEhmmzGwd3kVFgCc717sys/OBrwLvSdqlFu+icbCNqcAZeLMjjgDSpt8zs3eB64AbnXNNGfZxKbDI33y3u7Wd0tX11676AXAsey52B/d7EbjEOfd88mMZCM7e2gK8kqLOncD1QI6/fZKZlTnndmZxnLOTtm9NrmBmhwFnAh/Cu2Cclpm9BFztnLsniz5kLN25lcF+pwBXA3NSPNxqZvcA3+pNAGogzlUzOw/4bYqHpppZd4GeY51zS5PaCta/1Tl3Xjf7B/c7DPgu8AHSPCczexXvdb0jkwCUmV0JXBEo2t85t87MJgA/Aj4O5KbYdaOZfcs5N5izC4PpCeP4f6OccxvM7Elgsf/Yh81srHOuMtsDmJkBpwGX4Z074TRV28zsWeAWvNe6dbDa7cP5sxh4IlB0vnPuljR1zyPxfD/WObfUzCYB1/jPJT95N2B3gMtP0fofwCeB44GJ3XSvzczuB77vnPtnJs8nRZ9nAP8DfAQo6abeKuAu4FfOuQ2B8t8DnwpUneucezPLPlwLXBIoOsY593Q2bYiIiIiIx8zy8Ab2TcEbGNYEVAL/dM693ce2D8AbaDkeKMQbfFUPbABWAm9lM6DPzEJ4AysPwhsAVgC0AruA9cDbI3FwpYjIvkYBLpERwk/1dTvwiQzrh/FG2XcJGqUxFfgZcJ6ZnToYI+bN7IvAT+kmmAEcCTxpZp92zv0py0MEA1wPpPqy65yrMbN78S7oAnSmG/x1Jgcws1F4M7g6NQJ3J9U5Dngsi34fAfzFzO4ALsw04DhQ/Av9/w/4XDfVOl+3JWZ2GtCRRfvD/lzNlv+aXYMXHOnpeR0E/B74rJmdlmVwtfN4i4A/4f0wS2cycKuZHeqc+0q2x+hFn8YBJwSKnnDObQ5s386eAFcEL1BxXZbHmIj3eXtfT3Xx/s4s9m8r8Ga1DWq7g83Mjgf+SOIM0+58279lIgp8FDjVzC53zv00i34Z8L/AN8jsu+gM4L/xAnTBc/dGEgNcn8EbAJJpP2IkDlB4W8EtERERkeyZ2Szge8BJeBk4UtVZg/c77tfOufYM240CX8L7LTq9h+q1ZvaY3/6j3bRZCFwOXED3A7ows+3AI8DPnXMvZdJnEREZXApwiYwc17EnuOWAf+Glb3LANGD/pPpG4oV1hxdEWAnU+NvleCOgygP15gGP+hfB6/v3KQQ6Z/Zp4IZA0WvAKqAF74vrgkD/o8AtZvYv59zKDNsvYs+MMUidnrDTrewJcIGXpjCjABferKNYYPueFOnKktc7bAXexEvtV+vvPxHvvQjOsDgT7zU4M8O+DJTr6BrcagFewJsZV4YXlCsDioB7gK9l0f6wPld76f+AC5PKWvFes814qSkPI/H5LAKeMrNjsgxyzQXuwEshB955tRxv5OEEvCBNcEbXl83sFefc7xhYZ5H4PSP5eHfjBU47+3YuWQS4zGwO8A+6/ihtAZbhnZvteK/xwXip74as3SEwE/gJe86LHXizWKvx+nxIin2S/1bV4f1trsQbHZuPF2yay54ZbWHgJ2bW4Jzr8e+mH9D+I95Mw2Rv4/0/UOv3eyYwizRBYufcU2b2FjDbLzrbzL7hnGvrqR++j5D4Gfz/MtxPRERERHxm9hW8TBLdDVwF77rFz4GLzOzEnlK1+6n9HyH199ZUSvAGYIWBlAEuP4PAo0BFhm2OAT6N911aAS4RkWFIAS6RkWEBe4I1vwP+2zm3MVjBzCpS7NcO/BUvtdMjzrna5Ar+tPwP4l0IPdAvnok3++QL/dD3VMrxAgD4/fuac25VUr/m4F0E7VxDKw9vRNjpGR7jQ+wJPDXS/QyqR4CteKkOAN5nZjOS+5TGOUnbXdIT+mqB2/Ce79OpLsCaWT7el+cfsGfGxRlm9hfn3F0Z9KXfmdmH8EbMdXJ4gckrgueTPxPiQuDHeEGuH2Z5qIE4V+8Glvr3/4g3GxBgE95aROlszbLvyf08l8TgVudrdqVzriZQL4IX1LmWPUGIA4Ffkl1Q8zZ//1eBLzvngintOmcZ/orEIO41ZnaHcy7jmXa9EExP2ETSGlvOuV1mdl+gX/PN7CDn3Ks9NewHsO8hMQhViZe68bZUa0OZ2UF4r+tnB7vdIXItXuqWLXiznv4cfL/9z2yqmV1rgZvxBgW8mmrmq5mN99v8Knu+S/7MzB7MYE25/yUxuOXwUit+zzm3NsWxRuGlV7woTXs34T1X8C5AnErSLNpufCZwv430f79FREREJAUz+x+8lOxBHcDLwLt430fn460D2+lA4Fkze3+6tav9Gf9/oWtwaxve754qvBToJXgDZGfQwzVOM8sFHqJrcGs98AbeQLCw3+ZMvIBcpllGRERkqDjndNNNt0G64V1sd4Hb4m7qrkuq64AfZnEsA6ZkUb8AeD5wrEZgVBbPZ12Wz90BvwCsm33GATsD9ZuBsgyfz22B/e7NoP5Pkvp2VQb7zEraZyMQSlFvFFCYxXsxC+8Le2e7L2awT7Aft/RQN3huLe2mXghYndT2ZT20vdh/n5Lf6/NGyrnal9cX7wdcTVL9S3po+0igIWmfD3ZT/8oUr+/zQFEP7+UzSfssyfZ1yOL1mp90rDvT1Ds5qd5PMmz/F0n7vZXpOeSfPyk/jwPYbsafz6T9FmfxOTovxXmxGW+NtkyPN5kUf8O6qf+xpONd00P9w/EuRHTWbwM+lcXxxqUoG4UXQO1s8+EM25qKd/Glc7+7+/tzoJtuuummm2666TZcbnhBneD3tnX90OaxSd/tHN6auxOS6hnezPnNSXWfAcJp2j4xqe5KvHWNU14/8L+Ln4o3sPGuNHW+kNTmS8Dh3Ty/UryMLX8Drh3q91A33XTTTbfUt+RUNCIyfC0H/ifTys7T00j6YP0GEkfI55G4hlV/ew3vwr/rpk/b8GaedMoB3ttTw34KrCWBovsz6E/yyP1PZ7BP8uyt251z8eRKzrlql0UKPefcO8BVgaIj0szQG2gfxhu11mmpc+4n3e3gnFuKFyzM2Ag4V7NxLt6Iv04PO+d+1t0OzrkXge8kFX85i2O2AGe6rqkxg8eI482cCVqUxTGydW7Sdrp0iA/jBXM7neV/ftPy1/YKzpBrAk7L9BxyzjWk+jwOVLtD7GKXYlZUOs65jan+hnVT/894I2s79TTD9pskjoL9vnPuD1kcb1uKsmoSZwd+0Mz2y6C5C0lMyfibTPshIiIisq/zs2vcSOJ3uxucc59yzm0J1vV/7/0VOAZvBlanhXjrYKVyUuB+O/AfzrnH0l0/8L+L3+ucO4PENVbTtbnDb/PlNHVxztU45/7onDsR73usiIgMQwpwiYwc17mBTSeGc+7feOmpOh2Zrm4/+JnLbJ2UB5O252Wwz0L2pN5yZBDgcl5atH8FiqaZWdo0dn7KhOQg2G0Z9C1T9yZtD+R7kc5ZSdvfy3C/H+HN4howg3yuZiP5Nbsiw/1uALYHtpf4qdky8SeXJrVHksfxgmGdMvksZc1PvfipQFEVXiCrC/9vwJ2BovHACT0c4mwS1xT7tXPuzV50dbDaHSpr8NItDrTg36qpfqCwCzMbizeqttM2vHSs/eHGwP0Q6S+UdPYlhDfjrdN64O/91BcRERGRfcGH8dL4dXoNL311Ws5bAiA5tfyXUtUFpgTuL89y0Fa636LBNp9wgfTxfWhTRESGmAJcIiNHJrOQMmJmuWY21symmllF8IY3kqnT7P46ZgopL3in8FbS9pgM9jk5cP+lVKP+07glaTt5hlbQIrwUV51ezvZiuHkKzGxCivcheYHegXwv0nlf4P524IlMdnLO7SLz97dbw+RczYiZ5eCtl9dpjXMuo4WI/UBPcJ01I4PZir6MXmvnXDsQXFcuk89SbywBxga2/9RDMDt5dlfy7K9kxyZt99fMm4Fqd6g80N0M2WyYWcjMSsxscorPYfLAi3SfxUUkjvC9zTnX2h/9c849DQT//p7vD0JI5wQgOMvr5mxmromIiIhIl4F93/V/b3TLzwCwPFB0oJnN72G3gfjdMlC/hUREZJApwCUyMqz30zD1ipnNNLMrzGypme3AS721DW8tprVJt8MCu5b1vsvd2uWc25xh3dqk7eIM9gmmq8smMPgHvDVhOn3CD1qkkhz8Sk5xmJKZLTSzn5vZy3jrLtXj5SJPfh9WJe06UO9Fun6OInHx3X9meQE4baqHHo473M7VbBwIxALbL2a5/wtJ2wtS1uoqm8Bq8POUyWepNzJNTwiAc+4FEs/3U8ysJF19Emfr7XDOvZFl/wa73aGyvOcqqZlZjpl91Mx+b2ZvAq14a8ttoOvnMPn9TfdZTJ5l+XRv+5fGTYH7U4EPdlP3M4H7ceDmfu6LiIiIyN7uqMD9RuC+LPZNTlF9VIo6bwfuTzWz5JlfvRFs82gzGy5p7kVEpA8U4BIZGbb3XKUrMys1s9/gfZG7Em8EfaZpz2DgLoAnB63SSjHzI3lmUwIzOwCYFSjK+Iu2c66KxJSIpaRY28nM8oCPBYpagTt66NccM3sKbyHdi/GCM3mZ9o2Bey/SGZu0vTrL/ZMDdN0axudqNpJHAa7Mcv+3k7YzHVWY8eeJxABut5+l3vADo8Hc9qudc89nsGswSJJLmrWczCzKnvSj0HWGZ68MVLtDrLf/b5yI9/z/jJdqcjbQ7bpoSdJ9Fscnbfd3+sfbSEyN+plUlfxUicFZvn93zm3o576IiIiI7LXMbDSJ2UxWZJnCL5OBfX9M2v6FmT1qZp8ys94Obgy2GQb+amZ/NrOPmFlhL9sUEZEhpgCXyMhQn+0O/pe+x4ELSUwLlY2B+hsxkKmgghcu1/lra2UjeSZWqgVqP0LiRdwHupthZ2aHAs8C78+yL0GD/fe6NGl7V5b7Zxx0Gebnajb6+zXL9IfbcEqtdiaJs9h+n+F+maYpTA56Zpw3vwcD1e5Q6s3/GxfgzXqt6MNx030WRydt9+tr7P8NvjtQdKp/8SXZuSQGd/+vP/shIiIisg8Y8IF9fqr3XyYVH4/3+6LKzJab2f8zs9P9AUyZuBt4ILBtwEfx1q3daWYvmNlPzexUM0v+bSciIsPUcLggKCID41rgkMB2M94I97P98nFAARB2zlnnDXhy0Hvav3qbnrDT30hc2+lDZpb8hTs5PeFt6Rozsxje7K5gsKIS+ClwKvAevIvrecH3wX8v9hX76rm6N0oOTH3HzFxPN7rO+DvKzGbSs35ZY2oQ2x22/Nf7VyQGmV8Hvgl8AJiBF9jPSfocJq9dlqmBeI1vDNyPkXodxQsD97fRj+tbioiIiOwjBmtg38XAt/BSIAaFgHnA5/FmZW0xsyfM7OPdrcPqp9z/GHAdkLxeWAQvpfalwF+BSjO738yOz+D5iIjIEFKAS2QvZGb7kXiheTMw3zl3rnPud8655c65SudcY4p1lYoGr6f9y0+PFszfnU0ecACcc8npBqPAGYFjjCdxbZfktIbJPkliysSlwEzn3GXOufucc28453Ymp3Qws6F+H5JnV2SbArC7NZR228vO1f5+zXb2oS+DzszmAIf3Y5OpghPJMyX7a2TlQLXbV4P5Pe1yEmff/QQ4yDn3Q+fc48651c65Ov9vZFCmn8MBf42dc88AwbXTgsEszOz9wAGBottSpMEVERERkWHAeX4ATMP7rvo8XQNT4H1nXgzcBTxpZhO6abPVOXcJ3m/07+KtW5sqI0YUL/X6o34aw+H221NERHwKcInsnZaQOAr/68655DQA6SSvkzKSnMietWJ20fsZPslpCoMX2s8icT2aP/RwgfTEwP04cK5zLpMRbkP9PlQmbU/Pcv8ZGdbbm87V5DWPMn0NOs1K2u7VGkpDKF1awd76dPIITP+zFgyUzO6PAw1UuwEdgfuRLPYbzEBb8G/VO8DlzrlMZlll+jncmrQ9J8P9snVT4P57zOy9ge0Lk+r+ZoD6ICIiIrI3G9SBfc65bc65HznnjsKb7fUBvHWbn6RrwOv9wMNmltNDm2udc99xzh0ClOP9Lr0aeJmumQY+ihc8ExGRYUgBLpG9U/KF9Ucy2cmfTTOx/7szaILpCR/u7ch859wrJM4COMyfnQJdZ5UkB8OSBd+LN51z6zPsxnt7rjJw/PVs1gWKFphZNv9nZDqTZ7DO1cFIOfcaEJzdckSW+ye/58v61p3B458bnw4UNeAF7PbP8hb8PFUAi1Ic7vnA/fLAZ7OvBqpdSEzbkk3Qam4/9iEtMysgMVD1aIoZk+lk+rfq+aTtvqxJ2J3b8NKcdvoMgJkVA58IlD/lnHtngPogIiIisjcbsoF9zrl6P7vAVc65xcAE4H+ApkC1g4ELsmhzp3PuIefcfzvnjgCm4i0pEBykdoKZfTjTNkVEZPAowCWyd0oeEZVpTuyz+rsjg8Vf6+qEQFHW6QmTJAeuzjazeXhflju95pz7Zw/tBN+LbHKTD4f3IuGCPxmutWNmJcCHMjzGYJ2rLYH7sbS1+sA510JiUGqGmS3IZF8zi5B48d0BL/Zj9wba8cCkwPbfnHMrnXPrsrnRdT27VLPCnkja/kw/PYeBahcSf7RnMzvshJ6r9ItefQ7NLB84LcNjPEli+pdzzCya4b4Zc87tJHGE7elmVgh8CsgPlGv2loiIiEgvOOd2AO8Giub1NGMqSb8N7HPOVTnnvg/8Z9JDJ/ehzQ3OucuAK/qrTRERGTgKcInsnZJTBiSPkOrCzMYAlwxMdwbFYvasBdMOPNTH9n5H4sXYs+h6sT35YnwqwfdiRiazoMxsEfAfGbQ90H6ftP0/Ge73NSA3w7qDda4GFzIuN7Nw2pp984ek7e9kuN/FwNjA9kP+D8eRIvmzcWcv23kS2BbY/rg/uyjodhJn6PyXmfV43mRgoNoFWBG4P93MZva0g5ktBI7up+P3JOvPoe8y0i8KnsA5tx1vwe5O44FvZHicbN0YuF8InE5iwLIGuHuAji0iIiKyL3gucL8Ab72qTH0qaTt5pn9v3EnioMaKfmgzedBrf7QpIiL9TAEukb3Tq0nbl3ZX2R+F/0cSL7CPNMHRVM/6KfZ6zTm3GXg0UDQF+EJguwMvCNaT4HsxhsQ0bl2Y2Qy/Xeuu3iB5CFgT2F5sZpd1t4OZLca76J2pwTpXg+t6RRm4wMGtJAbTTjGzz3e3g5kdjrfAcdAN/d2xgeKnfgvO4qkHHuxNW865DuDPgaJCvJz3wTqVJM6+yQf+amaTM+xvgT+jJ/nYA9KuL3l22Ld7aGsiXsBtUDjnGkn8rJ/UUxDOzE6ih+eRwg9JTBf6HTM7PdOdzWxcJvWcc88CrweKrgCCsyl/75xrQkRERER6K3lg37cyHMz5EeCQQNHrzrl/9bUzzrl2vDTpnVrT1c1CclaD/mhTRET6mQJcInunh4DGwPb5ZnatmRUlVzSz9wPPAsfhXXgcSbNGgoIBrvv7qc3kEVvB1HaPOue2ZNBG8iyBX5vZ+ckziMwsambn4L0Xk4GqrHvbz/w1eL6QVPwjM/uZn4ZwN7//n8N77XPoOiMkncE6V59K2r7VzC40s/lmtr+ZVQRumc4+68I5V0fXIN3PzezHKV6ziJmdjxdIDQZG/uScy2gtsmHiE0BeYPt+51xzusoZ+FPSdvK6dwD/TWLQcg7wipl91g+CdmFmB5rZ9/HSqaRbJ2Cg2v0jiesCnG1mPzWz4OuGmYXM7KPAC3hrkmX6OeoPwb9VOcDfzaxLINjMSszsu8A9QIQs/lb56xv+IFAUAe4ws5vMrCLVPmY2yswuMLOX8N6fTN0UuL9f0mNKTygiIiLSNw8CqwPbhwBXd7eDmU0DfpVU/PM0dT/nZ+7IiL8+1qhA0dsp6lya6ndmN5LT4ndpU0REhl5kqDsgIv3POVdlZj8lcXT9JcB/mtkLeCnAioF5eDOTOv0UOBxYNFh97Q/+2lhTA0V9XX+r01/xRm0Vp3gsOfiVknPuITN7CjjGL8oDbgZ+YGYvA3V461sdAZT6deJ4i+L21/PoNefcw2Z2A/Alv8iArwCfM7PngK14KcqOYM8Pinq8C9HJP15StT9Y5+pjwBvAXH97Kukvch8LLM2w3S6cczeb2THsSdsXwpvV9kUzex7YgvdeH4733ge9AXyut8ceIv2VnrDT03iv0QR/+zgzm+yc29hZwTlX7weCHgUm+sXj8FLT3eB/trbgzbQcg7d2Xo8/kAew3Z1m9j3g+4HiS4HP+J+jarzP0WGB9qqAr+P9vRgMPwEuBEb72xXA02b2FvAa3nOeBByJNwuys4+XAbdkcZwr8NYh+5i/bXhrJvynmb0JrGLP392ZeOkSOwdkPUfmbsO7yJKXVL7MObc8i3ZERERE9kaRdAOMeuKvnxs3s4vwvjd3Zh/5mj/j/uvOud1px83MgFOAX+Klqe70POl/k10OXGtmf8FbX/UxfzBhAn8t40/RNQNGqmwrP8XLIPAnvMFdT6ea1e8PQruIxICdo+usNRERGQYU4BLZe12FN/vg44GyQuD4NPVvwvsS+fgA92sgBGdvveWcW9kfjTrnmvwvv59JeqiWxLVkevJJvIDJ7EDZeFIvUtsGfNY5d7/3O2BY+ArejI6LAmU5eIGgZA14KeXasmh/wM9V55zzU6H9jcRA2UA5Hy9o8RX2/ODLwVsrLp1ngFP7ml5zMPmjMIOzfHYBD/elTf/H8t3AF/2iEHA2Xnq7YL03zOxIvJlEhwUeyqEPKSgHql3gR3iB2k8GyoqBD6WouxVYApSkeGxAOOe2m9lpwAMkBvVnk/i3q9M24ET2rH2Y6XE6zOyTeO/nZSRmE5jj3/rMOVdjZnfRdQagZm+JiIiIeAOX1vZyXwNwzj1mZv+LN4Cp0znAWWb2IrAeb32uQ/CylARtBj7tpyhPJxcvePUpwJnZO36fd/qPT/DbTv7O/FfnXLqsLiX4g6uAdn+A1Qa/zbDfzwV0HSR1vXNuBSIiMuwoRaHIXsr/ovhJ4Mt4F0vTeR74mHPuIj8l3Uh0SuB+f6Un7JRqptZd2aRg80evHYGXfiHdui+teBfUD3fO3ZJtJweS8/wX8BHgzTTV2vDWTjrUOfdomjrp2h+Uc9U59xpwEF7axQeAdXizzVw3u/WK/5pdCrwX+DvQ3k311/F+CB4zkoJbvnNIXC/uPudcS7rKWUieBZY8SwwAf1bXEXjpQ5bR/XvZijfC9Ey8GUlpDUS7/roAZ+IFPdOl9avHC+DO64+1CLLlnHsaL6j3AOmfczXw/4CDnHPLenmcuHPucrzP450krpeQytt4gfBrsjzUjUnbjWjkrYiIiEi/cc5diTdoKfh7JwwcBZyBN6gzObj1BrDQObeGzBlwAN7gsDP922K6Brfu9I+biQje99EleN/7z8Ab0BYMbjngOuCrWfRVREQGkTnX79f1RGSYMbMo3sXag/HSYO3CS7P1T+dcb0dtDQtmNh5v9FfnRfb3O+eeGcIudcvP+f1+vLV6CvEudG8CnnPO7exu3+HCzOYD8/FmodUBG4FnnXN9XqETJLEAACAASURBVDdsbz1X/fW3jsEbKTkKL5CxDXjRObduCLu2V/FTohyFl1ZwNF7wqRovQPIv51xPgZRBaddPpfI+vJSZo/DW2loPPOmcq+9NH/ubmU3E+1s1Ge/H/1a8Pj7jnMtmhmYmx4rhvb4VeCkao3if/bXAimB6yizbfQ+JQcdbnHPn9623IiIiIiOPn46wX35POee6pBoxs9nAd4GT8GZepbIWuB74ZU/fJ/1lCE4DTsCbURXtpnoceAK41jn3YDdtLgROBT6IF9gKp6uL933/YeBq59zz3fVVRESGlgJcIjKimdl/4s14AC9YNL6HNAciIrIPMLOfkDja9mjn3LND1R8RERGRvZ2Z5eMNkpqCt95wE1CJNygsXTaQntrMBQ7EGyQ6Hm+gaBve0gGr8AZDZpUJwx94eiAwHRgL5AMteAPPOgexdVnzS0REhh8FuERkRDOz+/FGiQHc5pxLmcpMRET2Hf6ssI14M8IA3nTOzR3CLomIiIiIiIhIP4sMdQdERProabw1cqD/198SEZGR6dPsCW4B/GqoOiIiIiIiIiIiA0MzuERERERkr2FmpcCr7FnQvBaY6pyrHbpeiYiIiIiIiEh/0wwuERERERmxzGwy3nfaPLwFw7/DnuAWwHUKbomIiIiIiIjsfTSDS0RERERGLDNbB0xN8/Aa4CDnXOPg9UhEREREREREBkNoqDsgIiIiIjIAdgAfVXBLREREREREZO+kGVy+8vJyV1FRMdTdEBEREZEsvPrqq7S2tgJgZsRiMUpKShg/fjzRaHSIeyf7mmXLllU558YMdT+yYWY3AycBlc65A/2yUcCdQAWwDvikc26nmRlwPbAEaATOc879s6dj6LeWiIiIiIj0RbrfWlqDy1dRUcErr7wy1N0QEREREZERyszeHeo+9MItwC+A2wJl3wAec85dbWbf8LcvBz4MzPRvRwK/8v/tln5riYiIiIhIX6T7raUUhSIiIiIiIvso59xTQHVS8anArf79W4GPBMpvc54XgFIzmzA4PRUREREREUmkAJeIiIiIiIgEjXPObfHvbwXG+fcnARsC9Tb6ZV2Y2WfN7BUze2X79u0D11MREREREdlnKcAlIiIiIiIiKTlv0easF252zt3knDvMOXfYmDEjalkyEREREREZIRTgEhERERERkaBtnakH/X8r/fJNwH6BepP9MhERERERkUE3IgJcZnazmVWa2WuBslFm9qiZrfT/LfPLzcxuMLNVZvZvMzt06HouIiIiIiIy4twHnOvfPxe4N1B+jv+b671AbSCVoYiIiIiIyKAaEQEu4BbgQ0ll3wAec87NBB7ztwE+DMz0b58FfjVIfRQRERERERlRzOwO4HngADPbaGYXAlcDHzSzlcDx/jbAg8AaYBXwf8Dnh6DLIiIiIiIiAESGugOZcM49ZWYVScWnAov9+7cCS4HL/fLb/FzxL5hZqZlN0MhCERERERGRRM65M9M89IEUdR3whYHtkYiIiIiISGZGygyuVMYFglZbgXH+/UnAhkC9jX6ZiIiIiIiIiIiIiIiI7AVGxAyunjjnnJm5bPczs8/ipTFkypQp/d4vEREREREREREREZHhoqWlherqaurq6ujo6Bjq7sg+KBwOU1RUxKhRo8jJyelTWyM5wLWtM/WgmU0AKv3yTcB+gXqT/bIunHM3ATcBHHbYYVkHyERERERERERERERERoKWlhbWr19PWVkZFRUVRKNRzGyouyX7EOccbW1t7Nq1i/Xr1zNlypQ+BblGcorC+4Bz/fvnAvcGys8xz3uBWq2/JSIiIiIiIiIiIiL7surqasrKyigvLycWiym4JYPOzIjFYpSXl1NWVkZ1dXWf2hsRAS4zuwN4HjjAzDaa2YXA1cAHzWwlcLy/DfAgsAZYBfwf8Pkh6LKIiIiIiIiIiIiIyLBRV1dHcXHxUHdDBIDi4mLq6ur61MaISFHonDszzUMfSFHXAV8Y2B6JiIiIiIiIiIiIiIwcHR0dRKPRoe6GCADRaLTP68CNiBlcIiIiIiIiIiIiIiLSN0pLKMNFf5yLCnCJiIiIiIiIiIiIiIjIiKIAl4iIiIiIiIiIiIiIiIwoCnCJiIiIiIiIiIiIiIjIiKIAl4iIiIiIiIiIiIiIyAC48sorMTOWLl06YMeoqKigoqJiwNofrhTgEhERERGRftXaHufNLbuorGvuc1s76lvYVNPUD70SkRGhuRY2L4d3n4MNL8GmZdDaONS9EhERkb3EunXrMDPOO++8oe6K9IPIUHdARERERGS4WFvVwNK3K8mLhpk1vohZ44oozEn8yhyPO/61oYbtdS2EQ0YkZJTkR5lcmkd5YQ4AVX5QZmdjK02tcRpb22nrcDgczkFRboSZY4uYNqaA3Gh4d9tNrR1U1bewo6GVDdWNvLFlF29s3sXW2mYKcyMU5UYoyo36/0Yozo1S7JeV5EUZU5TD2KIcYpEQy97dyUtrq3l98y4cjpB5fQ2HzLsf9v4N+2Vhvwxge10rW2qbqKpvoWJ0AQumljF/v1JyomGaWttpbO2gsbWDJv/fxrZ2mlo7aGjpYFVlHW9uqaO1Iw7ArHGFLJxRzrRy77nmxyJEwoYBZkZdcxuVdS27X88JJblMKMlj485G/v76Nl55t5q4g8llebxv2mhmjC2kPe5obY+TFwvzX4umD87JISIDo3otvP0gvPMwbHsdGnd0rTPvTDjt14PfNxEREZF+cPHFF3PGGWcwZcqUoe7KXkcBLhERERHpd/G4o7qxlfYOx7jiHMy8wMnOhlaeWVXFhp2NzJlQzMGTShhdmENDSzuba5rYtquF+pY26ls6qGlsZePOJjbubKS2qY1DppRx9IxyDq8YRVs8Tm1jG7VNe241/nZNUyt1ze1EQkZOJEQ4FGLbrmY2VDeypbaZiaW5HDiphPdMLCHuHNUNrWytbeaZVVWsqqzv8lymlRcwb79SDppUwtqqBh5+fSvb61pSPu9YJASO3cGdnoQMSvNjNLd10NIepyPuEh6PhIyZ44qYMjqfxtZ2qhtaeXdHI7ua2qhrbu/xOLFwiNkTioiGQ3TE3e5b3Dna44543NHhHO0dXpn3GJQXxphQksvs8cWsqqzjpqfW0J7Ut+TnnR8Lkx8NM3V0AecvrGDuxGK21Dbz7Koq/vDielrau+9rfixMR9wl1Js9voiLj5tJWX6UF9bs4NE3t3HXso27H59UmqcAl8hIFY/DHafDyr9722PnwpyToWx/GLU/5BR5dR76GjTtHNq+ioiIiPRBeXk55eXlQ92NvZICXCIiIiIjUH1LO4+9uY0n39nOxJI83jd9NAumlpEbDdPeEaehpYPt9c1srmlma20zm2ub2FrbzNZdzUwuy+MDc8bxvmmjyY2GiccdtU1tvFvdyMptdayqrGd7XQt1Le3UN7cTCkFpXozS/CixSIjW9jgt7XFyoyEmleYzqSwP5xyvb97F65trWbu9gcq6lt0BkbxomP3LCwiHjNc21+KS4iSFORHqW9pTPs+CWJj9RuVTkBPhlmfXcdNTa3p8bWLhEEW5ETqco6UtTltHnHHFuUwuy+PwijLWVzdyx0vraW7bE0jJjYY4dEoZZx05hePnjCPuHG9vrePtrXX8e1Mtz6yq4p5/bSI3GuLYA8by4YMmMH1MAfE4tMfj7PSDcZt2NoHB5NI8JpbmMaogRn4sQn4sTDQcwgwM2NnYxjvb6lhZWc+O+hZyo2HyomHyc8KUF+ZQXhhjfHEe08cWkBMJp32uzW0d1DW3U9fcRk1TG9vrWqisa6GxpZ15+5Uyf7/ShBlivdXU2sEbW3YBjryo93zyY2HyYl6/I+H0mc//a9F0Wtvj1Da10dzmzfhq8wNzzkFBTpixxbkU5kRwfsBxS20zxblRpozO393O+Qv3Jx53NLS2E4uEiIZChELW5+cmIkPk7b95wa2jvgiHXQCjpqWu90QpxDsGt28iIiKyV7ryyiu56qqrALj11lu59dZbdz/229/+lvPOO4+lS5dy7LHHcsUVV7BkyRKuuuoqnn/+eXbu3MnatWupqKjgiSee4I477uCZZ55h48aNtLW1MX36dD7xiU9w+eWXk5ubm/K4TzzxBIsXL95dbmYsWrSIu+++m29+85vcf//9VFdXM2PGDC677DLOP//8Pj/nlpYWfvazn/H73/+e1atXE4lEmDdvHl/84hf55Cc/2aX+fffdx/XXX88bb7xBdXU1o0ePZubMmZx++ul8/vOf311vzZo1XH311Tz++ONs2rSJvLw8Jk2axMKFC/n+97/P6NGj+9z3TCjAJSIiItIHHXHHsnd38u6OBhYdMIaxRbkp6/1r/U6eXlnFoVPKOGL/Ud5Mn4C3t9Zx45Or+durW5g9oZhFs8ZwRMUoNtc28erGWt7eWofDkRMJE3eOV97dSWt7nLL8KLua2/nFE6t2p59LN1OmvNBLX/fimmp+98J68qJhinIjVDe0JszOiYVDjCnK2Z0GL94Bb9Xuoqaxjdb2OLFIiFgkRGNrB7VNbXv2i4SYPb6I904fzfjiXMYV5xIKGWu3N7B6ez3NbR185QOzeP8sL13dm1vqeHVTDZtrmhlXnMvEUm+fotwIRTlRivMilORFd8/+amxt58W11fx7Qy35sTAleVFK8r3UfKWd/+bFyI2Gdu+TTntHnHerG4mFQ34QKtxln6mjC/iP94wHwDnHtl0tlORFyYv1PWA0tjiXA8YX9bmd3GiY3GiYMUU5fW6rO3mxMAumlvV6/1gklFEfzYzRhTmMLkxdNxQyinKjve6HiAwTzsFTP/GCWsdfBaFu/q6GwuAU4BIREZG+W7x4MTU1NVx//fXMmzePj3zkI7sfmz9/fkLd559/nh/+8IccffTRXHDBBVRVVRGLxQC45ppreOuttzjqqKM48cQTaW5u5tlnn+XKK69k6dKl/OMf/yAczux3Y01NDQsXLiQWi/Hxj3+clpYW7rrrLi644AJCoRDnnntur59va2srJ5xwAk8++SSzZ8/mC1/4Ao2Njdx9992cfvrpLF++nB/84Ae76990001cdNFFjB8/npNPPpny8nIqKyv597//zW9/+9vdAa4tW7Zw+OGHs2vXLpYsWcLHPvYxmpubWbt2LbfffjsXX3yxAlwiIiIiw4Vzjl1N7Wyv99YJ2l7fQlVdC29u2cVjb1VS3dAKeOnmjtx/NB+cO46JpXmUF8bY2djGb55ew4trq3e3V5QT4chpoynKjWAG2+taeHplFXnRMCcdPJG1VfX84vGVdMacCnMizPHTzDW1ddDeEeesI6ew5KAJLJhSRkNrO6+s28nL66rpcI4Cf8bQmKIcJpTkMaHECxx1BtWa2zp4Yc0Olr69nea2DkYXxhhdkMOksjxmji1kyqj8bmfkBNW3tLNpZxMOx/QxhUQz3A/gfdNH877pmX/pzY9FOPaAsRx7wNiM90knEg4xfUxhxvXNjPElqYOXIiKSpVWPwZblcMovug9uAVhYM7hEREQGwVX3v84bm3cNdTe6NXdiMVec/J5e77948WIqKiq4/vrrmT9/PldeeWXaun//+9/59a9/zUUXXdTlsV/+8pfsv//+XQZJfvvb3+Z73/ve7gBSJlasWMGFF17IjTfeuDso9pWvfIWDDz6Ya665pk8Brp/+9Kc8+eSTfPjDH+a+++4jEvHCQVdccQVHHHEEP/zhDznppJM46qijALjxxhuJxWKsWLGCsWMTf3dXVVXtvn/33XdTXV3Nddddx5e//OWEeg0NDYRCmV8X6CsFuERERGRYiscdW3Y1Myo/ltGMmY07G7n9hXdZv6MR5yDuHLFIiKLcKMW5EVra42ytbWbLrmZiYWPWuCJmjy9iTFEubR1eGrv6lnYvgFXXQlVnMKuuhar61pRrHRXlRDh29lhOeM94po7O5+9vbOOBFZv53wfeSKg3sSSXb580l1PmTWT5hhoee3MbL6+rprUjTjzuzW655PhZnPO+qZQVeCPCahpbWbGxlslleew/uqDbVGxFuVGOnT2WY2dnFvjJjYZZfMBYFvdDoKgwJ9IvM5FERGQf4Rw89WMongwHZ3DhJ6QAl4iIiAy++fPnpwxuAUybljq18iWXXML3vvc9HnnkkYwDXPn5+Vx77bUJM77mzp3LwoULeeqpp6ivr6ewMPPBmUE333wzZsa11167O7gFMHbsWL797W/zmc98ht/85je7A1wAkUiEaLRr1oxUa4jl5eV1KSsoKOhVX3tLAS4REREZUJtqmsiPhinN35NqrnM9nrL86O6ZQq3tcV5aW80Tb1fy6sZa3tyyi7qWdsIh44BxRcyfUkrF6HxGF+QwujBGLBzavcbSfSs287dXt2BARXkBYTPMoKU9Tl1zG7ua24mFQ4wvyWV8cS4t7R3ct2Izv3+x67pPIYPRhTmUF+YwpiiHGWOLKC+KMcbfHlOYQ7n/b0leNCHwdOCkEi45fiaVfmBsR0Mr8bjj6Jnlu2c2fXDuOD44d1yPr1tpfoxFs8b0wzsgIiIyyJyDXZuhcCyEky6QvPssbHgBlvwEIrGe27IQxFOv0ygiIiL9py8zo/ZGRxxxRNrHGhoauP7667nnnnt45513qKurwwUWm960aVPGx5k5cybFxcVdyvfbbz8Adu7c2asAV11dHatWrWLSpEnMnj27y+PHHXccAP/61792l5111ll89atfZe7cuZxxxhksWrSIhQsXMmZM4rWJU045hW9+85t84Qtf4JFHHuGEE05g4cKFzJ07t8flAvqbAlwiIiLSo464o7U9Tkt7B20djmjYiIZDtLbHeXVTLcs31LC2qoG5E4o5ctooKsoLePDfW/j9i+t5dVMt4K3rNLowRn1LO3XN3oWqSMjYb1Q+44pzeH2TF9DKiYQ4aFIJpx06iVnjiti2q5nlG2q4f8Xm3fslK8yJcMHCCs5fuD8TS7uOIErFOcfWXc1UN7SSEwkRDYcoyIlQlh8j3M1sqZ6YGeP89adERESGvfYWWPFHqF4NNRugYTtE8yCnGPJKoXgSlE6BognQsgvqt0F9pf/vNmis9uqMmwtl+8PGl+HtB6F6DYyeAR/4Dsw5xTvW1lfhH1dCwVg45NOZ9S8U8fooIiIiMojGjx+fsrytrY3jjjuOl156iQMPPJDTTz+dMWPG7J71dNVVV9HSkvl3l9LS0pTlnTOuOjp6N5O9tta7FjNhwoSUj3eW19TU7C679NJLKS8v55e//CU33HAD1113HWbGokWL+PGPf8xhhx0GwNSpU3nppZe48sorefjhh/nLX/4CeEG5yy67jC996Uu96nNvKMAlIiKyj2lu62DdjgZqGtuoaWyjtqmV2qbO+23UNLWxy9/e2dhKTWMb9S09j5weU5TDPf9KHKV0wLgi/ufEOYTM2FbXzI76VgpzIowuiFGcF6Wyrpl1VY1srGnixIMncPyccSycUZ4yJaFzjobWDqrqWtjR0EJbhyMcMkIGM8cVUZzbdQp9d8zMX58qs4CYiIjIXmn143D/lyAc8wJVReO9ANaOVdC007ulkjcKCsdBXhm8+xy8+ievPByD/Y+BQ86Gf98JfzoHJh4CLXVemxaGU27wgmiZCIXBKUWhiIiIDK50M5HuvfdeXnrpJc477zx++9vfJjy2ZcsWrrrqqsHoXo9KSkoA2Lp1a8rHt2zZklCv0znnnMM555xDTU0Nzz33HPfccw8333wzJ5xwAm+99dbu2Vxz5szhzjvvpL29nRUrVvCPf/yDn//853z5y1+moKCACy+8cACf3R4KcImIiAyRzTVN5EbDjCrIID1PQEt7B69urGVnYxuFORGKciNs29XMS2ureXFtNbua2qgoL2BaeQHjS3KJhkNEwkblrhaeX7OD5etrUq4nFQ4ZpXlRSvKilORHGV0YY8bYQkrzoxTnRsmNhv2ZTkZ73NHWEccw5kwo5uD9SijOjbJtVzMvrNnBym31LD5gDAumlvXb9HQzozAnQmFOhIrywc3pLCIistdqa/L+vegpGDun6+Mt9VC7Aeq2QG6pF9QqGNM1vWBTjTcLbPRMyPXT7Cz8Miz/Azx3AxRPhKO+6M3myh+Vef9Ma3CJiIhI/+lc66q3M6NWrVoFwEc/+tEujz355JO971g/KyoqYvr06axZs4aVK1cyc+bMhMefeOIJAA499NCU+5eWlrJkyRKWLFlCPB7n5ptv5qmnnuJjH/tYQr1IJMKCBQtYsGABRx11FMcccwx//etfFeASERHZW72+uZZfPL6Kh17zRtHMnVDMwhmjKc2PsavZmz0Vj0MsEiIW8dZtau+I09rhWL29nuUbamht7xqgioVDzNuvhAPGF7G2qoHnVlfR3Lannhm8Z2Ix5x41lYMnlzK6IEZJvhfQKs2PURAL9zkYNa44l1PnT+pTGyIiIjKIOoNHoTQzoXMKvcBXquBXUF4pTFqQWBYKw6Fne7fe0gwuERER6UdlZd5A3PXr1/dq/4qKCgCWLl3KySefvLt8zZo1XH755f3RxX5zwQUX8K1vfYuvfe1r/PnPf94d3KuqquK73/3u7jqdnnjiCRYvXtzl2lBlZSUA+fn5ACxbtowZM2Z0mf21bdu2hHqDQQEuERGRPqhtamPltjre2VbPmu31OCA3GiI3EiY3GiY3GiInEqaqoYVNO5tYvb2eF9ZUU5QT4eJjZ5AbDfHMqipufe5dWjvixMIhivOihEPQ2h7fHciKhL2ZUxNL8zjnvVM5fP9RTCzJo76lnfqWdopyI8zfr5Tc6J7UfvG4o66lnfaOOO1xR14snHUaPxEREdnLdQaPQqGh7Uc6FoJ414E9IiIiIr1RWFjIkUceydNPP81ZZ53FrFmzCIfDnHLKKRx88ME97n/yySczY8YMrr32Wl599VUOOeQQ1q9fzwMPPMCJJ57Y68DZQLjssst46KGHuPfee5k3bx5LliyhsbGRu+66i8rKSr7+9a9z9NFH765/2mmnUVhYyHvf+14qKipwzvH000/z8ssvs2DBAo4//ngAbr/9dm688UaOPvpopk+fTllZGatXr+b+++8nJyeHr3zlK4P2HBXgEhER6UFVfQvPrqqixZ8N1dLewaubaln27k5Wb2/YXS8nEiIcMprbOoi7ru2U5UeZVJbHJcfP4ryFFZTkecGmi4+bSUt7B86REKDqq1DIdh9DREREJKW4v85maJheHgiF9/RRREREpB/cfvvtXHLJJTz88MPccccdOOeYPHlyRgGugoICHn/8cb7xjW+wdOlSnn76aaZNm8a3v/1tLr30Uu68885BeAaZicViPProo1x77bX84Q9/4Oc//zmRSIR58+Zx3XXXceaZZybUv/rqq3nkkUf45z//yYMPPkhubi5Tp07lmmuu4XOf+xzRqHeN6cwzz6SlpYXnnnuOZcuW0dTUxKRJkzjjjDP46le/yoEHHjhoz9GcS3EFbh902GGHuVdeeWWouyEiIn3knKO1I05OZE+gqCPueH71Dl5Ys4Omtg5a2jto73DkRELkxsKU5sX4wJyxzBpXtHufnQ2tPP5WJfet2Mwzq6roSIpYleZHWTCljEOmlDJ3YjEzxxYxqTSPUMhwztHW4Whp76C5LU5Lewdl+TEKcobphSMREekXZrbMOXfYUPdjuNFvrWFu2S1w/5fh0je9dbKGm7vOh63/hi8uG+qeiIiIjHhvvvkmc+b0kHZYZBBlek6m+62lK20iIjLi1DW38dBrW9m4s4lDp5SyYGoZDrjnn5v4/YvvsrKynhljCpm3XymFOREefHULlXUthENGXjS8e6ZVS3ucprYOWtvjXPPwW8weX8RR08tZvmEnyzfUEHcwqTSPi46ZxpKDJlBW4C2mHjZjXHFO2vWqzIxYxIhFQhTlDuILIyIiIpKtzjW4rP9mkferUGRPH0VEREREAhTgEhGRYa2uuY03t9RRVd9CVX0Lr6zbyd/f2Epz2561GEIG0XCIlvY4B08u4b8WTeftrXU8/lYldc1tLD5gLB+ZP4kPzBmbMgXg9roW/vbvzdy3YjO3PLeWgyaV8MXjZnLs7LHMm1ySNpAlIiIiMuJ1Bo+Gc4pCpwCXiIiIiHQ1TL/BiojI3qauuY0ttc1srmmiqbUDMyMcMpraOthR30J1QyuxcIiZ4wqZMbaIrbXN3LVsAw+/tpWW9j3BrJK8KB9fMJnTDpnM7PFFLN9Qw4trdrCruZ2PHjqJgyeX7q7bmSowFul+0fQxRTmct3B/zlu4P+0dcSLhYbrIuoiIiEh/270G1zCdwWVhiMd7riciIiIi+xwFuEREpF8452hpj7Oppok12xtYvb2e1ZX1rN5ez5qqBmoa27rd3wySl4Uszo3wycP247g5YxlXlEt5UYzRBTmEQ3tmVC2cUc7CGeVp2vRSBWZDwS0RERHZp7jhPoMrpBlcIiIiIpLSMP0GKyIiw5FzjpWV9Sx9u5K3t9azvrqBd3c0squ5jZb2eJcA1ZiiHKaVF7DkoAlMGZXPxNI8JpbkUpATIe4c8TjkREOMLohRmh+jua2DNdsbWFlZR34szOIDUqcUFBEREZF+MiJmcCnAJSIiIiJdKcAlIrKPe3ZVFb9auprcaJgpo/KZVJaHAS3tcZrbOmhpj9PS3kF9czsvrN3BhuomAMYV5zB1dAGLZo2hrCBGbiRETjTM+OJcpo8tZNqYAopzo1n1pSAnwkGTSzhocskAPFMRERER6WJ3gGuYXh4Ihff0UUREREQkYJh+gxURkYG2tbaZ7/7tDf727y1MKs2jKDfCc6uraGxNHCEbi4TIiYTIjYaZN7mEzy2awXGzxzK+JHeIei4iIiIi/aZzfSsbxjO4lKJQRERERFJQgEtEZC9T29TGs6uqOHhyCZPL8hMea22P88yq7dy3fDOPvL6NuHNc+sFZfPaYaeRGwzjnqGlswwxyo2Fi4RChUHZrWImIiIjICBJvB8xb2aFIEQAAIABJREFU62o4CkX2BOFERERERAIU4BIR2UvE4467lm3gRw+/zY6GVgDmTijmqOmjqW5sZV1VAysr66lrbqckL8pHDpnI5xbNYMroPUEwM6OsIDZUT0FEREREBlu8ffimJwQv8KYZXCIiIiKSwjD+FisiIs1tHexqaqPDOcYV5RIKGc45nl21g1ufX8dzq6ooL8phUmkeOxvbeHPLLhZMLePa0+fzztY6Hn1jG799bh1jCnOoKM/n5HkT+cDssbx/5hhikWE6SldEREREBo/rGN4BLgtDXAEuEREREelqGH+LFRHZ97y7o4FH39jGo29sY8XGGprb9qRjiUVCTB2VT3vcsbaqgVEFMU6ZP4m65jY21TQBcN3p8zl1/kTMjEWzxvCfx0zDOYeZ0gyKiIiISArxDggN0/W3wOubZnCJiIiISAoKcImIDKG3t9ax9O1KVmys4f9n777DoyrTN45/z8ykhwQSCARC6FKl915FQRSpCiIgqKurK+pafuraXXVX17JrFxALICCIoPSOinTp0nsnQICEJDNzfn+8CSEkQEgCmYT7c125Bmbec86b0XVn5p7nef7Yc/JcUFWtVBHuahxL8dAAwoL8cFiw+1gC24+eITHZw8PtKtO1djSBfpf/MELhloiIiIhclNft2wGX5UydEyYiIiIikpECLhGRa+zY6SQmr97PxFV7WbcvHoCyEUHUiy3Kfa0q0KF6ScpGBF/mLCIiIiIiecDnZ3Clhm9er5nHJSIiIiKSyodfxYqIFB5Jbg9zNx7m+5V7mf/nEdxem1plwnixWw261o4mqkhgfm9RRERERK5HXo+pkvJVaXuzPYACLhEREfF95cuXB2Dnzp3n7vvyyy8ZPHgwI0eOZNCgQdk6z6BBgxg1ahQ7duw4d85Ladu2LQsWLMC27SvfdAGlgEtEJJc27I9nzd4TnEhM4XhCMsF+LmqUDqNG6TAOx5/l+5V7mfLHAU4mphBVJIAhLSvQo34MVUsVye+ti4iIiMj1rsBUcHnA6Ze/exERERERn+LDr2JFRHzblkOneGfmZqavP3juPn+ngxSvl/O/KBHgctC5Zil6NoihRaVIXE5981RERHzYkc0QWVmtwESuF15PwQi4bE/+7kNEREQkF+644w6aNm1KdHR0fm+lUPHhV7EiIr4nMdnD/D8PM2XNfqatO0iIv4thHavQs34MkaH+BPk5SUj2sOngKTYciCfQ5aBzrVKEBerbpiIiUgAsGw4/PQ6NhkLXd/JvHzt/MVUlFdvk3x5Erhe2x7cDbeu8Ci4RERGRAio8PJzw8PD83kah48OvYkVEri3btpmx/iBd3l9E63/No/cnv/LXb1fyyJhVDB21nLs+W0KD12bx4Lcr+X17HPe3rsiip9oxrOMNlI0IJtjfhWVZhAS4aFCuGAOalqN3w7IKt0REChuvF378Gyz9/OpdI+UsHFwLB9aYnxN7sn+sJwX2r4YL+65vnQ1f3gpHt2Z93M7FMO0pCC0Jy74wYVdWkk7BDw/B5hnZ39OV2DYPvrodvu0Fe1dkfOz4LvO7iUjeKSgtClXBJSIiIrm0ZMkSLMvijjvuuOia6tWrExAQQFxcHADJycn873//o0uXLpQrV46AgAAiIiLo2LEj06ZNy/a1v/zySyzL4ssvv8z02OzZs2nVqhUhISFERETQvXt3Nm3adMW/38V4vV4++eQTGjVqRGhoKCEhITRq1IiPP/4Yr9ebaf2iRYvo1q0bMTExBAQEUKpUKZo2bcrLL7+cYd2hQ4f4+9//TtWqVQkJCaFo0aJUrVqVQYMGsX379jzb/6X48KtYEZFrw+u1WbYzjndmbmbpzjgqlQihXmxRDsWfZePBeGwbAv2cBPk56F6vDLfeGE3jChFqNSgicj04uA7CSkNwRPp9y4fDylHg9IdK7SGyUsZjbNuEP/Neg6AIuGss+AenP550CuJ2QNGyEFgULCv9sVMHTbi0fAQkHMt43ui6UKsnVO8GxcpnPC7N2XgYdw9snwdVboJb34PwMiaMm/YU2F6Y9ADcOwOc570VOL4TvhsAxSrAkJlmzbSnoERVKN8yfZ3HDRPuhS0zYc130PMLqHnxN4cAuJPM2qiaENPg0mv3rYCx/aH4DeZ5GncPPLAAQorD7iUwug8kn4Gew6Fm90ufS0Syx9cDLlVwiYiISB5p2rQpVatW5eeff+bYsWNERkZmeHzp0qVs2rSJnj17EhFh3gPGxcXx6KOP0rx5czp16kSJEiU4cOAAU6ZMoUuXLnz++ecMHTo0x3uaMGECffv2xd/fn759+xIdHc3ixYtp1qwZtWvXztXvm2bAgAGMHj2asmXLMnToUCzLYtKkSTz00EMsXryYb7/99tza6dOn07VrV8LCwrjtttsoU6YMcXFxbNy4kY8++ogXX3wRgISEBFq0aMG2bdvo1KkT3bp1w7Ztdu3axeTJk+nVqxcVK1bMk/1fig+/ihURuXqS3B5mbzjMnI2HWLD5CMfOJFM8NIDX76hF34ZlFV6JiOSFlV/D+klw02tQskbuz5d4HP4YC9sXQPkWJlgJj8ndOVPOwoE/4PB6qNgOIiqkP7ZxqglYipWHQVNN0BW3A2a9CLHNTIXVzOfhrjHpx+xdATOehT1LoGgsHFoP391tQi6XP+xbaf4ev8+sDwiD4Mj0sOrEHvNhc9UuUKsHuALN/cd3wvqJMOsf5ieoGJSsBaXrQdVboGwTOH0Ivu0NRzZBg0GwZhx81BQqtIZNU+GGW8zaKX+DX9+HVk+Yc58+AmP6mQ+P7xprwryeX8AXHU3o1XskVEhtFTjtKRNu3fS6OeeEe8GdDHX6Zn5uvR5YOx7mvQ4ndoMryDxXldpl/c/i6Baz/5BIGDARTh2A4Z3h+yHQ6D5zG1YGileFCYPBkwy1++TwH7yInOP1pIdIviitfaICLhERkatr2jPmPY4vK3Uj3PJmrk4xcOBAnn32WcaMGcPDDz+c4bFRo0adW5OmWLFi7Nq1i5iYjO89T548SYsWLXjqqafo378/QUFBV7yX06dP88ADD+BwOFi0aBENGzY899hjjz3Ge++9d8XnvNCYMWMYPXo09erVY+HChYSGhgLw2muv0aZNG0aPHk3Xrl3p168fAJ9//jler5f58+dTp06dDOc6evTouT/PmTOHbdu2MWzYMN59990M65KTk0lKSsr13rNDAZeIFGpnUzys33+SFI9NoJ8T27aZtu4gE1bsJe5MMsWC/WhzQwnaVo2iU42ShAToP4siUkjsWWaCjrMnIfm0qfopWfPKz3N4E2ybY9rkHVpnKnpu+y/4h2Rck3DMhE5pjmyGn54ATxJ8uhDaPAUtHwPnBW1bbdtU6gSGXXwPR7fA4vdg3ffgToSwGNg8zYRLsc2hyQPm90trY5V0Gnb9Cn6Bpt1eaFTGSqmT+0zwtmEy7F8F3hRzf0AY3PEpVOti2uRNGGyCubgdprXfwCnw4yNgOaDH5ya8mfMybJ0DlTvA+h9g4n2mauvWd6HeABPI/fgwTBxqQqspj0JIFHT/xDxnJ3ZDYlz671rtVmg4GCKy+KZb84fNXrbONm88D66F3z+BXz+A4OJmXymJ0G+c2U+LYWa/m6ZCs4eh0ytmzba5MO8NqNIZTh+ESQ+af0/uGg3FK5trBYbDnWNg1K2mXWBUTShTD1Z9Ay0eNXtpOBjG3GmqvfYsgXp3Q+n65lx/jDWVbkc3Q3Qd6PQqLPgXjO4Lfb+BG25K/70OrYclH5tALqAIDPgBipQyP13fMc/f9vnm3P3Hm9BvzJ0w8X5THVZ/wCX/FRaRy/B60v/76YvSqsvUolBERETywIABA3j++ecZNWpUhoArOTmZsWPHEhUVxS233HLu/oCAgEzhFpiZWvfeey9PPPEEy5Yto3Xr1le8l8mTJxMXF8c999yTIdwCeOmllxg5ciQnT5684vOeb8SIEQC8+eab58ItgJCQEN566y06duzIF198cS7gSpNVYFe8ePFM92W1zt/fH39//1ztO7v0Sa6IFDoHTiYyceU+ftl6lOW7jpPszthL1uWw6FSjJHc1jqVF5eI4HVm0eBIRKahsGxa9DXNfy3j/r/+DfmMztps7346FcOaIqWIKjoBTh2DuqybQwIYi0aZt3PpJcHKvCVGCisKqb+Gnx001TY/P4cZe5sPSyX8FvyC4fx4sesdU8WycAn1GpYc3KYkmENo8E/p9l7my5+Q+WPCmuYYrwFQJNbzXBCbHtpmKplXfwviBEFEJ6t9jAqvNM0wQdj6nvwm7/EPhyEZzX6na0OyvENPIVIJNeRTG3gX1B8LaCRBZxYRaRzbDNz3go2aQdBK6fWDaCzb7K6z8Cqb/HzQaaqqbyjZOr4ICE74kxZuqrg2ToVxL8xyEZH5jkC0RFaDxfel/TzoFW2bBpp9MVViXf5tvNaatvedHOLnbVKGl6fof2PULfN3d/DMvUR3u+SFzAFq8MvxtNaybYAKoVd9Aje7Q4SXzuH+I+ffg5ydh9WjTVjGysvnn5k6EMg2g10hzjMNhKsm+7g5j+0GN2yAhzlRpHdlkqrvq3Q3NH8lYRVd/AMRtM0Fgtw8gIPUNWf/xppXhgrdMpdv5gauIXBm1KBQRERHIdWVUQRETE0OHDh2YNWsWGzZsoEYN021kypQpxMXF8dhjj+FyZXxttH79ev7973+zcOFCDhw4wNmzZzM8vm/fvhztZeXKlQC0adMm02Ph4eHUrVuXBQsW5Ojc51/D4XDQtm3bTI+1adMGp9PJqlWrzt3Xv39/Jk6cSJMmTejbty/t2rWjRYsWmUK+Nm3aUKZMGd58801WrlxJly5daNGiBXXr1sXpvHZfnvLhV7EiIpd3NsXD8YRkTiSksCcugfEr9jJn4yG8NtSIDuOepuVoUjGSEH8nSW4vSW4v9csVJapIYH5vXURyKiURfvvQBDWxTfN7N7mXdNpUv5SobmYlQfocps3Tofad0PTBrL9d70mBwxsgpIQJoLxuEzat/Apq94X2z5vKpaRT8PUd8E1P6PN1xuoZMOHF9GdS/2JB6bom1PEkmxCn+SOmmgZMldL3Q01lT+l65lrlW5kPHifeb4Ko4zth71ITeJWsCb1GmHaCkx+GT9tCj88gpqGpwtm73LSdG9sP7plsAiJPCvzyPiz8tzlv4/tNO73QEul7jqwErZ+Elo/Dxh9h8bsw+0XzXNS721R0WRacPmxa950+ZP6ccMwEIjV7pFcrpbl3Bvz8dzNfK6IiDJhkWgHGNoG7J5qQq1IHE6SB+V07/9OEYtOeNBVRvb/MOG8LzHNoOU2Y1PaZzFVsuRFQxPw+tXpk/bjDkTHcAtMC8Lb/moCo0VDTQtLvIu00/ALN81m3v6m0KlE1vV0YmONu/x90ft2En+snQbkWJogsXTfjuYIjTOD2/VDYu8wEjpGVoc5d5jk9f87Z+Tq+lMW+Utsdnj6scEskt2xfr+BK3ZsquERERCSPDBo0iFmzZjFq1CjeeustIOv2hABLliyhffv2uN1uOnTowG233UZYWBgOh4PVq1czefLkHLfjS6vOKlmyZJaPlypVKkfnvfAaERERWVZUuVwuihcvzuHDh8/d16NHD6ZOnco777zDiBEj+PTTTwFo0KABb7zxBp06dQIgLCyMJUuW8OKLL/Ljjz8yY8YMwFR5PfTQQzz//PP4+eXhe9+LUMAlIgXS2RQPH8zZwueLtpPisc/dHxnizwNtKtGvcSxlI4IvcQYRKZD2rYBJfzFtz4Ii4MFfISw6v3dl5jglxpkZTdl1Yg8s/cyEKWdTWw4Uq2A+8N8+34RVJarBzOdM5c/tH5q2cQfXwoHVpgXf7iWQcsYcGxxpwphjW03w0+659JZ8gWEweJoJaMbeZcKiG/uYkGjBWzD/DdMar/nfYPs8057vhpug/T/MmvPV7G6qoL672+ylxTCzzp1oQrTxg00bvKpd4cbe6cdV72ZmRo0bAGP6mjZ9SfHQ5yszP2rkzfBtL1Nd9Mv7cHAN1LjdtLYrVu7iz6PDacKzGt3h+A4IjwVnDl/i+gWasKZWTxPMhUalPxbbBB5dYwIl67zK36q3mHlXrkATFF0svGr6l5zt6Wqpegs8u+/iwdaFLAtK1br444Hh5nloMOjS5wkqCndPyO4uL80VYCrpRCR3VMElIiIi15k77riDsLAwvvnmG/75z39y7Ngxpk2bRp06dTLNnXrttddITExk3rx5maqg3njjDSZPnpzjfYSHhwNw6NChLB8/ePBgjs99/jXi4uJISUnJFDi53W6OHj1KWFjGkQFdu3ala9eunDlzht9//52pU6fy8ccfc+utt7Jq1apzVW8xMTEMHz4c27bZsGEDc+fO5cMPP+SVV17B6/Xy6quv5nr/l+PDr2JFRDKzbZsFm4/wwuT17I5L4I56ZWhSIYLwID+KhfhTP7YY/i7H5U8kIgXPondg7uum6qPbB6biaOJ9purnct88P77L3J4flLiTTVs+22vmFV3pt9e9HhMErfvezDhKiodK7U21U8V2GUOQtD0s/cy0Yzu62QRclsMEP3XugrjtsHMxHF5vqmqa3G8Cr7XjTeu7DxtlPF9UDajX34RDCXEmEDq21cy5qnd35v2GRMLAH01AuOBfJtgqVt5UW9XpZyp6nC4T5LR9JvPx56vSEYbOgsTjpu0cgLMI9J9g5jWd2A23/ifzcxBRAYbMMlVSW+ea9n9lG5vH7pkMI26B74eY8KvP16aNXXZZVtZzq3LiwlaJaUIis75ut/fz5rrXWnbDLREp3Lwe3w64zlVweS+9TkRERCSbgoKC6NOnD1988QWzZ89m48aNuN3uTNVbAFu3biUiIiLLFn+5bR9Yv379c+e59957Mzx28uRJVq9enavzA9SrV485c+awcOFCOnTokOGxhQsX4vF4zu3jQiEhIbRv35727dtTrFgxXnjhBaZNm3Yu4EpjWRY1a9akZs2adO/endjYWH744QcFXCIiACcSkvnxj/38tu0YS3fEcexMMhWLhzDmvqY0q5TFh40iknt7lsHy4XDLW6Yy43JSEmHrbBPwXNguLPlM5vuObDaVPG2eMtUyl7N+Esx5xVTq3PqeqQJxOM2cp1/eMxVJFzq8KTV8+smERmCqoyp3NPvd+KMJaACKloMmfzFt3oIiwOUPZ46aFoGbfjK/Q6vHoWJbs37fSjOv6eAaCAiH6reZSpLlI0wVU8laJuiq2cNU9Kz6xsxp8iSZqqyYxmbOU+2+GStQmj2U+feo3cdcd+nnpkqr1I2muiio6OWftwsFhpu2bif3wYYfTGVY9dug48sZ285lR9qcp/MFFTUBVvLpi7eb8wsy1Wi2nTEAKxprArh135uA72LHi4hI3vJ6wOXDHw1Yqf//5HXn7z5ERESkUBk0aBBffPEFX331FRs3bsTlctG/f/9M68qXL8+ff/7JmjVrqF279rn7hw8ffq4tX07dfvvtFCtWjNGjR/PII4/QsGHDc4+99NJL51oY5sa9997LnDlz+L//+z/mz59PcLDpeJWQkMAzz5gvtw4ZMuTc+oULF9K8efNMc8jSqszSjl+/fj3FixfP1F7xwnVXmw+/ihWR692Bk4kMX7SD0Ut3k5DsoUzRINpULUGzipHcVrc0AS4fnhUgUpClnIVJ95uKooRjcNfYS1c3Hd0C4wfBoXWmuqrNU1DvHti5EH77CLbNhQ4vmIAIzMyp7+6Go3/CD3+F4lUv3frs1EGY+piZ99Tj8/QWcHX7m3PPfd3MXYptbip49i4185g2TzcfisU2N3OSHC7YMgtWfGnaHVXrasI191n4/ROY8X/mB8Av2NxveyEsBrBNZVLFduYaK0aaKqMen5s2eq4Ac1zLx2DtBPj1vzDpAZj9spnztGMhlGsJ3T+6dLu9iwmNgvbPXflxFxNexsyFavbXvDtnGpc/uLIRTl1Y3QWmHWKbp/J+TyIicnFeNzh8eJadQy0KRUREJO+1aNGCypUrM378eFJSUujWrRtRUVGZ1g0bNowZM2bQsmVL+vTpQ3h4OMuXL2fx4sX06tWLCRNy3oI9NDSUzz77jL59+9KqVSv69u1LdHQ0ixcvZt26dbRu3ZqFCxfm5tekX79+TJ48mXHjxp2rsLIsix9++IEdO3bQt2/fDMHe3/72N/bt20eLFi0oX748/v7+rFixgrlz51KuXDnuvPNOAGbNmsWTTz5Js2bNuOGGG4iKimLv3r1MnjwZh8PBk08+mat9Z5cCLhHxOVsPn+azhduYtGofXhu61Y7m/taVqFE67PIHi0hmHjf89l/TEu+Wf11+PtHid024Vbc/rP7WVE51etk8duqgmQ8VWNSELkf+NO3mnP7Q5W1YNxF+egJm/gNSEkzgVa4FzHnZBBothsGPj8CxLdDjC5j5vKnkum+eqf7ZuwKWfATRdaDxfWau0eS/mtDt/HALzPlufRcOrDHnBLPefdZUYbV7DhoMhtAS6cc0eQDcqcNf00IpMHOl9q8ylWtJJ81MLP9QM6eoVG1zzPIRsOht8/s3Ggod/pG5us0VYNoG1u0HW+fArx+Y8970OjR96MqrpERERK42X5/BlbY3WwGXiIiI5K2BAwfyj3/849yfs3LzzTczZcoUXnvtNb777jucTieNGzdm3rx5bN++PVcBF0CvXr2YPn06L7/8MuPGjSMgIIDWrVvz22+/8eabb+Y64AIYM2YMbdq0YcSIEXz66acAVK9enSeeeIIHH3www9pnn32WSZMmsXz5cmbPno3D4SA2NpZnn32WYcOGUaxYMQA6d+7M7t27WbhwIZMnTyY+Pp7o6Gg6derE448/TvPmzXO97+ywbNu+JhfydQ0bNrSXL1+e39sQua5tOXSKt2f+ycwNhwhwOejbsCxDW1WkbMS1KWkVySD5jKn0aTAY/PPo38GkUzD5YTNz6cZeF18Xvx8OrjUhy9mTENPQVC+lORtvQh9PCtz2gQmaLuboVlNJtC/1/+Oa/w1uukQP5KNb4eNmpm1dr+Gmcmr5CFOBdeRPE2B5UzIeU7Yp9BphqoJs27QqXDseKnUwLQUth9nDugmmAmr7POj4kql22r0EvuxqWhsGhpvj/ENNi7sipU1rvj9Gm/Cs8X1Z79mdDEc2mufs0Hozt6pe/8xtEfNC0inzE1Y6788tIgWeZVkrbNtuePmV1xe91/Jxn7SE8LKmha0v+nM6jOlrvgxTJuv5ECIiIpI9GzdupHr16vm9DZFzsvvv5MXea/nw17RE5HpxOsnN+7M3M/KXnQT5O3mkXWUGNi9PZGjA5Q8WuVrmv2mqbzwp0HJY7s/nccOEe2HLTDPTKawMlGuWed2RP+GLTqaKKI3lMGFQm2fg1AEY3ddUQDlc8Ekr6PkFVGiV8TyHNpiwaMnHpqqo1wjY9av5naLrmIDNtmHzDNi7DGIaQWxT+PkJUwXV+Z/mPDe/ZeZlzXnFBE+NhpjqJI8bTh8yYVfVLumVVZYFVTqZn/PdYb4hxLoJUO1WU8kF5po3vQ7TnzbXbfV383zvX22qvv4YbYKyRkMv/ty6/M3vFF0n+/88ciqgiPkREREpLLyeS7cizm9pe7O9+bsPEREREfE5CrhEJN+cSXIzfvkePl6wjUPxSdzZqCxPdq6qYEvy37FtJhiynKZdXpO/gF9g+mPj7jEhTcth4Bd0+fPZtglwtsyETq/Ayq/MDKr750HR2PR1Z47B6D4mkLrrJygSbVr/LXgLFr1jwqjTh8CTDHdPhOBIGD8QvrrN7McvyFzr0Do4vMEEY1W7mOqnsGio1s1UOE1+2LTcW/kV7Fly3kYtwDbri6QOCXX5w53fwOaZUPXmzC35ssvpMiFX9W5QuWPG+UtNHjAVUaXrQdGy5r4KrWDILFPhVbJm1vOaREREJPd8vUWhldreVzO4REREROQCPvwqVkQKI9u22Xr4NBNX7ePbJbuIP+umQblifHJ3A+rFFsvv7YkvSjxuWvIVK3ftrjnjWVNN1O09+H6IqSJqeK8Jj3563FRZHVpn7r/5TRMipQUwHjesGAm/vG/mVMU0NB8aLfvCtAds8ahZ/3kHGNMPBv8MgWEmcPrubog/AIN+grKN0vdz+/+gWlczZyqgCPQbB8WrmMfunw/Tn4Gdi9PXh5UxIVWN2zO2L3T5Q+9R8FkbmPwQhJYyM6xu7G0qpnYuNq0BG96b8fkIKgZ1+ub+eXW6zKyrC1kW1Lgt6/uzqnITERGRvOP1mC/1+Kq0Ci6vO3/3ISIiIiI+RwGXiFx1cWeSWbHrOL9uO8qcjYfZHZeAw4LONUsxtFVFGpRTsFWgJJ02VUYV20LrJzNW1njc5kOIi1Xb2LaZxZRwDNo9C2UaXP5awztD/D4zd6HEDemPnT4Cm6bAid3mJ7SkqY5Ka5WXJjnBVDMdXGNmJzUYdOkqpC2zYfN0c65aPU0F1y/vQ717YN33sH2+CY9KVIWfn4Sx/UylVaUOULouLP0cjv5p5lL5B5uZVUknoUZ36PiyuUbxKma+1eg+8GasCe/8QuDweug5PGO4labqLfDoGvMt5rRqMjCB1+0fXvp5PF+RkjBgEuz6Ber0S58vVqFV5jaHIiIiUvj5fAVXWotCVXCJiIiISEY+/CpWRAqyJLeHL3/ZyXfL97D9yBkA/F0OWlSK5P7WFelQPYro8Gy0dhPfs+BNE47s+gXOHDUVTJZlwp9pT5s2c71HZj2naOMUWPOdqY76vL2pMOrwIkRWyrzWtmHqY3B0s6lw+u5uuG8uBITC8Z0wqpsJthx+pv3eid0m3Or0Svo5fvkAZr+U8QOR3z6CW94y1z4/iHMnQdx2Uw0VUQmaPGgeb/mYufaKkTD/DSjTEBoOAYcD/rIY1k6ALTNM2Lb6G4ioCHeOTq/q8nrN3Kyw0hmvV6UTDJwKOxaa3zFuu3kub+x18ec+LYzKrajq5kdERETE6/EmFMf+AAAgAElEQVTtgOtcBZcCLhERERHJyIdfxYpIQWTbNjM3HOKfP29k17EEmlaMoFeDGBqWi6B2TDiBfj7c/kQu79B6ExDVG2CqoH77H5w9YSqt/vwJSlSHbXNh5C3Qb7wJntIkJ8CM5yCqJgz+CX7/FH79L+z8Be6dAcUrZ7zWipGwdhy0ew7KNoGvu8OPD0O7583MqZQEc1xMI/PBx9THTKVV2aZQrYuppJr1DxM01e0PpW6EhKNm3fiBZl1AKJw9CWeOmIDM9gKWaQHo8jf7qNoVit8AP//dfPjT7X0TboEJ1OreZX48bji21QRcaceCWRteJuvns3wL8yMiIiKSX7zu9Nc2vigtfFMFl4iIiIhcQAGXiOSJsykepvyxn6+X7GLN3pNUiQpl1L2NaXNDifzemuQVrxemPg5BRU2VVFAxCAiD+f80FVmdXoWmD5kWfuMHwhcd4c5vTEUXwC/vwcndZr5UUDFo+wzU6gUjboKv74AhM9MDsT3LTDVYpfbQ6u/mQ5cOL5hqrM0zwC/YVD+VqpW+v85vwL4V8MNfTNXV7Jfghlugz1fpbQuLlYOhc2Hpp7DqG/CmmKCuaCzc2McEWdF1MrZCdDigxTAzs6rZwxmveT6nC6Kq5fGTLiIiInKV2T5ewZXWotDrzd99iIiIFBK2bWNdbLSEyDVk23auz+HDr2JFpCCwbZuvftvFe7M3czwhhcpRobx+Ry36NiyLy+nD3wSVyzuwxlRMhZSAal0h+QzsWWLmPQVHmDVtnzZztCIqpLcZrNIRBv8M3/aBz9qZlnv17obF75lAq3zL9GsUrwz9J5h2g9/0MO0KV4w0IVZYaejxefo3ilsMgwN/wO7fzQypC8Mkv0DoPQo+bWPCrfKtoPeXmWdyOV3Q7K/mJ7vq3GVmV5VvfSXPoIiIiIjv8/UZXGmvBVXBJSIikmtOp5OUlBT8/f0vv1jkKktJScHpzF23Lx9+FSsivu5Mkpunv1/D1DUHaFm5OA+1rUSzSpH6Fkh+s20zT8ovMHvrTx0yM6Yqd4TmD4N/iJkLNaaf+fPZk6atH0Bsc6jTL+PxVTpmPmd0Hfjr76Zl4JKPYe148AuBm17NvLZMfbjzW/i2N4zpC8HFoc1T0GgohBRPX2dZ0Guk+RDmwtAqTUQF6DMK1k0w86yy+xxcjsNhnh8RERGRwsbXZ3BZmsElIiKSV4oUKUJ8fDzFixe//GKRqyw+Pp4iRYrk6hw+/CpWRHzZtiOneeDrFWw/cpqnb67GA60r4nAo2MoRj9tUFZ1vxShY+pkJhCq1v/w53Emwdzls+gk2TYWTe6HLv6HRkMsfu/hd2LsM9i6FFV9CnTvNbK2IinD39xBWBg5vNLO1atyW/RkNQUWh44vQ5AEza6t0PVOVlZWKbc214vdDje4XD6Ys6+LhVppK7cyPiIiIiFye1wOWD3decKQFXO783YeIiEghEBERwe7duwEICwvDz89PX1SXa8q2bVJSUoiPj+f48ePExsbm6nwKuETkiq3Ze4KBI5bisCy+GdKE5pWv8299bJ5hvlmaVSXTpbiTYMK9phXg0FlQpJS5/9g2M3/Km2JmU9W/B256zcyKOt/hTbDyKxNMHfgDPMngDDBhUdFY+Olx8KRA079cfA/x+2H5CNNCsG5/mPF/sPg/ULYJ3DU2vRVhyRrmJyeKlILOr19+XQW1/xMRERG55vKxReHJxBS2Hj7F0dPJHDudjI1NiL+LYH8nXtvm1Fk3rmMHuAPUolBERCQPBAQEEBsbS1xcHDt37sTj0f+/yrXndDopUqQIsbGxBAQE5OpcCrhE5Ios2X6MoaOWUzTYj2+HNqFcZEh+byl/JSfA9/dBSgIMmWna7WWHOwnGDYTN00woNe4eGDjVfLgw5VFTpfTgLybA+vUD2PSzmWVVq6cJjOa/BX+MBoefuWaTv0DZxibcCigC7mSYMBimP21aDJasCSd2Q9IpaHgvhJYw+1j0H/NhQesnoVg5GDrXzNkqXQ/8gq7WsyYiIiIiviKfAq4zSW5ufm8hB06eveS6itZ+7ggAvN5rszEREZFCLiAggOjoaKKjo/N7KyK5poBLRC5p44F4ftt2jMQUD/FnU/jyl52UjQjmmyFNKBWeR/ONCrINkyHpJASEmUDpgYWZK60u5E5OD7e6vA3BkebYaU9BdG3YuQi6vQ+RlaDTy1Djdlj0DiwfCb9/Ys7hDICmD0HLxyEkMvM1XP7Q+0uYeD/M/2fGx1Z/a9oB+gXBylFQb4AJt8C0HyzXPNdPi4iIiIgUALZtvuzkyN1w75wYs3Q3B06e5a2eN1KzdDjFQwNwWHA6yc2ZJA9Oh0WRQBcvjJwCp1AFl4iIiIhkooBLRC5q8up9PDlhDclu821Jy4KG5Yrx6YCGRIT45/PufMTKURBRCW7/EL7saqqveo00T9b5bBsOb4B138PaCXBilwm3Gt9nHj/wB/zynqnIqtAa6g9MP7ZMfbjzWzgbD3/+DMe2mseLlr303px+0PMLU7EVEApFy0HcdhjdF4Z3MlVatg2tnsjb50RERERECgY7tSrqGldwJbk9fLFoB00qRNC3Uca5C1EXrPXzS52/6lXAJSIiIiIZKeASkUxs2+aDOVt5d/ZmGleI4L2+dYkM9cff6dDgyfMd+RN2/wYdX4ZyzaD98zDnZfAPhYgK4AqEhGNwcK2Zs3X6oJnVVbEN3PwGVOuafq4OL5h1e36Hbh9kDsgAAsOgzp1XtkeHEyq0Sv97cISZ9/VNL9g2FxoNvXxQJiIiIiKFk9dtbq9xBdcPq/ZxMP4sb/Wqfdm1VtreVMElIiIiIhdQwCUiGeyJS+DVqRuYueEQPevH8M8etQhwXfuWJbmycQrM/Afc0BnaPG1Cnath5Vfm2651+5m/txgGB9fAqq/T11hOKFHNzMYq2xiq35Y+/+p8Dif0GweJx7N+PC9FVIQhs2DZFybgEhEREZHrU1pVlHXtXu97vDafLNhOrTJhtK5S/PIHpAVcquASERERkQso4BIRAOLPpvDhvK2MXLwThwOe7VKN+1pVLFgVW8kJMONZWDHStONb+hn8McaEXI3vNy37cipuB4wbACElTIVVaBSsHg1Vu5g/g5lf1ftL6DkCPMngPmvmXLkCsncNp+vqh1tpQiKh7dPX5loiIiIi4ptSK7i8lhPHNbrk9HUH2XH0DB/1r5+t9xrnKrjSqs1ERERERFIp4BIRZm84xLOT1nL4VBI968fwZOeqlAoPzO9tXZnE4zDiZjiyCVo8Cu2eN7OqZj5nQq+jW6Dbe9k71+FN4B8MRVPnAexeAmP7mTfVx7bDx81NJVZiHDQYmPl4hwMcgeBXwJ5DEREREbm+pIZGr0/fwrhZMygVFkhkqD8er02S20uy20ugn5OQACeBLifJHi8JyR4Skj0kJrtJSPZwNsVDSICL8CA/igS6SPbYnElyk5jswbLA3+nA3+XAL/V217EzVCweQueapbK1xfQWhd6r9SyIiIiISAGlgEvkOnYiIZmXp2xg0qp9VCtVhM/vaUidskXze1uX5kmBY9ugRNWMc6p+ed/MxOr/PVTpaO4rWQMGTIJZL5jHyzWH2n2yPq9tm5lUi9+FnYvMfcVvgJjGsHYchJc1LQQdTvjhQVj9DYTHQsX2V/f3FRERERG5WlJDo2SvRdsaUSS7PRw7nYyf00FIiAs/p4Mkt5eEJDfHz6QQ4Ocg2N9JsWB/gv2dBPs7CfRzcibJzcnEFOLPphDu76JM0UCC/FzY2CS7vaR4vKm3NpVKhPKXNpVwOrLXKcKhFoUiIiIichEKuESuUycTU7jjo1/ZE5fA3zpU4eF2lfF3XavGJDmw6zcTNG2YDAnHoMvb0Pg+89ipQ7DkE7ixd3q4db72L8De5TDlUShV2wRXa8fB/DdN5ZcrELDh9CEoEg2dXjWztbbOhnUTTDDWa2T6LK9BP5k5W8UqmGotEREREZGCKLWCy4OTYR2rUKlEaD5vKAtpbcZtBVwiIiIikpECLpHrkNdrM2zsKvbEJfDN0CY0rRiZ31u6tJVfw48Pg18wVL0FTh2Emc9D+ZYQVR0WvQ3eFGj7TNbHO13QawR80hK+uxv8Q+DAaihdD6rcZGZleZJTK7z6ps/MavaQ+aao44Kh2w4nNBh0VX9lEREREZGrLjXgcuPAz0e/uKUKLhERERG5GAVcIteh92ZvZt6fR3i1ey3fD7fi95sZWuVaQv9xJpw6fRg+agbfD4XeX8LykVBvAERWuvh5ipSCnsPh6+6mSuuOz0zF1+XeyF8YbomIiIiIFBapoZEXB05n9loGXmvnAi5VcImIiIjIBRRwiVxnZq4/yAdzt9K7QQx3N4nN7+1cmm3D1MfN3K3b/2vCLYDQKLj9QxjTF4bfZEKoNk9d/nwV28DDy03A5R98dfcuIiIiIuLr0iq4bCeubM7EutYspyq4RERERCRrvtmDQESuimlrD/DImFXUjgnn1e61sCzffBN7zrrvYfM0aP88RFTM+FjVm6HRUEiMM7O4wkpn75yRlRRuiYiIiIjAudDIgwOnjwZcDkfq93IVcImIiIjIBVTBJXIdsG2b4Yt38PrPG6lXtiif39OQQD8fb713cC1MewrKNISmD2a95qbXIKoG1O5zbfcmIiIiIlIYpFZweXD4bAWX0+nAi4VDLQpFRERE5AIKuEQKufizKbw5bROjf9/NLbVK8W7fur4dbu36FRa/C1tmQkA43P6/i8/B8guCRkOu7f5ERERERAoLO62Cy+mzFVwup4UXBw5VcImIiIjIBRRwiRRSbo+XMcv28O6szRxPSOaB1hV5+uZqOK7GG1fbNre5bXm48G2Y+yoER5q2hI2GQlCx3O9PRERERK6YZVmPAUMBG1gLDAaigbFAJLACGGDbdnK+bVJyJ20GFw78nL45wcDpsHDjxKUKLhERERG5gAIukUIoye2h76dLWL3nBI0rRPDCrTWoVSb86l1wxnOw5jto+ww0GAxOl+mRv2MhnDkKNe8w913Kqm9NuHVjH+j2vuZkiYiIiOQjy7LKAH8Dati2nWhZ1jjgTqAL8K5t22Mty/oEGAJ8nI9bldwoADO4nJaFF0szuEREREQkEwVcIoXQ/+ZuZfWeE/y7V216NYjBym1l1aUc3QK/fwLBEfDz32Hp51ClE6z/AeL3mjVLPoTbP4SSNbM+x5bZ8OMjULGtWefyv3r7FREREZHscgFBlmWlAMHAAaA90C/18VHASyjgKri857UovJrvGXLB6XDgsR1ge/N7KyIiIiLiY3yzB4GI5NiG/fF8PH8bPeqXoXfDslc33AKY87KZhfXgb3DnGNPmZMlHEFUdeo2EnsPhxB74tA3M+ycknUo/1rZhw48w7h4oWQP6fK1wS0RERMQH2La9D3gb2I0Jtk5iWhKesG3bnbpsL1Amq+Mty7rfsqzllmUtP3LkyLXYsuREaotCL86r08o8D7icFh4c5/YqIiIiIpJGFVwihYjb4+Wp7/+gaLAfL9xa4+pfcM9S2DgF2j0HoSWgWheochOkJEBgWPq6iu1g2lOw4C1T4dX8EYhtZloS7voFompA/wkZjxERERGRfGNZVjHgdqACcAIYD9yc3eNt2/4M+AygYcOG9tXYo+SBtNDI4czffVyC02HhxaEWhSIiIiKSiSq4RAqRzxftYN2+eF65vRZFg/OoEupsPJzO4lu3tg2zXoSQKGj21/T7na7MQVVIJPQaDkPnQkxDU/U18mY4sgm6vgMPLIIipfJmvyIiIiKSFzoCO2zbPmLbdgowEWgBFLUsK+2LkjHAvvza4BU7sAY+ag67f8/vnfgOOzU08uGAy+VIreCyFXCJiIiISEaq4BIpJKb8sZ93Zv5J55ol6XJjdO5P6E4ys7UWvm3aCpZrDrV6QHRdOHME9q+G3b9C1/+Af0j2zhnTAPqPh70r4MAquLE3BIbnfq8iIiIiktd2A00tywoGEoEOwHJgHtALGAsMBCbn2w6vlMMJh9fDqf35vRPfkVoVZTt896MBZ2rAZXs9+GYTRRERERHJL777KlZEsu2bJbv4x+R1NCoXwb9718n9CbfNgymPwoldUKUzlK4H6yfCT09kXFe6HtS/58rPH9PA/IiIiIiIT7Jt+3fLsiYAKwE3sArTcvAnYKxlWa+l3jc8/3Z5hYIjzW1CXP7uw5ektii0LN+t4HJaFm6cCrhEREREJBMFXCIF3Efzt/Kv6X/SoVoUH/avT6BfLt+cJsTB+EEQUgIGTIJK7c39bZ+BQ+vh5F4IjYLQkubHqf+MiIiIiBRGtm2/CLx4wd3bgcb5sJ3cC4owtwq40hWECi6nhde2sDWDS0REREQu4LuvYkXkspbuiONf0//ktjqleadPHfyceTBWb+G/ISkeBv8MJWum329ZUKqW+RERERERKWhc/uBfBBKO5fdOfEdqBRc+XMGVNoPL9rjzeysiIiIi4mPy4NNwEckPHq/Niz+up3R4IG/1rJ034dbRrbD0M6g3IGO4JSIiIiJSGARHKOA6X1rA5fDdgMvpcODFgdergEtEREREMirwAZdlWY9ZlrXesqx1lmWNsSwr0LKsCpZl/W5Z1lbLsr6zLMs/v/cpktfGLtvNxgPxPNu1OkH+efSGdPaL4AqEds/lzflERERERHxJcCQkqkXhObYXAMuH246nVXChFoUiIiIicoECHXBZllUG+BvQ0LbtWoATuBN4C3jXtu3KwHFgSP7tUiTvnUxI4e0Zf9KkQgRdb4zOm5PuXAybpkLLYVCkZN6cU0RERETElwRHqoLrfOcquHw34HKmtShUwCUiIiIiFyjQAVcqFxBkWZYLCAYOAO2BCamPjwK659PeRK6Kd2dv5mRiCi92q4llWXlz0jmvQlgZaPrXvDmfiIiIiIivUYvCjFIDLsunWxRaeBVwiYiIiEgWCnTAZdv2PuBtYDcm2DoJrABO2Lad1qB7L1Amf3Yokvf+2HOCr5fs4q7GsdQoHZa9gy43kPnoVtizBJo8AP7Bud+kiIiIiIgvCo6EBLUoPCctNPLxCi43TgVcIiIiIpLJFQdcqXOu2l6FvVwxy7KKAbcDFYDSQAhw8xUcf79lWcsty1p+5MiRq7RLkbyTmOzhse9WE1UkgKdurpa9gxLi4H8NYHRfSDmb9Zo134HlgBv75N1mRURERER8TXAEJJ8Gd1J+78Q3pFVw+fgMLq9mcImIiIhIFnJSwdUXmGNZ1hbLsp6yLCsqrzd1BToCO2zbPmLbdgowEWgBFE1tWQgQA+zL6mDbtj+zbbuhbdsNS5QocW12LJILb07byPajZ3i7dx3Cg/wuf4Btw+SH4eRe2Dwdvrs7c8jl9cKasVCxLYTl0TwvERERERFfFBxpblXFZaSGRr7eotDM4LpMVwoRERERue7ktEWhBVQE3gD2WJY13rKsznm3rWzbDTS1LCvYMoOIOgAbgHlAr9Q1A4HJ+bA3kTy1aMsRRv22i8EtytOicvHsHbTsC/jzJ+j0CnR7H7bOyhxy7f4NTuyGOnddnY2LiIiIiPiKoAhzqzlchp0WcGXjy3P5xOVw4FEFl4iIiIhkIScBVwPgU+AUJujyA3oAP1uWtcOyrOcty7omM69s2/4dmACsBNZifp/PgKeBxy3L2gpEAsOvxX5Erpb4syk8OX4NlaNCeTq7rQkPrYcZz0HlTtDkQWgwKD3kGncPeFLMuj/GgH8oVOt61fYvIiIiIuIT0iq4ElXBBaS3KPTpGVzgtR2awSUiIiIimVxxwGXb9irbth8EooEhwK+YoMsCygEvAzssy5psWdatlmXltEosu/t50bbtarZt17Jte4Bt20m2bW+3bbuxbduVbdvubdu2GqxLgfberC0cOnWWd3rXIdAvG+1DbBsmPgCB4dD9Y3Ck/s+wwSDo+h/YMgMmPQBJp2H9D1DjdvAPuaq/g4iIiIhIvjvXolAVXEB6wOXy5RaFDjxYquASERERkUxy/DUt27YTgZHASMuyqgP3A3djKqZcwK2pPwcsyxoBDLdte1futyxyfdl0MJ5Rv+3krsax1ClbNHsHxW2HQ2uhy9sQesF8uUZDICkeZr8ER7dA8imoc2deb1tERERExPcEq0VhBudmcPluBZfLYeHFAbY3v7ciIiIiIj4mT6qrbNveaNv2Y0AZoB8wN/UhCygNPAdssyxrumVZPSzL8t1XzyI+xLZtXpi8niKBLp68qWrWiw78AclnMt63fb65rdQ+62NaPgYtH4eDayAsBsq1zLM9i4iIiIj4rHMzuNSiEDgXcDkcvlzBZeHGeW5emIiIiIhImjxtH2jbdrJt22Nt2+4IVAbeAA5ggi4H0AkYD+y1LOuflmWVzcvrixQ2P/6xn6U74niqczWKhfhnXnBiN3zWDua/mfH+7fNNcBVR8eIn7/AC3PQ6dPl3egtDEREREZHCzOUPAWEKuNJ43Xhw4HL6bsDlclh4cKhFoYiIiIhkctU+1bZtewcwD1iSdhfps7qigKeBrZZlfWJZVjb7rolcPxKS3bz+00Zqx4TTt9FFsuCVX5tvMq6bCN7Ulh1eD+xcBBXbgmVd/AKWBc0fhmpd8nrrIiIiIiK+KzhCLQrTpAZcTucl3jfkM2dai8LUeWEiIiIiImnyPOCyLCvasqxnLcvaCswAuqc9BGwE/gvsSf27H3AfsNyyrBJZnU/kejV1zQEOn0ri2S7VcTqyeMPpccOqb8w3UOP3wt5l5v6DayDxOFRsc203LCIiIiJSEAQp4DrH9uDBiSur9xs+wplWwaUWhSIiIiJygTwJuCzjVsuyfgB2Aa8CFTEhVjIwGmhj23ZN27YfBcoDtwPLU9dUAF7Ii72IFBbjlu2hYokQmlSIyHrB1tlwaj/c8hY4A2D9RHP/9gXmtoICLhERERGRTIIjFXCl8ZqAK8sv1PmI9Aoub35vRURERER8TK4CLsuyylmW9QqwG5gMdANcmNBqK/AUEGPb9t22bS9KO842pgBNgVmp62/JzV5ECpOth0+xfNdx7mxUFutibQZXjoKQKLixN1TpBOsnmfaE2+dDVA0oUvKa7llEREREpEAIjoREzeACwOvGi8OnK7hcDgceHFiq4BIRERGRC1xxwGVZlsuyrF6WZc0AtgHPAWUwIZUH+B7oZNv2DbZtv23b9kW/Gmfbthf4MvWvsVe6F5HC6rtle3A5LHrUj8l6QfwB2DwD6vYDpx/U6gGnD8H2ebB7iaq3REREREQuJjgSEhRwAeD14MaB03HVxnPnmloUioiIiMjFuHJwzD6geOqf077mtQv4HBhu2/ahKzxf2jsLZw72IlLoJLu9TFy5j47VS1I8NCDrRau/MW/w6t9j/n7DzeAXDDOeB3ciVGx7rbYrIiIiIlKwBBeD5NPgTgLXRV5vXy+8bjw48XP6cAWX08Jjq0WhiIiIiGSWk4CrROqtB/gZ+ASYbtu2ncM97ANG5fBYkUJnzsZDHDuTTN9GZbNe4HHDyq+hfCuIrGTu8w+BGzqbNoWWE8q3uHYbFhEREREpSIIjzW1CHIRF5+9e8pvXgweHz8/gMi0K3fm9FRERERHxMTnpQ7APeAUob9v27bZtT8tFuIVt2+ts2x5s2/bgnJ5DpDD5bvkeSoUF0vqGElkvWPhvOLELmj6U8f6aPcxtTEMIKHJ1NykiIiIiUlCdC7gu2k3/+mF7cNu+PYPLaVl4NYNLRERERLKQkwqucqmzs0Qkj+07kciCzUd4uF3lrL9Fuft3WPgvqHMXVOuS8bEqnSC0FFTvdm02KyIiIiJSECngSud148ZZQGZw6WMIEREREcnoigMuhVsiV8+3S3ZhAX0aZtGe8Gw8TBwK4WXhln9lftwvCIatBaffVd+niIiIiEiBFRRhbhVwpc7g8u0KLpczrUWhKrhEREREJKOcVHBhWVZZwAJO2LYdn431YUBRwGvb9t6cXFOksDub4mHssj10rF6SshHBmRf8/CSc3AuDp0NgWNYncflf3U2KiIiIiBR0aRVciXH5uw8fYHtTWxQ6fTfgcjrSWhTqu7YiIiIiktEV9yGwLKsxsAvYDtTP5mF1gZ3ATsuyal/pNUWuB1PXHCDuTDIDm5fP/GDcdlgzFloMg9gm13xvIiIiIiKFRnBaBZcCLtvjxoPTtyu4HA5VcImIiIhIlnLSaLtP6u0W27bnZ+cA27YXAhsxVV935eCaIoWabduM+nUnlaNCaV4pMvOCPcvM7Y29ru3GREREREQKG6cfBISpRSFge914sArADC6nKrhEREREJJOcvIptCdjAz1d43M+YgKtVDq4pUqit2nOCtftOMrBZOSwri29P7l0G/qFQotq135yIiIiISGETHKGAC9Oi0NcruEzAZeFQBZeIiIiIXCAnAVeV1Nt1V3jc+tTbG3JwTZFCbdSvOykS4KJH/ZisF+xdBmXqg8N5bTcmIiIiIlIYBUeqRSGmRaEbJ04fDrhcDkstCkVEREQkSzkJuIqk3sZf4XGnUm/Dc3BNkULryKkkfl57gF4NYwgJcGVekJwAh9ZBTKNrvzkRERERkcIoOFIVXABeNx4cuJy+G3A5HRZeHFjYYNv5vR0RERER8SE5CbjSgq1iV3hc6iRfEnNwTZFCa/q6A6R4bO5qHJv1ggN/gNetgEtEREREJK8ERaiCi9QWhbYDly/P4LIsPHbq/ryq4hIRERGRdDl5Fbs39bbFFR7XPPV2fw6uKVJoTV9/kIolQqgSFZr1gr3LzG2ZhtduUyIiIiIihVlwJCQq4LK9pkWhL8/gcjgsbCv1owu1KRQRERGR8+Qk4FoAWEAfy7LKZOcAy7LKAn0BO/V4EQGOn0lmyfY4bqlVCsu6yJvKvcugWHkILXFN9yYiIiIiUpj8secEdV6eya9bj0JwBCSfhpSz+b2t/OVx48Xh0zO4AGwrdRaxKrhERERE5Dw5Cbi+Sr0NBH60LCvqUosty8b8S5YAACAASURBVCoJ/JC6HmBUDq4pUijN3niIaPswj67tAbt+zXrR3uVqTygiIiIikkv+LgcnE1OIP5tiKrhAVVxeN24fn8EF4E0LuFTBJSIiIiLnueKAy7btFcAYTBVXXWCdZVnPW5ZVx7IsfwDLsvxT//4PYG3qOhuYYNv2krzbvkjBNn3dQbqGbMb/9D6Y8ii4kzMuOLkPTu1XwCUiIiIikkuhAS4ATp11mwougIRj+bgjH2B78OAsQBVc7vzdiIiIiIj4lJxOkr0PWI4JuSKBl4GVQKJlWclAYurfXwKKp65bBgzO5X5FCo3TSW4WbTnKTUX3gsMFRzfDrx9kXJQ2fytG87dERERERHIjLeA6neT+f/buPcyyuyzw/ffde9etq6q70+lO0p0LCSEQIneCIAhCkOE4iODgoOIoMgg644x4jsrFmWfmzNHjGXU8yIzjOIgXYEBUZhQUuV8ULwSCBAWSEAy5p5NO0peq6q7L3uudP9baVdVNJd21u2qvvau+n+ep51d77bXq9yaQ59lrv+t935UKruPbvYKrQ4fGQM/gAmA5wVXUG4ckSZIGSk8Jrsw8Djwb+A2gQ5nA6v60Tnm9BPw68G3VdZKAT954H4udgiuLm+HSZ8NVL4G/+GV48OsrJ935OWiNw/mPry9QSZIkaQuYrBJccycluLZ5BVfRrhJcvT772idRxWeLQkmSJK3S86fYzFzIzH8JXA68Hng/ZdXW16r1/cDPAJdn5r/KzIUNiFfaMj705YNcOJnsOHwTXPhU+D/+Y1nJ9Wc/A5nlSXd+DvY/CVqj9QYrSZIkDbnRVoOxVoMZE1wrig5tmjQHfAbXSotCE1ySJEla0TrbP5CZdwD/qfqRdAbmlzp88sb7+IkrjhL/0CkTXDsPwPN+Fj78s/Dmx8H+J8Dd18M3v6bucCVJkqQtYXq8xex8GybOKQ9s+xaFbYohaFGYjQYUWMElSZKkk5x1gkvS+l379Qc5vtjh+TvvLA9c+JRy/eYfheYo3P4ZOPj35bErXlBPkJIkSdIWMzXWKmdwNUdgbBec2OYJruzQzibNQU9wRfXVhRVckiRJWsUEl1SD6259kGYjuGzhJth5IUxfUL7RbJUVW92qrUyIwb7ZlCRJkobF5FhVwQWwY8+2b1EYRWe4ZnAV7XrjkCRJ0kAZ8E+x0tZ03a2Heez+aVr3/O1K9dZaTG5JkiRJG2ZqrFXO4AITXADZLhNcAz6Di0Y1gyuLeuOQJEnSQDmrCq6ImAReAjwduAjYCTRPc1lm5vPPZl9pmC11Cq6/4wg//OSd8Hdfh6e+su6QJEmSpG1herzFPUfnyxc7zoXZ++oNqGZRdGjTHPgZXGGLQkmSJK2h5wRXRPwE8P8A0+u5DMhe95S2ghvvmeHEUodvm7qjPHDhU+sNSJIkSdomlmdwQZnguu/GegOqWWTZonDgZ3B1WyimCS5JkiSt6CnBFRE/D7yJMmF1Ot2E1mB/Ypb65LrbykHWVxU3AwH7n1RvQJIkSdI2MTW+egbXudu+RWFkt4JrwKcXRNUoxgouSZIkrbLuT7ER8QTgZ6uXNwLPAyaq1wm8FJgCvgn4KeDO6r23AxOZeboWhtKWdt1thzmwa5ydD/wd7HsMjO+sOyRJkiRpW5hcPYNr4hxYmoOl+XqDqlEUHYohqOBamcFlgkuSJEkrenlM68eqdQl4YWb+eWYurD4hM49n5g2Z+WbKRNdHgR8C3n1W0UpDLjP5/K2HeeojzoG7/9b2hJIkSVIfTY+1WGwXLLQ7ZQUXwIkH6w2qRmUFV2PgZ3AtJ7iKot44JEmSNFB6SXA9h7JS6w8y847TnZyZs8DLgIPASyPiZT3sKW0Jdx+d5+Cxeb7t/HmYOwQHnlx3SJIkSdK2MTVWdumfW1iV4NqubQqLgqCgk01azcFOcMVygqtdbyCSJEkaKL0kuC6q1r99iPfHTj2QmXPA71DO4fqhHvaUtoTrbi2fDn3aeNW50wSXJEmS1DdT4yMA5Ryu7Z7gqtr9dWgM/gwuWxRKkiRpDb18it1RrXedcvx4te56iOu+VK1P6mFPaUv4/G2H2THa5KL27eWBvY+uNyBJkiRpG+lWcM0utGHHnvLgdk1wFd0EV3PgZ3BFo/zfrRuzJEmSBL0luI5V68gpxw9X6+UPcd10tZ7Xw57SlnDdrYd58iW7aT5wM0wfgPGddYckSZIkbRvT46sTXN0Krm06g6tq9zcUM7ii+urCCi5JkiSt0kuC62vVeuEpx79C2YLw2x/ium+t1uMP8b60pc0utLnx4DGe+og9cP9NsM/qLUmSJKmfJpcruJZg4pzy4DZPcBU0aA78DC4ruCRJkvSNeklwXUeZyDp1eNBHqvUpEfHPV78RES8BfgBI4As97CkNvS/ecYQi4epLdsGhr8K+K+sOSZIkSdpWui0KZ+bb0ByB8V3bvkVhm+bAV3DF8gyuot5AJEmSNFB6SXB9rFpfEBGrr38HcLT6/Tcj4tqIeHdEXAv8r1V7/WZvoUrD7YZ7yu6eT9g5B0tzzt+SJEmS+uykFoUAE3vgxDat4MruDK4GrUYvXw30UdMKLkmSJH2jXj7Ffgi4DWizqh1hZh4CfoyySiuAq4Hvrdbu42DvyszfP5uApWF148EZ9k2PsXvulvLAvsfUG5AkSZK0zXQruGbnqwTXjnO3cQVX+e+gMwQzuJYruKqYJUmSJOghwZWZ85l5WWbuz8yPnPLe7wPXAJ8COpSJrQBuBn4iM3/o7EOWhtONB49x5QXTZXtCgL0muCRJkqR+2jHaJALmFkxwrSS4mjSGJcGVVnBJkiRpRWuj/2Bm/gVwTUSMAOcCxzPz2EbvIw2TTpHcfO8sP/iMR8D9N5UDrSf31h2WJEmStK1EBFNjLWaWE1x74L6v1BtUXap2fxnNmgM5vejGaItCSZIkrbJpjbYzcykzD5rckuDWB+ZYaBdcuX9nWcG19zEQg/2UpCRJkrQVTY21TmlRuE1ncHUTXI3BT3A1mt0KrqLeQCRJkjRQ1p3giogiIjoR8TubEZC0Fd10cAagbFF4/02w79E1RyRJkiRtT1NjLWZXV3AtzcHSiXqDqkN3nlVseGOXDRdNK7gkSZL0jXqp4Fqq1j/fyECkrezGgzM0Ah41tVD2+Hf+liRJklSLqfHVCa5zy3U7VnHlEFVwNaoknDO4JEmStEovCa6D1Xp8IwORtrKbDh7j0r2TjB/5Wnlg35X1BiRJkiRtU1NjLWa6LQon9pTr8QfqC6guyxVcg5/gopvg6sYsSZIk0VuC6/pqtQRFOkM3Hpwp2xMeurE8YItCSZIkqRbTa1VwndiGFVxVsmgoKrhsUShJkqQ19JLgejsQwD+LGIJm3VLNji+2uf3B4zzm/J1w6KswsgN2XlR3WJIkSdK2NDXWYu4bWhRuxwquolyH4LY+bFEoSZKkNaw7wZWZ/wv4Y+AK4J0RMbHhUUlbyFfvnSUTHnPBNNx/E+y9Ahq95JYlSZIkna3JsRaz887gWm73N1QVXEW9gUiSJGmgrPtRrYi4BHgjMAa8HHhmRPw28GngLuDE6f5GZt6+3n2lYXXTwWMAPHb/NHzkq/CIZ9YckSRJkrR9TY+1mF1sUxRJY+Kc8qAJroEWVYxF0e6pDY0kSZK2pl56EdwK5KrXFwP/bh3XZ4/7SkPpxoMz7BhtcvFkAcfudP6WJEmSVKOp8RaZcHypw9RYC8Z3bc8Whd12f43Bvz1vNssY0xlckiRJWqXXh59i1c+pr8/kR9o2bjo4wxXnT9N44ObywN7H1BuQJEmStI1NjY0AnNymcDsmuJYruAY/wdWdwVV02jVHIkmSpEHSyyfZt294FNIWlZnceHCGFzz2fLj3i+XB8x5bb1CSJEnSNjY1Xt4Gzy4sAePbOMFVVUPF4Lco7FZwmeCSJEnSautOcGXmqzYjEGkrOjS7wINzizzmgmm453oYnYY9l9cdliRJkrRtTY2VCZ3ZhSrBM7EHZg/WGFFNiuFpUUiz/N8sO7YolCRJ0ooh+CQrDa+vHpwF4MoLpuGG62H/E6DhWGRJkiSpLmu2KLzvKysnHL0LHrwF5o/AiSPQWYQsyp+is/L72FR57cQeWDoOMwdh9j44cRgWjsHCTPn3RidhZALGd8PUeTC5DxpNmD8G80fhEc+EC5/S538LLLcobDSHqILLGVySJElaxQSXtIlue3AOgMvOHYN7vwRXv7rmiCRJkqTtbWpsdYtCYMeelRaF93wR3vbtZVKrV6NTMDZd/gAsnYDFuTJhlsU3nv+IZ8Gr/qz3/Xq1PINrGBJcVQVXYYtCSZIkrTDBJW2ie47M02wE583fBu15OPCkukOSJEmStrXpagbXzHIFV1WBtXQCPviGMjH1srfBjr0wvgtaY+WcqkYTIsrfI2BhtkyMHX8ARnbA9PkwdX55/lqKDhx/EObuKxNd47vgT14Hc4f69E9+iirZFo2RevZfh1YjaGeDtIJLkiRJq5jgkjbR3UdPcP70GM2DXywP7DfBJUmSJNVppYJrVYtCgM/+Jtz+N/Dit8Dl15z+D41Nw879Z75xowlT+8qfrvHdcOT2M/8bG2mYKrgaQYcGhTO4JEmStMq6E1wRcctZ7pmZeflZ/g1pKNxzZJ79uyfgnuvLViXnPqrukCRJkqRtbbKb4Jo/JcH1yf8XLngCPPkH+xfMyA5YPN6//VarElzRGPznXpuNoKBhi0JJkiSdpJdPspcCCcRpzstqPfW8PPVEaau65+gJHnfhLrj7erjg8dBo1B2SJEmStK2NthqMthrfWMHVnofv+KX+VjSN7oCluf7tt1o3WdQcjgRXmybZMcElSZKkFb18kr2d0yepGsAeYLJ6ncA9wFIP+0lDKTO55+g8L7xqL9zy9/DUH647JEmSJEnA9FhrVYJrb7k+7nvgEd/S30BqreAq2/01hyDB1Wo0KAgybVEoSZKkFev+JJuZl57puRHxOOB1wKuBrwEvy8wH1runNIwenFtkoV1wZesgtE/AAedvSZIkSYNganxVgmvvFfAdvwyPe1n/AxmdhGIJOkvQHOnv3lWCa1haFHZogDO4JEmStMqm9kvLzC9l5muA1wLPAd4fEYM/wVbaAPccnQfg8vY/lAf2m+CSJEmSBsHUWGtlBlcEPP21MHlu/wMZ2VGuizW0KezO4BqKCq4ywZWFCS5JkiSt6MtAoMx8G/BJ4BnAj/RjT6ludx85AcCB4zfCyGT5ZKgkSZKk2k2NtZhZGIB5TqNVgmuphjaFOUQVXM2gMMElSZKkU/QlwVX5IyCAH+zjnlJtuhVcuw5/GS54fH+HVUuSJEl6SNPjqyq46jRSja1eOtH/vasKrkZr8O9TmlG1KDTBJUmSpFX6meA6WK1X9nFPqTZ3Hz3BeBNah74E+59YdziSJEmSKpNjq2Zw1Wl0AFoUDkEFV6vRreAagP/NJEmSNDD6meA6UK0TfdxTqs09R+Z52vQDxNJxOOD8LUmSJGlQTI21mBuEBNdIdXtcR4vCogCg0Rzp/97r1GwE7WxawSVJkqST9CXBFRGjwKurl3f2Y0+pbvccOc6r4k/KFxc9rd5gJEmSpHWKiN0R8d6IuDEiboiIb4mIPRHx0Yi4uVrPqTvOXkyND8gMrm6LwhoruJrNwW9R2GqWLQqdwSVJkqTVNjXBFRHNiHgu8HHg8UACH9zMPaVB8ZwH/oBrTnwEnv3TsPeKusORJEmS1ustwIcy80rgicANwBuBj2fmFZT3eW+sMb6eTY+1WGwXLLRrTph0WxTWUsHVZimbNJvR/73XqdloUNCANMElSZKkFetuth0Rt5zhqaPAXmB1v4PDwC+ud09p2HRu+DN+fOnt3HjuNVz5vH9TdziSJEnSukTELuA5wA8DZOYisBgRLwGeW532duBTwBv6H+HZmRorb4XnFjqMtWqsYFqu4KohwZUdOjRoNQY/wdVqWMElSZKkb9TLNNlLKSux1vsp+GvA92XmPT3sKQ2PB/6B+F8/wt/nZXz5qf8fVzb6OepOkiRJ2hCXAYeA34mIJwKfB14HnL/qnu4gcP5aF0fEa4HXAlxyySWbH+06TY2Xz2HOzrfZMzlaXyDLFVz9b1GYnTYdGjSH4H6lEVFWcJngkiRJ0iq9JLhup0xwnc4CcAT4CvAh4I+rp/6kre32v6GxNMfPLP0ob9gzlCMJJEmSpBbwFOBfZ+a1EfEWTmlHmJkZEWveG2bmW4G3Alx99dVncv/YV1NjZdXWzMJSvYGMVAmuGiq4smjTocnIMFRwNYMFwhaFkiRJOsm6E1yZeekmxCFtHdVThcdyB/t3TdQcjCRJktSTO4E7M/Pa6vV7KRNc90bE/sy8JyL2A/fVFuFZmBorK7jmFuqewVW1KFw60feti06HNo0hmcFVtii0gkuSJEmrDX4vAmnYVE8VdmhwYPd4zcFIkiRJ65eZB4E7IuIx1aHnU3bneD/wyurYK4H31RDeWZsaL5/1nK27gqs5Ao1WPS0Ki/aQzeBqmuCSJEnSSXppUSjp4VQ3XaMjI+yaGKk5GEmSJKln/xp4V0SMArcAr6J8SPIPIuLVwG3Ay2uMr2dTY+Wt8Mx8u+ZIgJHJeloUdpbo0ByKGVzLFVy2KJQkSdIqJrikjVYluPbtmiBi8J+GlCRJktaSmdcDV6/x1vP7HctG21lVcB0bhATX6I6aKrg6tGkOSQVXg4IGYYJLkiRJq6z7Ua2I2BcRH4+IT0TEC87wmhdU5380InavP0xpiFQ3XeftnKw5EEmSJElrmR4vOy3MzNfcohBgZEdNFVxtigyaQ5DgajSgkw0oirpDkSRJ0gDppRfBK4DnAU8BPn2G13waeBJwDfD9PewpDY9uBdfOHTUHIkmSJGkt4yMNRprBsRODUsHV/wRX0WnTpslIc/ATXK1GwxaFkiRJ+ga9JLheACTwgcycP5MLqvP+FAjghT3sKQ2NTqe8ST5/lwkuSZIkaRBFBNPjIwNSwTUJi/1vUUjRGaoZXLYolCRJ0ql6+ST7hGq9dp3Xfe6U66UtafbEAgDn77ZFoSRJkjSopsdbzAzMDK4Tfd82izYdGkMygyvo0CAKE1ySJEla0UuC67xqvXud1x2s1gt62FMaGjPzZYLrgt1WcEmSJEmDqkxwDUIFVz0tCqkSXMMwg6tZJbhsUShJkqTVeklwdR9xG1vndaPVOvifnqWzMHdiEYD950zVHIkkSZKkhzI9NjIYFVwjO2ppUZjVDK6hquAywSVJkqRVeklwHarWx67zuu759/ewpzQ0Ou02RQY7xlp1hyJJkiTpIQxWi8L+V3Bl0aEYugquou5QJEmSNEB6SXB9jrIK6+URcUbXR0QT+F4ggS/0sOfD/e3dEfHeiLgxIm6IiG+JiD0R8dGIuLlaz9nIPaWHk9kZmlYfkiRJ0nY1PT7CsYFoUTgJi/W0KGzTYKTZy9cC/RURpBVckiRJOkUvn2T/pFovB37+DK/5+ep8gPf1sOfDeQvwocy8EngicAPwRuDjmXkF8PHqtdQXw/QkpCRJkrRd7ZwYsAquzP7uW7Tp0Bya+5YimoQVXJIkSVqllwTXu4Fbqt/fEBHvjIhL1zoxIh4REf8DeD1l9dZtwNt72HNNEbELeA7wWwCZuZiZR4CXrNrn7cBLN2pP6XSi6NCmQTOG40ZRkiRJ2o6mx0eYXWjTKfqcWDrVyA4gYelEf/ctOnSyMRQzuACSBg0ruCRJkrTKuocEZWYnIr4P+HNgHHgF8H0R8SXK6qlZYIpy5tbjKJNoAZwAvjczN/IRucsoZ4L9TkQ8Efg88Drg/My8pzrnIHD+WhdHxGuB1wJccsklGxiWtrMsbFEoSZIkDbqd4+Xt8OxCm10TI/UFMjpZrkvHy2qufqlaq48NyX1Lhi0KJUmSdLKemm1n5nXACymTRwE0gSdQztl6dbU+oToewN3AP8rMz21AzKu1gKcA/y0znwzMcUo7wsxMyuqxtf453pqZV2fm1fv27dvg0LRdRbYpaNAYkhtFSZIkaTuarhJcM3XP4RqpklpLfZ7DVbRp06TVHI77lo4tCiVJknSKnqfJZuZfUlZp/VvgK5SJrNU/AF8G3gRclZl/dXahrulO4M7MvLZ6/V7KhNe9EbEfoFrv24S9pbUVBR2Gp9WHJEmStB1Nj5dVW8dO1DyHq1u1tdjvBFenum/p+WuB/oomgRVckiRJWrHuFoWrZeYx4BeAX4iIc4ALgZ3AMeCuzDx89iE+7P4HI+KOiHhMZt4EPJ8y2fYV4JXAf6zW921mHNJJslNWcDmDS5IkSRpYg1fBNdfffYsOHZpD01q9iAYNK7gkSZK0ylkluFarklmbmtB6CP8aeFdEjAK3AK+irEz7g4h4NXAb8PIa4tJ25QwuSZIkaeDtrCq4ZuZrruAaqaeCK7JNm8bQtCjEFoWSJEk6xYYluOqSmdcDV6/x1vP7HYsELA9rblrBJUmSpE0WEd8EPIvy3u6Lm9QafktaruBaqLmCa3SyXPs+g6vsPDEsrdUzGkTaolCSJEkrekpwRcSzKedsfT0z7ziD8y8BLgWKanaXtGVFdiiyQWNIbhQlSZI0eCLiAPDT1cvfzcy/W+Oc3wBec8qxvwD+yWa3i98Kpnuo4CqKZLFTsNAuaASMNBuMNhsUmSx1yvcyk4igESyvjQiKTDpFUhQw0grGW83ynmG5gqu/LQojO7Rp0hySGVwZTRomuCRJkrTKuhNcEXEN8DEgKSunTpvgAs4BPgVkRDzHpwq1pRUFRQzHTaIkSZIG1vcDPwnMAf/u1Dcj4ieA165x3XOAPwBesKnRbQErM7hWElwnFju86D9/mkOzC4w0y7bj7U7BYrtMarWL3NAYdow2+fEnj/Dj0PcKrijadHK4KricwSVJkqTVeqng+ifVen1mfuFMLsjML0bE54GnAP8UMMGlratqUShJkiSdhedU6yczc3b1GxHRAn62erkA/BfgVuCVwNOAayLiH2fmn/Up1qE0PtJktNng2ImVFoW3P3icW+6f45orz+PC3RO0i4JWo8FYq8Fo9TPWajJSza1arJJfzQhGWmWyqBFBAplJkUkmdDJpRNCMoFElzeYWO/zxF+7i2jvmqgTXif7+C8iCzhDN4Mpo0cAElyRJklb0kuD6FsrqrQ+v87oPA08FntnDntLQiCx72UuSJEln4ZGU913XrvHeNcB51fs/lplvB4iI3wVuAg4ArwBMcJ3G9HiLY6squA7NLADwo895JE9/5Lmbvv/X7pvhtnvKPfvforBNhybNoangapYJrkxw3rEkSZKgp2/hL6/WG9Z53U2nXC9tTVmY4JIkSdLZ2lutt67x3jXVegx4V/dgZh4H3k05L/nqzQxuq9g5McLM/EoF130z8wCct3O8L/tPjrZ4cKFZvuh3i8Ls0KZBa0hmcNGN0zaFkiRJqvTySbaagMt6P313+y1M97CnNDQiO87gkiRJ0tnaU61r3Xc9i7J66xOZ2T7lve6DhRduVmBbyfR466QZXPdVFVznTY/1Zf/JsRaziwW0Jmqo4Co7TwxLBRdRJQKLTr1xSJIkaWD08i38kWo9b53Xdc+f6WFPaXhkQUGz7igkSZI03BarddfqgxExzkp11l+ucd3Rau1PhmbIlQmulQquQzML7BhtMjnWSzf/9ZsaazG32CZHd/S9gquRHdo0aQ1bgitNcEmSJKnUS4Lr1mp93jqve2613tHDntLQKJ+ENMElSZKks3JXtT75lOPfzkry6q/XuG53tc5uRlBbzfTYyDdUcPWregvKCq4iIUd2wGKfWxQWnSGbwVV9fVGcWrQoSZKk7aqXBNcnKXu6vzQirjqTCyLiccB3U7XR6GFPaWg0ClsUSpIk6ax9hvK+659FxOUAEdEEfrp6/whw3RrXPbZab9/0CLeA6fEWx1bP4Do2z3nT/Zm/BTA1XlaKFa0dsNTfFoWNagbXSHNI7l0atiiUJEnSyXr5JPs2oAM0gQ+cLskVEd8EvL86v6iul7asoOxlL0mSJJ2F36nW3cDnIuKPgC8Cz6F8cPB/ZK7Zq+3Z1ft/35coh9z0+MkVXIdmF9jXxwquqbEyadNpTvS3giuTBh06NBiSAi6yUbWNzKLeQCRJkjQw1v0tfGbeDPwa5dOElwCfj4i3RcRLIuLREXGgWl8SEb9F+VThIyhvsn4jM7+ykf8A0sDJYqV9hiRJktSDzPxz4Lco77t2A9/FSnXW3cDPnXpNRFwKPK16+VebHuQWsHOixfHFDu1OmTQ5dKy/Ca7J0TJps9ScgKUTfdu3myRKmkQMR4YrwgouSZIknazXybk/DTwSeDFl//dXVT9r6X5afj/wkz3uJw2NcgaXCS5JkiSdtdcCXwJ+BHgUcBz4KPCGzLx/jfN/fNXvH9788Ibf9PgIALMLbcZaTWYW2n2u4KoSXI1xWHqwb/t251gVMUSzg7stCtcsXJQkSdJ21NO38JnZycyXAG8EHqRMYj3Uz4PA6zPzpQ/RQkPaUiILcphuFCVJkjSQsvSWzHx8Zk5k5rmZ+X2ZedtDXPIrwGXAZZn59T6GOrSmqxlYM/NtDs0sAHBePyu4qgTXYmO8vy0Ku1VQw3Tf0u2SYQWXJEmSKr1WcAGQmb8UEf8V+A7gW4GLgJ3AMeBO4NPABzOzj5/UpXo1rOCSJElSDTLzYN0xDJudVYLr2PwSJxbLxMl5O8f7tn83wbUQY7DUzwRXWcG1PNdqGHQruIr2w58nSZKkbeOsP81m5hzw3upH2vbCGVySJEnSUOi2KDx2os2R44sA7Jvqf4vCecZhca5v+y4nuIapgssWhZIkSTpF376Fj4iRiHhZRHygX3tKdbBFoSRJkvohIvZFxC9FxF9HxGcj4jcj4rF1xzVMVloULnFft0Xhzn62KCzvG04w3t8KrizKZZgezOtWmxVFvXFIkiRpYGx6P4KIeBLwKuAVwJ7NNjqbsAAAIABJREFU3k+qW9AZrhtFSZIkDZyI+Fbg/UAC35WZf3XK+xcAnwEuXnX4qcAPRMSLM/PjfQt2iO2sKrhm5tvcNzNPsxHs2THat/0nR8tb8rkchc4idNrQ7EPbwCFsURhhBZckSZJOtimfZiPiXOAHKBNbT1j9FuUNmrRlNbKgsIJLkiRJZ+e7gd3Abacmtyq/AlyyxvFx4N0RcUVmHtvMALeC1RVch2YW2Ds1SqMRfdu/0Qh2jDaZy6pqbOk4NHdu/sbLCa4hum9ZnsFlgkuSJEmlDSsziYhGRLwoIt4L3AW8mTK5FdVPAXwY+MGN2lMaRIEzuCRJknTWnkb5cOBHT30jIvYBL6/e/1vgccAU8IbqlL3AP+9PmMNt+qQKrgXOmx7vewyTYy1ms6oa61ebwm6SaIgezGs4g0uSJEmnOOsKroh4DOXN0w8C53cPrzrleuCdwLsz896z3U8adI3sOINLkiRJZ+uCav3iGu99J9CkTHD9SGZ+pTr+yxHxncCzgX8M/OqmRznkRlsNxloNZhba3Hdsgf27+p/gmhprMdupElyLc/3ZtKrgIoanRaEVXJIkSTpVT59mI2Ia+D7KFoRP7x4+5bQEfjkz39h7eNLwaVCY4JIkSdLZ2lut963x3nOq9ebMvP6U995PmeD6ps0KbKuZHh/h2IklDs0u8ISLdvV9/8mxJsc6ZSVZvyu4hqlFYZjgkiRJ0inWleCKiGsok1rfDUx0D1frceCPgXcAH1p1TNpWrOCSJEnSBpiq1mKN955J+UDhJ9Z47+5q3bMZQW1FO8dbHDm+xAOzC5w3Pdb3/SdHWxyZ71Zw9ekWutvmbxgTXLYolCRJUuW0Ca6IuBT4YeCVrAwx7ia1EvgkZVLrf2bmbHXNBocpDY+GM7gkSZJ09maA3cCB1Qcj4kLgCsp7sb9e47puQsybsjM0PTHCrQ/MUSTs21lPi8Kjs9Wt+VJ/WxRmY5haFFaxWsElSZKkysN+mo2IT1C2vwhOvkG6gXKu1rsy847NC08aPpG2KJQkSdJZu4myHfwLgP+y6vg/XfX7X65xXXd21wObFNeWs3O8xWfvOQbAvqkaKrjGWhxeqloU9quCawhncDWaVnBJkiTpZKf7NPvcVb/fB/w+8M7MvG7TIpKGnBVckiRJ2gAfBZ4BvCgifgp4G+VcrTdRVm99OTNvXeO6J1Xr1/oR5FYwPd5ioV0Wvp23s54E111L/Z7BVf7zRmOI7luqFoVFp80QRS1JkqRNdCafC7P6+SxlO8JThxhLWqWRnaHqZS9JkqSB9BvAbPX7LwEPAp8G9lXH3nzqBVH2in8h5f3b5/sQ45YwPTay/HsdM7imxpo8sNhtUdjnCq7mEFVwVS0KOx0ruCRJklQ6XYJrlpX2hC8C/idwT0T814h4xmYHJw0jK7gkSZJ0tjLzHuD7gTlW7sm6bePfnZm/s8Zlz2elReGfb3qQW8T0+EqSZ29NLQofXKpi6HeLwiGawRWrKrgkSZIkOH2LwvMpe7z/MPBtlDdU5wI/BvxYRHyNchbX/3iI9hjSttOgAGdwSZIk6Sxl5gci4krKRNejgOPARzPzQw9xybdQJrYS+Fh/ohx+0+NlBdeuiRHGR/r/OX5qrMU8VWJtaa4/m1ZzrGKI7lsaVbWZCS5JkiR1PWyCKzNPAO8A3hERlwKvAn4IeER1yqOA/wD8h4j4q+rcP9ysYKVhYIJLkiRJGyUz7wZ+5QzP/Tng5zY3oq1n50R5W7yvhvaEUFZwLdIio0n0u4JriFoUWsElSZKkU51xH7XMvDUz/31mXgZ8O/AuYJ6VVhnPAv47cHAzApWGRdMWhZIkSdLQ6FZw1TF/C8oEFwTFyI4+zuCqKriGqEWhFVySJEk6VU/fwmfmJzLzByn7u/8Y8BlWEl1jlC0xAH4yIn4jIp69EcFKw8AKLkmSJGl4dGdw1ZXgmhqrKpNaE7DYpxaFVQXXMCW46FZwVck5SZIk6azKTDJzJjPfmpnPBK4C/hNlBVc32bULeA3wqYi4JSJ+ruohL21NmTTI5ZsvSZIkaSNExDUR8WsR8bmIuDMijlbrZ6vjz6s7xmHVTXDV1qJwtNy/3ZzofwVXc3juW5pVBVenY4JLkiRJpQ3ro5aZN2bm64GLgBcDfwS0WUl2PQL4WeBLG7WnNHC6TxOa4JIkSdIGiIhHR8S1wEeBfwE8BTgATFfrU6vjH4uIv4mIK2oLdkjtXG5ROF7L/mWLQlhqTMDSif5s2p3BNUQVXN0ZXGmLQkmSJFU2fFBQZhaZ+YHMfBnlDdf/CXyRlURXbPSe0sDIMsGVtiiUJEnSWYqIJwGfBa7m5Pupo8Bd1br6+NOBz0XEE2sJeEgd2D3BxEiTqw7srGX/qeUE13jfWxQ2hujBvGaralFogkuSJEmVTX1cKzMfAN4CvKW6OfvnwPdv5p5b2d/8wwMUmTzrUXvrDkUPpfskpAkuSZIknYWIGAP+GOhmXf4O+GXgI5l5aNV5e4EXAj8FPKk6/48i4rGZudDfqIfTnslR/u7//keMNDf8+c8z0q3gWmiMw21/Db94WVnJNTIOex8Ne6+AHefC/DFYOAbzR8vf54+W50VUP42VH1a9zgIWZ2FhBtrz5b1KFuXmzZFa/pl7EY0yVmdwSZIkqatv/Qgy83rgJyLip/q151bzqx/7qgmuQWeLQkmSJG2M1wCXAAn8JvAvM7tZiRWZeT/wroj4PeC/Aj9K2R7+R6rXOgN1JbdgpYLrCwdewYGLL4eRHTAyUSak7r8ZvvoROHEYxnet+tkJO/eX52ZWCatqXf6pXkfA6FT5MzJeHi86/Pq1D3Bs/KLa/rnXq9m0RaEkSZJO1veG25m51O89t4qZ+TajrfpuvHQG0gSXJEmSNsRLqvXveYjk1mqZWUTEjwPfAjweeCkmuIbC+EiDRsANU8/gRS98Zd/2/fXPfJjvbQ3TDK4y1qIwwSVJkqSS2ZIhMrfYplNk3WHo4RTV9w4muCRJknR2vomyeuudp0tudVXnvZNyHtfjNjE2baCIYHKsxexCfxM37aKg1RieEdmNZpngSlsUSpIkqWKCa4jMLXRom+AabFUFVziDS5IkSWfn3Gq9bZ3X3V6t52xgLNpkU2Mt5vqc4OoUSXOYElytbotCE1ySJEkqmeAaInMLbTrFGT28qZpk1S4jreCSJEnS2Tlareev87p91XpsA2PRJpscazG32L8EV2ay1MmhquBqWsElSZKkU5jgGhKdIjmxZAXXoCs6VnBJkiRpQ3yNstXg96zzuu75X9vYcLSZyhaF/UvcdG8rm43h+Uqg0SzvsYqOM7gkSZJUGp5Ps9tc92k+Z3ANtnZ1sxVNE1ySJEk6Kx+s1udExOvO5IKI+FfAcylnd31gk+LSJpgaa/a1RWG76gzSag5PBVerOQJYwSVJkqQVJriGRPdmp90xwTXIlvvBW8ElSZKks/NrwJHq9/8/It4dEU9a68SIeEJEvBN4S3XoKPDrfYhRG2RytL8zuLoPTg5Ti8JGs/z6wgSXJEmSulp1B6Az073ZsYJrsHW6FVxD1OpDkiRJgyczD0fEq4D3Uj6Y+L3A90bE/cDNwBwwCTyKlblbAXSAV2bm4f5HrV5NjbWY7WsFV3lf2RyqBNcosDL3WJIkSTLBNSS6/didwTXYCiu4JEmStEEy830R8RLgt4HzqsP7gL2rTludobgPeFVmfhANlcmx/lZwdTuDDFMFV6tqA28FlyRJkrrWneCKiB+qfv1EZt65jusOAN8OkJnvWO++291KBVdRcyR6OIUzuCRJkrSBMvPPIuIK4FXAdwNPA3asOuU48DngfwK/m5mz/Y9SZ6tMcPUvcdOdwdVsDk/niWazQScDTHBJkiSp0ksF1+9SDi3+buCME1zA46trC8AE1zp121VYwTXYVloUmuCSJEnSxsjMGeA/Vz9ExE5gGpjJzGN1xqaNMTXWZLFTsNguGG1tftJpGGdwtRpBh4YVXJIkSVpWR4vC4fkEPUCcwTUclvvBN+z+KUmSpM1RJbXWTGxFxHcDLy5Py1f3NTD1bHKsvH+YW2gz2hrd9P2GsUVhsxEUNJzBJUmSpGX97EfQ3cseez2YW3QG1zBYblFogkuSJEn1eArww9WPhkQ3wTXbpzlcyxVczeFKcHVo2KJQkiRJy/qZ4NpfrTN93HPLsIJrOBSd8mbLFoWSJEmSztRUt4JrsT8Jru6Dk83GEM3gskWhJEmSTtGXT7MRcRHwL6qX/9CPPbea1QmuTJNcg6pbwdUwwSVJkiTpDK1uUdgP7aJsrDJMLQpbjQYdmpAmuCRJklR62D5qEfE64HUP8fZbI+JXT/P3A5gEzq1eJ/DBdUUo4ORWFZ0ih6qVxHZSVE8TRtMElyRJkqQzMzVW3j/MLvQnedOdwdUcogSXFVySJEk61ekGBe0GLqVMTK3+5BvAeT3sdxPwKz1ct+3NLbRpUSa52kXSMn8ykNIWhZIkSZLWqd8VXMszuIYowdVqBEvO4JIkSdIqp0twHQFuO+XYIygTXvcDx09zfQHMAl8HPg78dmbO9RDntje30OFXRn6DJgWd4kV1h6OHUBTlDWk0TvefliRJkiSVJkfL+4fZvrUorBJczSGawdUM5k1wSZIkaZWH/RY+M98CvGX1sYgoql9fk5nv36zAdLLZhTaPjjs4wdjyzYgGT7ddhhVckiRJks7UlBVcp9WMskWhM7gkSZLU1cvjWrdXP6er3tIGmltoszeOVRVcJrgGVdEpb0gbJrgkSZIknaF+tyhsd8rnVodtBleRYQWXJEmSlq27j1pmXroJceg0js8vsIdj3Mdu2kVx+gtUi6JbwdW0RaEkSZKkMzPaajDabDC70J/kTXsIK7hajbKCK6zgkiRJUmV4Gm5vc83FIzQjadHB/NYAW05wWcElSZIk6cxNjjX73qJw2Cq4OjTxhliSJEldlpkMifGFwwC06FjBNcCKTpngaoT/aUmSJOnMRIQlKWJyrNW/FoVVgmukOTzPvEYEhTO4JEmStErP38JHRAt4KfBC4CrgHGD8DC7NzLy81323qx1LD0ATZ3ANuKKoZnBZwSVJkqQzF0BW69nyZmFITY21mO1bBdfwzeACKKJBwwSXJEmSKj0luCLiycB7gEed+tYZXO4N1zq1OwU7O0egCa3osGCCa3B1K7icwSVJkqT12ahMw3BlLLRscqzF/bML3HzvDO0iaUQwPtJgrNVkpBkUCZlJAkUmRUJR3Rsuv84kEyJgrFVeO9pssFQUtDtZ7dNksTN8M7gACho0i/4kASVJkjT41v0tfERcCHwM2M3KzVMbuB9Y2LjQ1DW30GFvHAXKFoXHTXANrHQGlyRJktYpM4enT5w2zTk7RvnYDffygjf/Rd/2bA1Ri0KAgiakLfslSZJU6qXM5I2U7QgTuBb4t8BfZObSRgamFbOLbc6NYwA06Sw/eafBk90WhQ0TXJIkSZLO3L9/8VW8+In7aTaCZpQVW/NLHebb5T1goxEE0IigEeVKnPw6opxVlZkstAsWljosdpKRZiy3I5xbaDM732ZspMkj9uyo9x96ndrRYs/SYZbL1CRJkrSt9ZLgeiFlcuvLwLdl5uLGhqRTzS20OZcywTVCxxlcA6xbwWWLQkmSJEnrcfGeHVw8ZAmnfvtI41t5/Ynfgr//Q3jCy+sOR5IkSTXrpR/BRdX6NpNb/TG70F5uUdikoF3YkmFQrSS4rOCSJEmSpI30R80XcvvEVfChN8LcA3WHI0mSpJr1kuCaq9a7NjIQPbS5hTZ7qxaFLSu4BpoVXJIkSdpKIqIZEV+IiD+tXl8WEddGxNci4vcjYrTuGLV9RKPFHxz4GZg/Ch/5N3WHI0mSpJr1kuC6sVr3b2Qgemhli8KygqtFh7YJroG1nOBqmOCSJEnSlvA64IZVr38ReHNmPgo4DLy6lqi0LTWbwV2jj4Rn/SR88ffgHz5Rd0iSJEmqUS8JrncCAbxkg2PRQ5hd6CxXcI1Eh07HFoUDyxaFkiRJ2iIi4iLgRcDbqtcBXAO8tzrl7cBL64lO21Gr0Sgf+HzOz8CeR8Inf6HukCRJklSjXhJcvwX8NXBNRPi0Xh8sHj/Gjlig3SoHDrc7nZoj0kOxRaEkSZK2kF8FXg90n7A7FziSme3q9Z3AhWtdGBGvjYjrIuK6Q4cObX6k2haajaAoEkbG4aqXwN1fgMXjdYclSZKkmqw7wZWZHcrqrU8Db42It0bE4zY8Mi3rzJY3hEs7zgcgO4t1hqOH0U1wNU1wSZIkaYhFxHcC92Xm53u5PjPfmplXZ+bV+/bt2+DotF21GkG7qPKtFz8Dijbc1dP/RSVJkrQFrPtb+Ii4ZdW1Qdlz/dURcRx4gJWn+x5KZubl6913O4u5+wDoTO6HY1+n016qOSI9JFsUSpIkaWt4FvBdEfGPgXFgJ/AWYHdEtKoqrouAu2qMUdtMsxF0ujOpL/7mcr3jM3DZs+sLSpIkSbXppczkUqD6RElSJrkAJquf08nTn6LVmscfAKAzVVZwFe32w52uOqUVXJIkSRp+mfkm4E0AEfFc4Kcz8wci4g+B7wHeA7wSeF9tQWrbaTainMEFsGMP7H0M3H5tvUFJkiSpNr18C387Jqn6qjlfJriKqQvKtWMF18ByBpckSZK2tjcA74mInwe+QDmjWeqL0WaDhaVVTWMueTp85X1QFNDoZcS4JEmShtm6v4XPzEs3IQ49jLH5+wEopvaXa8cKrkGVRZsig5YtCiVJkrRFZOangE9Vv98CfHOd8Wj7On/nODccPLZy4OJnwN++Aw7dCOdfVV9gkiRJqoWPOA2B8cUHmYsdxGjZAdIKrgFWdOjQoNGI058rSZIkSTpjB3aPc/eRE2RWTWUueUa53vGZ+oKSJElSbUxwDYEdS4eZae4mmiMApAmuwZUdCho0TXBJkiRJ0oY6sHuC+aWCw8ere+I9j4Qde53DJUmStE2Z4BoC0+3DzLb2LM91soJrgBUFHRo0wwSXJEmSJG2k/bsmALj7yInyQERZxWUFlyRJ0rZ01gmuiHhGRPy7iPi9iPhQRHx8jXP2RsSBiNhztvttRzuLwxwfOYfGcgWXM7gGVrarFoV1ByJJkiRJW8uFu09JcAFc/HQ4fCvM3FtPUJIkSapNq9cLI+JK4LeBp68+DOQap78B+L+A+yPiwsw0Q7MOu/Mo94/uodEaBaBo+69vYBUFBUHLDJckSZIkbagDu8eBUxJcq+dwXfWSGqKSJElSXXr6Fj4ingF8jjK5Fat+HsqvVe/vBf5RL3tuW502u3OGxfG9NFpVPtIWhYMrO2UFlx0KJUmSJGlD7ZkcZazV4O6j8ysH9z8RmmPO4ZIkSdqG1p3giohJ4I+ASaAN/BzwGODlD3VNZt4GXFe9NMG1Dosz99OIpDNxLs3uDK7CCq6BlR0KGoQzuCRJkiRpQ0UEF+6e4K7VFVytMbjwKXDnZ+sLTJIkSbXopYLrXwLnAwXwTzLz32fmzcDpyor+krKK6+oe9ty25g/fA0Bnx77lFoVpBdfAiizonP1oO0mSJEnSGg7snji5RSHAvivhga/VE5AkSZJq08s38S+mnLP1/sz8wDquu7FaH9XDntvW/NFqUO7kPhrNbotCK7gGVlFWcEmSJEmSNt6B3ePfmODacxmcOAwnjtQTlCRJkmrRyzfxV1brh9Z53YPVuquHPbet9kyZ4GpOnUejOQJA2qJwcGWHgmbdUUiSJEnSlnRg9wT3zSyw2C5WDp5zWbke/no9QUmSJKkWvSS4ugmq+9d53Ui1dnrYc9vqzNwHQGvX+WCCa+BF0aEIK7gkSZIkaTMc2DVBJtx7bH7l4J4qwfWgCS5JkqTtpJdv4ruVWOeu87rqE+e6E2PbWs4eYimbjE+dA42qMsgZXIMrC1sUSpIkSdImObB7AuDkNoXnXFquVnBJkiRtK718E39ztT5zndd9B+Xsri/0sOfDiohmRHwhIv60en1ZRFwbEV+LiN+PiNGN3rNf4vj9PMBOJsdHoFHO4EpncA2syLYJLkmSJEnaJAd2jwNw99FVCa6xaZjcZwWXJEnSNtPLN/EfAgL4noi48EwuiIgXAs+qXv5ZD3uezuuAG1a9/kXgzZn5KOAw8OpN2LMvmscPcX/uYnK0BY2qy6MtCgdWZEHHGVySJEmStClWKrjmT37jnMvg8K39D0iSJEm16SXB9d+BGWAH8L6IuODhTo6IbwfeVb28F3hHD3s+3N+/CHgR8LbqdQDXAO+tTnk78NKN3LOfRuYf5MGcZmqstVzBRWGLwkEV6QwuSZIkSdos4yNNzp0c5a7VLQqhnMNlBZckSdK2su5v4jPzAcqKqQCeDNwYEf8NeEH3nIh4ZUT8m4j4c+DDwB6gAF6TmQsbEvmKXwVeX/19KGeDHcnMbpnTncCalWYR8dqIuC4irjt06NAGh7UxRpaOcoQpdow1l2dwRdGpOSo9JGdwSZIkSdKmOrB74uQZXFBWcB27C9ob/ZWDJEmSBlWrl4sy83cjYhfwy8BO4LXdt6r1t1edHsAS8C8y8wO9BrqWiPhO4L7M/HxEPHe912fmW4G3Alx99dV5mtNrMbp0jBkmGWs1V2Zw2aJwYDWyQ4YtCiVJkiRpsxzYPc7X7587+eCey4CEw7fBvkfXEpckSZL6q+dSk8x8C/BM4E8pE1uxxg/AB4FnZOZvr/V3ztKzgO+KiFuB91C2JnwLsDsiusm7i4C7NmHvzZfJWHuWE83p8nWznMEVJrgGlxVckiRJkrSpDuye4K7DJ8hc9ZzqOZeV62HbFEqSJG0XPVVwdWXmdZQJpt2UyaZLgV3ALGVS6S8yc9N6/2Xmm4A3AVQVXD+dmT8QEX8IfA9l0uuVwPs2K4ZNtTBDkw7zrZ3l6+UZXCa4BlVkh3QGlyRJkiRtmgO7Jphb7HBsvs2uifJB0LKCC+dwSZIkbSNnleDqyswjwIa2HzxLbwDeExE/D3wB+K2a4+nN/BEAFke6Ca7uDC4TXIMqrOCSJEmSpE11YPcEAHcfObGS4JrcByOTVnBJkiRtIxuS4BoEmfkp4FPV77cA31xnPBviRJngWlpOcFUf3E1wDazIDoUzuCRJkiRp0xzYPQ7APUdP8Nj91f1yRFnFZQWXJEnStmGpySCrKrg6Y7vK11WLQiu4BleDwhaFkiRJkrSJLqwquO46Mn/yG+dcagWXJEnSNrLub+Ij4rER0YmIdkR81xle8+LqmqWIuHz9YW5TVQVXMba7fN1NcGWnroh0GpEFiRVckiRJkrRZ9k6NMdIM7j5y4uQ39lwGh2+DoqgnMEmSJPVVL6UmrwACuCsz338mF2TmnwC3V/u9ooc9t6eqgivHuxVczuAadJEdK7gkSZIkaRM1GsH+XRPfmOA65zLoLMDMPfUEJkmSpL7q5Zv4bwMS+NN1XvcnlImx5/Ww5/ZUVXDFxDnl6wjaNIk0wTWoGmmLQkmSJEnabBfunuD2B4+ffHDPZeVqm0JJkqRtoZdv4q+s1uvXed3fVetje9hze5o/QjsbNCemlw8VJrgGWoMOhS0KJUmSJGlTXXVgJzfcc4ylzqp2hOdUCa4HTXBJkiRtB70kuKqBUDywzusOV+s5Pey5LRUnjnCMHUyOjSwf60SLhi0KB1Zkh2yY4JIkSZKkzfTEi3czv1Tw1XtnVg7uuricXW0FlyRJ0rbQS4Jrrlp3rvO67vmLPey5LXXmHuRoTrJjdCVh0okmkZ0ao9LDaVCQPf1nJUmSJEk6U0+6qHz29ot3HF052GyVSS4ruCRJkraFXr6J705rfdo6r+uef28Pe25LxfEjHGWSHaOtlWOY4Bpk5QwuK7gkSZIkaTNdvGeCc3aM8MU7jpz8xp7L4MFb6glKkiRJfdVLguvTQADfHxG7T3cyQEScA3wfkMBf9bDntpQnjnAsJ5kcW0mYFNGkaYvCgRUUZFjBJUmSJEmbKSJ44sW7+eKdpyS4Lng83PtlWDy+9oWdNnzqF+F9P775QUqSJGlT9fJN/HuqdRfw+xEx8XAnV++/h5XZXb/Xw57bUsyvUcEVLSJNcA2qRnas4JIkSZKkPnjiRf+bvfsOj7LO2jj+/c2kQEJL6D106R0UFBBBQKUoKhZQ7HUVy1pWfS27ru667urawYIFFcWGBVGaoiC9F0FQeq+hhsw87x9nskkgIT2ZkPtzXbmGPPOU38xkUObOOacCq7YlcvBomn8jJ3SD4DHYMOvEA/Ztgrf7w7S/w4L34Mj+wlusiIiIiOS7HAdcnudNBSZjVVy9gIXOuaHHV3M55yo454YBC0L7ecAPnudNzPuySwbf0X3s82KJjUpfweVTi8Kw5SMIPgVcIiIiIiIiBa117fIEPVi6Kc0crjqdwfnhj+npd14/C149E7YsgtaX27bdawpvsSIiIiKS73LbS+1y4A8s5GoIvA3sdM5tds6tcs5tBnYCo4FGof1+B4bkdcElhufhT9pnFVzRqRVcAReBDwVc4cqnFoUiIiIiIiKFolUt+z3bdG0Ko8tCzXbwx0/pd57yV4gsDTf9CF3+ZNs0q0tERESkWMvVJ/Ge5+0EOgHfYuGVC52rGtAgdOtLc983QGfP83bkw5pLhqQD+LzACRVcnvPjU4vCsOXzgmpRKCIiIiIiUggqlYmmVlxpFm3Yl/6OhDNh0zw4esC+T9xqgVe7q6BSQ4irZ9t3KeASERERKc5yXWried5Oz/POA7oCLwOLgd1AIHS7GHgJOMPzvAs8z9uVD+stOQ7bb6Dtowyl1aKw2PARBFVwiYiIiIiIFIrWtSuwcMPe9BsTzoJgcuocrmWfAx40v8i+j4qBcjXVolBERESkmIvIepeT8zxvJjAzH9YiaR0JBVxeLLFRqS9T0EXgV8AVtqxFoSq4RERERERECkObWhX4evEWdh44SqUy0baxdmfwRdgcrobnwNJxUK0lVG42ADosAAAgAElEQVScemB8fdilgEtERESkOMtxqYlzbm3o6/mCWJCE/K+CK5aY6DQtCn1+zeAKY1bBpYBLRERERESkMLSubXO4Fqebw1UGaraH36fDnj9g4xxoMTj9gfH1VcElIiIiUszlppdabaAu1oJQCkqoguugiyXKn/oyeargCms+gng+BVwiIiIiIiKFoUXNcvgcLMxoDtfmBTD/Xfs+pT1hiooN4NCu//1yqYiIiIgUP7kJuLaFbvfn50LkOKH/yU6KLIdz7n+bg74I/CQX1aokC34CmsElIiIiIiJSSGKiImhctWzGc7i8AMx8EWp1hLi66e+Pb2C3u9cWzkJFREREJN/l5pP45aHbhHxchxwvVMGVHFU+/XbnVwVXGPOrRaGIiIiIiEihalunAgvX7yEY9FI31u4MvkhIPnJie0KwFoWggEtERESkGMtNwPU+4IDL8nktktbhvQTxQVSZdJs9X4RVCUn48Tx8eDbMWERERERERApF+7rx7D+SzOrtB1I3RsVArQ6Ag2aDTjwovp7d7tIcLhEREZHiKjcB1zvAz0Bb59y/8nk9kuLIXg75YikdHZVus+ciiCCQ/jfTJDwEQ8GjTy0KRURERERECkuHunEAzFu3J/0dZ94N5/wflKt+4kGRpaFcLVVwiYiIiBRjOf4k3vO8IDAAmADc5Zyb5Zy72jlX3zkXne8rLKkO7+WAK0NMVPp2d1bBFSRZAVf4CbWO9NSiUEREREREpNDUrRhDxdgo5q7bnf6OxufCWXdnfmDF+rBbFVwiIiIixVWOe6k559L2x3NAB+DNNPdndQrP8zz1cMvKkb0kUobY6PRPlefzE0GAgAKu8JNSwaWAS0REREREpNA452hfN+7ECq6sxNeH5eMLZlEiIiIiUuBy00vNpfk6/vvsfklWDu9lH7EnVHDhiySCAMnBYNGsSzIXquByPgVcIiIiIiIihalDQhzrdh1iR+LR7B8U3wAO74bDOQzGRERERCQs5KaS6kdA5UMF7che9npViI06roLL+YlwquAKR8FAsiXGCrhEREREREQKVfs0c7j6tqiWvYMqNrDb3WuhZvsCWpmIiIiIFJQcB1ye5/UogHXI8Q7vZXcwgZjo4yu4NIMrXAUCAQu41KJQRERERESkULWoWZ6oCB/z1u3OfsAVHwq4dingEhERESmOctOiUAqa5+Ed2cuuQMwJFVz4IoggWRVcYSgQSLY/qIJLRERERESkUEVH+GlVs3zO5nDFJQAOdq8pqGWJiIiISAFSwBWOkg7igsnsDcZSOsMZXKrgCkfBUMClGVwiIiIiIiKFr31CHEs37efIsUD2DogsBeVrwS4FXCIiIiLFkQKucHRkLwD7iCX2hIDLj58AgYACrnATCNg/ohRwiYiIiIiIFL72deJICgRZsmlf9g+Kr68KLhEREZFiKk8Bl3PO75y7zDn3pnNupnNupXPuhP8zdM61cM51cc41z8v1SozDoYDLiyUm+rgWhf4IIgmQHAwWwcLkZFIquDSDS0REREREpPC1rxsHwNw/ctCmsGID2L4Cvv0L/PIKrJtRQKsTERERkfwWkfUuGXPO9QDeBmql3QxkVFo0CHgcSHTOVfc873Bur1sipKvgOn4GV6RVcKlFYdgJBo4BquASEREREREpChXLRFO/UmzO5nA1HQB//Axz34Tkw4CDEYuhQp3UfX79Fr64FW6fCzHx+b5uEREREcmdXFVwOef6A99j4ZYDAsDJegC8BgSBssD5ublmiZKugit9WOL8EZrBFaaCoRaF+BVwiYiIiIiIFIXO9eP5Ze2u7M/hanA23D4bHtoCN/8MeLDss/T7zBkFh3bBxjn5vl4RERERyb0cB1zOuUrAe4Af2A9cB1QArsnsGM/zdgA/h77tlfNlljAnqeByvgh8ziOQnFwUK5OTSGlR6Hy5LowUERERERGRPOjbojoHjibz46odOTvQOajWAmq2hyXjUrcf2A5rptifN83Pv4WKiIiISJ7lpoLrT1glVhLQ2/O8tzzPO5SN437Bqr3a5uKaJUuogmu/F0tM1HHVQP5IAAKhdngSPgKhCi61KBQRERERESkaXRpUJC4mkq+XbMndCVoMhq2LYedq+37pp+AFoXQcbF6QfwsVERERkTzLTcDVD5uz9ZHneXNzcNyq0G39XFyzZDmyFw9HIqVPCLhSqoOCyQq4wo2X0qJQAZeIiIiIiEiRiPT76NuiGpOWb8t+m8K0ml8EOFj6iX2/eCxUawVNzrOAy9O4ABEREZFwkZuAq0HodmoOj0uZ0VUuF9csWQ7vJSmyLB4+YqOPa1Hot+8DCrjCTjBoLQp9CrhERERERESKzPkta3AwKcC0X7fn/OBy1SHhTGtTuHM1bJ4PrYZAjbZwcDvs35T/CxYRERGRXMlNwBUbut2fw+NKh26P5OKaJcuRvRyNsBzwhAquUItCVXCFn6AquERERERERIrc6fXjqRgbxVeL89CmcNdq+O4RcD77vkZo2oLaFIqIiIiEjdwEXLtCt1VzeFyj0G0OJ72WQIf3cthfFoCYqEwquALJhb4sObnUCq6ILPYUERERERGRghIRalM4ecV2Diflok1hs4Hgi4BVE6Bed6vqqtrCtm2an/8LFhEREZFcyU3AtSx02yOHxw3AZnfNycU1S5YjeznkK0OpSB9+n0t3V0rA5amCK+ykVHA5X27eViIiIiIiIpJfzm9VncPHAkxZmYs2hTHx0OAc+3OrS+02shRUaaYKLhEREZEwkptP4r8GHDDAOdcsOwc454YBrUPfjs/FNUuWqFh2R1QhNurESiBfqEVhIKCAK9x4wZSASxVcIiIiIiIiRalzvYpUKhPNV4s35/IEN0H1NtC0f+q2Gm0t4PK8/FmkiIiIiORJbgKu14HtQCTwtXOu5cl2ds5dD7yGVW+tBcbm4poly1VfMKbqfcREnzjLKWUGl6eAK+wEQ20jnV8zuERERERERIqS3+e4oFV1Jq/YzvbEXIwCb3gO3PQDRJdN3VazHRzZC3t+z7+FioiIiEiu5Tjg8jzvIHANEATqAPOccxOAK1P2cc496pwb5Zxbi4VbpYAk4ErP84L5svJT3KGkADGRGVVw2bagAq6wEwxVcPl8CrhERERERESK2vAuCRwLBnlnxrr8OWGNtnarNoUiIiIiYSFXw4I8z5sAXAYkAhHAucBgrEoL4P+Aa4G6WDvDvcBAz/Nm53XBJcXBpOQsKriSC3tJkgUvmFLBpRaFIiIiIiIiRS2hUix9mlXj3V/WcSgpH/4NXaUZ+KOzDriOHoAti9XKUERERKSA5SrgAvA87xOgBfAisAcLso7/SgReAVp6nvddnldbghxKCmQ4g8sfCriCyQq4wk1K6KgKLhERERERkfBwQ7f67Dt8jI/nbsz7yfyRUK0lbMog4Eo6BFOfgtd7wz/qwmtnwdJP8n5NEREREclUrgMuAM/zNnqed4fneZWAlkB/YCgwCOgIxHued5vneZvyvtSS5eDRZGKiMqjgirDQSzO4wo8XsBaFTgGXiIiIiIhIWGhfN452dSrw+k9rCQTzoaKqRlvYshCCx01f+O5h+OFpwIMuf4KKDeGn51TFJSIiIlKAchxwOedKOeeqOedi0m73PG+Z53lfe573vud54z3Pm6d5W7l3KClAbHQGFVwRUQAEg6rgCjeeF5rBpRaFIiIiIiIiYePGbvXZsPswE5dtzfvJanWEpAMwf3TqtjVTYe4bcMbtcP0k6PUYnHk3bFsCaybn/ZoiIiIikqFsBVzOuQrOuaecc6uBg8AmINE5t8Y597RzrmKBrrIEOpSUcQVXSniiCq7wEwxoBpeIiIiIiEi46d2sGnUrxvDaj2vx8lpR1fxCaNgbvrobloyDI/vgi9uhUmPo+XDqfi0vgbLV4efn83Y9EREREclUlgGXc64RsAC4D6hP+hlbCcCfgQXOudMKbpklz8GjGVdwKeAKX14wVMGlFoUiIiIiIiJhw+9zXH9mPRZt2MvcdXvydrKIKBjyLtTtCp/eCO8PgcTNMOgViCydfr/Tb4Xff4RN8/N2TRERERHJ0EkDLudcBDAOqJuy6fhdQl+1gI+dc5H5vsISKBj0OHwsQOnIDCq4Qi0KUYvCsPO/gEsVXCIiIiIiImHl4va1iYuJZOSPa/N+ssjScMWHUKMNrJ8JXUdArQ4n7td+OESXh5+fy/s1RUREROQEWVVwDQZaAh6wC7gRqAlEhW5vAnaE9m0GXFIwyyxZDh+zoCQ2+sSAyx9hGWJKOzwJI6GAy6mCS0REREREJKyUjvIz7PS6TFqxjTU7DuT9hNFlYegnMOBF6PFgxvuUKgcdr4Xl42HXmrxfU0RERETSySrguih0exjo7nne657nbfE8Lzl0OwroDhwK7XdhQS20JDmYZOFVTNSJlUB+f6hILqgWheEmGAq4/BGq4BIREREREQk3w85IINLv442ffs+fE5aOg3bDrB1hZjrfDD4/zHkjf64pIiIiIv+TVcDVDqveGuN53oqMdvA8byUwBmtV2DZ/l1cyHTqadQWXFwgU6pokaymvic+ngEtERERERCTcVC4bzeB2Nflk3kZ2HjhaOBctWw2a9oeFYyDpUNb7i4iIiEi2ZRVwVQ3dzshiv5T7q+RtOQInr+DyhQIuAqrgCjuevW4+v1oUioiIiIiIhKPrzqzP0eQg785cV3gX7Xg9HNkLyz4tvGuKiIiIlABZBVxlQrd7sthvb+g2Nm/LEYBDSaEKrgwCLlLmOwU1gyvceMEgoAouERERERGRcNWwShl6Na3C2zP/YN/hQvrF0bpdofJp2WtTmLgN3hkIv35b8OsSERERKeayCrikCBw8GqrgyqBFIb6UGVwKuMJOaAaXz6+3lYiIiIiISLi6q3dj9h8+xnOTVhXOBZ2DDtfC5vmwaX7m+x3ZD2MuhrXT4Jt74diRwlmfiIiISDGlT+LD0OFQBVdMVEYBl1UHeQq4wo4XCrhS5qSJiIiIiIhI+GleozyXd6rDOzPXsWpbYuFctPVlEBkDczOp4kpOgo+GwbZlcObdsG8DzHm9cNYmIiIiUkxlt5eaV6CrkHQOnrRFoW1zCrjCTkroqBlcIiIiIiIi4e3ec5vw1eItPP7lMt67rjPOuYK9YKny0PISWPwRVEiA7ctg52qILgcVasOBbVa5NfBlaHslbFkE0/8FbYdC6QrZv47nwYHtsGMl7FwFNdtBzfYF9ahEREREilR2A67Ps/k/e845F8hiH8/zPA0pOolDSaEWhRlVcPlDT12wkHqFS/altCj0KeASEREREREJZ3GxUdx7bmMe+WIZE5dtpW+L6gV/0U43wIJ3YerfIC4BKjWBo4mwbiYc2gm9n7BwC6DXY/DaWfDz89Dr0ZOf9/Ae+G2yfa2dColbUu8rVwvuWAARUQX0oERERESKTk6CppMlXB6pVV4F/GtPp76DR0MVXNGZV3ClhCkSRlJaFPqV34qIiIiIiIS7yzvVYcys9Tzx5XLa142nctnogr1gtZZw5yIoHQfRZdPf53k2qytF9VbQ8lL45RXocA1UqJPxOfdvgVFnW6hVOg7qnw21O0OV0+DgTvjkOlj0PrQfXmAPS0RERKSoZGcGlyPr0Mplcz/JhkNJyfgcREdk8PKktCgMqIIr7KRUcGkGl4iIiIiISNiL8Pv458Wt2HPoGFe/OZv9Rwrh39kV6pwYbkH6cCtFz4fAC8J/28K7F8Hct+DIvtT7k5Pgo6vgyH64ajz8eQ1c8hacfjPU7wEtBkPNDjD9WSjozxB2/AqTn4CAximIiIhI4TlpwOV5nq8AvtS/LQsHjwaIjYrIuAd4SgWXpwqucOOFXpOICFVwiYiIiIiIFAetalXg1WHtWb09ketHz+XIsTD6t3ZcAtw4Fc64DXavha9GwIudYMWXdv+398PG2TDoZajfHY5vl+8cdL8f9q6HRR8W7FpnvGBB2tw3C/Y6IiIiImlkp4JLCtnhY8nERGeSA6ZUcAX1W1FhRzO4REREROQU4Zyr7Zyb6pxb7pxb5py7M7Q93jn3vXNudeg2rqjXKpJX3RtX5t+XtmHOut3c/v58PM/L+qDCUrW5zea6YwFc9z3EVoaxQ2HUORYmnXkXNB+U+fGNekONtjD9XwVXXRUMwqpv7c9T/gYHdhTMdURERESOo4ArDB08GiAmKpMqIOcI4FPAFY68AMmeD79PnTpFREREpNhLBu7xPK8ZcDpwm3OuGfAAMNnzvEbA5ND3IsVe/9Y1ePj8ZkxasZ2vl2wp6uWcyDmo3ckquno9BtuWQoNzoOcjWR/X/X7Y8wcs+ahg1rZpHhzcAd3ug2OHYNJjBXMdERERkeMo4ApDh5KSiYnKvAoogB/nKeAKO16AAD78GbWWFBEREREpRjzP2+J53vzQnxOBFUBNYCDwdmi3t4GTlI6IFC/DuyRwWrWy/PPbX0lKDhb1cjLmj7SqrbtXwBVjT2xLmJHGfaF6G/jmPvhtUv6v6devwfnhjFvta+F7sGF2/l7j6AH44ArYODd/zysiIiLFmgKuMJQygyszyUTggmHUF1xMMEgQHz5VcImIiIjIKcQ5lwC0BWYBVT3PSylv2QpUzeSYG51zc51zc3fsULsyKR78PscD/U5j/e5DvD9rXVEv5+Ri4i3syg7n4LL3babXmEth7lv5u5ZfJ0BCVygdZ1VcZWvA1/dA4Fj+XWPVtxakfXwNHN6bf+cVERGRYk0BVxg6lHSSGVxA0PlUwRWOglbBJSIiIiJyqnDOlQE+AUZ4nrc/7X2eDSrKcFiR53kjPc/r4Hleh8qVKxfCSkXyR/fGlenSoCL/nfIbiUfyMaApauVrwrUToMHZ8NUIGP8n2LUm/T4Hd8K+TTk77641sGMlNDnPvo8uA/3+AVsXw/eP5s/aAVaMh+jykLgZvroLwmlOmoiIiBQZfRofhiqViaZWXOlM7w/g1wyucOQFCOotJSIiIiKnCOdcJBZujfE879PQ5m3Oueqh+6sD24tqfSIFwTnHg/2asvtgEq/9sLaol5O/osvC5WPh9Fth4QfwQnur6PruYXj1THimAfynGYw6B2a+DAey8fb+dYLdNumXuq3ZAOh0E/zyEiwZl/mxB3dCMButII8dhtWToOVg6PEgLPsUFr6f9XFFZcev9riz89hEREQkTzLvgydF5o3hHU96f8BF4Dy1KAw3TgGXiIiIiJwinHMOeANY4Xnev9PcNR64Gng6dPtFESxPpEC1rFWegW1q8PpPaxnYpgaNqpYt6iXlH38E9H0Kut5prQrnvglrpkCd06HnIzbTa+knMPFB+PEZuGEKxNfL/Hy/ToAqza39YVrn/g22LLJKsSrNoGqz1Pv2bbR5YL9+DaXKQ80OUL2VtTQ8stduez0O5arb/mumwrGD0LQ/1Otu33/zZ6h7BsTXT3/dbcttvZGZ/9JwgTp2BD64HHavsRBu0MtQtlrRrEVERKQE0KfxxVDQ+fGpRWH4CQbVolBEREREThVdgWFAT+fcwtDXeViw1ds5txroFfpe5JTzl/OaUiY6khvfncf+U6lVYYqy1eDsB+HuFfDgBhj+FXS7F868C27+CW78AbyghTVH9md8jkO7Yf0MOO28E++LiIJL37aqsfcvhYkPwbzR8PPz8FJnC9XOvAuaXwgHttn2uW/Cb1MsYJuUpr3hii8tCEs4ywK4i14DLwAzXkh/zb0b4LWzrCItvwUDsGqiPR+f3miPPSM//dvCrU43wroZ8EoXWPAebF1iz+OBHRYsvnuhVc0lbsv/tZ6KloyDkWdD8tGiXomIiIQZVXAVQ0G1KAxLzksm6BRwiYiIiEjx53neT4DL5O5zCnMtIkWharlSvHxlO64Y9Qt3fbiQUVd1wOfL7C1RjPkj7Ot4NdpYQPXuRRboXDbGwqW9G2DTXNj5G2z4xUKwtO0J0ypbDYaMga/vhjmvQ/IR296wF5z/bPqqr2AQfKF/T09+AqY/C51vgmqtYNUEaNwP/JF2f/la0PwiWPwx9P6rzf0CmPcWBJMtUOp+P5Spki9PEUvGweTHYe96KFMVDu+x8OrSt6Fm+9T9dq6Gn/4DLS6G856BjtfDuOvgi9tOPGdcPUjcCh9fDVeNt0CwoASSYcZ/7Xmv3qrgrlOQ5r8Nm+fDyq+gxeCiXo2IiIQRfRpfDAVcBD7UyznsqEWhiIiIiIjIKaNTvXj+r38zJq/czvOTVxf1cgpf/R7Q7x8WML0zEP7bFp5rAR8Ph6l/g+0roOUlUL1t5ueo3RFung5/2QJ3LrbqsCvHndjS0Jfm39Jn3gWxla3q64+fLFBq2j/9/u2HQ1KiVXuBVfbMfweqt7Y/z3o1zw8fgD9+toCvdDxc/BbctQyunQg4eLMv/PBP2L0WPA++ugsiSkOfv9uxlZvAjVOtzeMlo63tYs9H4Oaf4Y4FMPBFWD/T2kEWpDVTLKAb1dOq3orbbLAj+yxQBJj3duFfv7g9XyIiJYwquIqhoPPj907BFgnFnPOCCrhEREREREROIcNOr8vijft4fvJqGlYpQ//WNYp6SYWr4/VWmbToA6jbBTreYLeVGkFUbPbP4/NBXN3s7RtdFs5+CL4aARPus9CoQc/0+9TuZLO95r0F7a+2NoYHd8CFr1orxDmvW1AWHZqftn0llKsBpcplf837t1iYF18Prv4y9dia7eCmH+DzW2Hqk/ZVvg7sWw/n/xvKVk09hz/SqrzSVnqlaHkxbFlooVP1NtBuWPbXlhNLx6W2ePzuYVj9PQx+Pf8q3LJr+XhrR9nphpwdt2aKVeY1OAfWTLZA8fjZawVl/xYLBrvdY+8FEREJO/o0vhgKOj8uGCjqZcjxgqrgEhEREREROZU45/jboBZ0TIjjno8XMeePTGYvnaqcg/P+aXO6rhgLZ9xq7QtzEm7lRtthFmDtXAWNekFUzInraj8cNi+AzQst0IqrB/V7Qte7rOpn3mirrJrxIrxyBrw7CI4dOfFaxw7Dwg/grfPhvcGw9FM4esDCraQDMOS9E4OxmHi44kO4cxH0fRriE6zKrP01OXuc5zwG9brD1/cUzDyuY4dh5dfQdIA9jv7/hQ2zYfQFubve7z9awJRT+7fAZzfDN/fac50TqyZC6Tjo/zw4n1Xq5dTRxJwfAxbsJm6Gbx+ErUtzdw4RESlQ+jS+GAq6CHwo4Ao3zgsScP6iXoaIiIiIiIjko1KRfkYO60DNCqW54Z25/L7zYFEv6dTnj4A+T9qfm1+U8T6thkBEKWtluH4mdLzOKsVqtbdqpZkvwfjb4buHoFZH2DTP5oF5nh2ffBSmPAn/bgqf3wwHtsKOX2HcNfDP+jZjbMALUKVp5uuMS4DTb7EKryHvpW+1mN3Hef6zEDhqYUp+WzXRQrqWF4dCwath6CewbwO83T815Nq5Gn54BrYty/g8ngdTn7Jj3ugDu3/P2Tqm/A0CSVbJ9uWdsGm+bT92GKY9ba9hyuuSVjBgFWcNe0OF2tCoDywYA4FjqetKOpT5dYMB+ObP8I8E2DgvZ2v2PFg4xubAlaoAn96QcUAqIiJFSgFXMWQtCpOLehlyHKcZXCIiIiIiIqekuNgo3hreEZ9zDH9rNhv3nORDdckfDXpahVTzCzO+v3QFC7/W/WRBV5srU+87cwQkboEF70G3++Cab6H7/RZYzB5lQc6onvDjPy0Mu/pLuH2uXW/oJ9D0ApuX1fLign+clRpBnS5WmZRRyJMXS8dBbBV7jCkSutoctH0bYfR58Ma58GIHm6v2dn/YsSr9OY4dgU+uhx+ettcieAzeuwgO7MjeGjYvtOe9801wxUfWGnHsUJuf9vIZMO0pmPmitZk83qb5cGgnNO5j37cfDge3w68TrO3k6AvgmYawZ92JxyYdgrHDYPZI+/6Xl7K33hQbZsOu32zdg16B7cth0mM5O0dBWDcTFo0tmmvvWJU/P6O/T7fZeiIi+UCfxhdDnovA56mCK+x4QTxUwSUiIiIiInIqSqgUy+tXd2D3wSQGvTSDRRv2FvWSTn1xCVZ5lJkOoZaALS62toEpGpwDXUfApe9Az4essqr7A9C4H3z7AIzsAQe2W+Ay5F2o182u4/NDw15w8ZvQ7d6CfGTptb8adq+BdT/n7Ljda2HctbBrzYn3HdkPq76zUMp33GcVCV1h6Dir4Dq8B3o/AddOtBaA7w6CvestyFj7A7zV14Kyc/4PLn7LnrP9W+D9S6yV48l4nlVnxcRDtz9DbCWrdDu0y9bt88PQT6FKc5j4lxOrsVZ9C86fOoOtYS8oW8NaBr7aFbYttcqwGS+kP+7wHgvrfv0G+v0TOt8My7+A/Zuz/9wufA8iY6DZQGuT2ekmmPUKfHQV/PBPWPFVaiVZYfr+ERj/J2vDmR2rvoP3L4NDeWyvunoSvNTRAuK82LPOXptvH8zbefLT3vVW7SgixZICrmIoqIArLDkvQNDpLSUiIiIiInKqalcnjk9v6UKpSB9DRs5kwpItRb2kkq1WRxjwIpzzSPrtzkHvxy2cSOHzwUUjoUZbaNwXbp2ZWhlU1JoOgOjyOZsvdWQ/fHC5VUJ9dPWJ7fNWfm2tDzOrQqvbBf78G9w2G7reCXVOh2GfWWj1ziB46zx4Z4CFYJe+A2fdY89r7U5wyWjYstgqu4LB1HMGjsG7F8Gzp1n11Dd/tgq7Hg9axR3YDLfL3oc+f4dbZkDDc+C8Z6xt4k//Tr/GVRNtXSnhpT8COlwL+zdCq8vgT/Og9RBY8K4FlikmPABbFlp42fkm6Hi9tSuc+2b2ntukg7D0M2g2CKLL2rbej1uV4JZFMPVJGHulhaXZtfhjWD/rxO2bF8B3j8C7F8K/mtgsuIwCS4CDO2HjXHtdV36d9TWPHYav7oJVE+DDK9P/jAQD6Z+zrCwcY7ffPQzbV2T/uOMt+QjwYMk4C0rDwTf3wftDrEWpiBQ7+jS+GIkQJ1UAACAASURBVPJ8fs3gCkNqUSgiIiIiInLqa1S1LJ/f1pVm1ctxy5j53D12Idv3azZPkXAO2g2DstWyt3+pcnDDZAs+YisV7NpyIioGWl1iVUbZad0WDMJnN9nsrLPugW1LYOJxFTFLP4HydSwEzExkqfQVctVawpUfWXvHPb/Def+COxakDwoBmvSFvk9ZcDLj+dTtkx6DNZOhemvYuhjmjIIqzaD9NemPb3gOnHEbRETb9wldoeUl8PPzqeHOvk32uBqdm/7Ys+6GEUth0Ev2Gna9y+ap/fKy3f/bZFj8IZx5FzTtb9vi60GTfjD3rezN0VrxFSQlQts0bS8jS8Ogl62N5V82Q7ur7Hw7V6c/9tiRE9v4HdoNn98CH1+dvuotcRu8PRBmvWrhVb1u9phfPRPmvH7ieVZ/D3gQGWuvb1ZmvWZhYOdbYP0M+OJW+9nZMAdGdof/NLfqpawc2W/VcM0G2Xto3HW5m0fmebD4I6jUGLwAzH4t5+fYvzl/2xvu2wSrJwIeTH82/85bEhzabcHt4o/y53zHDufPeYqr5KNFvYJiS5/GF0Oe8xOhCq6w47wgniq4RERERERETnmVykTz/g2nc2uPBny1eAtn/2sar/2whkAwn2coScnR7mpIPmIfGAMcTbQqqWAGn/9M+7sFDn2fstaBXe6w6qSln1hg8eMzsHYqtLjo5C0eM1LndLhzsQU5nW6wECwjnW60GWiTn7CZSss+s1lanW6EK8ba8feuttaH/oisr9v7r+CPsqq0sUMtDAKrtkvL54cKtVO/r9TQArg5b0DiVqtYqtgIzjquxWTnm2yeV0bBUNIh+OUVq6BbP8tu4xKgbteM1xoVCz3/z0KvyY+nbt++Av7dFCY9mn7/JeNsdlniFnttUnz/CCQfhltmws3TYfAouPUXew2+vsdaEaa1eiKUqQqdroc1U+HgrozXBxY+TP83NOoD/Z6GXo/ZY3+jl30d2G7tHZd9nvk5Uqz40n42z7gdBr4M25elf9zZtXkB7Fxl4WbT/vYzmxL4HdwFb/aFSY9nPufr2GEYebbNzzuamP6+vethzx85X9OC98ALWhXlko8zr547lR3YcfKfpRSeZxWMPz5js/ueaQCfXg+f3pD3523tNHiqtlUolkQTH7LK1+PbtEq26NP4YijoIlTBFYasgkszuEREREREREqCUpF+7ut7Gt/d1Y0zGlTkqQkrefzLZXiZfTgrcjLVW0H1NjDzBXhnIPyjHrx2llXZTHzIqnem/t3mh/34DLQdZmESWMhVqxN8ehM81xKm/A3qnGGzp3KjTOXU6qrMOAcD/gvxDWDcNfDF7baGc59Mc54qVvGTHeWqQ//nLcDa+Zt90NtiMFRukvWxZ90NR/fDG71h7zo7z/HBXL3uULmpVUulfY8mHYIPhli7wfF/gjfPtbaKra84eThYprK1dlzxpYVi+zfDe4Ph8G6bU5V25tXCMVYd1+ZKmPmSPb7fp8PisXaOSg3TPA81bC5Zp5ssfNmxyrYHjll1WqNzrdrNC8CKL1KPm/wE/KclLBhjVVrTn7UqtF6P2f1dR0CH6yyg6PIna+9YvTUsz0bAtXgsxNWDWh2g8bn2c/fLyzZHKyfVVIs/shCz2UA4IzRHbMF7ViE2ZjCs/8XaVH73cMYh19w34cBW2P07fHV36j5bl8CrZ8ErXWHNlOyvJxiwMLP+2Vat6I+yUDDF3g2w9NOTzzvbv8We68KqPtqz7uSVPjt/s/fi0k+zPte+jRak/qcZvHfhyfed+5YFMK91s79fAkk2V+/KcTYnLyftVTM8/5sWAk/9e97OUxwtGWe/HHB4N6yfWdSrKZay8SsUEm48XwR+VXCFHYcquEREREREREqahEqxvH51R578ejmjpv9O9fKluaVHg6JelhRHnW+yVnaRsXD6LRburPzaWs3NfBGcz0KkXo/b/SkBjD8SLnnLqpdqdYRWl1oFUkGLLmvtHkf1hMgYm80VEZX787W8OPOZYSdTvTU07AW/TbJKuIQMKq+cs+f3qxEWyPV8BMpWt3Dr9+kw6BWrnNqxyuaBtb4s6+uecZu1Epz4F6twOrIPLhwJn91oFWXd/wzblts8sL5PW2C34kuY8GdrjVehrrWYzGit3e+z0GDGf2Hgixb+HN1vc+OqtrA2f0s/tZlkqydZyBJb2doQznoVdqy0QK1qs9Rznv8s9HoUSpW3bc0vtLaSe9ZBXN2MH+P+zfD7j9D9/tSft95PhNpCvgKLPoAz77Z2kYlb4dAu+9mr0Q6qNk8NGgPJsHScVeSVjoPaHaH26fDLS7DyKwupLv/QWlym/Kz3fiL1mkmH4KfnrI1jwlk2B61+d6jZ3gLhqFg775hLrMqs9ZCsX7/fJlsLx75/h7JVof1wez273wcb59j76eh+iChtr13Ha+16KYIB+OQ6WPcz7F4LA1/K+pp5seNXa1/Z6Ubo82T6+/ZvhmlPhyrSAvb3RsNeGQfM+zZakLfgXateq94GNs2116BayxP3n/O6BWF1u1qY3rCXPV8pGve1EPfsh3L3/j+8B36dALFV7PXfMNtm/RWkLYuhfK3U+X7ZFQzYcxFMtvdTZr8I8OsE2LYMut2b8f0pti61QLJ2Z6twXDvNWrjm1uE98OO/7O+mcjVyf55iRgFXceSLwE9yUa9CjuO8IEEFXCIiIiIiIiXSg/2asm3/Uf7x7Uqqlovmona1inpJUty0vhyanAelK6RuazvUqoE2L4AabTP/QLZ8Lbjy48JZZ1pVmlobwqhYKF+z8K+fovdfIaaShSKZaTsM9m+yKqrl4y2I2b0WLnw1NdCKr5/9a0bFQo8HLTTzRdjz36Cntbqb/ZpVSi163+5reYmFQD0esEAM4PKx1uYwI7GV7LWf/7YFB6u+tQqj+j0s9Gkx2AKNLYvh85tt1tkNU2x+2KTHwBcJZ/8l/TmdSw23wGZqTXrMZr91vSPjdSwZB3gWmqaILG3Ve51usGqr7x9Jvc8fDYFQhZEv0vbp+TCsmwEHd6QPDrvcbu0o926Ai0bZbLfGfSxEmPFfq1rr86RV9c19Ew5uhx5vWxjwx3T4+l4LWX2RcPWX9px9eKUFjFsXW9hZuXHmr9+80RaqNDnPvu96p11n9PkWctbqCN0fgJVf2vOwcAwMeMHm/oH9HK372YKfBe/ZutpdlXr+Y4czf31PxvNg21Ko1CQ1MAoG4csRVjm14D17TlPOnXTIWjce2gUdr7eA5P1LLejsfl/qefdtsiA0pdqq7VCrfowqA/9qDIs+PDHgmv+OBTqN+8Gl72QcYLUfDr9+bTP5jp/Xlx1LP7XHdenb9vMw7WkYlo0KtNzatwleP8d+1oa8l/3jgkH48g57/sHaYl42xn4Gjzflb/Yaxtez92pGDu+1x1uqPFz6roWla6fl+OGkM/t1C4jXz4RrJmRdiXuKUMBVDAVdBH6CRb0MOY7PSyZZLQpFRERERERKJJ/P8cwlrdh54Cj3jVuM58Hg9gq5JAecSx9upYiJz9tv9Re06q2KegVWqXTRayffxx9hwUCnG+2D/kUfpA+3cqPtMJsb1KiXhVtgwdY7A2Dhe7BorFW4xFay+zrdaB/ox9e3QOdkzrgN5r5hQcXq7yxISfkwvflFMO0pePsCOHYErhpvgUerS2y+1ZG9ULbayc8fXy+1TWFmAdfij6BmB6iYQVVqtZYw7HOrLIqIgjLVbA37Nlogu3qitTJc+bXNDisdBw17px7f5DxoealVZbW6xLY5F2oXGAmzXrGgqf9/4efnrM1k3S6230WjrCWhF4ThX6Wub+gnFgTNfMk+6K/SHBr2tGq58rVCX7Xh2CELDbveYdcCq3hJqeLqdp9Vrfkj7LU992/w0dUw/na7Zs32MOWv9lxf8ja8d5EFbtVbWyXfj89Y5VujPtDj/vSVX5k5ss9CpjlvwM5f7fFe9j5El7Fqq/UzrHXmovdtdlqby+24+e9Y68arv4J6Z9m20y6AGS9Y4BUTb0HuG32swicl2KpQJ/XajftYMNvr8dSZeUs/gfF3WMXWpW9nXp3V8BwoV8sCw6wCrqRDVtlUu2PqtkUfWEBb5wybJzjp0ZxXce1aY4G1Lxufy874rwVqK76CnauhUqOsj/E8+O4hC7e63Wfv3y9ug9EX2M9cyvsbrIXmtqUQUcpaadY5I+Nqqh+fsZ/v4V9bRVz97haMHdyZ/nzZFQzYa1C+DmyaZ8HkgBdyPoexGFK5SXHk8+PXDK6wowouERERERGRki06ws+rw9rTMSGeez5exGPjl3EsoF9QFQkrZapAv3/A/evyFm6BhQGDXrJ2fynqdbOg47tHrOqozRVp9o+E676Di0Zmfe74elZlNes12LnKgrIUlRtbwHRkn1U5pbQiBGsLmFW4laL5hfZh+N716bd7nn2Yv23JyZ8j56DKafaBf1SMfV+hNjQbYC37hn9jj3njbAvl0oYkPj8MHpVaEfW/7T57ffr+w8KxF9tb9VePB1P3KVsNbvoBbvk5/Zy2iGi48BW4ewX0+6cFgrNeg2/uhQ8usxZ//6gLz7WyVn5pK64A+vwd7lwMPR9KDXrAznPZ+xbQfXmHzVsrVQEuCM2NG/yGhRKv94a3+1vo1+Fae9yjelobxa/vsXl60/4BB3akv+4fP9kMtQn3WaDV5Q6rUntnoLXN/P4RqHumPacVG1qlGUBykgVZdbqkhltg1XtHE+2+xG3w7oXWVu/m6dD/ufThFkCrIXBgW2oF0f7NFhTW7mxVTierBPL57TVcMwX2/JH5fjt+tefijV4w40XbtnO1tYNsfZn97HS8HmIqWnibuM2O2bY845lsKX7/EV5oZ89tWoFkmPoUbJqfui1xm4VAjftZReSMFzI/bwrPs+Dpl5dtruHZf7Fw8bL3rRXoh1em33/lV3Z72fsWpH1+q1V/pRUMWIDYqI+1RgWbBQfw+w+p+x3cBbNGWmiWldXfWcvNPk/CWfdaKDrvrayPOwXo0/hiyPNFEEGAYFCDa8OJjyCeUwWXiIiIiIhISVauVCTvXteJ68+sx+gZf3Dl67PYuOdQUS9LRI5XUJUNzllAceyQtU1sdG76+33+7F+7652QfNj+3Pi485z9MHQdYaFAbjUbZLfLv0jdtnkhvNnXKlRqtk/fnjCnErrCzT9bFVbagCo7Tr/ZQoLko1YdV/eM9PeXr5V5kFeuus1cu24iPLQN7lkF10+xOXHn/g06XgfnPnliS0p/pAV0GYksZS3pGvWxiqmBL0FsRbsvtpK18KvZzirQ7lwMF/wHRiyxuVV7/rDKvXmjLbwZ2d2CRbDZce8Ntsdyw1RrNXnuX+18WxfDK12s3eEF/7HwLyU427oUlnxkocbxs9yqNrfWeLNeteqyA9uthWaVphk/tsZ9LLBb/KEFOl/fay0iL3wle20W2w61uWnz3834/kVjrY3iwe0WAH/3kAU8iz6w41qFZqalhHtrpsCzjeGlTvDKGTD+TxZYHS9wDL65D3D2WDfMTr1v2lPww9P23O5aY9tmvmihU58noe2Vdv3EranHeJ6FTymSk+x9MP1fVq3Z56nU926TvtYSdcMvsGFO6jErvoKqLa2yrc+TsHaqVQWmtX4mJG6BFhelbqvRFqLLp29T+N1DNrPvv23gzX6w8IPMw745b9hcwSb9LIRr2Nuem2lPW+VeTq2aaCFpMaAWhcVRKOAKeB4+Tv0yw+LCeQE8VXCJiIiIiIiUeBF+Hw9f0IyWtcrzwCdLOOfZH7ilRwNu7t6AUpH6xUiRU16zQfDTf6xVXEoLvNyo0cZaxCVuOzGMadI36zaHWUlpU7horLXeW/m1hQQxFWHAi9DmSgtV8iKyFLS/OnfHnnYe3LkIImNyf32fz1rAla0KtbLRKvBkIqItdNu77sS2jbU6wLXfpt8WXdbCp7QB1JZF8OFQCyw6XmfhR+Um1u4xbWu6pv3hio/go6vgzLtS54m1vhwmPW7H/TEdqrXKuIVpjwdh2WdWZXTFWFvfyR5Xi4ssQFnwns3U6v3X7M+kK1/LgtzZI636q1Z7iK1slWlrpsKu1VZldvEbUDoe3h0En91s878a9EwfVHa+2dbjj7TQbctCq7Q6tAsufjN94DZ7JOxYYS0rJz1uQdhNP9pstOnP2vtv3c82k+yKjywEajHYXrsuf7LA8ZdXoPfjsPYH+PRGq+xrfpE9/z/+0yrEejxoLSuPD6bbXAlTnrR2mrU72vt0wyybtQfQ/hpY+Y3Numt+IZSpbNuXjLOf6Sb9Us/l81sV3pppFmLtWGktK9tdDXF17bX5/GZIPgIdrkm/jj1/WFDa/b7Uv28Gj4Ivbregb+ZLNg+v2332fszK8i/g4+Fw+q0W0oW5Yh1wOedqA+8AVQEPGOl53vPOuXhgLJAA/AFc6nleLqLK8OS5CPwECAQ99P/F4cPnBQmqgktERERERERCBrapSceEeP7+zQqem7Saj+du5D9D2tCpXnxRL01ECpI/wtrn5YdL37FKlYLS/EL7AP77JRaWnP2QfRie0Ty4olCmSlGvID1/RMYzybKremu4cRp8cq21vavZAYaOsxllx2twNty3Nn1IGhNvYdS80YBnVWkZVQRWagiDXrEqs4a9sl5X68ut9eGXd0D1NhZu5ETvv9r8rN++tzlhYCFO3a5WTdf+mtS2j5e9D2/2sdabrS9Pf57IUnD6Lanft7zY5kpNuM9aLQ540R5b4jZrQdiwN7S8xMKw9y+BiX+xgKbyaRZ8bVlorR5f6w7HDlr7PrDwrtlAe8y+CPjp39b+sUpTe25nvwa+SLjwtczbdEaXsfaMv7xij3/1RMCzYA3sden7lFWi/fychUWBY7a+Jv0gKjb9+er3sBaHu9daW8SoMtDrMXvNu94F711ojy/hLHsOUswbbddqlyZILh1nFYdbl1oF2vRnwfmt/WZae9fbjLyUNpRrpsAn10OtjlYJVgwU64ALSAbu8TxvvnOuLDDPOfc9MByY7Hne0865B4AHgPuLcJ35K1TBlawWhWHFEbS/KERERERERERCalQozYtXtGPo6bt48NMlXDHqFx4d0JyhnevgSsDwdxHJo+M/BM9vnW6CcjVtFtDxs5mkYMRWhCs/sUCkXncLSjKTUQVg+2usvV7FhtB0QObHth6S/TXV6mihz971MPDF9DPIsqNyY7g81EJv73pri1i9Vcbzu2LiYdhnVsl0svWn6HyjVbd9drPNZGvYy64TOGrz2pyzFp4tL7XKtsgYuPormwtXt4uFYp/daNeqclrqebuOsCq36f+yNonn/9teiyP7YPX3UKmRBZIn0+kGCyrnvG7VeXH1rEVkikqNLMSb8zqccZvNFDu8G1pcfOK5GvS02+n/tqCrx1/suQKrRBz0qrVs/PR6uO57+9k4dsRaQzbuB+VrnnjOai0sBIVQJdeNqZVk63+Bt/pZGNb6cmtJ+sVtUKmxVf0V9N89+aRYB1ye520BtoT+nOicWwHUBAYCPUK7vQ1M41QKuPwRRBDkWEABVzjxeUGCGmsnIiIiIiIiGTi9fkU+v60rIz5cwCOfL2X55n1c3SWBGhVKU65UHlqYiYjkRVRM3uZsSe74I+C083N3bO1O0PkWaNTbWtvlB+eg//NwaDdUa5m388TVta+TKV8LzhyR/fO2uMiqweaNtqqrA1vhzLvTV9P1fdrCtc43pg+yWg+x2WpVmqU/Z402NiOtbHULeFJ+6aRUeascy464BGhyHsx7C44esNlxx//ySvf7YPFY+PFfNpuvVPmM20rG14fytWHhe9Ym9IzjqujKVYcBL8DYoVbRFhlj5z2004K2kzn7YVg+3sK8fv+wuW6f3wrlatnzMOtVCCbbGoZ+mnFFYZgq1gFXWs65BKAtMAuoGgq/ALZiLQwzOuZG4EaAOnWK0W8o+KxF4eFgsKhXImn4CKiCS0RERERERDJVvnQkr1/dkWe/+5WXp63hg9kbAChXKoJ7zm3C1V0SinaBIiIS/pyDfk/n/3nrdcv/c+anslWhx/1w1t02K6525/T3x1aE6yZmfGzdLhlvTzsfLbdOv9UqrgBO63/i/XEJ0O4qmP8O+KOgxYUZV7Y5B/W72xy0s+6xGW7Ha9of2g5Lba3YpB+0H27tLE+mUkNoO9SOO+M2mPUa7F4DV423ax7YDivGWyVY2QyjlLB1SgRczrkywCfACM/z9qct8fc8z3POZVjq5HneSGAkQIcOHYpPOZQvgsjQDC4JH44gnlMFl4iISH47evQou3fvJjExkUAgUNTLkRLC7/dTtmxZ4uPjiY7O4B+gIiK55Pc57ut7GgPb1GT19kQ27z3Mj6t28uj4ZexIPMo95zZW60IREZHM+CMhoWtRryJV3S42v+7ANmv1mJFuf4YFY2wOWIvBmZ+r/TVWXdXhusz3Oe8Zm9dVv4e1bsyu7vfDog9txtaG2XaN+t3tvjJVoOP12T9XGCn2AZdzLhILt8Z4nvdpaPM251x1z/O2OOeqA9uLboX5z/ki8DmPZH3AE1Z8XhAvv8qCRUREBLBwa/369cTFxZGQkEBkZKQ+9JMC53kex44dY//+/axfv546deoo5BKRfNekWlmaVLPfzr62az0e/nwpL079jV0Hk/jboBb4ffrvnYiISNhzDi59B5IO2KysjJSrAV3+BEs/gYSTVMrV6gAXv3ny60WWzn4LxbTK17T2jTNegPJ1oPfjOT9HGCrWAZezTzfeAFZ4nvfvNHeNB64Gng7dflEEyys4oeGCgeRjRbwQSctHEDSDS0REJF/t3r2buLg4KlXKwW+mieSRc46oqKj//dzt3r2b6tWrF/GqRORUFuH38dRFLalUJpoXp/7G9v1HeP7ytpSJLtYf24iIiJQM8fWy3qfnw/ZVlL+weebdsPM3m3+WUQvEYqi4fxrfFRgG9HTOLQx9nYcFW72dc6uBXqHvTx0++x9cBVzhRRVcIiIi+S8xMZFy5coV9TKkBCtXrhyJiYlFvQwRKQGcc9zbpwl/HdSCaat2cPErM9i451BRL0tERETyg3NFG24BxMTDFR9CndOLdh35qFj/KpDneT8Bmf1UnFOYaylMLhRwBZOTinglkpaPAJ5TwCUiIpKfAoEAkZGRRb0MKcEiIyM1+01ECtWw0+uSUDGGW8fMZ9BLP/PnPk04t1k14mKjinppIiIiImGluFdwlUjObwFXciC5iFciafkJgtNbSkREJL9p5pYUJf38iUhROKtRZT67tQtxMVHc/8kSOjw5iStG/cLYOes5eFSfBYiIiIhAMa/gKrFCAVfwmCq4womPIKiCS0RERERERPJBwypl+e6ubizbvJ9vl27lmyVbuP+TJTzx5XIuaFWDC1pXp2NCPKUi9e9QERERKZkUcBVDvpSASxVcYcVHQDO4REREREREJN8452hRszwtapbnnnMbM3/9HsbO2cCXizczdu4GSkX6OL1+RS5sW5MLWtXA71PVqYiIiJQcCriKI7/13Q4kHyvihUhaalEoIiIiIiIiBcU5R/u68bSvG89jA5oza+1ufli1g6m/bufODxfywpTfGNGrEee1qI5PQZeIiIiUAAq4iiGfL6WCSwFXOPF5QTy1KBQREZFTiHOO7t27M23atKJeioiIpBETFcHZp1Xh7NOq8H/BZkxYupXnJq3i9vcXUK7Ukv9VffVoUpkz6lfUPEERERE5JancpBhyfgVc4chHEHzKjEVERCT/OOdy9DV69OiiXnKe9O7dG+cctWvXJhAIFPVyRESKBZ/PcX6r6nw7ohsvXdGO81vV4MDRZEb//AdXjJrFwJd+5pslWwgEvaJeqoiIiEi+0qfxxZDzRwIQTNYMrnDiJwiawSUiIiL56NFHHz1h23PPPce+ffu48847qVChQrr72rRpk6/XX7FiBTExMfl6zsysXbuWyZMn45xj48aNTJgwgQsuuKBQri0icirwh4Ku81tVB+DIsQCfzt/EyB/XcOuY+TSpWpa/XdiCjgnxRbxSERERkfyhgKsY8qmCK/x4Hn7ngVoUioiISD567LHHTtg2evRo9u3bx4gRI0hISCjQ65922mkFev60Ro0ahed5PPDAAzz99NOMHDlSAZeISB6UivRzRec6DOlYmwlLt/DUNyu55NWZXNy+Fg/0O41KZaKLeokiIiIieaIWhcWQL1TB5SUr4AoXXjDUQsfpLSUiIiJFo0ePHjjnSEpK4oknnqBJkyZER0czfPhwAPbt28czzzxDz549qVWrFlFRUVSuXJkBAwYwc+bMDM/pnKNHjx7ptj322GM455g2bRrjxo2jU6dOxMTEEB8fz2WXXcamTZtyvPbk5GRGjx5NuXLl+L//+z/at2/PN998c9JzzZ49myFDhlCzZk2io6OpXr065557Lh999FGe9hUROdX4fY4LWtXg+7u7cUuPBny+YBNdnp7CXWMXMueP3XieWheKiIhI8aRP44shFxFqURhQi8JwEUh5LdSiUERERIrY4MGDefnll+nSpQsjRoygZcuWgLUbfOihh/D5fJx//vncfffd9O7dmylTptCtWze+/fbbHF3n5ZdfZujQoSQkJHDbbbfRokULxo4dS69evTh69GiOzjV+/Hi2bt3KkCFDKF26NMOHDycQCPDmm29muP+oUaPo0qULn3/+OV26dOGee+7h/PPPZ/v27bz88su53ldE5FQWExXB/X1PY+Jd3bisY20mLd/GJa/OpPsz03josyVMWLKFfYf0i7QiIiJSfKhFYTH0vwoutSgMG4FAMhGAU8AlIiJSaB7/chnLN+8v6mWcVLMa5Xi0f/NCvea6detYunQplSpVSre9adOmbN68+YTtGzdupFOnTtx111307ds329f59ttvmTNnzv8CNIArrriCDz74gC+++IJLL7002+caOXIkANdcc83/znPPPffwxhtv/C+US7F8+XJuvfVWypUrx/Tp4fIkjAAAIABJREFU02nePP3zu3HjxlztKyJSUjSoXIYnBrbggX6n8eWizXy/fBufL9jEmFnr8TloWbM8XRtWonvjynRIiMfvc0W9ZBEREZEMqYKrGPJFhGZwBRVwhYtgIKVFoQIuERERKVp//etfTwixAMqXL5/h9lq1anHxxRezcuVK1q9fn+3r/H97dx4fZXnv//91zZ5lsu8Q9iAgAioqnrqgFVp7qmJbe1prFVrR9tRWe/o952htq0fbX/ttS6v22PaAC1q/9rhQsVrrQgsWFEQUFQEFhLAv2cg++/X7Y4aQhAQSJJkMeT8fj3nknvu+5prPJHcm+cznvq7rO9/5TofiFsDcuXOB+JSAPbV9+3ZeeeUVTjnlFM4991wA8vLyuOyyy9i+fTsvvfRSh/a/+93viEQi/PCHPzyiYHXo9RxPWxGRwSbd4+JfzhrGA9edxTt3zOTpb5zLdz5Zgdvp4H/+sZV/mb+Kc/6/Jdz+zDr+tnE/ew62ajpDERERGVA0gisFHR7BpSkKB4rooQKXRnCJiIj0m/4eGZUqzj777G6Pvfbaa9x7772sXLmSAwcOEAqFOhzfvXs3w4YN69HzTJ069Yh95eXlANTV1fU43gceeIBYLNa2Vtghs2fPZtGiRSxYsIBLL720bf+qVasAOuzrTm/aiogMZm6ng6kj8pg6Io9bLhlLYyDMPzZV88L7e3kmMboLwO91MWVYDt+8cDTnjs7HGI3uEhERkeRRgSsFaYrCgSd26GehEVwiIiKSZCUlJV3uf+aZZ/jCF76Az+djxowZjB49moyMDBwOB8uWLePVV1/t1dpZOTk5R+xzJWYaaLv45xgOrbPlcDj46le/2uHYpz/9aUpKSnjuuefYt29f2+s6ePAgAEOGDDlm/71pKyIih/l9bv55Uin/PKmU1lCU93YdZNOBJjbta+TlDfu4+oE3OHtEHl87bwSFfh9+n4v8DA/5md5khy4iIiKDiApcKcjp0giugSYaif8stAaXiIiIJFt3V9P/8Ic/xOPxsGbNGsaPH9/h2I033sirr77aH+F18Pzzz7Nnzx7g6NMFPvTQQ3z/+98HDhfWdu/ezbhx447af2/aiohI19I8Ts4Zlc85o/IBuP2fx/PEmzv57bItfOOxtzu0PaXYz4WnFHJ+RQFTynPw+9zJCFlEREQGCRW4UpDjUIErpgLXQHFoDS4VuERERGSg2rJlC6eeeuoRxa1YLMaKFSuSEtOCBQsA+OxnP0txcfERx6PRKAsXLuTBBx/ktttuwxjDtGnTWLNmDX/961+PWbTqTVsREekZn9vJdf80gn85q5z1e+ppDERoDkbZUdvC8s1VPPzaNub/YyvGwNgiP2eNzOXac0cwttif7NBFRETkJKMCVwpyJqYoJKIpCgeK2KFiowpcIiIiMkCNGDGCzZs3s2fPHsrKygCw1nLnnXeyYcOGfo9n586dvPjii+Tm5vLUU0/h8/m6bLdlyxZWrFjBkiVLmDFjBt/85jf5/e9/z913382nPvUpJkyY0KH9rl272kaD9aatiIj0js/t5MzheR32fXP6aJqDEdZsr+OdHQdZu7OORW/t5rFVO7hkfDGz/2kEPreD5lCUaCzG5KE5mtZQREREjpsKXCnI4Y7/2DSCa+CIRTVFoYiIiAxs3/3ud/nGN77B6aefzuc//3ncbjevvfYaGzZs4LLLLuO5557r13gefPBBotEo11xzTbfFLYDrr7+eFStWMH/+fGbMmMGECRP47W9/2/ZarrjiCioqKqipqeHNN98kKyuLpUuXAvSqrYiInBgZXhcXji3kwrGFANQ1h3hkZSUPv1bJko37j2g/vjSLfxqdz6llWYwt9jOmKBOfW7m1iIiIHJsKXCnI5fLEN1TgGjAOLaRuHfqVEhERkYHpxhtvxOv1cs899/DII4+QlpbG+eefz8MPP8yiRYv6tcAVi8V46KGHgHgB62iuuuoqbr75Zp599lkOHDhAUVERc+fOZeLEifzyl79k2bJlLF68mIKCAiZNmnREf71pKyIiJ15uhodbLhnL3PNHsfKjGtwuB5leJ9EYvFlZy4rN1fxh5XZC0RgAbqfhS2cN4zufrKDQr9FdIiIi0j1jrU12DAPC1KlT7Zo1a5IdRo8Ea3fivW8iSytu56Kv/EeywxFg15Z1DH3sPN48/WecdcU3kx2OiIjISWPjxo1HrBkl0t96eh4aY96y1k7th5BSSirlWiKSHOFojO01zWza38TyzdU8tWYnXpeD2Z8YgdflpLK6mV11rRRmeRldmMnowgwmDc1hRH46xphkhy8iIiJ9rLtcS8NNUlDbGlwawTVgxGLxEVzGqWkURERERERERHrD7XQwpsjPmCI/nzmtlLnnj+QXL33I/Us/AqAs28eQ3DTe313PX9ftJZa4Vrsg08MZw3I5f2whl4wvojQ7LYmvQkRERPqbClwpyOnWFIUDjU2swYVRgUtERERERETk4xhVmMnvrjmTA40B/F43aZ7DuXYwEmVrVTNrdxzkre11rK6s4eUN+/nhYpg4JItLxhdzyfhiTi3L0uguERGRk5wKXCnIHFrnKRZObiDS5tAILodGcImIiIiIiIicEEV+3xH7vC4n40uzGF+axdXnDMNay0dVTbyy4QB/27ife/+2mXuWbKY02xcvdk0oZtqoPLwu5esiIiInGxW4UlFbgUsjuAaKaCT+s2grPoqIiIiIiIhInzPGtE1v+M3po6luCrL0gwMs2bifp9/axR9WbSfD46Qoy0fMWmLWMrIgk/PHFHBeRQFji/04HRrpJSIikor0aXwqOrQGVzSa3DikjT20BpdDV4SJiIiIiIiIJEtBpperppZz1dRyAuEoKz+q4e8fHKC+NYzDgAXW72ngJy9sBMAYyPK5yUl3M6ogg3NG5XP2yDyy09zsqmtlV10Lw/MyOK+iILkvTERERI6gAlcqSqzzZDRF4YARix4awaUCl4iIiIiIiMhA4HM7uWhcEReNKzri2N76VlZsrmZnXSv1LSFqW8Js2FPP0g+ruuzrwrGF/PCz4xlT5CcQjrJpfyO1zSH8Phd+n5uynDQyvfqYTUREpD/pL28qcjiIYsBqBNdAYWMqcImIiIiIiIikitLsNK6aWn7E/qrGIG9W1hIIRynPS6c028dL6/dzz5JNfOqe5YwuzGBrVTORmO3wOL/XxfdmjuWaacNxOR399TJEREQGNRW4UlQUp9bgGkBi0UNTFOpXSkRERERERCRVFfq9fOa00g77vn7eSGZNKeM3f9/C9ppmZkwoZmJZNkVZXhoDERoCEZ5as5M7n9vAk2t2ccMFowhFYtS3holaS0mWj5JsH2XZaRRne/G6dHGsiIjIiaBP41NUBBcOTVE4YMQSxUaHU/+kioiIiIiIiJxs8jO93Hn5qd0ev2xSKX99fx93PbeBW55456h9FWR6KMn2UZqdRmm2j9x0D4FIlJZgFKfDcOEphXxidAEel0aCiYiIHI0KXCkqikNTFA4gNhoDwKEpCkVEREREREQGHWMMnzmtlItOKaKyphm/z0V2mhtjDPvqA+ytb2VvfaDD9o6aFt7YWkNDIILX5SDD6yIQjrLw9UqyfC4uGFtITrobj9NJptfJuNIsJg3NZkhOGsaYZL9kERGRpFOBK0VFcWJiKnANFG1rcGkEl4iIiIiIiMigleZxMr40q8O+MUWZjCnK7PYxsZjF4YgXrIKRKCs2V/OXdXt5Y2streEooUiMllCEQ8t+Zflc+NxOHMbgdhlOKfYzeWgOE8qyiMQs9S1hmkMRTin2c/qwXNI8zrbnqWsJkZfhUYFMREROCipwpaioceGwmqJwoLCxQ2twqcAlIiIiIiIiIj13qLgF4HU5+eT4Yj45vrhDm2Akygd7G3lv10E+3N9IJGqJWUtrOMaGPfUs2Xigy75dDsP40iyaQxF21bUSisQYW5zJ1z4xklmnD8Hn1ucYIiKSulTgSlExjeAaUGKJn4XT6U5yJCIiIiIiIiJysvG6nEwuz2FyeU6Xx+tbw2w50IjX5SQ7zY3X7WD97gZWV9by3q6DlOelMWN8MbkZHv78zh5u/dM6fvbiB5RlpxGNWaLWMjQ3jVPLsji1LJuCTC8up8HjdJDlc5Of6SHd4yRmoaY5SFVjkJx0D2XZPo0GExGRpFGBK0VFjROjNbgGDBtNjODSFIUiIiKSgmbPns0jjzzCtm3bGDFiBACVlZWMHDmS6667joULF/aon4ULFzJnzhwefvhhZs+e3WfxioiISEfZaW7OHJ7XYV/ROB8XjSs6ou2NF4xi9bZannhzJ43BCK7ECLJt1c0s31xN9NBciJ14XQ4iMdvheH6Gh9OGZjNpSDanDc1h0tBsirN8bcetteyqa2X9ngastZw+LJeSbF9X3YuIiPSaClwpKooTh40kOww5JPGzcDj1KyUiIiInzle+8hUef/xx7r//fv71X//1qG1nzpzJK6+8wp/+9CeuvPLKforwxBo7diybN2/m3HPP5fXXX092OCIiIiclYwznjMrnnFH5RxwLhKNs2t9IQ2uEcCxGJGppaA1T3RSkpjmE1+WgyO+lINNLdVOQ93bVs253Pf/YVNW2RpjH5SDT6yLD6+RgS5jGQMfPr8qyfUwZlsP4kiwmlGVRnpeOwxicDkOm10VBptYIExGRntGn8SkqZpyYmApcA0UsMYLLoTW4RERE5ASaO3cujz/+OA888MBRC1yVlZUsWbKE0tJSLrvsshPy3EOGDGHjxo1kZ2efkP6OZenSpWzevBljDCtXruT9999n4sSJ/fLcIiIiEudzO5k0tOtpEI+mNRRlw9563t1Zz/6GAE3BCM3BCJk+FxNKs5lQlgXA29vreHtHHet21/PCun1d9pWX4eGUYj8jCzPISXOTnbhlJb763A4aAhEaWuNr058zMl+jwkREBikVuFJUTFMUDig2dmiKQv1KiYiIyIkzffp0xo4dy9q1a3n77bc544wzumz34IMPYq1lzpw5uFwn5v8Rt9vNuHHjTkhfPTF//nwA/vM//5Of/exnzJ8/n/vuu6/fnl9ERESOX5rHyZnD846YJrGzKeU5fI2RADQFI3y4r4G99QGiMYu1UNsc4sN9jXywv5EX399HfWu42ykT2xtX4ufc0fmU56ZTku0jJ93NwZYwVY1BmoIRyvPSqSjKpCwnjZ21LWw+0MiOmlaKsryMyM9gREE6xX4fDodGjomIpBJ9Gp+iorg0ReEAcqjA5dQaXCIiInKCzZ07l3//939nwYIF/O53vzvieDQa5eGHH8YYw/XXXw/A4sWLefrpp1m9ejW7d+8GYNy4cVx33XXcdNNNOByOYz7v0dbg2rJlC7fddhtLliwhFAoxefJkbr/99uN+jTU1NTzzzDNUVFRw9913s3DhQh577DF+/vOf4/N1fUX2yy+/zG9+8xveeOMN6uvrKSoq4owzzuDb3/42l1xyyXG3FRERkf6R6XUdsyBmraU5FKWhNUx9a5iG1jCBSAy/z0WWz00gHOW1LdW8uqmKx9/YQTASO+54fG4HI/IzGJ6fTml2GoV+L0V+L36fm3SPk3SPE2MgZiEStexraGV7TQu76lop8nuZNDS+DpnP5aAxEKEpGKEsJ428DM9xxyQiIkenAleKihknDo3gGjDaRnA59CslIiIiJ9Z1113H7bffzh//+EfmzZtHenp6h+N//etf2b17NzNmzGDkyPgV0bfeeisOh4NzzjmHIUOGUF9fz9///nduvvlm3nzzTf7whz8cdzyH1siqqanh0ksvZcqUKWzZsoVZs2Zx6aWXHlefjzzyCMFgkNmzZ+NyufjKV77CvHnzeOqpp/jqV796RPs77riDu+66i8zMTGbNmkV5eTl79uzh9ddf57HHHutQtOpNWxERERlYjImvy5XpdVGWk9Zlm4lDsrnxwtFYa6lrCbOvPsDB1hC56R4K/V4yPC4qa5rZfKCJ3XWtDMtLZ2xxJuV56VQ1BqmsaaaypoXK6mYqq5vZcqCJ17fU0Bjs2YXlRX4vtc0hIt2MNBtX4mfaqHyG5qbhdjpwOQ3Ffh+nlPgZkpOmUWMiIh+DPo1PUTHjxEYjrNpaQ2Ni3uHGQJiGQASHgSG5aW3DsnPTPaR7nAQjMd7deZA12+vYWdsSn8M43U2m10UoEiMUjeEwhhH56YwqzGRYXjo+t0Yk9cSh9dA0gktERKQf/fVW2Lcu2VEcXclpcOnPPlYXhYWFzJo1iyeffJInn3yS2bNndzi+YMECAG644Ya2fX/5y18YPXp0h3axWIw5c+bw6KOPctNNN3HOOeccVzzf+ta3qKmp4Z577uHmm29u2//ss88ya9as4+pzwYIFOBwOrr32WgBmz57NvHnzmD9//hEFrpdffpm77rqLkSNHsnz5coYMGdLh+K5du46rrYiIiKQ2Ywx5GZ4uR0yNL81ifGnWEfvL89Ipz0vn/Ioj+2sNRdumOGwJRWgORbHW4nQYnA5Dkd/H0Nw0fG4ngXCUjXsbeH9PA9FoDL/PTYbXxUdVTazaWsMTb+6kNXzkherpHmeHeG27Gpnf50pMn5hBVpqLhtYIDYEwHqeDCWVZTCzLZlh+OofqY26nA7fz2KP0RUROJipwpSqHm3AgyJfmr+Ra58uc4djMvtgwNtjhVNoSgtZNEDfNpBHGhcfpIGZt29UkBZkeGgIRQu2GbmfSQoXZzbt2NDHifxC9LgejvPVc4tnAkLGnc975FzG0IIdYsJl9H6yiqvJ9Kh3lrIuOoDpgmFCWxT+NLmB8aRYxa6nbtBLfip8R9hUQKD6d1uIziBRNxOlw4nQY8jO9ZPlcGGOw1rK/Ici26mbSPE6G5KSRn+FJ+pUsO2tbWLJxP2luJ5k+Fz6Xk6i1RGOHb5HqRs4GHFqDS0RERPrADTfcwJNPPskDDzzQocC1d+9eXnjhBYqKirjiiiva9ncubgE4HA5uvvlmHn30UV566aXjKnDt2rWLV155hZEjR3LTTTd1OHbFFVdw4YUX8uqrr/aqz+XLl/PBBx8wc+ZMhg4dCsDEiRM588wzWbFiBRs3bmT8+PFt7X/zm98AMG/evCMKVkBbH71tKyIiItJemsfJsPz0YzcEfG4npw/L5fRhuUcc+9ZFY4hEYzSHokSiMcJRy576Vjbta+TD/Y3Ut4bb2hoOfwZ2sCXEpgON/O2D/YSjFrfTkJ3mpjkY7bJYBpDlc1GQ6SXd66Q5GKUxEAEsw/MzGFkQv40uzGBkQSYl2T4C4SiNgXDblIpNgQiNh74GIsSs5bOTSqko9vfumyci0k/0aXyKGl6YRUnDAdZk/4GCHS8STctnVuvrR7SzGJq9hdS5S6jKGEvr1G8wYcJkchNXh7SGojSHIvh2v07GX/4D07CLYNYINo6aw7vuKZy64zEmH3gWd2sI3oXgO252Oospie2ljChlwGTgM9bJh45RLF53NrOj59HizmaOXcx3nU9TSxYGy5CP/gRAlc3mleiZvBybyurYOPBkUOT30tx4kMujr3CNcwmt+HgpNoZ1Ziy5p32Km2ddQJqn/0dHrdpaw9OP/jefjf6N/TaXD2whQdyMc+xggtlOqamlxmbhJgIOyPBpXmUREZF+8zFHRqWSiy++mNGjR/Paa691KPg8/PDDRCIRZs+ejdvtbmtfU1PDL37xC1544QW2bt1Kc3Nzh/4OrcvVW2vXrgXgvPPO63Lk+vTp03td4Jo/fz4Ac+bM6bB/9uzZvPXWWyxYsIBf/epXbftXrVqFMYZPf/rTx+y7N21FRERE+orL6SA77fDoqpJsH2d0UQzryqGimM/twBhDNGbZVt3M+j317KsPtLULhGPUNgepbg7REowwssBNptdJLAaVNc38Y1MVT7/Vu9HrxsC9f9vMBWML+eq04RRneXGYeBFub32AXXUtHGgMUp6bzqllWYwt9lPbEmJrVRNbq5rZVt3MR1VN7KxtYWhuOmcOz2XqiFzKc9PJTffg97mSfmG7iKQ2FbhSlNfjwVv/ITRsgZk/xnnuTRA4GJ+mp343RAIQCWJa68is30lm3XbKdz0Hf10Me74MU78GDhdpkSBp65+BVfdD3mj4zC/xrn2MKe/cwRQAhwumfBnO+jrVOzez/b1l2OotbMm+CNewsykZPYmh4e2kHVjLxK2vMnHP/+P7nv+lzlNKfnAX20svpXLa3cS8WXiaduE/sIbCPUv54r5XuTryd2I4qEobxQ7HcCa6V5PmaKS+6GwixsMXa1ZzTeRvxNb/nvc+nEjRuVdT9omrIS3n6N+chr2wew3sWgOlk2Hi59oOWWuJLr4J9r9P4PL/wVEwBp/L2eUf06ff2sWqZ+7n567fEc0uwxHbi7PlAADh9GKCBacSySqnOFCLq6WKsHcS6TnFJ/CnLCIiIhJnjOH666/ntttu44EHHmDevHlYa3nwwQcxxjB37ty2tgcPHuSss85i27ZtnH322Vx77bXk5eXhcrk4ePAg9957L8Fg8LjiqK+vB6C4uOv/eUpKSnrVX11dHU8//TQ5OTlHTG949dVX873vfY9HH32Un/70p3i9XiD++nJzc0lL63odjvZ601ZERERkIHI5HbjaXVfkdBjGFGUypiiz1301BSNUJopOBxqCpHud+H1u/F4XmT4Xfl98vTO/102G10lDIMLjb2zn0ZXbmfvomi77dBjoZvkxMjxORhVmMqEsi23VLdz3980dpmF0OgyjCzM4vTyXKcNyGFWQQUm2j+Is3xHLpuyrD7Bqaw37GwKEozFCUcuI/HRmnlpCpvfwR9x761s50BAkI7F2W16GB4+r49SN1lqsRcU1kZOAClypKrMIMgrhCw/DyPPj+9JyYeQF3T+mYS+8dg+seRjWdlpY/Ky5MOO/wJMBZ10P216FHW/ApC9CXnyx8oKy0yk454tddDwFSEyJU7UJx7uPk79tOZx1O8Mnf5nh5tAfi2LgTOBGiAShcgWOnasp3vUmxfveg4oL4bzvkj10arx5LAZVG9m54gly1j1F2YrbaH7txyzN/QKvFVxF0OVvmyLQieXM1hXMqHqU0sCWtsiiDje/X+/mpapcdtS2cHpwDQ+7HyNsncT+ZzrfDX+TVe5pTBudzydG51Ps9/Lengbe2XGQksrFzPP8ntjw83F/5QnwpEM4AOEW3Ol5uBERERHpP3PmzOFHP/pRW8Fn+fLlbN26lYsvvpgxY8a0tXvggQfYtm0bd9xxB3feeWeHPlauXMm999573DFkZ2cDsH///i6P79u3r1f9PfroowQCAQKBQLdFqJqaGhYtWsTVV18NQE5ODjU1NbS2th6zcNWbtiIiIiInu0yvi4lDspk4JLtH7fMyPNx0cQU3XDCa1dtqCYSjRBMVquKs+Bpkeekedta1sH5PA5v3N1Hg9zCqIJPRhRkU+r0Yc7iI1BgI8+7OevY3BKhrCVHbHGLj3gZe2rCPJ9bs7PDc2WluSrJ8FGV52VnbQmVNS5cx+tzrmDGhhJw0N69tqWZrdceZC7wuB2cOz2XaqHyy09ys3lbLG9tqCYajfHZyKV84cyhnDMvlYEuYXXWtRK3ltCHZONsVv2qagqzf04Db6cDnduD3uRiam35EEU5E+p8KXKnqs/eAjcYLUj2VVQqX/l/4xC2wYyU4PeDyQVYZFE843M4YGDU9fuutwrFwyZ3HbufywphPxm/dcTig+FSGf/4uamZ+n1/9aTHn7l7IZ2sf4cLap1jjmEydI5cGRzbnh19ntN1OJWX8JHINa6IV7LN5PO/9Phds+BGvlf2GKyfm850PH6POMYIlp9/L9HW3saDxV2zOnIrdVkPxR/tJI8hkcvicK5cxno+wIy/A9eX/jRe3ANy++E1ERESknxUXF3P55ZezaNEiFi9ezDPPPAPE1+dqb8uW+MU+n//854/oo7fTB3Z2+umnA7BixQqi0egR0xQuW7asV/0tWLAAgC9/+cukpx+5xkV9fT1PP/00CxYsaCtwTZs2jeeff54XX3yRK6+88qj996atiIiIiHTN43JwXkVBt8eH52cwPD8DTjt6P36fu8t+rLXsqG1hR20L+xuC7G8IsL8hwL76APsbg4wuzOSaacOZNiqfEQUZeJwOXA7D2p11LF67h+ff20MwEuOckXlcfc4wRuRn0ByK0ByM8lFVEys/quHXSzZhLZRl+zi/ogADLF67hz+u3onH6SAUjbXFk5/h4eJxRYwszGDZB1Ws2V57xCg1Y2BobhojCzIZlVjbrCjLx87alsS0jK0YEx+l5nIYXA4HTqfB63QwNDeNUYWZlOelsauulQ/3NbK1qhmf20Fuhoe8dA9pHidelwOvy0l+poeSbB8lWT7SPM62tdrqWkKJ71WQ0mwfp5Zl4XLGR6s1ByO8vaOODK+LyUNzOhTsRE4mKnClqo9TZMkq7TBtXyrI9/v4t+u+BHwJ9r6Hf8WvuWj/emjaGJ+aMX8MXLiAERM/z39ak5gHuJXGXQ5OW/otHp+wGsKtENwN1/6Zq0ZdCBcthVd+REXlcigdS6NvOgeNjyIO4mqpAv+5mEt/fri4JSIiIpJkc+fOZdGiRcybN493332XgoKCIwo3I0aMAOLFptNOO/wpw9q1a/npT3/6sZ5/6NChzJgxg1deeYX//u//5uabb2479uyzz/aqgPb666+zfv16JkyYwOOPP95lm1gsxqhRo1i2bBmbN2+moqKCb3/72zz//PN873vf4+yzz2bIkCEdHrN79+62fb1pKyIiIiLJYYw5XCTrhTOH53Hm8DzuvPxUrLVtxZ2u1DWHaAlHKcv2tY0qu2tWhBfW7WXTvkZKc9IYkpNGKBrjbxv38+L6fTQGIowr8XPTxRVMG5UHFgKRKPWtYSqrW9ha3czWqibWVNbSEoq2PVduupvh+Rk4DERjlkhiBqpIzNIairL4ndYOBTOXwzAsP51I1FLbHKIpGOndNzAh0+tiL2RaAAAXHUlEQVRi6ohc6lvDrNtVTyTxJLnpbs6vKKQk20dVY5DqpiBel5MxRZlUFGUSs5YNexvYuLeB6qYQDgMGg8/jpDDTS6HfS3aaG6cDnMYQjMaoaQpR0xTEAhPLspk0NJvyvHSqGoPsqw/QEoowpsjPuFI/BZneDnEeGrm3vaYFl9PgczvJ9DoZU+hnaG5at1NHBiNRPE5Hh1GBEC+Qdt4ng4cKXJJ6SifBVQ8fvh8JxkejJd7IXEB5Xjrleekw+hrY/zIsS3yYc9oXYdSF8W23Dz7z87Zu/ImbiIiIyEA1c+ZMRowYwerVqwG46aab8Hg8Hdpce+21/OIXv+CWW25h6dKlVFRUsHnzZp5//nk+97nP8cQTT3ysGO6//37OPfdcbrnlFl5++WUmT57Mli1beOaZZ7jssst47rnnetTP/PnzAfj617/ebRuHw8GcOXO48847mT9/Pr/4xS+YOXMmP/jBD/jxj3/M+PHjmTVrFuXl5ezfv58VK1Ywbdo0Fi5cCNCrtiIiIiKSmuKjk45e4MjN8JDbaV+m18UXp5Yf0fbyyWWEIjEOtoYo8h97kIG1tm3kWXleOnkZnqO2D0ai7KhpYWddC2U5aYwqyOywTlgoEiMQica/hqNUN4XYe7CVfQ0BgpEY1oLFkpPmoSTbS2Gmj8qaZlZtreHNyloyvS5uvHAU54zM52BrmGUfHuAfm6poDEQoyPRS4PfSGgrw6qYDhKPxIlia28kpJX7GFmfG+7fQHIqwq66FtTvqaAiEiVmIWYvb4SA/00N+podoDJZv/ohodwuxAX6fC5/bicfpIBiJUd3U/XrAGZ544S0rzY3P7cTlMOypD7CztoXa5hDpHieliXXaGgMR9jcEqGkO4XQYMjxO0j0u0j1O0r0u0twOWkNR6lrCHGwJkeF1UZTlo8jvpTjLS7E/PgWmwdAYjNAUiBcWPS4HHpcDb7uvdc0hKmtaqKxpxu10MHloNpPLcxiel9HWPhKNUd0Un3qzpjlITWK7KRjBYQxOB7idDrLT3GSnxRe/qaxpobK6mX0NAUKRGOFojJi1ba8jJ93NuJIsJg7JZmRBBs3BCHUtIRoCETxOg9ftBAtbDjTxwb5GtlU3EY5aLPGfR7o7vr7eoTXpMr1OMr1u8jI9FGZ6yMvwEo7GaGgN0xSM4HQYvC4nPreD0YWZjCjoXdE5GVTgktTn8h79+GfmQeUKiEbgUz/pn5hERERE+oAxhuuvv54f/OAHQHxEV2dlZWUsX76cW2+9lRUrVvDSSy8xbtw4fvvb33LJJZd87AJXRUUFq1at4tZbb2XJkiUsW7aMSZMmsXjxYqqqqnpU4Kqvr+epp57C4/Fw7bXXHrXt1772Ne666y4eeeQRfvKTn+DxeLj77rs599xzue+++3j++edpbm6mqKiIqVOnHtFfb9qKiIiIiEC8yNGT4hbE/0cvyfZRkt2z9l6Xk4piPxXFXV9qf6hgcsjQ3HSmlOcctc/ThmZz2eSyLo9dPrkMm1g7rf1Ip3A0xo7a+NpmI/Izjnsaw9ZQlA1769lbH6A4Kz6VotftYPP+eNFlR00zoaglHI3hMFBR5Gd8aRajCjOIxizBSJT61gib9zfywb5GthxooikYoaoxSDgaozQ7jU+dWkJJlo+DrSH2HgxwoDFAfqaH8YkRYjELLYlpKVtCEZpDUVpDEbLTPYwoyCA7zU1zMMqBxgA7alpYU1lLXUu4V68zw+NkeH4GgXCUVzZ0vSZxZ06HId3jxCaKg8FIrEMx0O00DMtLpywnDa/LicdlMJi217DlQBOvbNh/xBSZXSnyexlTlEl2mgOHMVji35OqxiDbqptpDERoDkZoDUeP2RfAv80Yy3c+WdGjtslkDp3cg93UqVPtmjVrkh2G9JWqDyEagpJjTAYsIiIiA8rGjRsZP358ssOQQa6n56Ex5i1r7dR+CCmlKNcSERERkYEmGIlS1RjEGEOmx0WG14kxhlAkRigSIxiNj6ILRmL4fS4KM71tBcL61jDv744X9eLto7icDvIzPORnesnL8JCf4SE7zd1hykVrLc2h+DSXsZilNNt31Kk1IV6k2ri3kR21zWT53OSke8jyuQhH48XBmIWRBRnHHDl4SDgao645xIHGILXNITwuB1k+N36fi5i1BMLxkYNFWV5Ks9OO/xt8gnWXa2kElwwOhackOwIRERERERERERERGQC8LidDc9OP2J/mcZLmcQLubh+bnebmE2MKev2cxpjEVIE9L8uke1ycOTyXM4d3nmTz+LidjvhUjVk9G3E40B29PCgiIiIiIiIiIiIiIiIywKjAJSIiIiIiIiIiIiIiIilFBS4RERERERERERERERFJKSpwiYiIiIiIiIiIiIiISEpRgUtERERERERERERERERSigpcIiIiIjKgWWuTHYIMYjr/REREREREBiYVuERERERkwHI6nYTD4WSHIYNYOBzG6XQmO4wBxRjzaWPMh8aYLcaYW5Mdj4iIiIiIDE4qcImIiIjIgOX3+2loaEh2GDKINTQ04Pf7kx3GgGGMcQL3A5cCE4AvG2MmJDcqEREREREZjFTgEhEREZEBKy8vj7q6OqqrqwmFQpouTvqFtZZQKER1dTV1dXXk5eUlO6SB5Gxgi7V2q7U2BPwvcEWSYxIRERERkUHIlewARERERES64/V6GTZsGLW1tVRWVhKNRpMdkgwSTqcTv9/PsGHD8Hq9yQ5nIBkC7Gx3fxdwTudGxpgbgBsAhg0b1j+RiYiIiIjIoKICl4iIiIgMaF6vl9LSUkpLS5Mdioj0kLV2PjAfYOrUqRp6KSIiIiIiJ5ymKBQREREREZGe2g2Ut7s/NLFPRERERESkX6nAJSIiIiIiIj31JlBhjBlpjPEAXwL+nOSYRERERERkENIUhSIiIiIiItIj1tqIMeYm4CXACTxkrV2f5LBERERERGQQUoFLREREREREesxa+wLwQrLjEBERERGRwU1TFIqIiIiIiIiIiIiIiEhKUYFLREREREREREREREREUooKXCIiIiIiIiIiIiIiIpJSVOASERERERERERERERGRlGKstcmOYUAwxlQB25McRgFQneQY5OSl80v6ks4v6Us6v6Qv6fySE2m4tbYw2UEMNAMg19LvufQlnV/Sl3R+SV/S+SV9SeeXnGhd5loqcA0gxpg11tqpyY5DTk46v6Qv6fySvqTzS/qSzi+Rk59+z6Uv6fySvqTzS/qSzi/pSzq/pL9oikIRERERERERERERERFJKSpwiYiIiIiIiIiIiIiISEpRgWtgmZ/sAOSkpvNL+pLOL+lLOr+kL+n8Ejn56fdc+pLOL+lLOr+kL+n8kr6k80v6hdbgEhERERERERERERERkZSiEVwiIiIiIiIiIiIiIiKSUlTgEhERERERERERERERkZSiAtcAYIz5tDHmQ2PMFmPMrcmOR1KfMabSGLPOGPOOMWZNYl+eMeYVY8zmxNfcZMcpqcEY85Ax5oAx5v12+7o8n0zcfYn3s/eMMWckL3JJBd2cX3caY3Yn3sPeMcZ8pt2x2xLn14fGmE8lJ2pJFcaYcmPMUmPMBmPMemPMzYn9eg8TGSSUa8mJplxLTiTlWtKXlGtJX1KuJQOFClxJZoxxAvcDlwITgC8bYyYkNyo5SVxkrZ1irZ2auH8r8DdrbQXwt8R9kZ5YCHy6077uzqdLgYrE7Qbgd/0Uo6SuhRx5fgH8OvEeNsVa+wJA4u/jl4BTE4/5beLvqEh3IsD3rLUTgGnAtxLnkd7DRAYB5VrSh5RryYmyEOVa0ncWolxL+o5yLRkQVOBKvrOBLdbardbaEPC/wBVJjklOTlcAjyS2HwFmJTEWSSHW2n8AtZ12d3c+XQE8auNWATnGmNL+iVRSUTfnV3euAP7XWhu01m4DthD/OyrSJWvtXmvt24ntRmAjMAS9h4kMFsq1pL8o15LjolxL+pJyLelLyrVkoFCBK/mGADvb3d+V2CfycVjgZWPMW8aYGxL7iq21exPb+4Di5IQmJ4nuzie9p8mJclNi2oKH2k3zo/NLjpsxZgRwOvAGeg8TGSz0Oy19QbmW9DX9nyJ9TbmWnFDKtSSZVOASOTmdZ609g/jw328ZYy5of9Baa4knZiIfm84n6QO/A0YDU4C9wLzkhiOpzhiTCSwCbrHWNrQ/pvcwERHpJeVa0m90PkkfUK4lJ5RyLUk2FbiSbzdQ3u7+0MQ+keNmrd2d+HoAeIb4sPL9h4b+Jr4eSF6EchLo7nzSe5p8bNba/dbaqLU2Bizg8NQYOr+k14wxbuIJ1/+z1v4psVvvYSKDg36n5YRTriX9QP+nSJ9RriUnknItGQhU4Eq+N4EKY8xIY4yH+IKOf05yTJLCjDEZxhj/oW1gJvA+8fPqukSz64BnkxOhnCS6O5/+DFxr4qYB9e2Gpov0SKd5uK8k/h4G8fPrS8YYrzFmJPHFaVf3d3ySOowxBngQ2Git/VW7Q3oPExkclGvJCaVcS/qJ/k+RPqNcS04U5VoyULiSHcBgZ62NGGNuAl4CnMBD1tr1SQ5LUlsx8Ez87wwu4HFr7YvGmDeBJ40xXwe2A19MYoySQowxfwSmAwXGmF3AHcDP6Pp8egH4DPEFaVuAOf0esKSUbs6v6caYKcSnMqgEbgSw1q43xjwJbAAiwLestdFkxC0p4xPAV4F1xph3Evu+j97DRAYF5VrSB5RryQmlXEv6knIt6WPKtWRAMPGpMEVERERERERERERERERSg6YoFBERERERERERERERkZSiApeIiIiIiIiIiIiIiIikFBW4REREREREREREREREJKWowCUiIiIiIiIiIiIiIiIpRQUuERERERERERERERERSSkqcImIiCSRMWa6McYmbncmOx4REREREZFUpzxLRGRwcCU7ABERObkZY+xxPOxda+2UEx6MiIiIiIjISUB5loiIiEZwiYiIiIiIiIiIiIiISIrRCC4REelPV/awXX2fRiEiIiIiInLyUJ4lIiKDkgpcIiLSb6y1i5Mdg4iIiIiIyMlEeZaIiAxWmqJQREREREREREREREREUooKXCIikhKMMdONMTZxuzOx7zRjzHxjzEfGmFZjTJUxZokx5su96LfcGPMzY8zbxphaY0zQGLPbGPOcMWa2McbZi76mGmPuM8a8a4ypMcaEE32+YYyZZ4w5p4f9DEu0/8AY02yMOWiMed0Y86/GmKOOvjbGOI0xX03Ev9MYE0h8b3YmXuNjxpjrjDEZPX1dIiIiIiJyclKepTxLRCSVGWttsmMQEZGTmDGm7Q+NtdZ8jH6mA0sTd/8L+AhYAHi7echfgC9YawNH6fNG4NdA2lGeeh1wubW28ij9ZADzgauP0s8hI6y129s9djodX9cq4I9ATjePfwW4zFob7CKOAuAF4KwexHGlpjIREREREUlNyrOOoDxLRGQQ0hpcIiKSis4Cvp/Yfgj4BxBN7P86kAH8M/AY8IWuOkgkXb9vt+s54snaQWAsMAcYCZwGrDDGnG6treqiHx/xxOlQshMAngReA+qALGAi8JlEv0dLPqcA/55o8z/ASiAITAW+kXhdM4DbgR918fgF7eLYQjyB2wS0JuI4BbgA6NEVjiIiIiIiMqgoz1KeJSKSUjSCS0RE+lQfXVkI0AjMtNau6tSuAlgGlCV2fcFau6hTmxHABuJXFEaBq621T3ZqkwY8RTyBA3jaWntVF3H9Fvhm4u67xK9C3NHNa7gYeNtae/Aor2sHcIm1dnOnx55NPJlzEU/oSttfXWiMKQL2EU/a1gDTrbXN3cQxHKD9FY4iIiIiIpI6lGd1aKs8S0RkkNIaXCIi0m/aze1+rNvsHnT3752TLoBEwvL1drv+TxeP/Q6Hp8uY1znpSvTTSnwqjL2JXZ9PJHXtX88wYG7ibg1waXdJV6LPv7dPurpxTeekK/HY1cATibu5wNmdmozi8FWLj3eXdCX62q6kS0RERETk5KA8S3mWiMhgpQKXiIikojrg4e4OWmtfJH7lIMA0Y0xJpyafS3yNAPOO0k8D8NvEXQNc2anJv3B4ut/fWGv38vGstdYuP8rxv7fbntDpWEu77VM/ZhwiIiIiIjL4KM9SniUiklK0BpeIiPSnzolLd94+xvHl1trQMdr8ncPJyVnE534/NMXE8MT+d621B47Rz8vA3YntznOqn9du+8/H6KcnjrhSspPd7bZzOx1bD+whPmXI140xhvhc8auttbETEJuIiIiIiAxMyrOOTnmWiMhJSgUuERHpN9baxSeoqy29bFPWbru03famHvTTvk1pp2ND221v7EFfx1J9jOPBdtu+9gestdHEgs6LAA/wtcTtoDFmJbACeMla+9YJiFNERERERAYI5VnHpDxLROQkpSkKRUQkFbUcuwnt50bPbLft76ZNd5q6eSxAVuJr1Fob6EFfx/KxrgC01j5PfM74xUA4sTsHuBT4CbDGGLPOGPPpjxWliIiIiIicjJRndUF5lojIwKUCl4iIpKL0HrTJaLfdPnlq7KZNd9onbY2djjUkvjqNMT4GAGvtu9baK4F84gnX3cCrHE7EJgIvGGO+kqQQRURERERkYFKe1Q3lWSIiA5MKXCIikorG9LLNnnbb7RcoruhBP+3b7Ol0bFe77fE96KvfWGsbrbUvWmt/ZK2dTnzaj18nDhvgV8YYZ9ICFBERERGRgUZ51jEozxIRGVhU4BIRkVR0njHGfYw2F7XbfvPQRmKx4+2Ju1OMMYXH6Gdmu+3VnY4tb7d9+TH6SSprbY219t+ANYldRfQs8RQRERERkcFBeVYvKc8SEUkuFbhERCQV5QGzuztojJkJnJq4u9Jau69Tk0WJry7glqP04wf+NXHXAs90avIEh6ek+LYxpvPiyANRZbttV7KCEBERERGRAUd51vGrbLetPEtEpJ+owCUiIqnql8aYszrvNMaMBh5qt2teF4/9DdCa2P4PY8znu+jHBzwGlCV2LbLWbm7fxlq7E1iQuJtPfM71Yd0FbIy50BiT093xj8MY8yljzM3GmOyjtBkDzEjcbQI+6otYREREREQkZSnP6ti38iwRkQFMVxSIiEi/McbM6kXzv1hrw90ce4F4AvGaMeYR4lNYRIGzgK9zeMHiRdbaRZ0fbK2tNMZ8F/g98b+FTxtjnk30e5D4lBJfA0YlHrKbw1cYdva9xPOeBUwBPjTGPAG8DtQCfuJXOV4KTABGJp7jRCsF7gF+boxZCrwBbAVagIJEfF/k8ILP91hrW7vqSEREREREUofyLOVZIiKDlQpcIiLSnzpPPXE0uXSfoLwJ/BF4ALg+cevsBeCa7jq31v6PMcYQXxDYB1yRuHX2PnCZtbaqm34CxpiLgYeBLyT6ui5x60qsu5g+Jpv46gE+lbh11+4+4I4+ikNERERERPqX8izlWSIig5IKXCIikpKstY8ZY94FvgNcTHyKixbgHeBBa+3jPejj98aYvwDfIp6ojADSgRpgLfAU8AdrbfQY/TQBVxlj/ol4wnVhIp40oB7YRPzqxz9aa3f0/tX2yKPARuASYBownvjVhj7i02RsA1YAD1lr1/ZRDCIiIiIiksKUZx1BeZaIyABmrLXHbiUiIpJkxpjpwNLE3f+y1t6ZvGhERERERERSn/IsERFJZY5kByAiIiIiIiIiIiIiIiLSGypwiYiIiIiIiIiIiIiISEpRgUtERERERERERERERERSigpcIiIiIiIiIiIiIiIiklJU4BIREREREREREREREZGUYqy1yY5BREREREREREREREREpMc0gktERERERERERERERERSigpcIiIiIiIiIiIiIiIiklJU4BIREREREREREREREZGUogKXiIiIiIiIiIiIiIiIpBQVuERERERERERERERERCSl/P8Mj+5pBg/N/QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_loss_array2=[i/10 for i in train_loss_array]\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "ax = plt.axes()\n",
        "plt.subplot(121)\n",
        "print(\"train_acc_array shape \", len(train_acc_array))\n",
        "plt.plot(np.arange(1, NUM_EPOCHS+38), train_acc_array)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+38),val_acc_array)\n",
        "plt.title(\"Train/Validation Accuracy\", fontsize=40)\n",
        "plt.xlabel(\"Epochs\", fontsize=30)\n",
        "plt.ylabel(\"Percent Accuracy\", fontsize=30)\n",
        "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"lower right\", fontsize=20)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "plt.subplot(122)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+38,dtype=int),train_loss_array2)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+38,dtype=int),val_loss_array)\n",
        "plt.title(\"Loss\", fontsize=40)\n",
        "plt.xlabel(\"Epochs\", fontsize=30)\n",
        "plt.ylabel(\"Loss\", fontsize=30)\n",
        "plt.legend(['train loss', 'valid loss'], loc=\"upper right\", fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"pruning_curves.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jHEaEYOfK40"
      },
      "outputs": [],
      "source": [
        "def plot_test_result(num_epochs, train_acc, train_loss, val_acc, val_loss):\n",
        "  fig = plt.figure(figsize=(16,6))\n",
        "  plt.subplot(121)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), train_acc)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), val_acc)\n",
        "  plt.title(\"Accuray\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), train_loss)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), val_loss)\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPyXSy3yD6G"
      },
      "source": [
        "<h2>Automatic Hyperparameter Search using Optuna</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefZAQVvyCgU",
        "outputId": "cf34d1f4-ebec-433f-b4e4-3fbe03a88f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 87.9 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=53e8ee9d3ea3548490fd413eba349d37bd0225e80f7f47138ae9737e34f426ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2MShrCMyLjz"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAKNVr4AyOPa"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # trying different optimizers\n",
        "  optimizer_name_class_1 = trial.suggest_categorical(\"optimizer\", [\"SGD\",\n",
        "                                                                   \"RMSprop\"])\n",
        "\n",
        "  # optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "  #                                                                  \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_1 = getattr(optim, optimizer_name_class_1)(curr_model.parameters(),\n",
        "                                                     lr=lr, momentum=momentum)\n",
        "\n",
        "  # optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 128, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_1, T_max=200)\n",
        "\n",
        "  # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  x\n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 10\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch, model=curr_model, validation_loader=val_loader)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "# numbers in ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F7S4oOdt1Rx4",
        "outputId": "d5d4c4b1-1dc2-4209-ec0b-736e713722ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:43:47,708]\u001b[0m A new study created in memory with name: resNet-18\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 115ms | Tot: 26s948ms | Train Loss: 2.338 | Train Acc: 10.172% (4570/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s939ms | Valid Loss: 2.340 | Valid Acc: 9.580% (479/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 116ms | Tot: 27s956ms | Train Loss: 2.338 | Train Acc: 10.212% (4588/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s910ms | Valid Loss: 2.341 | Valid Acc: 10.080% (504/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 114ms | Tot: 27s741ms | Train Loss: 2.339 | Train Acc: 10.250% (4605/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 2s421ms | Valid Loss: 2.341 | Valid Acc: 9.960% (498/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 115ms | Tot: 28s204ms | Train Loss: 2.340 | Train Acc: 10.170% (4569/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s948ms | Valid Loss: 2.342 | Valid Acc: 9.940% (497/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 116ms | Tot: 27s730ms | Train Loss: 2.339 | Train Acc: 10.123% (4548/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s928ms | Valid Loss: 2.340 | Valid Acc: 9.860% (493/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 115ms | Tot: 27s656ms | Train Loss: 2.340 | Train Acc: 10.272% (4615/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 2s208ms | Valid Loss: 2.342 | Valid Acc: 9.540% (477/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 116ms | Tot: 27s571ms | Train Loss: 2.339 | Train Acc: 10.225% (4594/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s941ms | Valid Loss: 2.344 | Valid Acc: 9.560% (478/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 116ms | Tot: 27s694ms | Train Loss: 2.339 | Train Acc: 10.243% (4602/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s898ms | Valid Loss: 2.343 | Valid Acc: 10.000% (500/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 113ms | Tot: 27s588ms | Train Loss: 2.340 | Train Acc: 10.145% (4558/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s933ms | Valid Loss: 2.340 | Valid Acc: 9.700% (485/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 118ms | Tot: 27s589ms | Train Loss: 2.338 | Train Acc: 10.110% (4542/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s915ms | Valid Loss: 2.342 | Valid Acc: 10.020% (501/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:48:53,651]\u001b[0m Trial 0 finished with value: 10.02 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.2, 'optimizer': 'SGD', 'momentum': 0.6748578199632881, 'lr': 0.061470023158151706, 'batch_size': 192}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 150ms | Tot: 26s767ms | Train Loss: 2.372 | Train Acc: 9.866% (4420/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 338ms | Tot: 2s153ms | Valid Loss: 2.371 | Valid Acc: 9.880% (494/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 152ms | Tot: 26s700ms | Train Loss: 2.372 | Train Acc: 10.000% (4480/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s880ms | Valid Loss: 2.372 | Valid Acc: 10.020% (501/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 150ms | Tot: 26s725ms | Train Loss: 2.371 | Train Acc: 10.071% (4512/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s888ms | Valid Loss: 2.367 | Valid Acc: 9.880% (494/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 154ms | Tot: 26s716ms | Train Loss: 2.371 | Train Acc: 9.908% (4439/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s860ms | Valid Loss: 2.369 | Valid Acc: 9.640% (482/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 148ms | Tot: 26s710ms | Train Loss: 2.371 | Train Acc: 9.978% (4470/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s927ms | Valid Loss: 2.371 | Valid Acc: 10.100% (505/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 150ms | Tot: 26s779ms | Train Loss: 2.372 | Train Acc: 9.964% (4464/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s937ms | Valid Loss: 2.370 | Valid Acc: 9.960% (498/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 151ms | Tot: 26s684ms | Train Loss: 2.372 | Train Acc: 9.960% (4462/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s785ms | Valid Loss: 2.369 | Valid Acc: 9.760% (488/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 151ms | Tot: 26s776ms | Train Loss: 2.371 | Train Acc: 9.891% (4431/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s947ms | Valid Loss: 2.370 | Valid Acc: 9.620% (481/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 152ms | Tot: 26s678ms | Train Loss: 2.371 | Train Acc: 9.991% (4476/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s828ms | Valid Loss: 2.372 | Valid Acc: 9.920% (496/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 150ms | Tot: 26s770ms | Train Loss: 2.369 | Train Acc: 9.915% (4442/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s873ms | Valid Loss: 2.371 | Valid Acc: 9.780% (489/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:53:50,653]\u001b[0m Trial 1 finished with value: 9.78 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.0, 'optimizer': 'SGD', 'momentum': 0.4865323376096785, 'lr': 0.024404311678597107, 'batch_size': 256}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 78ms | Tot: 28s680ms | Train Loss: 2.353 | Train Acc: 9.453% (4247/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s29ms | Valid Loss: 2.354 | Valid Acc: 9.560% (478/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 79ms | Tot: 28s502ms | Train Loss: 2.351 | Train Acc: 9.428% (4236/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 2s97ms | Valid Loss: 2.356 | Valid Acc: 9.240% (462/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 79ms | Tot: 28s655ms | Train Loss: 2.351 | Train Acc: 9.437% (4240/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s28ms | Valid Loss: 2.355 | Valid Acc: 9.180% (459/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 28s679ms | Train Loss: 2.350 | Train Acc: 9.420% (4232/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s60ms | Valid Loss: 2.353 | Valid Acc: 9.500% (475/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 77ms | Tot: 28s711ms | Train Loss: 2.352 | Train Acc: 9.339% (4196/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s964ms | Valid Loss: 2.354 | Valid Acc: 9.640% (482/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 80ms | Tot: 28s836ms | Train Loss: 2.352 | Train Acc: 9.486% (4262/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s960ms | Valid Loss: 2.356 | Valid Acc: 8.680% (434/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 80ms | Tot: 28s485ms | Train Loss: 2.351 | Train Acc: 9.524% (4279/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s953ms | Valid Loss: 2.353 | Valid Acc: 9.720% (486/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 81ms | Tot: 28s527ms | Train Loss: 2.352 | Train Acc: 9.515% (4275/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 2.358 | Valid Acc: 9.220% (461/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 80ms | Tot: 28s633ms | Train Loss: 2.351 | Train Acc: 9.346% (4199/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s991ms | Valid Loss: 2.349 | Valid Acc: 9.300% (465/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 78ms | Tot: 28s839ms | Train Loss: 2.351 | Train Acc: 9.480% (4259/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 2s412ms | Valid Loss: 2.355 | Valid Acc: 9.240% (462/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:59:04,087]\u001b[0m Trial 2 finished with value: 9.24 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.0, 'optimizer': 'SGD', 'momentum': 0.909853489730662, 'lr': 0.08251134217906209, 'batch_size': 128}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 79ms | Tot: 28s915ms | Train Loss: 2.391 | Train Acc: 10.025% (4504/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s944ms | Valid Loss: 2.389 | Valid Acc: 9.880% (494/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 78ms | Tot: 28s717ms | Train Loss: 2.393 | Train Acc: 9.992% (4489/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s966ms | Valid Loss: 2.395 | Valid Acc: 9.800% (490/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 80ms | Tot: 28s642ms | Train Loss: 2.392 | Train Acc: 10.012% (4498/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 2.397 | Valid Acc: 9.920% (496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 29s22ms | Train Loss: 2.393 | Train Acc: 10.009% (4497/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s46ms | Valid Loss: 2.397 | Valid Acc: 9.860% (493/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2022-11-22 15:01:17,907]\u001b[0m Trial 3 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-35-4ece1c94b17c>\", line 54, in objective\n",
            "    train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
            "  File \"<ipython-input-26-13119085b394>\", line 17, in train\n",
            "    train_loss += loss.item()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c957fa888094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resNet-18\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-4ece1c94b17c>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_trainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-13119085b394>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, train_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18\")\n",
        "\n",
        "study.optimize(objective, n_trials = 8)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RphsqTa1uv_"
      },
      "outputs": [],
      "source": [
        "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "7FyHCQ1cHeZM",
        "outputId": "70dfdf5b-6b38-4814-eb17-dfe5298bc492"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7032200-07a9-411d-a8f8-135cc582fbd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_dropout_rate</th>\n",
              "      <th>params_dropout_rate2</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_momentum</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81.42</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.046432</td>\n",
              "      <td>0.929673</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.14</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.029621</td>\n",
              "      <td>0.725203</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85.76</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.017706</td>\n",
              "      <td>0.424324</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.96</td>\n",
              "      <td>192</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.415626</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86.96</td>\n",
              "      <td>64</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.308545</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>86.48</td>\n",
              "      <td>192</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.010862</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>86.32</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.642634</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84.80</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030530</td>\n",
              "      <td>0.569134</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>87.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.515801</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>86.88</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.032970</td>\n",
              "      <td>0.676042</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>86.98</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.174142</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>86.30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.183899</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>86.62</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>86.14</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.026755</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>86.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.853746</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>88.02</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>0.265827</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86.82</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.344868</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>87.90</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.005739</td>\n",
              "      <td>0.534634</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>87.50</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.006430</td>\n",
              "      <td>0.269840</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86.84</td>\n",
              "      <td>128</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.780328</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>87.94</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.007808</td>\n",
              "      <td>0.568036</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>87.36</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.563467</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>87.54</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.460849</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>87.12</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.095388</td>\n",
              "      <td>0.594778</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>87.54</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008114</td>\n",
              "      <td>0.370643</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7032200-07a9-411d-a8f8-135cc582fbd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
              "0   81.42                192                  0.4                   0.2   \n",
              "1   85.14                192                  0.1                   0.1   \n",
              "2   85.76                256                  0.4                   0.3   \n",
              "3   85.96                192                  0.2                   0.2   \n",
              "4   86.96                 64                  0.4                   0.2   \n",
              "5   86.48                192                  0.3                   0.1   \n",
              "6   86.32                256                  0.3                   0.1   \n",
              "7   84.80                128                  0.5                   0.0   \n",
              "8   87.48                256                  0.0                   0.1   \n",
              "9   86.88                192                  0.4                   0.1   \n",
              "10  86.98                256                  0.0                   0.0   \n",
              "11  86.30                256                  0.0                   0.0   \n",
              "12  86.62                256                  0.0                   0.0   \n",
              "13  86.14                128                  0.1                   0.0   \n",
              "14  86.48                256                  0.1                   0.0   \n",
              "15  88.02                 64                  0.0                   0.1   \n",
              "16  86.82                 64                  0.2                   0.3   \n",
              "17  87.90                128                  0.1                   0.1   \n",
              "18  87.50                 64                  0.1                   0.2   \n",
              "19  86.84                128                  0.2                   0.1   \n",
              "20  87.94                 64                  0.1                   0.2   \n",
              "21  87.36                 64                  0.1                   0.2   \n",
              "22  87.54                128                  0.0                   0.3   \n",
              "23  87.12                 64                  0.1                   0.1   \n",
              "24  87.54                 64                  0.2                   0.2   \n",
              "\n",
              "    params_lr  params_momentum params_optimizer  \n",
              "0    0.046432         0.929673          RMSprop  \n",
              "1    0.029621         0.725203              SGD  \n",
              "2    0.017706         0.424324              SGD  \n",
              "3    0.000013         0.415626              SGD  \n",
              "4    0.003680         0.308545              SGD  \n",
              "5    0.001661         0.010862              SGD  \n",
              "6    0.000020         0.642634              SGD  \n",
              "7    0.030530         0.569134              SGD  \n",
              "8    0.000249         0.515801          RMSprop  \n",
              "9    0.032970         0.676042              SGD  \n",
              "10   0.000266         0.174142          RMSprop  \n",
              "11   0.000177         0.183899          RMSprop  \n",
              "12   0.000154         0.179775          RMSprop  \n",
              "13   0.000233         0.026755          RMSprop  \n",
              "14   0.000069         0.853746          RMSprop  \n",
              "15   0.000878         0.265827          RMSprop  \n",
              "16   0.000781         0.344868          RMSprop  \n",
              "17   0.005739         0.534634          RMSprop  \n",
              "18   0.006430         0.269840          RMSprop  \n",
              "19   0.000909         0.780328          RMSprop  \n",
              "20   0.007808         0.568036          RMSprop  \n",
              "21   0.008254         0.563467          RMSprop  \n",
              "22   0.002182         0.460849          RMSprop  \n",
              "23   0.095388         0.594778          RMSprop  \n",
              "24   0.008114         0.370643          RMSprop  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfILxanQHrkV"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path  \n",
        "filepath = Path('optuna_out.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tMVKiy5_1lQz",
        "outputId": "e026d825-5c19-4fea-c084-75e3f544bbbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"844e23c1-e7c4-47dd-aa84-54bea3041563\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"844e23c1-e7c4-47dd-aa84-54bea3041563\")) {                    Plotly.newPlot(                        \"844e23c1-e7c4-47dd-aa84-54bea3041563\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.48,86.32,84.8,87.48,86.88,86.98,86.62,86.48,88.02,86.82,87.9,87.5,86.84,87.94,87.54,87.12],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.96,86.96,86.96,87.48,87.48,87.48,87.48,87.48,88.02,88.02,88.02,88.02,88.02,88.02,88.02,88.02],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('844e23c1-e7c4-47dd-aa84-54bea3041563');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt_hist = optuna.visualization.plot_optimization_history(study)\n",
        "\n",
        "opt_hist.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "opt_hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ttCK-I3f1olz",
        "outputId": "2b5075cc-f6b9-450c-ee4f-630928b32a01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\")) {                    Plotly.newPlot(                        \"ebb31b8a-b414-4d35-b0fd-6702e59b597f\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[54.4,64,128,192,256,265.6],\"y\":[8.169610120215257e-06,1.2760918088428318e-05,1.9851358937422513e-05,6.895371131358072e-05,0.00015387349104295094,0.0002492294583100163,0.00026626831184196344,0.000780715307860027,0.0008781984559717051,0.0009089777877470327,0.0016608243757673467,0.002182085616397292,0.003679633596234943,0.005739052585337983,0.0064302752977516645,0.007808464498303689,0.017705749117129983,0.029621233669222247,0.03052954516379949,0.03297036376254276,0.04643207616533176,0.09538799451770531,0.1489958965909395],\"z\":[[null,null,null,null,null,null],[null,null,null,85.96,null,null],[null,null,null,null,86.32,null],[null,null,null,null,86.48,null],[null,null,null,null,86.62,null],[null,null,null,null,87.48,null],[null,null,null,null,86.98,null],[null,86.82,null,null,null,null],[null,88.02,null,null,null,null],[null,null,86.84,null,null,null],[null,null,null,86.48,null,null],[null,null,87.54,null,null,null],[null,86.96,null,null,null,null],[null,null,87.9,null,null,null],[null,87.5,null,null,null,null],[null,87.94,null,null,null,null],[null,null,null,null,85.76,null],[null,null,null,85.14,null,null],[null,null,84.8,null,null,null],[null,null,null,86.88,null,null],[null,null,null,81.42,null,null],[null,87.12,null,null,null,null],[null,null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[192,192,256,192,64,192,256,128,256,192,256,256,256,64,64,128,64,128,64,128,64],\"y\":[0.04643207616533176,0.029621233669222247,0.017705749117129983,1.2760918088428318e-05,0.003679633596234943,0.0016608243757673467,1.9851358937422513e-05,0.03052954516379949,0.0002492294583100163,0.03297036376254276,0.00026626831184196344,0.00015387349104295094,6.895371131358072e-05,0.0008781984559717051,0.000780715307860027,0.005739052585337983,0.0064302752977516645,0.0009089777877470327,0.007808464498303689,0.002182085616397292,0.09538799451770531],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"batch_size\"},\"range\":[54.4,265.6]},\"yaxis\":{\"title\":{\"text\":\"lr\"},\"range\":[-5.087798668887335,-0.8268256920739774],\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ebb31b8a-b414-4d35-b0fd-6702e59b597f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i2J9SpQJ1sy5",
        "outputId": "2141417f-a32b-48c1-c840-e59404d00512"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\")) {                    Plotly.newPlot(                        \"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"dropout_rate2 (FloatDistribution): 0.02052906992009996<extra></extra>\",\"batch_size (IntDistribution): 0.04208505899340595<extra></extra>\",\"dropout_rate (FloatDistribution): 0.09134791826999204<extra></extra>\",\"optimizer (CategoricalDistribution): 0.11600269442598625<extra></extra>\",\"lr (FloatDistribution): 0.24782621733655558<extra></extra>\",\"momentum (FloatDistribution): 0.48220904105396<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02\",\"0.04\",\"0.09\",\"0.12\",\"0.25\",\"0.48\"],\"textposition\":\"outside\",\"x\":[0.02052906992009996,0.04208505899340595,0.09134791826999204,0.11600269442598625,0.24782621733655558,0.48220904105396],\"y\":[\"dropout_rate2\",\"batch_size\",\"dropout_rate\",\"optimizer\",\"lr\",\"momentum\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f11ba62-5e0f-4a52-a81c-8ca76f07db38');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_importance_fig = optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "param_importance_fig.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "param_importance_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3tpr4KK2RVI",
        "outputId": "2c076844-1436-46ba-a10d-fcabf8929120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Number of finished trials:  25\n",
            "  Number of pruned trials:  4\n",
            "  Number of complete trials:  21\n"
          ]
        }
      ],
      "source": [
        "from optuna.trial import TrialState\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUoh2I8hGQhu"
      },
      "outputs": [],
      "source": [
        "# serialize the reult\n",
        "\n",
        "SERIALIZATION_DIR = \"\" \n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('study_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(study, f)\n",
        "\n",
        "with open('df_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj0rployJanz",
        "outputId": "7d93d6a4-b511-4056-bb1a-e2c89bed77ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best model is\n",
            "{'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'RMSprop', 'momentum': 0.26582732909111395, 'lr': 0.0008781984559717051, 'batch_size': 64}\n"
          ]
        }
      ],
      "source": [
        "print(\"The best model is\")\n",
        "\n",
        "print(trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OntkPiXekwLR"
      },
      "outputs": [],
      "source": [
        "def objective_2(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "  # trying different optimizers\n",
        "\n",
        "  optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "                                                                   \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 64, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 25\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTR21sA2lAnX",
        "outputId": "0f0d7470-4adc-4cd2-9e59-9b84e5ab85d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 06:25:03,584]\u001b[0m A new study created in memory with name: resNet-18-Ada\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna with Ada family optimizers\n",
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 41ms | Tot: 31s448ms | Train Loss: 2.346 | Train Acc: 10.371% (4666/44992)\b\b\b\b 703/703 \n",
            " [======>]  Step: 9ms | Tot: 2s74ms | Valid Loss: 2.303 | Valid Acc: 8.380% (419/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Optuna with Ada family optimizers\")\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18-Ada\")\n",
        "\n",
        "study.optimize(objective_2, n_trials = 5)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8OFkLJ5nQa"
      },
      "source": [
        "<h1>Model Visualization with Tensorboard</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odnt6T_i5mcA",
        "outputId": "fca4db79-ff96-4774-e1de-687c181bd165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.38.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVF5Rs1yg8-l"
      },
      "outputs": [],
      "source": [
        "# Run in shell: tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9M0JT27NZn",
        "outputId": "fa927eb0-3d81-4811-ab7c-630f16ac158d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 0.943s\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6l8H9BXcLp-",
        "outputId": "d567fcb6-1bcf-440b-e87e-0cca3e4723bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://legal-mails-turn-34-73-105-255.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!lt --port 6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr94MEgvcQAe",
        "outputId": "8ef084f8-974b-4198-8a02-04a80d1a8b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running the best model for 100 epochs\n"
          ]
        }
      ],
      "source": [
        "print(\"Running the best model for 100 epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD9CHX5P7WDw"
      },
      "outputs": [],
      "source": [
        "jsjhfhfhhfhf"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3df2267cf8d54d74aaa803ab0a7f39d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4fd0e91c384433c9e4e86677551a5eb",
              "IPY_MODEL_75fb31bd9ee64e3c8fe52490f031d917",
              "IPY_MODEL_c411225fe7b9462bbbef20d707e9b184"
            ],
            "layout": "IPY_MODEL_ae4f75575c494f9aa028a84b27b35718"
          }
        },
        "a4fd0e91c384433c9e4e86677551a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0361accc5944588b1f28e440421b32d",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3dee7be8734ab99425179b2d0a37d2",
            "value": "100%"
          }
        },
        "75fb31bd9ee64e3c8fe52490f031d917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1346132be0c544bdb53d0985afeb9db0",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f2e2b1de884cfe875db6b983566fb3",
            "value": 170498071
          }
        },
        "c411225fe7b9462bbbef20d707e9b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b432d075aafa47cb8121b097d421733e",
            "placeholder": "​",
            "style": "IPY_MODEL_fcfc666db5a6422b95ae3115185ae4af",
            "value": " 170498071/170498071 [00:10&lt;00:00, 17177215.09it/s]"
          }
        },
        "ae4f75575c494f9aa028a84b27b35718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0361accc5944588b1f28e440421b32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3dee7be8734ab99425179b2d0a37d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1346132be0c544bdb53d0985afeb9db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f2e2b1de884cfe875db6b983566fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b432d075aafa47cb8121b097d421733e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfc666db5a6422b95ae3115185ae4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}