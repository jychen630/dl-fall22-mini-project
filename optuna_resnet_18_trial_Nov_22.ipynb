{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaBEihcdtk8",
        "outputId": "a02db347-e397-4df0-af5f-9c3d07c4e794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXI-w576XzT_"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "import torch as torch\n",
        "\n",
        "\n",
        "def set_up_ssl():\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "set_up_ssl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC88owTK4XJj"
      },
      "outputs": [],
      "source": [
        "LOCAL_M1 = False\n",
        "\n",
        "if LOCAL_M1:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
        "else:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbtvE4s14XJj",
        "outputId": "c1d65db3-e2ca-42f6-8013-ed432078c882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTLc4fVcQ857"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "import humanize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAU4PYGddva",
        "outputId": "d3653024-bd73-4844-a600-f237e68073cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Tensorboard writer object\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating Tensorboard writer object\")\n",
        "\n",
        "TENSOR_BOARD_DIR = \"runs/resnet_18\"\n",
        "\n",
        "writer = SummaryWriter(TENSOR_BOARD_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQeGvfSCRM4i"
      },
      "outputs": [],
      "source": [
        "term_width = 5\n",
        "TOTAL_BAR_LENGTH = 7\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTCFIHn0XzUL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate3 = trial.suggest_float(\"dropout_rate3\", 0, 0.1,\n",
        "                                                step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate3)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, trial=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], trial,\n",
        "                                       stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], trial,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], trial,\n",
        "                                       stride=2)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], trial,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, trial, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, trial))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(trial=None):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet34(trial=None):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet50(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet101(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet152(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], trial=trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "3df2267cf8d54d74aaa803ab0a7f39d5",
            "a4fd0e91c384433c9e4e86677551a5eb",
            "75fb31bd9ee64e3c8fe52490f031d917",
            "c411225fe7b9462bbbef20d707e9b184",
            "ae4f75575c494f9aa028a84b27b35718",
            "f0361accc5944588b1f28e440421b32d",
            "0a3dee7be8734ab99425179b2d0a37d2",
            "1346132be0c544bdb53d0985afeb9db0",
            "91f2e2b1de884cfe875db6b983566fb3",
            "b432d075aafa47cb8121b097d421733e",
            "fcfc666db5a6422b95ae3115185ae4af"
          ]
        },
        "id": "N_K9-VkFRsiL",
        "outputId": "e3b5e70f-f7dc-4249-aee9-1bf89dd153a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3df2267cf8d54d74aaa803ab0a7f39d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "The length of a train set is  45000\n",
            "The length of a validation set is  5000\n",
            "The length of a test set is  10000\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# constructing validation set\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)\n",
        "print(\"The length of a train set is \", len(train_ds))\n",
        "print(\"The length of a validation set is \", len(val_ds))\n",
        "print(\"The length of a test set is \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = ResNet18() # 11.2 params\n",
        "#net = ResNet50() # 23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzjCm0gOElC",
        "outputId": "f1783bbc-f083-4252-a342-5d6745ee7501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "layers[0]:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "layers[1]:  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "layers[2]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[3]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[4]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[5]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[6]:  Linear(in_features=512, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "layers = list(net.children())\n",
        "\n",
        "print(len(layers))\n",
        "\n",
        "print(\"layers[0]: \", layers[0])\n",
        "print(\"layers[1]: \", layers[1])\n",
        "print(\"layers[2]: \", layers[2])\n",
        "print(\"layers[3]: \", layers[3])\n",
        "print(\"layers[4]: \", layers[4])\n",
        "print(\"layers[5]: \", layers[5])\n",
        "print(\"layers[6]: \", layers[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhtblo5n4uKQ",
        "outputId": "73870da1-5fce-4c9f-e69c-4098585c48af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-0.2.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch_pruning) (4.1.1)\n",
            "Installing collected packages: torch-pruning\n",
            "Successfully installed torch-pruning-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M1xDV4-VaKG"
      },
      "outputs": [],
      "source": [
        "import torch_pruning as tp\n",
        "\n",
        "def prune_model(model):\n",
        "    model.cpu()\n",
        "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 3, 32, 32) )\n",
        "    def prune_conv(conv, amount=0.2):\n",
        "        strategy = tp.strategy.L1Strategy()\n",
        "        pruning_index = strategy(conv.weight, amount=amount)\n",
        "        plan = DG.get_pruning_plan(conv, tp.prune_conv_out_channel, pruning_index)\n",
        "        plan.exec()\n",
        "    \n",
        "    block_prune_probs = [0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3]\n",
        "    blk_id = 0\n",
        "    for m in model.modules():\n",
        "        if isinstance( m, BasicBlock):\n",
        "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
        "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
        "            blk_id+=1\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgQPV3H4ZTxA"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def print_params(model):\n",
        "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkbs0btThnx",
        "outputId": "6071538e-8b91-47d6-b424-ee87adeebd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters before pruning is \n",
            "Number of parameters  11.2 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters before pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duOPOJDMV2Vn",
        "outputId": "9122f6c8-4135-489c-d3ba-5b31c96e7a28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(53, 83, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(83, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(83, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(83, 164, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(164, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(164, 359, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(164, 252, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(252, 359, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=252, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "prune_model(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAZTZsHwTyOK",
        "outputId": "6e5e7d5b-e1f5-4168-ce0a-d771e54bbeb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters after pruning is \n",
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters after pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqr1gYtVHgE",
        "outputId": "ce483cee-21fd-48ed-b051-c4a2d4430ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 53, 32, 32]           1,431\n",
            "       BatchNorm2d-2           [-1, 53, 32, 32]             106\n",
            "            Conv2d-3           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-4           [-1, 58, 32, 32]             116\n",
            "            Conv2d-5           [-1, 53, 32, 32]          27,666\n",
            "       BatchNorm2d-6           [-1, 53, 32, 32]             106\n",
            "        BasicBlock-7           [-1, 53, 32, 32]               0\n",
            "            Conv2d-8           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-9           [-1, 58, 32, 32]             116\n",
            "           Conv2d-10           [-1, 53, 32, 32]          27,666\n",
            "      BatchNorm2d-11           [-1, 53, 32, 32]             106\n",
            "       BasicBlock-12           [-1, 53, 32, 32]               0\n",
            "           Conv2d-13          [-1, 103, 16, 16]          49,131\n",
            "      BatchNorm2d-14          [-1, 103, 16, 16]             206\n",
            "           Conv2d-15           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-16           [-1, 83, 16, 16]             166\n",
            "           Conv2d-17           [-1, 83, 16, 16]           4,399\n",
            "      BatchNorm2d-18           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-19           [-1, 83, 16, 16]               0\n",
            "           Conv2d-20          [-1, 103, 16, 16]          76,941\n",
            "      BatchNorm2d-21          [-1, 103, 16, 16]             206\n",
            "           Conv2d-22           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-23           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-24           [-1, 83, 16, 16]               0\n",
            "           Conv2d-25            [-1, 205, 8, 8]         153,135\n",
            "      BatchNorm2d-26            [-1, 205, 8, 8]             410\n",
            "           Conv2d-27            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-28            [-1, 164, 8, 8]             328\n",
            "           Conv2d-29            [-1, 164, 8, 8]          13,612\n",
            "      BatchNorm2d-30            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-31            [-1, 164, 8, 8]               0\n",
            "           Conv2d-32            [-1, 205, 8, 8]         302,580\n",
            "      BatchNorm2d-33            [-1, 205, 8, 8]             410\n",
            "           Conv2d-34            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-35            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-36            [-1, 164, 8, 8]               0\n",
            "           Conv2d-37            [-1, 359, 4, 4]         529,884\n",
            "      BatchNorm2d-38            [-1, 359, 4, 4]             718\n",
            "           Conv2d-39            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-40            [-1, 252, 4, 4]             504\n",
            "           Conv2d-41            [-1, 252, 4, 4]          41,328\n",
            "      BatchNorm2d-42            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-43            [-1, 252, 4, 4]               0\n",
            "           Conv2d-44            [-1, 359, 4, 4]         814,212\n",
            "      BatchNorm2d-45            [-1, 359, 4, 4]             718\n",
            "           Conv2d-46            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-47            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-48            [-1, 252, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 4,493,525\n",
            "Trainable params: 4,493,525\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 8.69\n",
            "Params size (MB): 17.14\n",
            "Estimated Total Size (MB): 25.84\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def print_model_summary(model):\n",
        "  print(summary(model.to(device), (3, 32, 32)))\n",
        "\n",
        "print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tejFfYvQJxR5",
        "outputId": "9e109609-cb8d-4dd6-9671-e27c13d6482b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([53, 3, 3, 3])\n",
            "bn1.weight torch.Size([53])\n",
            "bn1.bias torch.Size([53])\n",
            "layer1.0.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([58])\n",
            "layer1.0.bn1.bias torch.Size([58])\n",
            "layer1.0.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([53])\n",
            "layer1.0.bn2.bias torch.Size([53])\n",
            "layer1.1.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([58])\n",
            "layer1.1.bn1.bias torch.Size([58])\n",
            "layer1.1.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([53])\n",
            "layer1.1.bn2.bias torch.Size([53])\n",
            "layer2.0.conv1.weight torch.Size([103, 53, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([103])\n",
            "layer2.0.bn1.bias torch.Size([103])\n",
            "layer2.0.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([83])\n",
            "layer2.0.bn2.bias torch.Size([83])\n",
            "layer2.0.shortcut.0.weight torch.Size([83, 53, 1, 1])\n",
            "layer2.0.shortcut.1.weight torch.Size([83])\n",
            "layer2.0.shortcut.1.bias torch.Size([83])\n",
            "layer2.1.conv1.weight torch.Size([103, 83, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([103])\n",
            "layer2.1.bn1.bias torch.Size([103])\n",
            "layer2.1.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([83])\n",
            "layer2.1.bn2.bias torch.Size([83])\n",
            "layer3.0.conv1.weight torch.Size([205, 83, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([205])\n",
            "layer3.0.bn1.bias torch.Size([205])\n",
            "layer3.0.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([164])\n",
            "layer3.0.bn2.bias torch.Size([164])\n",
            "layer3.0.shortcut.0.weight torch.Size([164, 83, 1, 1])\n",
            "layer3.0.shortcut.1.weight torch.Size([164])\n",
            "layer3.0.shortcut.1.bias torch.Size([164])\n",
            "layer3.1.conv1.weight torch.Size([205, 164, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([205])\n",
            "layer3.1.bn1.bias torch.Size([205])\n",
            "layer3.1.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([164])\n",
            "layer3.1.bn2.bias torch.Size([164])\n",
            "layer4.0.conv1.weight torch.Size([359, 164, 3, 3])\n",
            "layer4.0.bn1.weight torch.Size([359])\n",
            "layer4.0.bn1.bias torch.Size([359])\n",
            "layer4.0.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([252])\n",
            "layer4.0.bn2.bias torch.Size([252])\n",
            "layer4.0.shortcut.0.weight torch.Size([252, 164, 1, 1])\n",
            "layer4.0.shortcut.1.weight torch.Size([252])\n",
            "layer4.0.shortcut.1.bias torch.Size([252])\n",
            "layer4.1.conv1.weight torch.Size([359, 252, 3, 3])\n",
            "layer4.1.bn1.weight torch.Size([359])\n",
            "layer4.1.bn1.bias torch.Size([359])\n",
            "layer4.1.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([252])\n",
            "layer4.1.bn2.bias torch.Size([252])\n",
            "linear.weight torch.Size([10, 252])\n",
            "linear.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "def print_model_layers(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "print_model_layers(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3kWtBzVWg3Y"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "lr = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                       momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "lr = 0.0008781984559717051\n",
        "\n",
        "momentum = 0.26582732909111395\n",
        "\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=lr,\n",
        "                       momentum = momentum)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "\n",
        "# # test \n",
        "\n",
        "# optimizer = optim.RMSprop(net.parameters(), lr=0.001988661747922797,\n",
        "#                        momentum=0.6758665503145822)\n",
        "# # test\n",
        "\n",
        "# writing data to TensorBoard\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid, 0)\n",
        "writer.add_graph(net, images)\n",
        "writer.close()\n",
        "\n",
        "# --------------------------------------- # \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "save_loss = {'train':[], 'test':[]}\n",
        "save_acc = {'train':[], 'test':[]}\n",
        "\n",
        "train_acc_array, train_loss_array = [], [] # for plotting\n",
        "val_acc_array, val_loss_array = [], [] # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIzJObnOWz2d"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch, model=net, train_loader=trainloader):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_acc = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_acc=100.*correct/total\n",
        "        progress_bar(batch_idx, len(train_loader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    train_acc_array.append(train_acc) # for plottting\n",
        "    train_loss_array.append(train_loss) # for plottting\n",
        "    writer.add_scalar('training loss', train_loss)\n",
        "    writer.add_scalar('training accuracy', train_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CHlPBF6uIhT"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch, model=net, validation_loader=val_loader): # validation\n",
        "   \n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(validation_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(validation_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
        "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    valid_acc = 100.*correct/total\n",
        "    if valid_acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net_state_dict': model.state_dict(),\n",
        "            'acc': valid_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = valid_acc\n",
        "    val_acc_array.append(valid_acc) # for plottting\n",
        "    val_loss_array.append(valid_loss) # for plottting\n",
        "    writer.add_scalar('validation loss', valid_loss)\n",
        "    writer.add_scalar('validation accuracy', valid_acc)\n",
        "    return valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5i2dqetBgXp"
      },
      "outputs": [],
      "source": [
        "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
        "def test(model=net):\n",
        "   \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_acc = checkpoint['acc']\n",
        "    model.eval()\n",
        "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyuhb-GrXzUo",
        "outputId": "9854b62d-39a7-41ef-9665-94bf96d39a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HcWh5aXzUq",
        "outputId": "784216fd-bad3-4fec-e328-439915c4a414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcMkrBzW7o7",
        "outputId": "27f61c7a-0bae-496a-a9b7-9637e1f1346d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 50ms | Tot: 28s665ms | Train Loss: 1.111 | Train Acc: 60.824% (27371/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 1.031 | Valid Acc: 63.080% (3154/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 48ms | Tot: 28s759ms | Train Loss: 0.947 | Train Acc: 66.471% (29912/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s22ms | Valid Loss: 1.005 | Valid Acc: 63.840% (3192/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.857 | Train Acc: 70.096% (31543/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.932 | Valid Acc: 67.060% (3353/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 50ms | Tot: 28s522ms | Train Loss: 0.774 | Train Acc: 72.878% (32795/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s14ms | Valid Loss: 0.810 | Valid Acc: 71.040% (3552/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 48ms | Tot: 28s418ms | Train Loss: 0.717 | Train Acc: 74.871% (33692/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s182ms | Valid Loss: 0.743 | Valid Acc: 74.080% (3704/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 51ms | Tot: 28s571ms | Train Loss: 0.674 | Train Acc: 76.378% (34370/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 0.792 | Valid Acc: 73.040% (3652/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.633 | Train Acc: 78.022% (35110/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s974ms | Valid Loss: 0.804 | Valid Acc: 72.920% (3646/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 49ms | Tot: 28s574ms | Train Loss: 0.600 | Train Acc: 79.091% (35591/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s28ms | Valid Loss: 0.687 | Valid Acc: 75.840% (3792/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 52ms | Tot: 28s506ms | Train Loss: 0.580 | Train Acc: 80.016% (36007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s9ms | Valid Loss: 0.685 | Valid Acc: 76.740% (3837/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.545 | Train Acc: 81.111% (36500/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s54ms | Valid Loss: 0.637 | Valid Acc: 78.360% (3918/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 50ms | Tot: 28s456ms | Train Loss: 0.521 | Train Acc: 81.704% (36767/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.684 | Valid Acc: 76.480% (3824/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 49ms | Tot: 28s505ms | Train Loss: 0.499 | Train Acc: 82.687% (37209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.602 | Valid Acc: 78.900% (3945/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 50ms | Tot: 28s536ms | Train Loss: 0.482 | Train Acc: 83.049% (37372/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.584 | Valid Acc: 79.780% (3989/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 49ms | Tot: 28s491ms | Train Loss: 0.471 | Train Acc: 83.607% (37623/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.609 | Valid Acc: 79.140% (3957/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 48ms | Tot: 28s447ms | Train Loss: 0.450 | Train Acc: 84.411% (37985/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s5ms | Valid Loss: 0.613 | Valid Acc: 78.460% (3923/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.435 | Train Acc: 84.836% (38176/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s38ms | Valid Loss: 0.577 | Valid Acc: 80.200% (4010/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 50ms | Tot: 28s473ms | Train Loss: 0.423 | Train Acc: 85.196% (38338/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s991ms | Valid Loss: 0.536 | Valid Acc: 81.340% (4067/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 50ms | Tot: 28s765ms | Train Loss: 0.408 | Train Acc: 85.740% (38583/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s4ms | Valid Loss: 0.539 | Valid Acc: 81.700% (4085/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 49ms | Tot: 28s482ms | Train Loss: 0.406 | Train Acc: 85.764% (38594/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s10ms | Valid Loss: 0.537 | Valid Acc: 81.480% (4074/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 52ms | Tot: 28s565ms | Train Loss: 0.388 | Train Acc: 86.364% (38864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.556 | Valid Acc: 81.540% (4077/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 20\n",
            " [======>]  Step: 50ms | Tot: 28s479ms | Train Loss: 0.372 | Train Acc: 86.860% (39087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.525 | Valid Acc: 82.720% (4136/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [======>]  Step: 53ms | Tot: 28s451ms | Train Loss: 0.366 | Train Acc: 87.129% (39208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s363ms | Valid Loss: 0.519 | Valid Acc: 82.360% (4118/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 22\n",
            " [======>]  Step: 51ms | Tot: 28s453ms | Train Loss: 0.359 | Train Acc: 87.496% (39373/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 13ms | Tot: 2s76ms | Valid Loss: 0.508 | Valid Acc: 82.600% (4130/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 23\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.353 | Train Acc: 87.642% (39439/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s989ms | Valid Loss: 0.530 | Valid Acc: 82.180% (4109/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 24\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.344 | Train Acc: 87.833% (39525/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s44ms | Valid Loss: 0.534 | Valid Acc: 81.860% (4093/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 25\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.340 | Train Acc: 88.120% (39654/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s981ms | Valid Loss: 0.537 | Valid Acc: 82.220% (4111/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 26\n",
            " [======>]  Step: 50ms | Tot: 28s569ms | Train Loss: 0.331 | Train Acc: 88.502% (39826/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.503 | Valid Acc: 82.940% (4147/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.319 | Train Acc: 88.809% (39964/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s972ms | Valid Loss: 0.488 | Valid Acc: 83.240% (4162/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 28\n",
            " [======>]  Step: 51ms | Tot: 28s526ms | Train Loss: 0.312 | Train Acc: 89.100% (40095/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s952ms | Valid Loss: 0.481 | Valid Acc: 84.220% (4211/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 29\n",
            " [======>]  Step: 50ms | Tot: 28s527ms | Train Loss: 0.307 | Train Acc: 89.258% (40166/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.486 | Valid Acc: 84.440% (4222/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            " [======>]  Step: 51ms | Tot: 28s444ms | Train Loss: 0.302 | Train Acc: 89.658% (40346/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s970ms | Valid Loss: 0.480 | Valid Acc: 83.540% (4177/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 31\n",
            " [======>]  Step: 51ms | Tot: 28s530ms | Train Loss: 0.295 | Train Acc: 89.702% (40366/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s969ms | Valid Loss: 0.460 | Valid Acc: 84.760% (4238/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 32\n",
            " [======>]  Step: 52ms | Tot: 28s478ms | Train Loss: 0.292 | Train Acc: 89.962% (40483/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s989ms | Valid Loss: 0.464 | Valid Acc: 85.220% (4261/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 33\n",
            " [======>]  Step: 51ms | Tot: 28s456ms | Train Loss: 0.283 | Train Acc: 90.127% (40557/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s996ms | Valid Loss: 0.467 | Valid Acc: 84.860% (4243/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 34\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.282 | Train Acc: 90.104% (40547/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s932ms | Valid Loss: 0.521 | Valid Acc: 84.020% (4201/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 35\n",
            " [======>]  Step: 52ms | Tot: 28s466ms | Train Loss: 0.276 | Train Acc: 90.360% (40662/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s24ms | Valid Loss: 0.493 | Valid Acc: 84.380% (4219/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 36\n",
            " [======>]  Step: 48ms | Tot: 28s541ms | Train Loss: 0.272 | Train Acc: 90.544% (40745/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s995ms | Valid Loss: 0.472 | Valid Acc: 84.360% (4218/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 37\n",
            " [======>]  Step: 52ms | Tot: 28s482ms | Train Loss: 0.263 | Train Acc: 90.896% (40903/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s972ms | Valid Loss: 0.469 | Valid Acc: 84.660% (4233/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 38\n",
            " [======>]  Step: 49ms | Tot: 28s391ms | Train Loss: 0.264 | Train Acc: 90.831% (40874/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s263ms | Valid Loss: 0.480 | Valid Acc: 84.480% (4224/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 39\n",
            " [======>]  Step: 50ms | Tot: 28s508ms | Train Loss: 0.259 | Train Acc: 90.858% (40886/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s962ms | Valid Loss: 0.476 | Valid Acc: 85.020% (4251/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 40\n",
            " [======>]  Step: 52ms | Tot: 28s546ms | Train Loss: 0.256 | Train Acc: 91.071% (40982/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s935ms | Valid Loss: 0.477 | Valid Acc: 84.580% (4229/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 41\n",
            " [======>]  Step: 51ms | Tot: 28s573ms | Train Loss: 0.245 | Train Acc: 91.404% (41132/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s963ms | Valid Loss: 0.447 | Valid Acc: 86.200% (4310/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.248 | Train Acc: 91.451% (41153/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s999ms | Valid Loss: 0.500 | Valid Acc: 85.340% (4267/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 43\n",
            " [======>]  Step: 54ms | Tot: 28s511ms | Train Loss: 0.245 | Train Acc: 91.331% (41099/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s295ms | Valid Loss: 0.477 | Valid Acc: 85.320% (4266/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 44\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.241 | Train Acc: 91.576% (41209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s924ms | Valid Loss: 0.435 | Valid Acc: 85.440% (4272/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 45\n",
            " [======>]  Step: 50ms | Tot: 28s476ms | Train Loss: 0.235 | Train Acc: 91.836% (41326/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.475 | Valid Acc: 85.660% (4283/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 46\n",
            " [======>]  Step: 52ms | Tot: 28s576ms | Train Loss: 0.230 | Train Acc: 92.040% (41418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s971ms | Valid Loss: 0.439 | Valid Acc: 86.300% (4315/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 47\n",
            " [======>]  Step: 51ms | Tot: 28s477ms | Train Loss: 0.223 | Train Acc: 92.176% (41479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s960ms | Valid Loss: 0.453 | Valid Acc: 85.500% (4275/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 48\n",
            " [======>]  Step: 50ms | Tot: 28s576ms | Train Loss: 0.223 | Train Acc: 92.371% (41567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.432 | Valid Acc: 86.480% (4324/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            " [======>]  Step: 49ms | Tot: 28s480ms | Train Loss: 0.218 | Train Acc: 92.413% (41586/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s15ms | Valid Loss: 0.444 | Valid Acc: 86.060% (4303/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 50\n",
            " [======>]  Step: 51ms | Tot: 28s466ms | Train Loss: 0.217 | Train Acc: 92.320% (41544/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s973ms | Valid Loss: 0.451 | Valid Acc: 85.840% (4292/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 51\n",
            " [======>]  Step: 51ms | Tot: 28s525ms | Train Loss: 0.212 | Train Acc: 92.591% (41666/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s161ms | Valid Loss: 0.444 | Valid Acc: 86.180% (4309/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 52\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.215 | Train Acc: 92.513% (41631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.466 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 53\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.204 | Train Acc: 92.889% (41800/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.473 | Valid Acc: 86.520% (4326/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            " [======>]  Step: 52ms | Tot: 28s525ms | Train Loss: 0.207 | Train Acc: 92.693% (41712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.460 | Valid Acc: 85.900% (4295/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 55\n",
            " [======>]  Step: 50ms | Tot: 28s462ms | Train Loss: 0.206 | Train Acc: 92.784% (41753/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s51ms | Valid Loss: 0.455 | Valid Acc: 85.980% (4299/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 56\n",
            " [======>]  Step: 51ms | Tot: 28s540ms | Train Loss: 0.195 | Train Acc: 93.007% (41853/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s31ms | Valid Loss: 0.482 | Valid Acc: 85.420% (4271/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 57\n",
            " [======>]  Step: 51ms | Tot: 28s457ms | Train Loss: 0.196 | Train Acc: 93.393% (42027/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s998ms | Valid Loss: 0.470 | Valid Acc: 86.680% (4334/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 58\n",
            " [======>]  Step: 50ms | Tot: 28s578ms | Train Loss: 0.194 | Train Acc: 93.309% (41989/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s952ms | Valid Loss: 0.468 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 59\n",
            " [======>]  Step: 50ms | Tot: 28s689ms | Train Loss: 0.193 | Train Acc: 93.324% (41996/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s999ms | Valid Loss: 0.473 | Valid Acc: 86.900% (4345/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 60\n",
            " [======>]  Step: 49ms | Tot: 28s470ms | Train Loss: 0.190 | Train Acc: 93.351% (42008/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s85ms | Valid Loss: 0.452 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 61\n",
            " [======>]  Step: 51ms | Tot: 28s524ms | Train Loss: 0.190 | Train Acc: 93.542% (42094/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s17ms | Valid Loss: 0.409 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 62\n",
            " [======>]  Step: 48ms | Tot: 28s463ms | Train Loss: 0.184 | Train Acc: 93.631% (42134/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s993ms | Valid Loss: 0.414 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 63\n",
            " [======>]  Step: 51ms | Tot: 28s744ms | Train Loss: 0.184 | Train Acc: 93.653% (42144/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s961ms | Valid Loss: 0.408 | Valid Acc: 87.560% (4378/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 64\n",
            " [======>]  Step: 52ms | Tot: 28s463ms | Train Loss: 0.180 | Train Acc: 93.756% (42190/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s928ms | Valid Loss: 0.413 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 65\n",
            " [======>]  Step: 51ms | Tot: 28s594ms | Train Loss: 0.180 | Train Acc: 93.851% (42233/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s240ms | Valid Loss: 0.434 | Valid Acc: 86.660% (4333/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 66\n",
            " [======>]  Step: 52ms | Tot: 28s465ms | Train Loss: 0.176 | Train Acc: 93.924% (42266/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s987ms | Valid Loss: 0.411 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 67\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.177 | Train Acc: 93.918% (42263/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s32ms | Valid Loss: 0.417 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 68\n",
            " [======>]  Step: 51ms | Tot: 28s577ms | Train Loss: 0.172 | Train Acc: 93.971% (42287/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.466 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 69\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.175 | Train Acc: 93.867% (42240/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s977ms | Valid Loss: 0.454 | Valid Acc: 86.980% (4349/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 70\n",
            " [======>]  Step: 51ms | Tot: 28s523ms | Train Loss: 0.166 | Train Acc: 94.107% (42348/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s963ms | Valid Loss: 0.437 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [======>]  Step: 51ms | Tot: 28s474ms | Train Loss: 0.167 | Train Acc: 94.164% (42374/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s992ms | Valid Loss: 0.444 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 72\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.163 | Train Acc: 94.398% (42479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s973ms | Valid Loss: 0.426 | Valid Acc: 87.620% (4381/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 73\n",
            " [======>]  Step: 52ms | Tot: 28s561ms | Train Loss: 0.163 | Train Acc: 94.242% (42409/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.434 | Valid Acc: 87.700% (4385/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 74\n",
            " [======>]  Step: 51ms | Tot: 28s568ms | Train Loss: 0.161 | Train Acc: 94.502% (42526/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s995ms | Valid Loss: 0.448 | Valid Acc: 86.860% (4343/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 75\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.163 | Train Acc: 94.367% (42465/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s958ms | Valid Loss: 0.430 | Valid Acc: 87.540% (4377/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 76\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.159 | Train Acc: 94.596% (42568/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s51ms | Valid Loss: 0.408 | Valid Acc: 87.660% (4383/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 77\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.155 | Train Acc: 94.616% (42577/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.429 | Valid Acc: 87.260% (4363/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 78\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.154 | Train Acc: 94.591% (42566/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s56ms | Valid Loss: 0.426 | Valid Acc: 87.300% (4365/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 79\n",
            " [======>]  Step: 51ms | Tot: 28s447ms | Train Loss: 0.158 | Train Acc: 94.369% (42466/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s21ms | Valid Loss: 0.455 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 80\n",
            " [======>]  Step: 50ms | Tot: 28s534ms | Train Loss: 0.154 | Train Acc: 94.553% (42549/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s987ms | Valid Loss: 0.434 | Valid Acc: 88.500% (4425/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 81\n",
            " [======>]  Step: 52ms | Tot: 28s490ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s944ms | Valid Loss: 0.445 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 82\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s963ms | Valid Loss: 0.416 | Valid Acc: 88.160% (4408/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 83\n",
            " [======>]  Step: 49ms | Tot: 28s553ms | Train Loss: 0.146 | Train Acc: 94.922% (42715/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s960ms | Valid Loss: 0.417 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 84\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.146 | Train Acc: 95.029% (42763/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s966ms | Valid Loss: 0.473 | Valid Acc: 87.600% (4380/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 85\n",
            " [======>]  Step: 51ms | Tot: 28s555ms | Train Loss: 0.144 | Train Acc: 94.998% (42749/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s973ms | Valid Loss: 0.431 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 86\n",
            " [======>]  Step: 50ms | Tot: 28s554ms | Train Loss: 0.145 | Train Acc: 94.984% (42743/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s937ms | Valid Loss: 0.441 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 87\n",
            " [======>]  Step: 49ms | Tot: 28s520ms | Train Loss: 0.140 | Train Acc: 95.062% (42778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s54ms | Valid Loss: 0.406 | Valid Acc: 88.560% (4428/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 88\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.138 | Train Acc: 95.376% (42919/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s55ms | Valid Loss: 0.432 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 89\n",
            " [======>]  Step: 52ms | Tot: 28s505ms | Train Loss: 0.140 | Train Acc: 95.207% (42843/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s988ms | Valid Loss: 0.447 | Valid Acc: 87.680% (4384/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 90\n",
            " [======>]  Step: 52ms | Tot: 28s566ms | Train Loss: 0.136 | Train Acc: 95.249% (42862/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s931ms | Valid Loss: 0.408 | Valid Acc: 88.440% (4422/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 91\n",
            " [======>]  Step: 51ms | Tot: 28s499ms | Train Loss: 0.140 | Train Acc: 95.231% (42854/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s971ms | Valid Loss: 0.399 | Valid Acc: 88.480% (4424/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 92\n",
            " [======>]  Step: 51ms | Tot: 28s529ms | Train Loss: 0.137 | Train Acc: 95.244% (42860/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s120ms | Valid Loss: 0.416 | Valid Acc: 88.040% (4402/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 93\n",
            " [======>]  Step: 49ms | Tot: 28s555ms | Train Loss: 0.134 | Train Acc: 95.398% (42929/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s943ms | Valid Loss: 0.413 | Valid Acc: 88.580% (4429/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.132 | Train Acc: 95.362% (42913/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s992ms | Valid Loss: 0.457 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 95\n",
            " [======>]  Step: 51ms | Tot: 28s572ms | Train Loss: 0.131 | Train Acc: 95.518% (42983/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s968ms | Valid Loss: 0.434 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 96\n",
            " [======>]  Step: 52ms | Tot: 28s559ms | Train Loss: 0.132 | Train Acc: 95.422% (42940/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.431 | Valid Acc: 88.320% (4416/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 97\n",
            " [======>]  Step: 50ms | Tot: 28s503ms | Train Loss: 0.134 | Train Acc: 95.409% (42934/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s173ms | Valid Loss: 0.400 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 98\n",
            " [======>]  Step: 49ms | Tot: 28s578ms | Train Loss: 0.130 | Train Acc: 95.571% (43007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s8ms | Valid Loss: 0.419 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 99\n",
            " [======>]  Step: 51ms | Tot: 28s502ms | Train Loss: 0.131 | Train Acc: 95.609% (43024/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s968ms | Valid Loss: 0.382 | Valid Acc: 88.300% (4415/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 100\n",
            " [======>]  Step: 50ms | Tot: 28s563ms | Train Loss: 0.127 | Train Acc: 95.644% (43040/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 0.427 | Valid Acc: 88.140% (4407/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 101\n",
            " [======>]  Step: 51ms | Tot: 28s486ms | Train Loss: 0.126 | Train Acc: 95.702% (43066/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s968ms | Valid Loss: 0.399 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [======>]  Step: 52ms | Tot: 28s589ms | Train Loss: 0.123 | Train Acc: 95.749% (43087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.426 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 103\n",
            " [======>]  Step: 53ms | Tot: 28s495ms | Train Loss: 0.123 | Train Acc: 95.769% (43096/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s7ms | Valid Loss: 0.429 | Valid Acc: 88.680% (4434/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 104\n",
            " [======>]  Step: 49ms | Tot: 28s538ms | Train Loss: 0.123 | Train Acc: 95.753% (43089/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.418 | Valid Acc: 88.620% (4431/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 105\n",
            " [======>]  Step: 48ms | Tot: 28s571ms | Train Loss: 0.120 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s980ms | Valid Loss: 0.381 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 106\n",
            " [======>]  Step: 50ms | Tot: 28s472ms | Train Loss: 0.121 | Train Acc: 95.733% (43080/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.438 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 107\n",
            " [======>]  Step: 47ms | Tot: 28s553ms | Train Loss: 0.118 | Train Acc: 95.993% (43197/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s960ms | Valid Loss: 0.389 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 108\n",
            " [======>]  Step: 50ms | Tot: 28s483ms | Train Loss: 0.118 | Train Acc: 95.929% (43168/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.413 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 109\n",
            " [======>]  Step: 49ms | Tot: 28s519ms | Train Loss: 0.116 | Train Acc: 95.982% (43192/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s78ms | Valid Loss: 0.403 | Valid Acc: 89.220% (4461/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [======>]  Step: 48ms | Tot: 28s528ms | Train Loss: 0.117 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.434 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 111\n",
            " [======>]  Step: 52ms | Tot: 28s518ms | Train Loss: 0.114 | Train Acc: 96.084% (43238/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.415 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 112\n",
            " [======>]  Step: 52ms | Tot: 28s603ms | Train Loss: 0.112 | Train Acc: 96.204% (43292/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s40ms | Valid Loss: 0.425 | Valid Acc: 88.420% (4421/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 113\n",
            " [======>]  Step: 50ms | Tot: 28s519ms | Train Loss: 0.113 | Train Acc: 96.067% (43230/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s1ms | Valid Loss: 0.374 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.115 | Train Acc: 96.011% (43205/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 6ms | Tot: 1s947ms | Valid Loss: 0.380 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 115\n",
            " [======>]  Step: 48ms | Tot: 28s488ms | Train Loss: 0.115 | Train Acc: 96.018% (43208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s18ms | Valid Loss: 0.390 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 116\n",
            " [======>]  Step: 51ms | Tot: 28s482ms | Train Loss: 0.106 | Train Acc: 96.309% (43339/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s954ms | Valid Loss: 0.436 | Valid Acc: 88.780% (4439/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 117\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.106 | Train Acc: 96.313% (43341/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s924ms | Valid Loss: 0.413 | Valid Acc: 89.080% (4454/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 118\n",
            " [======>]  Step: 51ms | Tot: 28s515ms | Train Loss: 0.108 | Train Acc: 96.276% (43324/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s916ms | Valid Loss: 0.403 | Valid Acc: 89.280% (4464/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 119\n",
            " [======>]  Step: 52ms | Tot: 28s535ms | Train Loss: 0.105 | Train Acc: 96.344% (43355/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s941ms | Valid Loss: 0.405 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 120\n",
            " [======>]  Step: 53ms | Tot: 28s484ms | Train Loss: 0.108 | Train Acc: 96.233% (43305/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s964ms | Valid Loss: 0.401 | Valid Acc: 89.320% (4466/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 121\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.111 | Train Acc: 96.249% (43312/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s315ms | Valid Loss: 0.391 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 122\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.106 | Train Acc: 96.304% (43337/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s4ms | Valid Loss: 0.437 | Valid Acc: 89.000% (4450/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 123\n",
            " [======>]  Step: 49ms | Tot: 28s593ms | Train Loss: 0.105 | Train Acc: 96.351% (43358/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.400 | Valid Acc: 89.200% (4460/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 124\n",
            " [======>]  Step: 50ms | Tot: 28s593ms | Train Loss: 0.101 | Train Acc: 96.422% (43390/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s984ms | Valid Loss: 0.418 | Valid Acc: 88.860% (4443/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 125\n",
            " [======>]  Step: 51ms | Tot: 28s681ms | Train Loss: 0.099 | Train Acc: 96.484% (43418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s57ms | Valid Loss: 0.401 | Valid Acc: 89.260% (4463/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 126\n",
            " [======>]  Step: 51ms | Tot: 28s538ms | Train Loss: 0.097 | Train Acc: 96.684% (43508/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s6ms | Valid Loss: 0.387 | Valid Acc: 89.480% (4474/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 127\n",
            " [======>]  Step: 50ms | Tot: 28s532ms | Train Loss: 0.101 | Train Acc: 96.467% (43410/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s979ms | Valid Loss: 0.420 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 128\n",
            " [======>]  Step: 51ms | Tot: 28s492ms | Train Loss: 0.102 | Train Acc: 96.411% (43385/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s984ms | Valid Loss: 0.397 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 129\n",
            " [======>]  Step: 51ms | Tot: 28s463ms | Train Loss: 0.095 | Train Acc: 96.707% (43518/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s968ms | Valid Loss: 0.415 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 130\n",
            " [======>]  Step: 49ms | Tot: 28s533ms | Train Loss: 0.100 | Train Acc: 96.516% (43432/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s962ms | Valid Loss: 0.400 | Valid Acc: 89.440% (4472/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 131\n",
            " [======>]  Step: 47ms | Tot: 28s492ms | Train Loss: 0.099 | Train Acc: 96.509% (43429/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s931ms | Valid Loss: 0.394 | Valid Acc: 89.720% (4486/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 132\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.094 | Train Acc: 96.807% (43563/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s530ms | Valid Loss: 0.392 | Valid Acc: 89.560% (4478/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 133\n",
            " [======>]  Step: 52ms | Tot: 28s461ms | Train Loss: 0.099 | Train Acc: 96.627% (43482/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s949ms | Valid Loss: 0.390 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [======>]  Step: 52ms | Tot: 28s521ms | Train Loss: 0.092 | Train Acc: 96.756% (43540/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s967ms | Valid Loss: 0.432 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 135\n",
            " [======>]  Step: 49ms | Tot: 28s511ms | Train Loss: 0.094 | Train Acc: 96.736% (43531/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.398 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 136\n",
            " [======>]  Step: 50ms | Tot: 28s524ms | Train Loss: 0.088 | Train Acc: 96.947% (43626/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s960ms | Valid Loss: 0.410 | Valid Acc: 89.700% (4485/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 137\n",
            " [======>]  Step: 51ms | Tot: 28s489ms | Train Loss: 0.094 | Train Acc: 96.784% (43553/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s897ms | Valid Loss: 0.403 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 138\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.094 | Train Acc: 96.816% (43567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s213ms | Valid Loss: 0.386 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 139\n",
            " [======>]  Step: 51ms | Tot: 28s478ms | Train Loss: 0.091 | Train Acc: 96.878% (43595/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s929ms | Valid Loss: 0.411 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 140\n",
            " [======>]  Step: 50ms | Tot: 28s489ms | Train Loss: 0.088 | Train Acc: 96.958% (43631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.389 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 141\n",
            " [======>]  Step: 48ms | Tot: 28s538ms | Train Loss: 0.091 | Train Acc: 96.767% (43545/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s928ms | Valid Loss: 0.397 | Valid Acc: 89.360% (4468/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 142\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.091 | Train Acc: 96.822% (43570/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s11ms | Valid Loss: 0.389 | Valid Acc: 89.960% (4498/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 143\n",
            " [======>]  Step: 51ms | Tot: 28s467ms | Train Loss: 0.090 | Train Acc: 96.927% (43617/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.388 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 144\n",
            " [======>]  Step: 49ms | Tot: 28s689ms | Train Loss: 0.087 | Train Acc: 96.962% (43633/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s936ms | Valid Loss: 0.375 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 145\n",
            " [======>]  Step: 50ms | Tot: 28s637ms | Train Loss: 0.091 | Train Acc: 96.916% (43612/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s939ms | Valid Loss: 0.391 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 146\n",
            " [======>]  Step: 49ms | Tot: 28s666ms | Train Loss: 0.089 | Train Acc: 96.933% (43620/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.398 | Valid Acc: 89.660% (4483/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 147\n",
            " [======>]  Step: 49ms | Tot: 28s587ms | Train Loss: 0.089 | Train Acc: 96.856% (43585/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s27ms | Valid Loss: 0.382 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 148\n",
            " [======>]  Step: 49ms | Tot: 28s623ms | Train Loss: 0.086 | Train Acc: 96.978% (43640/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s940ms | Valid Loss: 0.409 | Valid Acc: 89.500% (4475/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 149\n",
            " [======>]  Step: 50ms | Tot: 28s595ms | Train Loss: 0.086 | Train Acc: 97.042% (43669/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s908ms | Valid Loss: 0.367 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 150\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.088 | Train Acc: 96.944% (43625/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.403 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 151\n",
            " [======>]  Step: 49ms | Tot: 28s462ms | Train Loss: 0.084 | Train Acc: 97.120% (43704/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s935ms | Valid Loss: 0.411 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 152\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.088 | Train Acc: 96.989% (43645/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.379 | Valid Acc: 90.100% (4505/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 153\n",
            " [======>]  Step: 50ms | Tot: 28s481ms | Train Loss: 0.083 | Train Acc: 97.064% (43679/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.397 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 154\n",
            " [======>]  Step: 51ms | Tot: 28s501ms | Train Loss: 0.085 | Train Acc: 97.098% (43694/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.406 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 155\n",
            " [======>]  Step: 50ms | Tot: 28s512ms | Train Loss: 0.082 | Train Acc: 97.180% (43731/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s937ms | Valid Loss: 0.414 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 156\n",
            " [======>]  Step: 49ms | Tot: 28s490ms | Train Loss: 0.085 | Train Acc: 97.007% (43653/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s948ms | Valid Loss: 0.368 | Valid Acc: 90.440% (4522/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 157\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.085 | Train Acc: 97.051% (43673/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.394 | Valid Acc: 90.220% (4511/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 158\n",
            " [======>]  Step: 47ms | Tot: 28s500ms | Train Loss: 0.083 | Train Acc: 97.082% (43687/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s922ms | Valid Loss: 0.411 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 159\n",
            " [======>]  Step: 50ms | Tot: 28s535ms | Train Loss: 0.083 | Train Acc: 97.138% (43712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s988ms | Valid Loss: 0.416 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 160\n",
            " [======>]  Step: 51ms | Tot: 28s552ms | Train Loss: 0.085 | Train Acc: 97.118% (43703/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s911ms | Valid Loss: 0.421 | Valid Acc: 90.080% (4504/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 161\n",
            " [======>]  Step: 49ms | Tot: 28s492ms | Train Loss: 0.081 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s912ms | Valid Loss: 0.379 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 162\n",
            " [======>]  Step: 51ms | Tot: 28s553ms | Train Loss: 0.083 | Train Acc: 97.076% (43684/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.375 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 163\n",
            " [======>]  Step: 49ms | Tot: 28s501ms | Train Loss: 0.079 | Train Acc: 97.129% (43708/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.380 | Valid Acc: 90.380% (4519/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 164\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.079 | Train Acc: 97.327% (43797/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s929ms | Valid Loss: 0.392 | Valid Acc: 89.880% (4494/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 165\n",
            " [======>]  Step: 50ms | Tot: 28s506ms | Train Loss: 0.082 | Train Acc: 97.216% (43747/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s932ms | Valid Loss: 0.373 | Valid Acc: 90.560% (4528/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 166\n",
            " [======>]  Step: 51ms | Tot: 28s534ms | Train Loss: 0.082 | Train Acc: 97.080% (43686/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s957ms | Valid Loss: 0.419 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 167\n",
            " [======>]  Step: 49ms | Tot: 28s507ms | Train Loss: 0.078 | Train Acc: 97.289% (43780/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s997ms | Valid Loss: 0.385 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.078 | Train Acc: 97.280% (43776/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s912ms | Valid Loss: 0.386 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 169\n",
            " [======>]  Step: 51ms | Tot: 28s556ms | Train Loss: 0.080 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s938ms | Valid Loss: 0.371 | Valid Acc: 90.360% (4518/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 170\n",
            " [======>]  Step: 52ms | Tot: 28s723ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s985ms | Valid Loss: 0.364 | Valid Acc: 90.700% (4535/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 171\n",
            " [======>]  Step: 49ms | Tot: 28s748ms | Train Loss: 0.080 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.392 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 172\n",
            " [======>]  Step: 52ms | Tot: 28s792ms | Train Loss: 0.079 | Train Acc: 97.307% (43788/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s999ms | Valid Loss: 0.366 | Valid Acc: 90.540% (4527/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 173\n",
            " [======>]  Step: 49ms | Tot: 28s701ms | Train Loss: 0.078 | Train Acc: 97.200% (43740/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s4ms | Valid Loss: 0.389 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 174\n",
            " [======>]  Step: 51ms | Tot: 28s685ms | Train Loss: 0.080 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.369 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 175\n",
            " [======>]  Step: 52ms | Tot: 28s693ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 0.404 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 176\n",
            " [======>]  Step: 52ms | Tot: 28s797ms | Train Loss: 0.076 | Train Acc: 97.398% (43829/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s950ms | Valid Loss: 0.367 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 177\n",
            " [======>]  Step: 51ms | Tot: 28s666ms | Train Loss: 0.077 | Train Acc: 97.367% (43815/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s11ms | Valid Loss: 0.380 | Valid Acc: 90.520% (4526/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 178\n",
            " [======>]  Step: 50ms | Tot: 28s650ms | Train Loss: 0.076 | Train Acc: 97.351% (43808/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s39ms | Valid Loss: 0.374 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 179\n",
            " [======>]  Step: 52ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s27ms | Valid Loss: 0.389 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 180\n",
            " [======>]  Step: 51ms | Tot: 28s595ms | Train Loss: 0.078 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s29ms | Valid Loss: 0.407 | Valid Acc: 90.760% (4538/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 181\n",
            " [======>]  Step: 53ms | Tot: 28s799ms | Train Loss: 0.075 | Train Acc: 97.378% (43820/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.391 | Valid Acc: 90.340% (4517/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 182\n",
            " [======>]  Step: 51ms | Tot: 28s714ms | Train Loss: 0.074 | Train Acc: 97.364% (43814/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s3ms | Valid Loss: 0.353 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 183\n",
            " [======>]  Step: 48ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.406 | Valid Acc: 89.940% (4497/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 184\n",
            " [======>]  Step: 52ms | Tot: 28s714ms | Train Loss: 0.077 | Train Acc: 97.338% (43802/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s63ms | Valid Loss: 0.381 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 185\n",
            " [======>]  Step: 49ms | Tot: 28s678ms | Train Loss: 0.077 | Train Acc: 97.344% (43805/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s940ms | Valid Loss: 0.349 | Valid Acc: 91.180% (4559/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 186\n",
            " [======>]  Step: 50ms | Tot: 28s714ms | Train Loss: 0.076 | Train Acc: 97.416% (43837/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s45ms | Valid Loss: 0.397 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 187\n",
            " [======>]  Step: 52ms | Tot: 28s770ms | Train Loss: 0.079 | Train Acc: 97.271% (43772/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.419 | Valid Acc: 90.120% (4506/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 188\n",
            " [======>]  Step: 50ms | Tot: 28s669ms | Train Loss: 0.079 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s983ms | Valid Loss: 0.356 | Valid Acc: 90.860% (4543/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 189\n",
            " [======>]  Step: 51ms | Tot: 28s679ms | Train Loss: 0.078 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s8ms | Valid Loss: 0.388 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 190\n",
            " [======>]  Step: 52ms | Tot: 28s718ms | Train Loss: 0.074 | Train Acc: 97.353% (43809/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s60ms | Valid Loss: 0.382 | Valid Acc: 90.000% (4500/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 191\n",
            " [======>]  Step: 50ms | Tot: 28s720ms | Train Loss: 0.076 | Train Acc: 97.482% (43867/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s987ms | Valid Loss: 0.358 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 192\n",
            " [======>]  Step: 50ms | Tot: 28s706ms | Train Loss: 0.075 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s974ms | Valid Loss: 0.364 | Valid Acc: 90.600% (4530/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 193\n",
            " [======>]  Step: 47ms | Tot: 28s697ms | Train Loss: 0.079 | Train Acc: 97.287% (43779/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s17ms | Valid Loss: 0.405 | Valid Acc: 89.980% (4499/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 194\n",
            " [======>]  Step: 50ms | Tot: 28s760ms | Train Loss: 0.079 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s35ms | Valid Loss: 0.384 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 195\n",
            " [======>]  Step: 47ms | Tot: 28s685ms | Train Loss: 0.078 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.376 | Valid Acc: 90.320% (4516/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 196\n",
            " [======>]  Step: 51ms | Tot: 28s671ms | Train Loss: 0.077 | Train Acc: 97.273% (43773/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s963ms | Valid Loss: 0.345 | Valid Acc: 91.020% (4551/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 197\n",
            " [======>]  Step: 51ms | Tot: 28s817ms | Train Loss: 0.075 | Train Acc: 97.476% (43864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.370 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 198\n",
            " [======>]  Step: 52ms | Tot: 28s707ms | Train Loss: 0.076 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.363 | Valid Acc: 90.780% (4539/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 199\n",
            " [======>]  Step: 50ms | Tot: 28s719ms | Train Loss: 0.075 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s13ms | Valid Loss: 0.381 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "---------------------------------------- Testing Model... ----------------------------------------\n",
            "Best validation acc: 91.180% at Epoch 185\n",
            " [======>]  Step: 21ms | Tot: 2s360ms | Test Loss: 0.348 | Test Acc: 93.820% (9382/10000)\b\b\b\b 100/100 \n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 200\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9l3iSKXzUs",
        "outputId": "b8c1f4be-717f-434e-9fce-be69987cb5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z_TwWP4Xkca",
        "outputId": "4f984e49-30b1-4465-9d01-eba30dbbdcf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24.788888888888888,\n",
              " 38.593333333333334,\n",
              " 51.28,\n",
              " 10.171830484330485,\n",
              " 10.211894586894587,\n",
              " 10.249732905982906,\n",
              " 10.1696047008547,\n",
              " 10.122863247863247,\n",
              " 10.27199074074074,\n",
              " 10.225249287749287,\n",
              " 10.243055555555555,\n",
              " 10.145121082621083,\n",
              " 10.109508547008547,\n",
              " 9.866071428571429,\n",
              " 10.0,\n",
              " 10.071428571428571,\n",
              " 9.908482142857142,\n",
              " 9.977678571428571,\n",
              " 9.964285714285714,\n",
              " 9.959821428571429,\n",
              " 9.890625,\n",
              " 9.991071428571429,\n",
              " 9.915178571428571,\n",
              " 9.452902421652421,\n",
              " 9.428418803418804,\n",
              " 9.437321937321938,\n",
              " 9.41951566951567,\n",
              " 9.339387464387464,\n",
              " 9.486289173789174,\n",
              " 9.524127492877493,\n",
              " 9.51522435897436,\n",
              " 9.346064814814815,\n",
              " 9.479611823361823,\n",
              " 10.024928774928775,\n",
              " 9.991542022792023,\n",
              " 10.011574074074074,\n",
              " 10.009348290598291,\n",
              " 60.824444444444445,\n",
              " 66.47111111111111,\n",
              " 70.09555555555555,\n",
              " 72.87777777777778,\n",
              " 74.8711111111111,\n",
              " 76.37777777777778,\n",
              " 78.02222222222223,\n",
              " 79.0911111111111,\n",
              " 80.01555555555555,\n",
              " 81.11111111111111,\n",
              " 81.70444444444445,\n",
              " 82.68666666666667,\n",
              " 83.04888888888888,\n",
              " 83.60666666666667,\n",
              " 84.41111111111111,\n",
              " 84.83555555555556,\n",
              " 85.19555555555556,\n",
              " 85.74,\n",
              " 85.76444444444445,\n",
              " 86.36444444444444,\n",
              " 86.86,\n",
              " 87.1288888888889,\n",
              " 87.49555555555555,\n",
              " 87.64222222222222,\n",
              " 87.83333333333333,\n",
              " 88.12,\n",
              " 88.50222222222222,\n",
              " 88.80888888888889,\n",
              " 89.1,\n",
              " 89.25777777777778,\n",
              " 89.65777777777778,\n",
              " 89.70222222222222,\n",
              " 89.96222222222222,\n",
              " 90.12666666666667,\n",
              " 90.10444444444444,\n",
              " 90.36,\n",
              " 90.54444444444445,\n",
              " 90.89555555555556,\n",
              " 90.83111111111111,\n",
              " 90.85777777777778,\n",
              " 91.07111111111111,\n",
              " 91.40444444444445,\n",
              " 91.45111111111112,\n",
              " 91.33111111111111,\n",
              " 91.57555555555555,\n",
              " 91.83555555555556,\n",
              " 92.04,\n",
              " 92.17555555555556,\n",
              " 92.3711111111111,\n",
              " 92.41333333333333,\n",
              " 92.32,\n",
              " 92.5911111111111,\n",
              " 92.51333333333334,\n",
              " 92.88888888888889,\n",
              " 92.69333333333333,\n",
              " 92.78444444444445,\n",
              " 93.00666666666666,\n",
              " 93.39333333333333,\n",
              " 93.30888888888889,\n",
              " 93.32444444444444,\n",
              " 93.35111111111111,\n",
              " 93.54222222222222,\n",
              " 93.63111111111111,\n",
              " 93.65333333333334,\n",
              " 93.75555555555556,\n",
              " 93.85111111111111,\n",
              " 93.92444444444445,\n",
              " 93.91777777777777,\n",
              " 93.97111111111111,\n",
              " 93.86666666666666,\n",
              " 94.10666666666667,\n",
              " 94.16444444444444,\n",
              " 94.39777777777778,\n",
              " 94.24222222222222,\n",
              " 94.50222222222222,\n",
              " 94.36666666666666,\n",
              " 94.59555555555555,\n",
              " 94.61555555555556,\n",
              " 94.5911111111111,\n",
              " 94.36888888888889,\n",
              " 94.55333333333333,\n",
              " 94.77777777777777,\n",
              " 94.77777777777777,\n",
              " 94.92222222222222,\n",
              " 95.02888888888889,\n",
              " 94.99777777777778,\n",
              " 94.98444444444445,\n",
              " 95.06222222222222,\n",
              " 95.37555555555555,\n",
              " 95.20666666666666,\n",
              " 95.24888888888889,\n",
              " 95.2311111111111,\n",
              " 95.24444444444444,\n",
              " 95.39777777777778,\n",
              " 95.36222222222223,\n",
              " 95.51777777777778,\n",
              " 95.42222222222222,\n",
              " 95.4088888888889,\n",
              " 95.57111111111111,\n",
              " 95.60888888888888,\n",
              " 95.64444444444445,\n",
              " 95.70222222222222,\n",
              " 95.74888888888889,\n",
              " 95.7688888888889,\n",
              " 95.75333333333333,\n",
              " 95.89111111111112,\n",
              " 95.73333333333333,\n",
              " 95.99333333333334,\n",
              " 95.92888888888889,\n",
              " 95.98222222222222,\n",
              " 95.89111111111112,\n",
              " 96.08444444444444,\n",
              " 96.20444444444445,\n",
              " 96.06666666666666,\n",
              " 96.0111111111111,\n",
              " 96.01777777777778,\n",
              " 96.30888888888889,\n",
              " 96.31333333333333,\n",
              " 96.27555555555556,\n",
              " 96.34444444444445,\n",
              " 96.23333333333333,\n",
              " 96.24888888888889,\n",
              " 96.30444444444444,\n",
              " 96.35111111111111,\n",
              " 96.42222222222222,\n",
              " 96.48444444444445,\n",
              " 96.68444444444444,\n",
              " 96.46666666666667,\n",
              " 96.41111111111111,\n",
              " 96.70666666666666,\n",
              " 96.51555555555555,\n",
              " 96.50888888888889,\n",
              " 96.80666666666667,\n",
              " 96.62666666666667,\n",
              " 96.75555555555556,\n",
              " 96.73555555555555,\n",
              " 96.94666666666667,\n",
              " 96.78444444444445,\n",
              " 96.81555555555556,\n",
              " 96.87777777777778,\n",
              " 96.95777777777778,\n",
              " 96.76666666666667,\n",
              " 96.82222222222222,\n",
              " 96.92666666666666,\n",
              " 96.96222222222222,\n",
              " 96.91555555555556,\n",
              " 96.93333333333334,\n",
              " 96.85555555555555,\n",
              " 96.97777777777777,\n",
              " 97.04222222222222,\n",
              " 96.94444444444444,\n",
              " 97.12,\n",
              " 96.9888888888889,\n",
              " 97.06444444444445,\n",
              " 97.09777777777778,\n",
              " 97.18,\n",
              " 97.00666666666666,\n",
              " 97.05111111111111,\n",
              " 97.08222222222223,\n",
              " 97.13777777777777,\n",
              " 97.11777777777777,\n",
              " 97.20222222222222,\n",
              " 97.07555555555555,\n",
              " 97.1288888888889,\n",
              " 97.32666666666667,\n",
              " 97.21555555555555,\n",
              " 97.08,\n",
              " 97.28888888888889,\n",
              " 97.28,\n",
              " 97.20222222222222,\n",
              " 97.27777777777777,\n",
              " 97.30444444444444,\n",
              " 97.30666666666667,\n",
              " 97.2,\n",
              " 97.22222222222223,\n",
              " 97.27777777777777,\n",
              " 97.39777777777778,\n",
              " 97.36666666666666,\n",
              " 97.35111111111111,\n",
              " 97.28444444444445,\n",
              " 97.22222222222223,\n",
              " 97.37777777777778,\n",
              " 97.36444444444444,\n",
              " 97.34666666666666,\n",
              " 97.33777777777777,\n",
              " 97.34444444444445,\n",
              " 97.41555555555556,\n",
              " 97.27111111111111,\n",
              " 97.30444444444444,\n",
              " 97.32888888888888,\n",
              " 97.35333333333334,\n",
              " 97.48222222222222,\n",
              " 97.31333333333333,\n",
              " 97.28666666666666,\n",
              " 97.28444444444445,\n",
              " 97.34666666666666,\n",
              " 97.27333333333333,\n",
              " 97.47555555555556,\n",
              " 97.31333333333333,\n",
              " 97.32888888888888]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "JHKohhBDJRIP",
        "outputId": "cd2bb181-e121-4bde-d208-bb7da7c72930"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_loss_array2=[i/10 for i in train_loss_array]\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "ax = plt.axes()\n",
        "plt.subplot(121)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1), train_acc_array[:200])\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),val_acc_array[:200])\n",
        "plt.title(\"Accuracy\", fontsize=60)\n",
        "plt.xlabel(\"Epochs\", fontsize=40)\n",
        "plt.ylabel(\"Percent Accuracy\", fontsize=40)\n",
        "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"lower right\", fontsize=30)\n",
        "plt.xticks(fontsize=25)\n",
        "plt.yticks(fontsize=25)\n",
        "plt.subplot(122)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),train_loss_array2[:200])\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),val_loss_array[:200])\n",
        "plt.title(\"Loss\", fontsize=60)\n",
        "plt.xlabel(\"Epochs\", fontsize=40)\n",
        "plt.ylabel(\"Loss\", fontsize=40)\n",
        "plt.legend(['Train loss', 'Valid loss'], loc=\"upper right\", fontsize=30)\n",
        "plt.xticks(fontsize=25)\n",
        "plt.yticks(fontsize=25)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"pruning_curves.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jHEaEYOfK40"
      },
      "outputs": [],
      "source": [
        "def plot_test_result(num_epochs, train_acc, train_loss, val_acc, val_loss):\n",
        "  fig = plt.figure(figsize=(16,6))\n",
        "  plt.subplot(121)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), train_acc)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), val_acc)\n",
        "  plt.title(\"Accuray\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), train_loss)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), val_loss)\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPyXSy3yD6G"
      },
      "source": [
        "<h2>Automatic Hyperparameter Search using Optuna</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefZAQVvyCgU",
        "outputId": "cf34d1f4-ebec-433f-b4e4-3fbe03a88f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 87.9 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=53e8ee9d3ea3548490fd413eba349d37bd0225e80f7f47138ae9737e34f426ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2MShrCMyLjz"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAKNVr4AyOPa"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # trying different optimizers\n",
        "  optimizer_name_class_1 = trial.suggest_categorical(\"optimizer\", [\"SGD\",\n",
        "                                                                   \"RMSprop\"])\n",
        "\n",
        "  # optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "  #                                                                  \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_1 = getattr(optim, optimizer_name_class_1)(curr_model.parameters(),\n",
        "                                                     lr=lr, momentum=momentum)\n",
        "\n",
        "  # optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 128, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_1, T_max=200)\n",
        "\n",
        "  # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  x\n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 10\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch, model=curr_model, validation_loader=val_loader)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "# numbers in ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F7S4oOdt1Rx4",
        "outputId": "d5d4c4b1-1dc2-4209-ec0b-736e713722ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:43:47,708]\u001b[0m A new study created in memory with name: resNet-18\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 115ms | Tot: 26s948ms | Train Loss: 2.338 | Train Acc: 10.172% (4570/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s939ms | Valid Loss: 2.340 | Valid Acc: 9.580% (479/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 116ms | Tot: 27s956ms | Train Loss: 2.338 | Train Acc: 10.212% (4588/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s910ms | Valid Loss: 2.341 | Valid Acc: 10.080% (504/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 114ms | Tot: 27s741ms | Train Loss: 2.339 | Train Acc: 10.250% (4605/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 2s421ms | Valid Loss: 2.341 | Valid Acc: 9.960% (498/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 115ms | Tot: 28s204ms | Train Loss: 2.340 | Train Acc: 10.170% (4569/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s948ms | Valid Loss: 2.342 | Valid Acc: 9.940% (497/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 116ms | Tot: 27s730ms | Train Loss: 2.339 | Train Acc: 10.123% (4548/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s928ms | Valid Loss: 2.340 | Valid Acc: 9.860% (493/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 115ms | Tot: 27s656ms | Train Loss: 2.340 | Train Acc: 10.272% (4615/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 2s208ms | Valid Loss: 2.342 | Valid Acc: 9.540% (477/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 116ms | Tot: 27s571ms | Train Loss: 2.339 | Train Acc: 10.225% (4594/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s941ms | Valid Loss: 2.344 | Valid Acc: 9.560% (478/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 116ms | Tot: 27s694ms | Train Loss: 2.339 | Train Acc: 10.243% (4602/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s898ms | Valid Loss: 2.343 | Valid Acc: 10.000% (500/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 113ms | Tot: 27s588ms | Train Loss: 2.340 | Train Acc: 10.145% (4558/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s933ms | Valid Loss: 2.340 | Valid Acc: 9.700% (485/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 118ms | Tot: 27s589ms | Train Loss: 2.338 | Train Acc: 10.110% (4542/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s915ms | Valid Loss: 2.342 | Valid Acc: 10.020% (501/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:48:53,651]\u001b[0m Trial 0 finished with value: 10.02 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.2, 'optimizer': 'SGD', 'momentum': 0.6748578199632881, 'lr': 0.061470023158151706, 'batch_size': 192}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 150ms | Tot: 26s767ms | Train Loss: 2.372 | Train Acc: 9.866% (4420/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 338ms | Tot: 2s153ms | Valid Loss: 2.371 | Valid Acc: 9.880% (494/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 152ms | Tot: 26s700ms | Train Loss: 2.372 | Train Acc: 10.000% (4480/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s880ms | Valid Loss: 2.372 | Valid Acc: 10.020% (501/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 150ms | Tot: 26s725ms | Train Loss: 2.371 | Train Acc: 10.071% (4512/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s888ms | Valid Loss: 2.367 | Valid Acc: 9.880% (494/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 154ms | Tot: 26s716ms | Train Loss: 2.371 | Train Acc: 9.908% (4439/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s860ms | Valid Loss: 2.369 | Valid Acc: 9.640% (482/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 148ms | Tot: 26s710ms | Train Loss: 2.371 | Train Acc: 9.978% (4470/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s927ms | Valid Loss: 2.371 | Valid Acc: 10.100% (505/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 150ms | Tot: 26s779ms | Train Loss: 2.372 | Train Acc: 9.964% (4464/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s937ms | Valid Loss: 2.370 | Valid Acc: 9.960% (498/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 151ms | Tot: 26s684ms | Train Loss: 2.372 | Train Acc: 9.960% (4462/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s785ms | Valid Loss: 2.369 | Valid Acc: 9.760% (488/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 151ms | Tot: 26s776ms | Train Loss: 2.371 | Train Acc: 9.891% (4431/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s947ms | Valid Loss: 2.370 | Valid Acc: 9.620% (481/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 152ms | Tot: 26s678ms | Train Loss: 2.371 | Train Acc: 9.991% (4476/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s828ms | Valid Loss: 2.372 | Valid Acc: 9.920% (496/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 150ms | Tot: 26s770ms | Train Loss: 2.369 | Train Acc: 9.915% (4442/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s873ms | Valid Loss: 2.371 | Valid Acc: 9.780% (489/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:53:50,653]\u001b[0m Trial 1 finished with value: 9.78 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.0, 'optimizer': 'SGD', 'momentum': 0.4865323376096785, 'lr': 0.024404311678597107, 'batch_size': 256}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 78ms | Tot: 28s680ms | Train Loss: 2.353 | Train Acc: 9.453% (4247/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s29ms | Valid Loss: 2.354 | Valid Acc: 9.560% (478/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 79ms | Tot: 28s502ms | Train Loss: 2.351 | Train Acc: 9.428% (4236/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 2s97ms | Valid Loss: 2.356 | Valid Acc: 9.240% (462/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 79ms | Tot: 28s655ms | Train Loss: 2.351 | Train Acc: 9.437% (4240/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s28ms | Valid Loss: 2.355 | Valid Acc: 9.180% (459/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 28s679ms | Train Loss: 2.350 | Train Acc: 9.420% (4232/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s60ms | Valid Loss: 2.353 | Valid Acc: 9.500% (475/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 77ms | Tot: 28s711ms | Train Loss: 2.352 | Train Acc: 9.339% (4196/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s964ms | Valid Loss: 2.354 | Valid Acc: 9.640% (482/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 80ms | Tot: 28s836ms | Train Loss: 2.352 | Train Acc: 9.486% (4262/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s960ms | Valid Loss: 2.356 | Valid Acc: 8.680% (434/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 80ms | Tot: 28s485ms | Train Loss: 2.351 | Train Acc: 9.524% (4279/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s953ms | Valid Loss: 2.353 | Valid Acc: 9.720% (486/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 81ms | Tot: 28s527ms | Train Loss: 2.352 | Train Acc: 9.515% (4275/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 2.358 | Valid Acc: 9.220% (461/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 80ms | Tot: 28s633ms | Train Loss: 2.351 | Train Acc: 9.346% (4199/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s991ms | Valid Loss: 2.349 | Valid Acc: 9.300% (465/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 78ms | Tot: 28s839ms | Train Loss: 2.351 | Train Acc: 9.480% (4259/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 2s412ms | Valid Loss: 2.355 | Valid Acc: 9.240% (462/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 14:59:04,087]\u001b[0m Trial 2 finished with value: 9.24 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.0, 'optimizer': 'SGD', 'momentum': 0.909853489730662, 'lr': 0.08251134217906209, 'batch_size': 128}. Best is trial 0 with value: 10.02.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 79ms | Tot: 28s915ms | Train Loss: 2.391 | Train Acc: 10.025% (4504/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s944ms | Valid Loss: 2.389 | Valid Acc: 9.880% (494/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 78ms | Tot: 28s717ms | Train Loss: 2.393 | Train Acc: 9.992% (4489/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s966ms | Valid Loss: 2.395 | Valid Acc: 9.800% (490/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 80ms | Tot: 28s642ms | Train Loss: 2.392 | Train Acc: 10.012% (4498/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 2.397 | Valid Acc: 9.920% (496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 29s22ms | Train Loss: 2.393 | Train Acc: 10.009% (4497/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s46ms | Valid Loss: 2.397 | Valid Acc: 9.860% (493/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2022-11-22 15:01:17,907]\u001b[0m Trial 3 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-35-4ece1c94b17c>\", line 54, in objective\n",
            "    train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
            "  File \"<ipython-input-26-13119085b394>\", line 17, in train\n",
            "    train_loss += loss.item()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c957fa888094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resNet-18\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-4ece1c94b17c>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_trainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-13119085b394>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, train_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18\")\n",
        "\n",
        "study.optimize(objective, n_trials = 8)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RphsqTa1uv_"
      },
      "outputs": [],
      "source": [
        "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "7FyHCQ1cHeZM",
        "outputId": "70dfdf5b-6b38-4814-eb17-dfe5298bc492"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7032200-07a9-411d-a8f8-135cc582fbd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_dropout_rate</th>\n",
              "      <th>params_dropout_rate2</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_momentum</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81.42</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.046432</td>\n",
              "      <td>0.929673</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.14</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.029621</td>\n",
              "      <td>0.725203</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85.76</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.017706</td>\n",
              "      <td>0.424324</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.96</td>\n",
              "      <td>192</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.415626</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86.96</td>\n",
              "      <td>64</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.308545</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>86.48</td>\n",
              "      <td>192</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.010862</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>86.32</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.642634</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84.80</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030530</td>\n",
              "      <td>0.569134</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>87.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.515801</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>86.88</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.032970</td>\n",
              "      <td>0.676042</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>86.98</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.174142</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>86.30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.183899</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>86.62</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>86.14</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.026755</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>86.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.853746</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>88.02</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>0.265827</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86.82</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.344868</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>87.90</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.005739</td>\n",
              "      <td>0.534634</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>87.50</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.006430</td>\n",
              "      <td>0.269840</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86.84</td>\n",
              "      <td>128</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.780328</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>87.94</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.007808</td>\n",
              "      <td>0.568036</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>87.36</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.563467</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>87.54</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.460849</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>87.12</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.095388</td>\n",
              "      <td>0.594778</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>87.54</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008114</td>\n",
              "      <td>0.370643</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7032200-07a9-411d-a8f8-135cc582fbd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
              "0   81.42                192                  0.4                   0.2   \n",
              "1   85.14                192                  0.1                   0.1   \n",
              "2   85.76                256                  0.4                   0.3   \n",
              "3   85.96                192                  0.2                   0.2   \n",
              "4   86.96                 64                  0.4                   0.2   \n",
              "5   86.48                192                  0.3                   0.1   \n",
              "6   86.32                256                  0.3                   0.1   \n",
              "7   84.80                128                  0.5                   0.0   \n",
              "8   87.48                256                  0.0                   0.1   \n",
              "9   86.88                192                  0.4                   0.1   \n",
              "10  86.98                256                  0.0                   0.0   \n",
              "11  86.30                256                  0.0                   0.0   \n",
              "12  86.62                256                  0.0                   0.0   \n",
              "13  86.14                128                  0.1                   0.0   \n",
              "14  86.48                256                  0.1                   0.0   \n",
              "15  88.02                 64                  0.0                   0.1   \n",
              "16  86.82                 64                  0.2                   0.3   \n",
              "17  87.90                128                  0.1                   0.1   \n",
              "18  87.50                 64                  0.1                   0.2   \n",
              "19  86.84                128                  0.2                   0.1   \n",
              "20  87.94                 64                  0.1                   0.2   \n",
              "21  87.36                 64                  0.1                   0.2   \n",
              "22  87.54                128                  0.0                   0.3   \n",
              "23  87.12                 64                  0.1                   0.1   \n",
              "24  87.54                 64                  0.2                   0.2   \n",
              "\n",
              "    params_lr  params_momentum params_optimizer  \n",
              "0    0.046432         0.929673          RMSprop  \n",
              "1    0.029621         0.725203              SGD  \n",
              "2    0.017706         0.424324              SGD  \n",
              "3    0.000013         0.415626              SGD  \n",
              "4    0.003680         0.308545              SGD  \n",
              "5    0.001661         0.010862              SGD  \n",
              "6    0.000020         0.642634              SGD  \n",
              "7    0.030530         0.569134              SGD  \n",
              "8    0.000249         0.515801          RMSprop  \n",
              "9    0.032970         0.676042              SGD  \n",
              "10   0.000266         0.174142          RMSprop  \n",
              "11   0.000177         0.183899          RMSprop  \n",
              "12   0.000154         0.179775          RMSprop  \n",
              "13   0.000233         0.026755          RMSprop  \n",
              "14   0.000069         0.853746          RMSprop  \n",
              "15   0.000878         0.265827          RMSprop  \n",
              "16   0.000781         0.344868          RMSprop  \n",
              "17   0.005739         0.534634          RMSprop  \n",
              "18   0.006430         0.269840          RMSprop  \n",
              "19   0.000909         0.780328          RMSprop  \n",
              "20   0.007808         0.568036          RMSprop  \n",
              "21   0.008254         0.563467          RMSprop  \n",
              "22   0.002182         0.460849          RMSprop  \n",
              "23   0.095388         0.594778          RMSprop  \n",
              "24   0.008114         0.370643          RMSprop  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfILxanQHrkV"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path  \n",
        "filepath = Path('optuna_out.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tMVKiy5_1lQz",
        "outputId": "e026d825-5c19-4fea-c084-75e3f544bbbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"844e23c1-e7c4-47dd-aa84-54bea3041563\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"844e23c1-e7c4-47dd-aa84-54bea3041563\")) {                    Plotly.newPlot(                        \"844e23c1-e7c4-47dd-aa84-54bea3041563\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.48,86.32,84.8,87.48,86.88,86.98,86.62,86.48,88.02,86.82,87.9,87.5,86.84,87.94,87.54,87.12],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.96,86.96,86.96,87.48,87.48,87.48,87.48,87.48,88.02,88.02,88.02,88.02,88.02,88.02,88.02,88.02],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('844e23c1-e7c4-47dd-aa84-54bea3041563');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt_hist = optuna.visualization.plot_optimization_history(study)\n",
        "\n",
        "opt_hist.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "opt_hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ttCK-I3f1olz",
        "outputId": "2b5075cc-f6b9-450c-ee4f-630928b32a01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\")) {                    Plotly.newPlot(                        \"ebb31b8a-b414-4d35-b0fd-6702e59b597f\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[54.4,64,128,192,256,265.6],\"y\":[8.169610120215257e-06,1.2760918088428318e-05,1.9851358937422513e-05,6.895371131358072e-05,0.00015387349104295094,0.0002492294583100163,0.00026626831184196344,0.000780715307860027,0.0008781984559717051,0.0009089777877470327,0.0016608243757673467,0.002182085616397292,0.003679633596234943,0.005739052585337983,0.0064302752977516645,0.007808464498303689,0.017705749117129983,0.029621233669222247,0.03052954516379949,0.03297036376254276,0.04643207616533176,0.09538799451770531,0.1489958965909395],\"z\":[[null,null,null,null,null,null],[null,null,null,85.96,null,null],[null,null,null,null,86.32,null],[null,null,null,null,86.48,null],[null,null,null,null,86.62,null],[null,null,null,null,87.48,null],[null,null,null,null,86.98,null],[null,86.82,null,null,null,null],[null,88.02,null,null,null,null],[null,null,86.84,null,null,null],[null,null,null,86.48,null,null],[null,null,87.54,null,null,null],[null,86.96,null,null,null,null],[null,null,87.9,null,null,null],[null,87.5,null,null,null,null],[null,87.94,null,null,null,null],[null,null,null,null,85.76,null],[null,null,null,85.14,null,null],[null,null,84.8,null,null,null],[null,null,null,86.88,null,null],[null,null,null,81.42,null,null],[null,87.12,null,null,null,null],[null,null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[192,192,256,192,64,192,256,128,256,192,256,256,256,64,64,128,64,128,64,128,64],\"y\":[0.04643207616533176,0.029621233669222247,0.017705749117129983,1.2760918088428318e-05,0.003679633596234943,0.0016608243757673467,1.9851358937422513e-05,0.03052954516379949,0.0002492294583100163,0.03297036376254276,0.00026626831184196344,0.00015387349104295094,6.895371131358072e-05,0.0008781984559717051,0.000780715307860027,0.005739052585337983,0.0064302752977516645,0.0009089777877470327,0.007808464498303689,0.002182085616397292,0.09538799451770531],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"batch_size\"},\"range\":[54.4,265.6]},\"yaxis\":{\"title\":{\"text\":\"lr\"},\"range\":[-5.087798668887335,-0.8268256920739774],\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ebb31b8a-b414-4d35-b0fd-6702e59b597f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i2J9SpQJ1sy5",
        "outputId": "2141417f-a32b-48c1-c840-e59404d00512"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\")) {                    Plotly.newPlot(                        \"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"dropout_rate2 (FloatDistribution): 0.02052906992009996<extra></extra>\",\"batch_size (IntDistribution): 0.04208505899340595<extra></extra>\",\"dropout_rate (FloatDistribution): 0.09134791826999204<extra></extra>\",\"optimizer (CategoricalDistribution): 0.11600269442598625<extra></extra>\",\"lr (FloatDistribution): 0.24782621733655558<extra></extra>\",\"momentum (FloatDistribution): 0.48220904105396<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02\",\"0.04\",\"0.09\",\"0.12\",\"0.25\",\"0.48\"],\"textposition\":\"outside\",\"x\":[0.02052906992009996,0.04208505899340595,0.09134791826999204,0.11600269442598625,0.24782621733655558,0.48220904105396],\"y\":[\"dropout_rate2\",\"batch_size\",\"dropout_rate\",\"optimizer\",\"lr\",\"momentum\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f11ba62-5e0f-4a52-a81c-8ca76f07db38');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_importance_fig = optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "param_importance_fig.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "param_importance_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3tpr4KK2RVI",
        "outputId": "2c076844-1436-46ba-a10d-fcabf8929120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Number of finished trials:  25\n",
            "  Number of pruned trials:  4\n",
            "  Number of complete trials:  21\n"
          ]
        }
      ],
      "source": [
        "from optuna.trial import TrialState\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUoh2I8hGQhu"
      },
      "outputs": [],
      "source": [
        "# serialize the reult\n",
        "\n",
        "SERIALIZATION_DIR = \"\" \n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('study_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(study, f)\n",
        "\n",
        "with open('df_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj0rployJanz",
        "outputId": "7d93d6a4-b511-4056-bb1a-e2c89bed77ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best model is\n",
            "{'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'RMSprop', 'momentum': 0.26582732909111395, 'lr': 0.0008781984559717051, 'batch_size': 64}\n"
          ]
        }
      ],
      "source": [
        "print(\"The best model is\")\n",
        "\n",
        "print(trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OntkPiXekwLR"
      },
      "outputs": [],
      "source": [
        "def objective_2(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "  # trying different optimizers\n",
        "\n",
        "  optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "                                                                   \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 64, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 25\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTR21sA2lAnX",
        "outputId": "0f0d7470-4adc-4cd2-9e59-9b84e5ab85d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 06:25:03,584]\u001b[0m A new study created in memory with name: resNet-18-Ada\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna with Ada family optimizers\n",
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 41ms | Tot: 31s448ms | Train Loss: 2.346 | Train Acc: 10.371% (4666/44992)\b\b\b\b 703/703 \n",
            " [======>]  Step: 9ms | Tot: 2s74ms | Valid Loss: 2.303 | Valid Acc: 8.380% (419/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Optuna with Ada family optimizers\")\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18-Ada\")\n",
        "\n",
        "study.optimize(objective_2, n_trials = 5)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8OFkLJ5nQa"
      },
      "source": [
        "<h1>Model Visualization with Tensorboard</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odnt6T_i5mcA",
        "outputId": "fca4db79-ff96-4774-e1de-687c181bd165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.38.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVF5Rs1yg8-l"
      },
      "outputs": [],
      "source": [
        "# Run in shell: tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9M0JT27NZn",
        "outputId": "fa927eb0-3d81-4811-ab7c-630f16ac158d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 0.943s\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6l8H9BXcLp-",
        "outputId": "d567fcb6-1bcf-440b-e87e-0cca3e4723bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://legal-mails-turn-34-73-105-255.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!lt --port 6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr94MEgvcQAe",
        "outputId": "8ef084f8-974b-4198-8a02-04a80d1a8b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running the best model for 100 epochs\n"
          ]
        }
      ],
      "source": [
        "print(\"Running the best model for 100 epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD9CHX5P7WDw"
      },
      "outputs": [],
      "source": [
        "jsjhfhfhhfhf"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3df2267cf8d54d74aaa803ab0a7f39d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4fd0e91c384433c9e4e86677551a5eb",
              "IPY_MODEL_75fb31bd9ee64e3c8fe52490f031d917",
              "IPY_MODEL_c411225fe7b9462bbbef20d707e9b184"
            ],
            "layout": "IPY_MODEL_ae4f75575c494f9aa028a84b27b35718"
          }
        },
        "a4fd0e91c384433c9e4e86677551a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0361accc5944588b1f28e440421b32d",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3dee7be8734ab99425179b2d0a37d2",
            "value": "100%"
          }
        },
        "75fb31bd9ee64e3c8fe52490f031d917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1346132be0c544bdb53d0985afeb9db0",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f2e2b1de884cfe875db6b983566fb3",
            "value": 170498071
          }
        },
        "c411225fe7b9462bbbef20d707e9b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b432d075aafa47cb8121b097d421733e",
            "placeholder": "​",
            "style": "IPY_MODEL_fcfc666db5a6422b95ae3115185ae4af",
            "value": " 170498071/170498071 [00:10&lt;00:00, 17177215.09it/s]"
          }
        },
        "ae4f75575c494f9aa028a84b27b35718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0361accc5944588b1f28e440421b32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3dee7be8734ab99425179b2d0a37d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1346132be0c544bdb53d0985afeb9db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f2e2b1de884cfe875db6b983566fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b432d075aafa47cb8121b097d421733e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfc666db5a6422b95ae3115185ae4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}