{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "GXI-w576XzT_"
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "import torch as torch\n",
    "\n",
    "\n",
    "def set_up_ssl():\n",
    "    try:\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "set_up_ssl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "LOCAL_M1 = True\n",
    "\n",
    "if LOCAL_M1:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "else:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device: \", device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "wTLc4fVcQ857"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import humanize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "jQeGvfSCRM4i"
   },
   "outputs": [],
   "source": [
    "term_width = 5\n",
    "TOTAL_BAR_LENGTH = 7\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "wTCFIHn0XzUL"
   },
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        # adding Optuna dropout trial\n",
    "        if trial is not None:\n",
    "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.1)\n",
    "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "\n",
    "        # adding Optuna dropout trial\n",
    "        if trial is not None:\n",
    "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.3, step=0.1)\n",
    "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "\n",
    "        # adding Optuna dropout trial\n",
    "        if trial is not None:\n",
    "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.1)\n",
    "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        \n",
    "        # adding Optuna dropout trial\n",
    "        if trial is not None:\n",
    "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.3, step=0.1)\n",
    "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        \n",
    "        # adding Optuna dropout trial\n",
    "        if trial is not None:\n",
    "            dropout_rate3 = trial.suggest_float(\"dropout_rate3\", 0, 0.1,\n",
    "                                                step=0.1)\n",
    "            self.drop2 = nn.Dropout2d(p=dropout_rate3)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, trial=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], trial,\n",
    "                                       stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], trial,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], trial,\n",
    "                                       stride=2)\n",
    "        # removing the 4th layer to reduce the size of the network\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], trial,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, trial, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, trial))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # removing the 4th layer to reduce the size of the network\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(trial=None):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], trial=trial)\n",
    "\n",
    "\n",
    "def ResNet34(trial=None):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], trial=trial)\n",
    "\n",
    "\n",
    "def ResNet50(trial=None):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], trial=trial)\n",
    "\n",
    "\n",
    "def ResNet101(trial=None):\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], trial=trial)\n",
    "\n",
    "\n",
    "def ResNet152(trial=None):\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3], trial=trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "f9cddfc3bc9d458e83054c3175b478ed",
      "b49d88b0fea6496592f35fddf0826c24",
      "fe6a906e76f3494baf5e4a109daa4e9c",
      "a9e02dc71a1f4283ac6086f30f354490",
      "374936fc9fb54190a370b476131bf5c6",
      "0d3ee5109c5c4fc0b47db02deca1f2f5",
      "79c500cbc94a4fcbbed6e968a01c760a",
      "ff5988d1a5cb4ac8a0fa6b69bc2cb428",
      "160869b4947e4dc6b74fe1856d6a3853",
      "9d407f071df2445e866ad8ed86f32afc",
      "13a0c8f358234c4e8bcb1ccf4e40eda1"
     ]
    },
    "id": "N_K9-VkFRsiL",
    "outputId": "f1de1c1e-62bc-4665-81fe-66ba4dceb0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The length of a train set is  45000\n",
      "The length of a validation set is  5000\n",
      "The length of a test set is  10000\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    #transforms.RandomErasing()\n",
    "  \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# constructing validation set\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "torch.manual_seed(43)\n",
    "val_size = 5000\n",
    "train_size = len(trainset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)\n",
    "print(\"The length of a train set is \", len(train_ds))\n",
    "print(\"The length of a validation set is \", len(val_ds))\n",
    "print(\"The length of a test set is \", len(testset))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "net = ResNet18() # 11.2 params\n",
    "#net = ResNet50() # 23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbzjCm0gOElC",
    "outputId": "5332130d-89a1-41ed-f572-d6f75d1660fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "layers[0]:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layers[1]:  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layers[2]:  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "layers[3]:  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "layers[4]:  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "layers[5]:  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n",
      "layers[6]:  Linear(in_features=512, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layers = list(net.children())\n",
    "\n",
    "print(len(layers))\n",
    "\n",
    "print(\"layers[0]: \", layers[0])\n",
    "print(\"layers[1]: \", layers[1])\n",
    "print(\"layers[2]: \", layers[2])\n",
    "print(\"layers[3]: \", layers[3])\n",
    "print(\"layers[4]: \", layers[4])\n",
    "print(\"layers[5]: \", layers[5])\n",
    "print(\"layers[6]: \", layers[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "2M1xDV4-VaKG"
   },
   "outputs": [],
   "source": [
    "import torch_pruning as tp\n",
    "\n",
    "def prune_model(model):\n",
    "    model.cpu()\n",
    "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 3, 32, 32) )\n",
    "    def prune_conv(conv, amount=0.2):\n",
    "        strategy = tp.strategy.L1Strategy()\n",
    "        pruning_index = strategy(conv.weight, amount=amount)\n",
    "        plan = DG.get_pruning_plan(conv, tp.prune_conv_out_channel, pruning_index)\n",
    "        plan.exec()\n",
    "    \n",
    "    block_prune_probs = [0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3]\n",
    "    blk_id = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance( m, BasicBlock):\n",
    "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
    "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
    "            blk_id+=1\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "kgQPV3H4ZTxA"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def print_params(model):\n",
    "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCkbs0btThnx",
    "outputId": "35468c13-ef6e-4576-9303-fee326e8ffbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters before pruning is \n",
      "Number of parameters  11.2 million\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of parameters before pruning is \")\n",
    "print_params(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duOPOJDMV2Vn",
    "outputId": "de142ea6-e741-4eb8-9455-bf8002e763e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(53, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(53, 83, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(83, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(83, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(83, 164, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(164, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(164, 359, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(164, 252, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(252, 359, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=252, out_features=10, bias=True)\n)"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAZTZsHwTyOK",
    "outputId": "e7f7e5e7-69e9-4306-f896-9b37f9320651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters after pruning is \n",
      "Number of parameters  4.5 million\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of parameters after pruning is \")\n",
    "print_params(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "htKbN2cYXzUh"
   },
   "outputs": [],
   "source": [
    "def get_pruned_parameters_countget_pruned_parameters_count(pruned_model):\n",
    "    params = 0\n",
    "    for param in pruned_model.parameters():\n",
    "        if param is not None:\n",
    "            params += torch.nonzero(param).size(0)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTqr1gYtVHgE",
    "outputId": "52f0f8db-80c4-4c58-9ed1-7f4fd63a064a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 53, 32, 32]           1,431\n",
      "       BatchNorm2d-2           [-1, 53, 32, 32]             106\n",
      "            Conv2d-3           [-1, 58, 32, 32]          27,666\n",
      "       BatchNorm2d-4           [-1, 58, 32, 32]             116\n",
      "            Conv2d-5           [-1, 53, 32, 32]          27,666\n",
      "       BatchNorm2d-6           [-1, 53, 32, 32]             106\n",
      "        BasicBlock-7           [-1, 53, 32, 32]               0\n",
      "            Conv2d-8           [-1, 58, 32, 32]          27,666\n",
      "       BatchNorm2d-9           [-1, 58, 32, 32]             116\n",
      "           Conv2d-10           [-1, 53, 32, 32]          27,666\n",
      "      BatchNorm2d-11           [-1, 53, 32, 32]             106\n",
      "       BasicBlock-12           [-1, 53, 32, 32]               0\n",
      "           Conv2d-13          [-1, 103, 16, 16]          49,131\n",
      "      BatchNorm2d-14          [-1, 103, 16, 16]             206\n",
      "           Conv2d-15           [-1, 83, 16, 16]          76,941\n",
      "      BatchNorm2d-16           [-1, 83, 16, 16]             166\n",
      "           Conv2d-17           [-1, 83, 16, 16]           4,399\n",
      "      BatchNorm2d-18           [-1, 83, 16, 16]             166\n",
      "       BasicBlock-19           [-1, 83, 16, 16]               0\n",
      "           Conv2d-20          [-1, 103, 16, 16]          76,941\n",
      "      BatchNorm2d-21          [-1, 103, 16, 16]             206\n",
      "           Conv2d-22           [-1, 83, 16, 16]          76,941\n",
      "      BatchNorm2d-23           [-1, 83, 16, 16]             166\n",
      "       BasicBlock-24           [-1, 83, 16, 16]               0\n",
      "           Conv2d-25            [-1, 205, 8, 8]         153,135\n",
      "      BatchNorm2d-26            [-1, 205, 8, 8]             410\n",
      "           Conv2d-27            [-1, 164, 8, 8]         302,580\n",
      "      BatchNorm2d-28            [-1, 164, 8, 8]             328\n",
      "           Conv2d-29            [-1, 164, 8, 8]          13,612\n",
      "      BatchNorm2d-30            [-1, 164, 8, 8]             328\n",
      "       BasicBlock-31            [-1, 164, 8, 8]               0\n",
      "           Conv2d-32            [-1, 205, 8, 8]         302,580\n",
      "      BatchNorm2d-33            [-1, 205, 8, 8]             410\n",
      "           Conv2d-34            [-1, 164, 8, 8]         302,580\n",
      "      BatchNorm2d-35            [-1, 164, 8, 8]             328\n",
      "       BasicBlock-36            [-1, 164, 8, 8]               0\n",
      "           Conv2d-37            [-1, 359, 4, 4]         529,884\n",
      "      BatchNorm2d-38            [-1, 359, 4, 4]             718\n",
      "           Conv2d-39            [-1, 252, 4, 4]         814,212\n",
      "      BatchNorm2d-40            [-1, 252, 4, 4]             504\n",
      "           Conv2d-41            [-1, 252, 4, 4]          41,328\n",
      "      BatchNorm2d-42            [-1, 252, 4, 4]             504\n",
      "       BasicBlock-43            [-1, 252, 4, 4]               0\n",
      "           Conv2d-44            [-1, 359, 4, 4]         814,212\n",
      "      BatchNorm2d-45            [-1, 359, 4, 4]             718\n",
      "           Conv2d-46            [-1, 252, 4, 4]         814,212\n",
      "      BatchNorm2d-47            [-1, 252, 4, 4]             504\n",
      "       BasicBlock-48            [-1, 252, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           2,530\n",
      "================================================================\n",
      "Total params: 4,493,525\n",
      "Trainable params: 4,493,525\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.69\n",
      "Params size (MB): 17.14\n",
      "Estimated Total Size (MB): 25.84\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "def print_model_summary(model):\n",
    "  print(summary(model.to(\"cpu\"), (3, 32, 32)))\n",
    "\n",
    "print_model_summary(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tejFfYvQJxR5",
    "outputId": "e0ef5bf9-b181-486a-eb53-ce7d5108df52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([53, 3, 3, 3])\n",
      "bn1.weight torch.Size([53])\n",
      "bn1.bias torch.Size([53])\n",
      "layer1.0.conv1.weight torch.Size([58, 53, 3, 3])\n",
      "layer1.0.bn1.weight torch.Size([58])\n",
      "layer1.0.bn1.bias torch.Size([58])\n",
      "layer1.0.conv2.weight torch.Size([53, 58, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([53])\n",
      "layer1.0.bn2.bias torch.Size([53])\n",
      "layer1.1.conv1.weight torch.Size([58, 53, 3, 3])\n",
      "layer1.1.bn1.weight torch.Size([58])\n",
      "layer1.1.bn1.bias torch.Size([58])\n",
      "layer1.1.conv2.weight torch.Size([53, 58, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([53])\n",
      "layer1.1.bn2.bias torch.Size([53])\n",
      "layer2.0.conv1.weight torch.Size([103, 53, 3, 3])\n",
      "layer2.0.bn1.weight torch.Size([103])\n",
      "layer2.0.bn1.bias torch.Size([103])\n",
      "layer2.0.conv2.weight torch.Size([83, 103, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([83])\n",
      "layer2.0.bn2.bias torch.Size([83])\n",
      "layer2.0.shortcut.0.weight torch.Size([83, 53, 1, 1])\n",
      "layer2.0.shortcut.1.weight torch.Size([83])\n",
      "layer2.0.shortcut.1.bias torch.Size([83])\n",
      "layer2.1.conv1.weight torch.Size([103, 83, 3, 3])\n",
      "layer2.1.bn1.weight torch.Size([103])\n",
      "layer2.1.bn1.bias torch.Size([103])\n",
      "layer2.1.conv2.weight torch.Size([83, 103, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([83])\n",
      "layer2.1.bn2.bias torch.Size([83])\n",
      "layer3.0.conv1.weight torch.Size([205, 83, 3, 3])\n",
      "layer3.0.bn1.weight torch.Size([205])\n",
      "layer3.0.bn1.bias torch.Size([205])\n",
      "layer3.0.conv2.weight torch.Size([164, 205, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([164])\n",
      "layer3.0.bn2.bias torch.Size([164])\n",
      "layer3.0.shortcut.0.weight torch.Size([164, 83, 1, 1])\n",
      "layer3.0.shortcut.1.weight torch.Size([164])\n",
      "layer3.0.shortcut.1.bias torch.Size([164])\n",
      "layer3.1.conv1.weight torch.Size([205, 164, 3, 3])\n",
      "layer3.1.bn1.weight torch.Size([205])\n",
      "layer3.1.bn1.bias torch.Size([205])\n",
      "layer3.1.conv2.weight torch.Size([164, 205, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([164])\n",
      "layer3.1.bn2.bias torch.Size([164])\n",
      "layer4.0.conv1.weight torch.Size([359, 164, 3, 3])\n",
      "layer4.0.bn1.weight torch.Size([359])\n",
      "layer4.0.bn1.bias torch.Size([359])\n",
      "layer4.0.conv2.weight torch.Size([252, 359, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([252])\n",
      "layer4.0.bn2.bias torch.Size([252])\n",
      "layer4.0.shortcut.0.weight torch.Size([252, 164, 1, 1])\n",
      "layer4.0.shortcut.1.weight torch.Size([252])\n",
      "layer4.0.shortcut.1.bias torch.Size([252])\n",
      "layer4.1.conv1.weight torch.Size([359, 252, 3, 3])\n",
      "layer4.1.bn1.weight torch.Size([359])\n",
      "layer4.1.bn1.bias torch.Size([359])\n",
      "layer4.1.conv2.weight torch.Size([252, 359, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([252])\n",
      "layer4.1.bn2.bias torch.Size([252])\n",
      "linear.weight torch.Size([10, 252])\n",
      "linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "def print_model_layers(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "print_model_layers(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "a3kWtBzVWg3Y"
   },
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "lr = 0.1\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                       momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "save_loss = {'train':[], 'test':[]}\n",
    "save_acc = {'train':[], 'test':[]}\n",
    "\n",
    "train_acc_array, train_loss_array = [], [] # for plotting\n",
    "val_acc_array, val_loss_array = [], [] # for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "CIzJObnOWz2d"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, model=net):\n",
    "    print(\"device is \", device)\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_acc = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_acc=100.*correct/total\n",
    "        progress_bar(batch_idx, len(trainloader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    train_acc_array.append(train_acc) # for plottting\n",
    "    train_loss_array.append(train_loss) # for plottting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "0CHlPBF6uIhT"
   },
   "outputs": [],
   "source": [
    "def evaluate(epoch, model=net): # validation\n",
    "   \n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "          \n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(val_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
    "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    valid_acc = 100.*correct/total\n",
    "    if valid_acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'acc': valid_acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = valid_acc\n",
    "    val_acc_array.append(valid_acc) # for plottting\n",
    "    val_loss_array.append(valid_loss) # for plottting\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "G5i2dqetBgXp"
   },
   "outputs": [],
   "source": [
    "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
    "def test(model=net):\n",
    "   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    model.load_state_dict(checkpoint['net_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_acc = checkpoint['acc']\n",
    "    model.eval()\n",
    "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
    "    with torch.no_grad():\n",
    "          \n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qyuhb-GrXzUo",
    "outputId": "ccbf2e25-30ab-436d-cade-48bd9295b4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device  mps\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79HcWh5aXzUq",
    "outputId": "b23136a8-001e-4d87-f413-718c34343418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters  4.5 million\n"
     ]
    }
   ],
   "source": [
    "print_params(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJcMkrBzW7o7",
    "outputId": "31d33665-d65f-40ec-c16c-09c225256cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is  mps\n",
      "\n",
      "Epoch: 0\n",
      " [>......]  Step: 94ms | Tot: 1s134ms | Train Loss: 2.312 | Train Acc: 11.238% (187/1 13/352 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x123890b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [157], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m NUM_EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(start_epoch, start_epoch \u001B[38;5;241m+\u001B[39m NUM_EPOCHS):\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     evaluate(epoch)\n\u001B[1;32m      6\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn [152], line 18\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch, model)\u001B[0m\n\u001B[1;32m     15\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 18\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     20\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    evaluate(epoch)\n",
    "\n",
    "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8F9l3iSKXzUs",
    "outputId": "ce43f615-dfa7-4844-e22b-74e128597ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters  4.5 million\n"
     ]
    }
   ],
   "source": [
    "print_params(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRtpQiLSWkIT",
    "outputId": "12bd0a98-308f-4e6e-8303-fe0628a74de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x2c5f0dcb0>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6z_TwWP4Xkca",
    "outputId": "0761cc04-4bf4-4fb6-dedf-8190b30539e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "JHKohhBDJRIP",
    "outputId": "ee8099c9-f661-449d-abeb-fb112f7ca069"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [183], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m16\u001B[39m,\u001B[38;5;241m6\u001B[39m))\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m121\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mNUM_EPOCHS\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_acc_array\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m,NUM_EPOCHS\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m),val_acc_array)\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/matplotlib/pyplot.py:2740\u001B[0m, in \u001B[0;36mplot\u001B[0;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2738\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[1;32m   2739\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 2740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2741\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscalex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaley\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaley\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2742\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1662\u001B[0m, in \u001B[0;36mAxes.plot\u001B[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1419\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1420\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[1;32m   1421\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1659\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[1;32m   1660\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1661\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[0;32m-> 1662\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[1;32m   1664\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[0;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    310\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001B[0m\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39myaxis\u001B[38;5;241m.\u001B[39mupdate_units(y)\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[0;32m--> 504\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must have same first dimension, but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    505\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y can be no greater than 2D, but have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    508\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(np.arange(1,NUM_EPOCHS+1),train_acc_array)\n",
    "plt.plot(np.arange(1,NUM_EPOCHS+1),val_acc_array)\n",
    "plt.title(\"Accuray\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),train_loss_array)\n",
    "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),val_loss_array)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "JX1dmdIIuPOo"
   },
   "outputs": [],
   "source": [
    "# can you create a subset of params exclusing pruned weights ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUPyXSy3yD6G"
   },
   "source": [
    "<h2>Automatic Hyperparameter Search using Optuna</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aefZAQVvyCgU",
    "outputId": "0f5c6f2c-3302-483e-f340-3435e052f8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in ./venv/lib/python3.10/site-packages (3.0.3)\r\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in ./venv/lib/python3.10/site-packages (from optuna) (4.13.0)\r\n",
      "Requirement already satisfied: colorlog in ./venv/lib/python3.10/site-packages (from optuna) (6.7.0)\r\n",
      "Requirement already satisfied: cmaes>=0.8.2 in ./venv/lib/python3.10/site-packages (from optuna) (0.9.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./venv/lib/python3.10/site-packages (from optuna) (1.4.44)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from optuna) (4.64.1)\r\n",
      "Requirement already satisfied: cliff in ./venv/lib/python3.10/site-packages (from optuna) (4.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./venv/lib/python3.10/site-packages (from optuna) (1.8.1)\r\n",
      "Requirement already satisfied: PyYAML in ./venv/lib/python3.10/site-packages (from optuna) (6.0)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from optuna) (1.23.4)\r\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in ./venv/lib/python3.10/site-packages (from optuna) (1.8.1)\r\n",
      "Requirement already satisfied: Mako in ./venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.10/site-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\r\n",
      "Requirement already satisfied: cmd2>=1.0.0 in ./venv/lib/python3.10/site-packages (from cliff->optuna) (2.4.2)\r\n",
      "Requirement already satisfied: stevedore>=2.0.1 in ./venv/lib/python3.10/site-packages (from cliff->optuna) (4.1.1)\r\n",
      "Requirement already satisfied: autopage>=0.4.0 in ./venv/lib/python3.10/site-packages (from cliff->optuna) (0.5.1)\r\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in ./venv/lib/python3.10/site-packages (from cliff->optuna) (3.5.0)\r\n",
      "Requirement already satisfied: attrs>=16.3.0 in ./venv/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\r\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in ./venv/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\r\n",
      "Requirement already satisfied: pyperclip>=1.6 in ./venv/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in ./venv/lib/python3.10/site-packages (from stevedore>=2.0.1->cliff->optuna) (5.11.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "j2MShrCMyLjz"
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "MAKNVr4AyOPa"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "  # generate a model\n",
    "  model = ResNet18(trial).to(device)\n",
    "\n",
    "  prune_model(model)\n",
    "\n",
    "  # trying different optimizers\n",
    "  optimizer_name_class_1 = trial.suggest_categorical(\"optimizer\", [\"SGD\",\n",
    "                                                                   \"RMSprop\"])\n",
    "\n",
    "  # optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
    "  #                                                                  \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
    "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
    "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "  optimizer_class_1 = getattr(optim, optimizer_name_class_1)(model.parameters(),\n",
    "                                                     lr=lr, momentum=momentum)\n",
    "\n",
    "  # optimizer_class_2 = getattr(optim, optimizer_name_class_2)(model.parameters(),lr=lr)\n",
    "\n",
    "  curr_batch_size = trial.suggest_int(\"batch_size\", 64, 256, step=64)\n",
    "\n",
    "  # defining a loss function\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_1, T_max=200)\n",
    "\n",
    "  val_size = 5000\n",
    "  train_size = len(trainset) - val_size\n",
    "\n",
    "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "  val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=curr_batch_size, shuffle=False, num_workers=2, drop_last=True)  \n",
    "  \n",
    "  NUM_EPOCHS = 100\n",
    "\n",
    "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
    "      scheduler.step()\n",
    "      train(epoch)\n",
    "      accuracy = evaluate(epoch)\n",
    "      trial.report(accuracy, epoch)\n",
    "\n",
    "      if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: link database to the Optuna study"
   ],
   "metadata": {
    "id": "3WVQFDtkmJDP"
   },
   "execution_count": 188,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7S4oOdt1Rx4",
    "outputId": "e8026ecf-aa96-44e4-e36f-689c944d3fc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-11-20 18:48:18,674]\u001B[0m A new study created in memory with name: resNet-18\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is  mps\n",
      "\n",
      "Epoch: 0\n",
      " [======>]  Step: 100ms | Tot: 33s313ms | Train Loss: 1.753 | Train Acc: 35.607% (16023/45 352/352 \n",
      " [======>]  Step: 63ms | Tot: 890ms | Valid Loss: 1.598 | Valid Acc: 41.620% (2081/5 40/40 \n",
      "Saving..\n",
      "device is  mps\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [======>]  Step: 104ms | Tot: 33s467ms | Train Loss: 1.265 | Train Acc: 54.662% (24598/45 352/352 \n",
      " [======>]  Step: 25ms | Tot: 822ms | Valid Loss: 1.202 | Valid Acc: 57.380% (2869/5 40/40 \n",
      "Saving..\n",
      "device is  mps\n",
      "\n",
      "Epoch: 2\n",
      " [======>]  Step: 105ms | Tot: 33s521ms | Train Loss: 1.027 | Train Acc: 63.573% (28608/45 352/352 \n",
      " [======>]  Step: 12ms | Tot: 817ms | Valid Loss: 1.270 | Valid Acc: 58.400% (2920/5 40/40 \n",
      "Saving..\n",
      "device is  mps\n",
      "\n",
      "Epoch: 3\n",
      " [>......]  Step: 165ms | Tot: 5s296ms | Train Loss: 0.954 | Train Acc: 66.602% (4092/6 48/352 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x123890b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "\u001B[33m[W 2022-11-20 18:51:32,056]\u001B[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dennisfenchenko/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/4l/kfc4gh5d1jn6zkrmv51vvbyw0000gn/T/ipykernel_73372/1635776638.py\", line 46, in objective\n",
      "    train(epoch)\n",
      "  File \"/var/folders/4l/kfc4gh5d1jn6zkrmv51vvbyw0000gn/T/ipykernel_73372/3700065941.py\", line 18, in train\n",
      "    train_loss += loss.item()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [189], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m, sampler\u001B[38;5;241m=\u001B[39moptuna\u001B[38;5;241m.\u001B[39msamplers\u001B[38;5;241m.\u001B[39mTPESampler(), study_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresNet-18\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m trial \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_trial\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(trial\u001B[38;5;241m.\u001B[39mvalue))\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/study.py:419\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    317\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    324\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    325\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    327\u001B[0m \n\u001B[1;32m    328\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 419\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:234\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    227\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    230\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    233\u001B[0m ):\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/NYU-Fall-2022/deep-learning/mini_project/dl-fall22-mini-project/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 196\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    199\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn [187], line 46\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     43\u001B[0m NUM_EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(start_epoch, start_epoch \u001B[38;5;241m+\u001B[39m NUM_EPOCHS):\n\u001B[0;32m---> 46\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     accuracy \u001B[38;5;241m=\u001B[39m evaluate(epoch)\n\u001B[1;32m     48\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn [175], line 18\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch, model)\u001B[0m\n\u001B[1;32m     15\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 18\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     20\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18\")\n",
    "\n",
    "study.optimize(objective, n_trials = 50)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RphsqTa1uv_"
   },
   "outputs": [],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMVKiy5_1lQz"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttCK-I3f1olz"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2J9SpQJ1sy5"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3tpr4KK2RVI"
   },
   "outputs": [],
   "source": [
    "from optuna.trial import TrialState\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f9cddfc3bc9d458e83054c3175b478ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b49d88b0fea6496592f35fddf0826c24",
       "IPY_MODEL_fe6a906e76f3494baf5e4a109daa4e9c",
       "IPY_MODEL_a9e02dc71a1f4283ac6086f30f354490"
      ],
      "layout": "IPY_MODEL_374936fc9fb54190a370b476131bf5c6"
     }
    },
    "b49d88b0fea6496592f35fddf0826c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d3ee5109c5c4fc0b47db02deca1f2f5",
      "placeholder": "​",
      "style": "IPY_MODEL_79c500cbc94a4fcbbed6e968a01c760a",
      "value": "100%"
     }
    },
    "fe6a906e76f3494baf5e4a109daa4e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff5988d1a5cb4ac8a0fa6b69bc2cb428",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_160869b4947e4dc6b74fe1856d6a3853",
      "value": 170498071
     }
    },
    "a9e02dc71a1f4283ac6086f30f354490": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d407f071df2445e866ad8ed86f32afc",
      "placeholder": "​",
      "style": "IPY_MODEL_13a0c8f358234c4e8bcb1ccf4e40eda1",
      "value": " 170498071/170498071 [00:02&lt;00:00, 73101614.46it/s]"
     }
    },
    "374936fc9fb54190a370b476131bf5c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d3ee5109c5c4fc0b47db02deca1f2f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79c500cbc94a4fcbbed6e968a01c760a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff5988d1a5cb4ac8a0fa6b69bc2cb428": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160869b4947e4dc6b74fe1856d6a3853": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d407f071df2445e866ad8ed86f32afc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13a0c8f358234c4e8bcb1ccf4e40eda1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
