{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaBEihcdtk8",
        "outputId": "12a53931-17d7-45f3-e478-83ead94f07f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "GXI-w576XzT_"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "import torch as torch\n",
        "\n",
        "\n",
        "def set_up_ssl():\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "set_up_ssl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "outputs": [],
      "source": [
        "LOCAL_M1 = False\n",
        "\n",
        "if LOCAL_M1:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
        "else:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "lC88owTK4XJj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbtvE4s14XJj",
        "outputId": "8be67d03-b46f-47cf-8f14-48fd9523eb14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wTLc4fVcQ857"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "import humanize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating Tensorboard writer object\")\n",
        "\n",
        "TENSOR_BOARD_DIR = \"runs/resnet_18\"\n",
        "\n",
        "writer = SummaryWriter(TENSOR_BOARD_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAU4PYGddva",
        "outputId": "a28579b4-e81b-4eb1-d424-3057cbd4ead4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Tensorboard writer object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "jQeGvfSCRM4i"
      },
      "outputs": [],
      "source": [
        "term_width = 5\n",
        "TOTAL_BAR_LENGTH = 7\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "wTCFIHn0XzUL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.3, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.3, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate3 = trial.suggest_float(\"dropout_rate3\", 0, 0.1,\n",
        "                                                step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate3)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, trial=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], trial,\n",
        "                                       stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], trial,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], trial,\n",
        "                                       stride=2)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], trial,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, trial, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, trial))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        # removing the 4th layer to reduce the size of the network\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(trial=None):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet34(trial=None):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet50(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet101(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet152(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], trial=trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_K9-VkFRsiL",
        "outputId": "d16be077-86ea-43ae-aa1b-c9d15da8d7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "The length of a train set is  45000\n",
            "The length of a validation set is  5000\n",
            "The length of a test set is  10000\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# constructing validation set\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)\n",
        "print(\"The length of a train set is \", len(train_ds))\n",
        "print(\"The length of a validation set is \", len(val_ds))\n",
        "print(\"The length of a test set is \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = ResNet18() # 11.2 params\n",
        "#net = ResNet50() # 23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzjCm0gOElC",
        "outputId": "c7beea8e-cd6f-4387-97f8-9963bc53513a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "layers[0]:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "layers[1]:  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "layers[2]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[3]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[4]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[5]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[6]:  Linear(in_features=512, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "layers = list(net.children())\n",
        "\n",
        "print(len(layers))\n",
        "\n",
        "print(\"layers[0]: \", layers[0])\n",
        "print(\"layers[1]: \", layers[1])\n",
        "print(\"layers[2]: \", layers[2])\n",
        "print(\"layers[3]: \", layers[3])\n",
        "print(\"layers[4]: \", layers[4])\n",
        "print(\"layers[5]: \", layers[5])\n",
        "print(\"layers[6]: \", layers[6])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_pruning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhtblo5n4uKQ",
        "outputId": "39ba5cb4-d479-460b-8d4e-c374735e7ffa"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_pruning in /usr/local/lib/python3.7/dist-packages (0.2.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch_pruning) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "2M1xDV4-VaKG"
      },
      "outputs": [],
      "source": [
        "import torch_pruning as tp\n",
        "\n",
        "def prune_model(model):\n",
        "    model.cpu()\n",
        "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 3, 32, 32) )\n",
        "    def prune_conv(conv, amount=0.2):\n",
        "        strategy = tp.strategy.L1Strategy()\n",
        "        pruning_index = strategy(conv.weight, amount=amount)\n",
        "        plan = DG.get_pruning_plan(conv, tp.prune_conv_out_channel, pruning_index)\n",
        "        plan.exec()\n",
        "    \n",
        "    block_prune_probs = [0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3]\n",
        "    blk_id = 0\n",
        "    for m in model.modules():\n",
        "        if isinstance( m, BasicBlock):\n",
        "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
        "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
        "            blk_id+=1\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "kgQPV3H4ZTxA"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def print_params(model):\n",
        "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkbs0btThnx",
        "outputId": "9c52551c-d259-4b10-8db5-abed8214e855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters before pruning is \n",
            "Number of parameters  11.2 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters before pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duOPOJDMV2Vn",
        "outputId": "b3b58a04-78eb-4d8b-b090-3ea29b8e7dd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(53, 83, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(83, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(83, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(83, 164, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(164, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(164, 359, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(164, 252, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(252, 359, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=252, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "prune_model(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAZTZsHwTyOK",
        "outputId": "a9a49e8d-a754-40c8-958c-9254f7847e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters after pruning is \n",
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters after pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqr1gYtVHgE",
        "outputId": "619fa57a-f222-4c56-c845-91515596a4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 53, 32, 32]           1,431\n",
            "       BatchNorm2d-2           [-1, 53, 32, 32]             106\n",
            "            Conv2d-3           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-4           [-1, 58, 32, 32]             116\n",
            "            Conv2d-5           [-1, 53, 32, 32]          27,666\n",
            "       BatchNorm2d-6           [-1, 53, 32, 32]             106\n",
            "        BasicBlock-7           [-1, 53, 32, 32]               0\n",
            "            Conv2d-8           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-9           [-1, 58, 32, 32]             116\n",
            "           Conv2d-10           [-1, 53, 32, 32]          27,666\n",
            "      BatchNorm2d-11           [-1, 53, 32, 32]             106\n",
            "       BasicBlock-12           [-1, 53, 32, 32]               0\n",
            "           Conv2d-13          [-1, 103, 16, 16]          49,131\n",
            "      BatchNorm2d-14          [-1, 103, 16, 16]             206\n",
            "           Conv2d-15           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-16           [-1, 83, 16, 16]             166\n",
            "           Conv2d-17           [-1, 83, 16, 16]           4,399\n",
            "      BatchNorm2d-18           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-19           [-1, 83, 16, 16]               0\n",
            "           Conv2d-20          [-1, 103, 16, 16]          76,941\n",
            "      BatchNorm2d-21          [-1, 103, 16, 16]             206\n",
            "           Conv2d-22           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-23           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-24           [-1, 83, 16, 16]               0\n",
            "           Conv2d-25            [-1, 205, 8, 8]         153,135\n",
            "      BatchNorm2d-26            [-1, 205, 8, 8]             410\n",
            "           Conv2d-27            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-28            [-1, 164, 8, 8]             328\n",
            "           Conv2d-29            [-1, 164, 8, 8]          13,612\n",
            "      BatchNorm2d-30            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-31            [-1, 164, 8, 8]               0\n",
            "           Conv2d-32            [-1, 205, 8, 8]         302,580\n",
            "      BatchNorm2d-33            [-1, 205, 8, 8]             410\n",
            "           Conv2d-34            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-35            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-36            [-1, 164, 8, 8]               0\n",
            "           Conv2d-37            [-1, 359, 4, 4]         529,884\n",
            "      BatchNorm2d-38            [-1, 359, 4, 4]             718\n",
            "           Conv2d-39            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-40            [-1, 252, 4, 4]             504\n",
            "           Conv2d-41            [-1, 252, 4, 4]          41,328\n",
            "      BatchNorm2d-42            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-43            [-1, 252, 4, 4]               0\n",
            "           Conv2d-44            [-1, 359, 4, 4]         814,212\n",
            "      BatchNorm2d-45            [-1, 359, 4, 4]             718\n",
            "           Conv2d-46            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-47            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-48            [-1, 252, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 4,493,525\n",
            "Trainable params: 4,493,525\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 8.69\n",
            "Params size (MB): 17.14\n",
            "Estimated Total Size (MB): 25.84\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def print_model_summary(model):\n",
        "  print(summary(model.to(device), (3, 32, 32)))\n",
        "\n",
        "print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tejFfYvQJxR5",
        "outputId": "2a725869-e30c-4baa-b284-73fcf942c197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([53, 3, 3, 3])\n",
            "bn1.weight torch.Size([53])\n",
            "bn1.bias torch.Size([53])\n",
            "layer1.0.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([58])\n",
            "layer1.0.bn1.bias torch.Size([58])\n",
            "layer1.0.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([53])\n",
            "layer1.0.bn2.bias torch.Size([53])\n",
            "layer1.1.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([58])\n",
            "layer1.1.bn1.bias torch.Size([58])\n",
            "layer1.1.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([53])\n",
            "layer1.1.bn2.bias torch.Size([53])\n",
            "layer2.0.conv1.weight torch.Size([103, 53, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([103])\n",
            "layer2.0.bn1.bias torch.Size([103])\n",
            "layer2.0.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([83])\n",
            "layer2.0.bn2.bias torch.Size([83])\n",
            "layer2.0.shortcut.0.weight torch.Size([83, 53, 1, 1])\n",
            "layer2.0.shortcut.1.weight torch.Size([83])\n",
            "layer2.0.shortcut.1.bias torch.Size([83])\n",
            "layer2.1.conv1.weight torch.Size([103, 83, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([103])\n",
            "layer2.1.bn1.bias torch.Size([103])\n",
            "layer2.1.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([83])\n",
            "layer2.1.bn2.bias torch.Size([83])\n",
            "layer3.0.conv1.weight torch.Size([205, 83, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([205])\n",
            "layer3.0.bn1.bias torch.Size([205])\n",
            "layer3.0.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([164])\n",
            "layer3.0.bn2.bias torch.Size([164])\n",
            "layer3.0.shortcut.0.weight torch.Size([164, 83, 1, 1])\n",
            "layer3.0.shortcut.1.weight torch.Size([164])\n",
            "layer3.0.shortcut.1.bias torch.Size([164])\n",
            "layer3.1.conv1.weight torch.Size([205, 164, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([205])\n",
            "layer3.1.bn1.bias torch.Size([205])\n",
            "layer3.1.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([164])\n",
            "layer3.1.bn2.bias torch.Size([164])\n",
            "layer4.0.conv1.weight torch.Size([359, 164, 3, 3])\n",
            "layer4.0.bn1.weight torch.Size([359])\n",
            "layer4.0.bn1.bias torch.Size([359])\n",
            "layer4.0.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([252])\n",
            "layer4.0.bn2.bias torch.Size([252])\n",
            "layer4.0.shortcut.0.weight torch.Size([252, 164, 1, 1])\n",
            "layer4.0.shortcut.1.weight torch.Size([252])\n",
            "layer4.0.shortcut.1.bias torch.Size([252])\n",
            "layer4.1.conv1.weight torch.Size([359, 252, 3, 3])\n",
            "layer4.1.bn1.weight torch.Size([359])\n",
            "layer4.1.bn1.bias torch.Size([359])\n",
            "layer4.1.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([252])\n",
            "layer4.1.bn2.bias torch.Size([252])\n",
            "linear.weight torch.Size([10, 252])\n",
            "linear.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "def print_model_layers(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "print_model_layers(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "a3kWtBzVWg3Y"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "lr = 0.1\n",
        "lr = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                       momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "'''\n",
        "batch_size = 64\n",
        "\n",
        "lr = 0.0008781984559717051\n",
        "\n",
        "momentum = 0.26582732909111395\n",
        "\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=best_lr,\n",
        "                       momentum = best_momentum)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "'''\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "# writing data to TensorBoard\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid, 0)\n",
        "writer.add_graph(net, images)\n",
        "writer.close()\n",
        "\n",
        "# --------------------------------------- # \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "save_loss = {'train':[], 'test':[]}\n",
        "save_acc = {'train':[], 'test':[]}\n",
        "\n",
        "train_acc_array, train_loss_array = [], [] # for plotting\n",
        "val_acc_array, val_loss_array = [], [] # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "CIzJObnOWz2d"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch, model=net, train_loader=trainloader):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_acc = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_acc=100.*correct/total\n",
        "        progress_bar(batch_idx, len(train_loader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    train_acc_array.append(train_acc) # for plottting\n",
        "    train_loss_array.append(train_loss) # for plottting\n",
        "    writer.add_scalar('training loss', train_loss)\n",
        "    writer.add_scalar('training accuracy', train_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "0CHlPBF6uIhT"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch, model=net): # validation\n",
        "   \n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(val_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
        "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    valid_acc = 100.*correct/total\n",
        "    if valid_acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net_state_dict': model.state_dict(),\n",
        "            'acc': valid_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = valid_acc\n",
        "    val_acc_array.append(valid_acc) # for plottting\n",
        "    val_loss_array.append(valid_loss) # for plottting\n",
        "    writer.add_scalar('validation loss', valid_loss)\n",
        "    writer.add_scalar('validation accuracy', valid_acc)\n",
        "    return valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "G5i2dqetBgXp"
      },
      "outputs": [],
      "source": [
        "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
        "def test(model=net):\n",
        "   \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_acc = checkpoint['acc']\n",
        "    model.eval()\n",
        "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyuhb-GrXzUo",
        "outputId": "904bf4a2-9508-4b02-f278-90b6d5c9ac7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HcWh5aXzUq",
        "outputId": "fa16e4f8-17a2-4d31-ace4-28f5d79ba1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcMkrBzW7o7",
        "outputId": "c623f981-7d59-4cae-b621-2f536120ddde",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [======>]  Step: 465ms | Tot: 26s718ms | Train Loss: 1.760 | Train Acc: 35.220% (15849/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 119ms | Tot: 2s559ms | Valid Loss: 2.068 | Valid Acc: 33.840% (1692/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 47ms | Tot: 26s633ms | Train Loss: 1.250 | Train Acc: 55.116% (24802/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 1.279 | Valid Acc: 56.060% (2803/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 45ms | Tot: 26s913ms | Train Loss: 1.020 | Train Acc: 64.247% (28911/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 1.070 | Valid Acc: 62.540% (3127/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 47ms | Tot: 26s810ms | Train Loss: 0.897 | Train Acc: 68.473% (30813/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s979ms | Valid Loss: 0.986 | Valid Acc: 65.900% (3295/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 44ms | Tot: 27s17ms | Train Loss: 0.816 | Train Acc: 71.469% (32161/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s45ms | Valid Loss: 0.849 | Valid Acc: 71.080% (3554/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "---------------------------------------- Testing Model... ----------------------------------------\n",
            "Best validation acc: 71.080% at Epoch 4\n",
            " [======>]  Step: 21ms | Tot: 2s323ms | Test Loss: 0.615 | Test Acc: 79.190% (7919/10000)\b\b\b\b 100/100 \n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 5\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9l3iSKXzUs",
        "outputId": "37dbdff5-e410-4ed7-9e78-35166f072dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z_TwWP4Xkca",
        "outputId": "d41fa0a0-68d5-48ef-f384-0bdac4e68e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[35.22,\n",
              " 55.11555555555555,\n",
              " 64.24666666666667,\n",
              " 68.47333333333333,\n",
              " 71.46888888888888]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_acc_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "JHKohhBDJRIP",
        "outputId": "d9be0506-852a-4799-db9f-e21d6b3382bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(16,6))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),train_acc_array)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),val_acc_array)\n",
        "plt.title(\"Accuray\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),train_loss_array)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),val_loss_array)\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_test_result(num_epochs, train_acc, train_loss, val_acc, val_loss):\n",
        "  fig = plt.figure(figsize=(16,6))\n",
        "  plt.subplot(121)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), train_acc)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), val_acc)\n",
        "  plt.title(\"Accuray\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), train_loss)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), val_loss)\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1jHEaEYOfK40"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX1dmdIIuPOo"
      },
      "outputs": [],
      "source": [
        "# can you create a subset of params exclusing pruned weights ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPyXSy3yD6G"
      },
      "source": [
        "<h2>Automatic Hyperparameter Search using Optuna</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefZAQVvyCgU",
        "outputId": "bb28c431-f459-4c5b-caf1-619485331ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 90.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=95401d6e48f1745b6b0f164a753f98566265ed14b043c8984b8f70db240dba35\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "j2MShrCMyLjz"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "MAKNVr4AyOPa"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # trying different optimizers\n",
        "  optimizer_name_class_1 = trial.suggest_categorical(\"optimizer\", [\"SGD\",\n",
        "                                                                   \"RMSprop\"])\n",
        "\n",
        "  # optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "  #                                                                  \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_1 = getattr(optim, optimizer_name_class_1)(curr_model.parameters(),\n",
        "                                                     lr=lr, momentum=momentum)\n",
        "\n",
        "  # optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 64, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_1, T_max=200)\n",
        "\n",
        "  # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 25\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7S4oOdt1Rx4",
        "outputId": "2c07a3b7-dbcc-4632-9ab1-d2c661765110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 05:12:23,349]\u001b[0m A new study created in memory with name: resNet-18\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning:\n",
            "\n",
            "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [======>]  Step: 110ms | Tot: 26s92ms | Train Loss: 2.382 | Train Acc: 10.000% (4493/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s993ms | Valid Loss: 2.303 | Valid Acc: 9.040% (452/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18\")\n",
        "\n",
        "study.optimize(objective, n_trials = 25)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RphsqTa1uv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf347a37-5a9a-414c-86ba-16f5d23b5af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
            "0   81.42                192                  0.4                   0.2   \n",
            "1   85.14                192                  0.1                   0.1   \n",
            "2   85.76                256                  0.4                   0.3   \n",
            "3   85.96                192                  0.2                   0.2   \n",
            "4   86.96                 64                  0.4                   0.2   \n",
            "5   86.48                192                  0.3                   0.1   \n",
            "6   86.32                256                  0.3                   0.1   \n",
            "7   84.80                128                  0.5                   0.0   \n",
            "8   87.48                256                  0.0                   0.1   \n",
            "9   86.88                192                  0.4                   0.1   \n",
            "10  86.98                256                  0.0                   0.0   \n",
            "11  86.30                256                  0.0                   0.0   \n",
            "12  86.62                256                  0.0                   0.0   \n",
            "13  86.14                128                  0.1                   0.0   \n",
            "14  86.48                256                  0.1                   0.0   \n",
            "15  88.02                 64                  0.0                   0.1   \n",
            "16  86.82                 64                  0.2                   0.3   \n",
            "17  87.90                128                  0.1                   0.1   \n",
            "18  87.50                 64                  0.1                   0.2   \n",
            "19  86.84                128                  0.2                   0.1   \n",
            "20  87.94                 64                  0.1                   0.2   \n",
            "21  87.36                 64                  0.1                   0.2   \n",
            "22  87.54                128                  0.0                   0.3   \n",
            "23  87.12                 64                  0.1                   0.1   \n",
            "24  87.54                 64                  0.2                   0.2   \n",
            "\n",
            "    params_lr  params_momentum params_optimizer  \n",
            "0    0.046432         0.929673          RMSprop  \n",
            "1    0.029621         0.725203              SGD  \n",
            "2    0.017706         0.424324              SGD  \n",
            "3    0.000013         0.415626              SGD  \n",
            "4    0.003680         0.308545              SGD  \n",
            "5    0.001661         0.010862              SGD  \n",
            "6    0.000020         0.642634              SGD  \n",
            "7    0.030530         0.569134              SGD  \n",
            "8    0.000249         0.515801          RMSprop  \n",
            "9    0.032970         0.676042              SGD  \n",
            "10   0.000266         0.174142          RMSprop  \n",
            "11   0.000177         0.183899          RMSprop  \n",
            "12   0.000154         0.179775          RMSprop  \n",
            "13   0.000233         0.026755          RMSprop  \n",
            "14   0.000069         0.853746          RMSprop  \n",
            "15   0.000878         0.265827          RMSprop  \n",
            "16   0.000781         0.344868          RMSprop  \n",
            "17   0.005739         0.534634          RMSprop  \n",
            "18   0.006430         0.269840          RMSprop  \n",
            "19   0.000909         0.780328          RMSprop  \n",
            "20   0.007808         0.568036          RMSprop  \n",
            "21   0.008254         0.563467          RMSprop  \n",
            "22   0.002182         0.460849          RMSprop  \n",
            "23   0.095388         0.594778          RMSprop  \n",
            "24   0.008114         0.370643          RMSprop  \n"
          ]
        }
      ],
      "source": [
        "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "7FyHCQ1cHeZM",
        "outputId": "70dfdf5b-6b38-4814-eb17-dfe5298bc492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
              "0   81.42                192                  0.4                   0.2   \n",
              "1   85.14                192                  0.1                   0.1   \n",
              "2   85.76                256                  0.4                   0.3   \n",
              "3   85.96                192                  0.2                   0.2   \n",
              "4   86.96                 64                  0.4                   0.2   \n",
              "5   86.48                192                  0.3                   0.1   \n",
              "6   86.32                256                  0.3                   0.1   \n",
              "7   84.80                128                  0.5                   0.0   \n",
              "8   87.48                256                  0.0                   0.1   \n",
              "9   86.88                192                  0.4                   0.1   \n",
              "10  86.98                256                  0.0                   0.0   \n",
              "11  86.30                256                  0.0                   0.0   \n",
              "12  86.62                256                  0.0                   0.0   \n",
              "13  86.14                128                  0.1                   0.0   \n",
              "14  86.48                256                  0.1                   0.0   \n",
              "15  88.02                 64                  0.0                   0.1   \n",
              "16  86.82                 64                  0.2                   0.3   \n",
              "17  87.90                128                  0.1                   0.1   \n",
              "18  87.50                 64                  0.1                   0.2   \n",
              "19  86.84                128                  0.2                   0.1   \n",
              "20  87.94                 64                  0.1                   0.2   \n",
              "21  87.36                 64                  0.1                   0.2   \n",
              "22  87.54                128                  0.0                   0.3   \n",
              "23  87.12                 64                  0.1                   0.1   \n",
              "24  87.54                 64                  0.2                   0.2   \n",
              "\n",
              "    params_lr  params_momentum params_optimizer  \n",
              "0    0.046432         0.929673          RMSprop  \n",
              "1    0.029621         0.725203              SGD  \n",
              "2    0.017706         0.424324              SGD  \n",
              "3    0.000013         0.415626              SGD  \n",
              "4    0.003680         0.308545              SGD  \n",
              "5    0.001661         0.010862              SGD  \n",
              "6    0.000020         0.642634              SGD  \n",
              "7    0.030530         0.569134              SGD  \n",
              "8    0.000249         0.515801          RMSprop  \n",
              "9    0.032970         0.676042              SGD  \n",
              "10   0.000266         0.174142          RMSprop  \n",
              "11   0.000177         0.183899          RMSprop  \n",
              "12   0.000154         0.179775          RMSprop  \n",
              "13   0.000233         0.026755          RMSprop  \n",
              "14   0.000069         0.853746          RMSprop  \n",
              "15   0.000878         0.265827          RMSprop  \n",
              "16   0.000781         0.344868          RMSprop  \n",
              "17   0.005739         0.534634          RMSprop  \n",
              "18   0.006430         0.269840          RMSprop  \n",
              "19   0.000909         0.780328          RMSprop  \n",
              "20   0.007808         0.568036          RMSprop  \n",
              "21   0.008254         0.563467          RMSprop  \n",
              "22   0.002182         0.460849          RMSprop  \n",
              "23   0.095388         0.594778          RMSprop  \n",
              "24   0.008114         0.370643          RMSprop  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7032200-07a9-411d-a8f8-135cc582fbd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_dropout_rate</th>\n",
              "      <th>params_dropout_rate2</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_momentum</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81.42</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.046432</td>\n",
              "      <td>0.929673</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.14</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.029621</td>\n",
              "      <td>0.725203</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85.76</td>\n",
              "      <td>256</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.017706</td>\n",
              "      <td>0.424324</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.96</td>\n",
              "      <td>192</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.415626</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86.96</td>\n",
              "      <td>64</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.308545</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>86.48</td>\n",
              "      <td>192</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001661</td>\n",
              "      <td>0.010862</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>86.32</td>\n",
              "      <td>256</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.642634</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84.80</td>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030530</td>\n",
              "      <td>0.569134</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>87.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.515801</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>86.88</td>\n",
              "      <td>192</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.032970</td>\n",
              "      <td>0.676042</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>86.98</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.174142</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>86.30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.183899</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>86.62</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>86.14</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.026755</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>86.48</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.853746</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>88.02</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>0.265827</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>86.82</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.344868</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>87.90</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.005739</td>\n",
              "      <td>0.534634</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>87.50</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.006430</td>\n",
              "      <td>0.269840</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86.84</td>\n",
              "      <td>128</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.780328</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>87.94</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.007808</td>\n",
              "      <td>0.568036</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>87.36</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.563467</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>87.54</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.460849</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>87.12</td>\n",
              "      <td>64</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.095388</td>\n",
              "      <td>0.594778</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>87.54</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.008114</td>\n",
              "      <td>0.370643</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7032200-07a9-411d-a8f8-135cc582fbd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7032200-07a9-411d-a8f8-135cc582fbd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path  \n",
        "filepath = Path('optuna_out.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath) "
      ],
      "metadata": {
        "id": "gfILxanQHrkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "tMVKiy5_1lQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e026d825-5c19-4fea-c084-75e3f544bbbd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"844e23c1-e7c4-47dd-aa84-54bea3041563\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"844e23c1-e7c4-47dd-aa84-54bea3041563\")) {                    Plotly.newPlot(                        \"844e23c1-e7c4-47dd-aa84-54bea3041563\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.48,86.32,84.8,87.48,86.88,86.98,86.62,86.48,88.02,86.82,87.9,87.5,86.84,87.94,87.54,87.12],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,12,14,15,16,17,18,19,20,22,23],\"y\":[81.42,85.14,85.76,85.96,86.96,86.96,86.96,86.96,87.48,87.48,87.48,87.48,87.48,88.02,88.02,88.02,88.02,88.02,88.02,88.02,88.02],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('844e23c1-e7c4-47dd-aa84-54bea3041563');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "opt_hist = optuna.visualization.plot_optimization_history(study)\n",
        "\n",
        "opt_hist.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "opt_hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttCK-I3f1olz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2b5075cc-f6b9-450c-ee4f-630928b32a01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ebb31b8a-b414-4d35-b0fd-6702e59b597f\")) {                    Plotly.newPlot(                        \"ebb31b8a-b414-4d35-b0fd-6702e59b597f\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[54.4,64,128,192,256,265.6],\"y\":[8.169610120215257e-06,1.2760918088428318e-05,1.9851358937422513e-05,6.895371131358072e-05,0.00015387349104295094,0.0002492294583100163,0.00026626831184196344,0.000780715307860027,0.0008781984559717051,0.0009089777877470327,0.0016608243757673467,0.002182085616397292,0.003679633596234943,0.005739052585337983,0.0064302752977516645,0.007808464498303689,0.017705749117129983,0.029621233669222247,0.03052954516379949,0.03297036376254276,0.04643207616533176,0.09538799451770531,0.1489958965909395],\"z\":[[null,null,null,null,null,null],[null,null,null,85.96,null,null],[null,null,null,null,86.32,null],[null,null,null,null,86.48,null],[null,null,null,null,86.62,null],[null,null,null,null,87.48,null],[null,null,null,null,86.98,null],[null,86.82,null,null,null,null],[null,88.02,null,null,null,null],[null,null,86.84,null,null,null],[null,null,null,86.48,null,null],[null,null,87.54,null,null,null],[null,86.96,null,null,null,null],[null,null,87.9,null,null,null],[null,87.5,null,null,null,null],[null,87.94,null,null,null,null],[null,null,null,null,85.76,null],[null,null,null,85.14,null,null],[null,null,84.8,null,null,null],[null,null,null,86.88,null,null],[null,null,null,81.42,null,null],[null,87.12,null,null,null,null],[null,null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[192,192,256,192,64,192,256,128,256,192,256,256,256,64,64,128,64,128,64,128,64],\"y\":[0.04643207616533176,0.029621233669222247,0.017705749117129983,1.2760918088428318e-05,0.003679633596234943,0.0016608243757673467,1.9851358937422513e-05,0.03052954516379949,0.0002492294583100163,0.03297036376254276,0.00026626831184196344,0.00015387349104295094,6.895371131358072e-05,0.0008781984559717051,0.000780715307860027,0.005739052585337983,0.0064302752977516645,0.0009089777877470327,0.007808464498303689,0.002182085616397292,0.09538799451770531],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"batch_size\"},\"range\":[54.4,265.6]},\"yaxis\":{\"title\":{\"text\":\"lr\"},\"range\":[-5.087798668887335,-0.8268256920739774],\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ebb31b8a-b414-4d35-b0fd-6702e59b597f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "i2J9SpQJ1sy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2141417f-a32b-48c1-c840-e59404d00512"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\")) {                    Plotly.newPlot(                        \"9f11ba62-5e0f-4a52-a81c-8ca76f07db38\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"dropout_rate2 (FloatDistribution): 0.02052906992009996<extra></extra>\",\"batch_size (IntDistribution): 0.04208505899340595<extra></extra>\",\"dropout_rate (FloatDistribution): 0.09134791826999204<extra></extra>\",\"optimizer (CategoricalDistribution): 0.11600269442598625<extra></extra>\",\"lr (FloatDistribution): 0.24782621733655558<extra></extra>\",\"momentum (FloatDistribution): 0.48220904105396<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02\",\"0.04\",\"0.09\",\"0.12\",\"0.25\",\"0.48\"],\"textposition\":\"outside\",\"x\":[0.02052906992009996,0.04208505899340595,0.09134791826999204,0.11600269442598625,0.24782621733655558,0.48220904105396],\"y\":[\"dropout_rate2\",\"batch_size\",\"dropout_rate\",\"optimizer\",\"lr\",\"momentum\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f11ba62-5e0f-4a52-a81c-8ca76f07db38');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "param_importance_fig = optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "param_importance_fig.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "param_importance_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3tpr4KK2RVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c076844-1436-46ba-a10d-fcabf8929120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Number of finished trials:  25\n",
            "  Number of pruned trials:  4\n",
            "  Number of complete trials:  21\n"
          ]
        }
      ],
      "source": [
        "from optuna.trial import TrialState\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize the reult\n",
        "\n",
        "SERIALIZATION_DIR = \"\" \n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('study_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(study, f)\n",
        "\n",
        "with open('df_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ],
      "metadata": {
        "id": "UUoh2I8hGQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best model is\")\n",
        "\n",
        "print(trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj0rployJanz",
        "outputId": "7d93d6a4-b511-4056-bb1a-e2c89bed77ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model is\n",
            "{'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'RMSprop', 'momentum': 0.26582732909111395, 'lr': 0.0008781984559717051, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_2(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "  # trying different optimizers\n",
        "\n",
        "  optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "                                                                   \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 64, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  # run for 100 epochs once the best model is found \n",
        "  NUM_EPOCHS = 25\n",
        "\n",
        "  for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader)\n",
        "      accuracy = evaluate(epoch)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "OntkPiXekwLR"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Optuna with Ada family optimizers\")\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18-Ada\")\n",
        "\n",
        "study.optimize(objective_2, n_trials = 5)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTR21sA2lAnX",
        "outputId": "8ff864e1-f932-4a62-a152-00254aec93fb"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 05:08:12,652]\u001b[0m A new study created in memory with name: resNet-18-Ada\u001b[0m\n",
            "\u001b[33m[W 2022-11-22 05:08:12,755]\u001b[0m Trial 0 failed because of the following error: UnboundLocalError(\"local variable 'net' referenced before assignment\")\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-108-96c6e15fe7e7>\", line 7, in objective_2\n",
            "    net = torch.nn.DataParallel(net)\n",
            "UnboundLocalError: local variable 'net' referenced before assignment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Optuna with Ada family optimizers\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-d074b36b17ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resNet-18-Ada\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-96c6e15fe7e7>\u001b[0m in \u001b[0;36mobjective_2\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'net' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Model Visualization with Tensorboard</h1>"
      ],
      "metadata": {
        "id": "LP8OFkLJ5nQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odnt6T_i5mcA",
        "outputId": "fca4db79-ff96-4774-e1de-687c181bd165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.38.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in shell: tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "UVF5Rs1yg8-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9M0JT27NZn",
        "outputId": "fa927eb0-3d81-4811-ab7c-630f16ac158d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 0.943s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lt --port 6006"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6l8H9BXcLp-",
        "outputId": "d567fcb6-1bcf-440b-e87e-0cca3e4723bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://legal-mails-turn-34-73-105-255.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running the best model for 100 epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr94MEgvcQAe",
        "outputId": "8ef084f8-974b-4198-8a02-04a80d1a8b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the best model for 100 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jsjhfhfhhfhf"
      ],
      "metadata": {
        "id": "HD9CHX5P7WDw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}