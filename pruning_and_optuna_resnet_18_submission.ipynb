{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaBEihcdtk8",
        "outputId": "a02db347-e397-4df0-af5f-9c3d07c4e794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXI-w576XzT_"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "import torch as torch\n",
        "\n",
        "\n",
        "def set_up_ssl():\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "set_up_ssl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC88owTK4XJj"
      },
      "outputs": [],
      "source": [
        "LOCAL_M1 = False\n",
        "\n",
        "if LOCAL_M1:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
        "else:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbtvE4s14XJj",
        "outputId": "c1d65db3-e2ca-42f6-8013-ed432078c882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device:  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTLc4fVcQ857"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# from torchsummary import summary\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "import humanize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAU4PYGddva",
        "outputId": "d3653024-bd73-4844-a600-f237e68073cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Tensorboard writer object\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating Tensorboard writer object\")\n",
        "\n",
        "TENSOR_BOARD_DIR = \"runs/resnet_18\"\n",
        "\n",
        "writer = SummaryWriter(TENSOR_BOARD_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQeGvfSCRM4i"
      },
      "outputs": [],
      "source": [
        "term_width = 5\n",
        "TOTAL_BAR_LENGTH = 7\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
        "\n",
        "    if current < total-1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTCFIHn0XzUL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, trial=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1, step=0.1)\n",
        "            self.drop1 = nn.Dropout2d(p=dropout_rate)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate2 = trial.suggest_float(\"dropout_rate2\", 0, 0.2, step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate2)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        \n",
        "        # adding Optuna dropout trial\n",
        "        if trial is not None:\n",
        "            dropout_rate3 = trial.suggest_float(\"dropout_rate3\", 0, 0.1,\n",
        "                                                step=0.1)\n",
        "            self.drop2 = nn.Dropout2d(p=dropout_rate3)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, trial=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], trial,\n",
        "                                       stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], trial,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], trial,\n",
        "                                       stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], trial,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, trial, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, trial))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(trial=None):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet34(trial=None):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet50(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet101(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], trial=trial)\n",
        "\n",
        "\n",
        "def ResNet152(trial=None):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], trial=trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "3df2267cf8d54d74aaa803ab0a7f39d5",
            "a4fd0e91c384433c9e4e86677551a5eb",
            "75fb31bd9ee64e3c8fe52490f031d917",
            "c411225fe7b9462bbbef20d707e9b184",
            "ae4f75575c494f9aa028a84b27b35718",
            "f0361accc5944588b1f28e440421b32d",
            "0a3dee7be8734ab99425179b2d0a37d2",
            "1346132be0c544bdb53d0985afeb9db0",
            "91f2e2b1de884cfe875db6b983566fb3",
            "b432d075aafa47cb8121b097d421733e",
            "fcfc666db5a6422b95ae3115185ae4af"
          ]
        },
        "id": "N_K9-VkFRsiL",
        "outputId": "e3b5e70f-f7dc-4249-aee9-1bf89dd153a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3df2267cf8d54d74aaa803ab0a7f39d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "The length of a train set is  45000\n",
            "The length of a validation set is  5000\n",
            "The length of a test set is  10000\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# constructing validation set\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(trainset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)\n",
        "print(\"The length of a train set is \", len(train_ds))\n",
        "print(\"The length of a validation set is \", len(val_ds))\n",
        "print(\"The length of a test set is \", len(testset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = ResNet18() # 11.2 params\n",
        "#net = ResNet50() # 23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbzjCm0gOElC",
        "outputId": "f1783bbc-f083-4252-a342-5d6745ee7501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "layers[0]:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "layers[1]:  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "layers[2]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[3]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[4]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[5]:  Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential()\n",
            "  )\n",
            ")\n",
            "layers[6]:  Linear(in_features=512, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "layers = list(net.children())\n",
        "\n",
        "print(len(layers))\n",
        "\n",
        "print(\"layers[0]: \", layers[0])\n",
        "print(\"layers[1]: \", layers[1])\n",
        "print(\"layers[2]: \", layers[2])\n",
        "print(\"layers[3]: \", layers[3])\n",
        "print(\"layers[4]: \", layers[4])\n",
        "print(\"layers[5]: \", layers[5])\n",
        "print(\"layers[6]: \", layers[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhtblo5n4uKQ",
        "outputId": "73870da1-5fce-4c9f-e69c-4098585c48af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-0.2.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_pruning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch_pruning) (4.1.1)\n",
            "Installing collected packages: torch-pruning\n",
            "Successfully installed torch-pruning-0.2.8\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing Torch_Pruning module to be used for model size reduction\")\n",
        "\n",
        "!pip install torch_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M1xDV4-VaKG"
      },
      "outputs": [],
      "source": [
        "import torch_pruning as tp\n",
        "\n",
        "def prune_model(model):\n",
        "    model.cpu()\n",
        "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 3, 32, 32) )\n",
        "    def prune_conv(conv, amount=0.2):\n",
        "        strategy = tp.strategy.L1Strategy()\n",
        "        pruning_index = strategy(conv.weight, amount=amount)\n",
        "        plan = DG.get_pruning_plan(conv, tp.prune_conv_out_channel, pruning_index)\n",
        "        plan.exec()\n",
        "    \n",
        "    block_prune_probs = [0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3]\n",
        "    blk_id = 0\n",
        "    for m in model.modules():\n",
        "        if isinstance( m, BasicBlock):\n",
        "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
        "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
        "            blk_id+=1\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgQPV3H4ZTxA"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def print_params(model):\n",
        "  print(\"Number of parameters \", humanize.intword(count_parameters(model)))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkbs0btThnx",
        "outputId": "6071538e-8b91-47d6-b424-ee87adeebd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of parameters before pruning is \n",
            "Number of parameters  11.2 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters before pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duOPOJDMV2Vn",
        "outputId": "9122f6c8-4135-489c-d3ba-5b31c96e7a28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(53, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(53, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(53, 83, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(83, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(103, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(83, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(83, 164, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(164, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(205, 164, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(164, 359, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(164, 252, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(252, 359, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(359, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(359, 252, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=252, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Pruning the model...\")\n",
        "prune_model(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAZTZsHwTyOK",
        "outputId": "6e5e7d5b-e1f5-4168-ce0a-d771e54bbeb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of parameters after pruning is \n",
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters after pruning is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqr1gYtVHgE",
        "outputId": "ce483cee-21fd-48ed-b051-c4a2d4430ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 53, 32, 32]           1,431\n",
            "       BatchNorm2d-2           [-1, 53, 32, 32]             106\n",
            "            Conv2d-3           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-4           [-1, 58, 32, 32]             116\n",
            "            Conv2d-5           [-1, 53, 32, 32]          27,666\n",
            "       BatchNorm2d-6           [-1, 53, 32, 32]             106\n",
            "        BasicBlock-7           [-1, 53, 32, 32]               0\n",
            "            Conv2d-8           [-1, 58, 32, 32]          27,666\n",
            "       BatchNorm2d-9           [-1, 58, 32, 32]             116\n",
            "           Conv2d-10           [-1, 53, 32, 32]          27,666\n",
            "      BatchNorm2d-11           [-1, 53, 32, 32]             106\n",
            "       BasicBlock-12           [-1, 53, 32, 32]               0\n",
            "           Conv2d-13          [-1, 103, 16, 16]          49,131\n",
            "      BatchNorm2d-14          [-1, 103, 16, 16]             206\n",
            "           Conv2d-15           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-16           [-1, 83, 16, 16]             166\n",
            "           Conv2d-17           [-1, 83, 16, 16]           4,399\n",
            "      BatchNorm2d-18           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-19           [-1, 83, 16, 16]               0\n",
            "           Conv2d-20          [-1, 103, 16, 16]          76,941\n",
            "      BatchNorm2d-21          [-1, 103, 16, 16]             206\n",
            "           Conv2d-22           [-1, 83, 16, 16]          76,941\n",
            "      BatchNorm2d-23           [-1, 83, 16, 16]             166\n",
            "       BasicBlock-24           [-1, 83, 16, 16]               0\n",
            "           Conv2d-25            [-1, 205, 8, 8]         153,135\n",
            "      BatchNorm2d-26            [-1, 205, 8, 8]             410\n",
            "           Conv2d-27            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-28            [-1, 164, 8, 8]             328\n",
            "           Conv2d-29            [-1, 164, 8, 8]          13,612\n",
            "      BatchNorm2d-30            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-31            [-1, 164, 8, 8]               0\n",
            "           Conv2d-32            [-1, 205, 8, 8]         302,580\n",
            "      BatchNorm2d-33            [-1, 205, 8, 8]             410\n",
            "           Conv2d-34            [-1, 164, 8, 8]         302,580\n",
            "      BatchNorm2d-35            [-1, 164, 8, 8]             328\n",
            "       BasicBlock-36            [-1, 164, 8, 8]               0\n",
            "           Conv2d-37            [-1, 359, 4, 4]         529,884\n",
            "      BatchNorm2d-38            [-1, 359, 4, 4]             718\n",
            "           Conv2d-39            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-40            [-1, 252, 4, 4]             504\n",
            "           Conv2d-41            [-1, 252, 4, 4]          41,328\n",
            "      BatchNorm2d-42            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-43            [-1, 252, 4, 4]               0\n",
            "           Conv2d-44            [-1, 359, 4, 4]         814,212\n",
            "      BatchNorm2d-45            [-1, 359, 4, 4]             718\n",
            "           Conv2d-46            [-1, 252, 4, 4]         814,212\n",
            "      BatchNorm2d-47            [-1, 252, 4, 4]             504\n",
            "       BasicBlock-48            [-1, 252, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           2,530\n",
            "================================================================\n",
            "Total params: 4,493,525\n",
            "Trainable params: 4,493,525\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 8.69\n",
            "Params size (MB): 17.14\n",
            "Estimated Total Size (MB): 25.84\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def print_model_summary(model):\n",
        "  print(summary(model.to(device), (3, 32, 32)))\n",
        "\n",
        "print_model_summary(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tejFfYvQJxR5",
        "outputId": "9e109609-cb8d-4dd6-9671-e27c13d6482b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight torch.Size([53, 3, 3, 3])\n",
            "bn1.weight torch.Size([53])\n",
            "bn1.bias torch.Size([53])\n",
            "layer1.0.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([58])\n",
            "layer1.0.bn1.bias torch.Size([58])\n",
            "layer1.0.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([53])\n",
            "layer1.0.bn2.bias torch.Size([53])\n",
            "layer1.1.conv1.weight torch.Size([58, 53, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([58])\n",
            "layer1.1.bn1.bias torch.Size([58])\n",
            "layer1.1.conv2.weight torch.Size([53, 58, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([53])\n",
            "layer1.1.bn2.bias torch.Size([53])\n",
            "layer2.0.conv1.weight torch.Size([103, 53, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([103])\n",
            "layer2.0.bn1.bias torch.Size([103])\n",
            "layer2.0.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([83])\n",
            "layer2.0.bn2.bias torch.Size([83])\n",
            "layer2.0.shortcut.0.weight torch.Size([83, 53, 1, 1])\n",
            "layer2.0.shortcut.1.weight torch.Size([83])\n",
            "layer2.0.shortcut.1.bias torch.Size([83])\n",
            "layer2.1.conv1.weight torch.Size([103, 83, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([103])\n",
            "layer2.1.bn1.bias torch.Size([103])\n",
            "layer2.1.conv2.weight torch.Size([83, 103, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([83])\n",
            "layer2.1.bn2.bias torch.Size([83])\n",
            "layer3.0.conv1.weight torch.Size([205, 83, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([205])\n",
            "layer3.0.bn1.bias torch.Size([205])\n",
            "layer3.0.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([164])\n",
            "layer3.0.bn2.bias torch.Size([164])\n",
            "layer3.0.shortcut.0.weight torch.Size([164, 83, 1, 1])\n",
            "layer3.0.shortcut.1.weight torch.Size([164])\n",
            "layer3.0.shortcut.1.bias torch.Size([164])\n",
            "layer3.1.conv1.weight torch.Size([205, 164, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([205])\n",
            "layer3.1.bn1.bias torch.Size([205])\n",
            "layer3.1.conv2.weight torch.Size([164, 205, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([164])\n",
            "layer3.1.bn2.bias torch.Size([164])\n",
            "layer4.0.conv1.weight torch.Size([359, 164, 3, 3])\n",
            "layer4.0.bn1.weight torch.Size([359])\n",
            "layer4.0.bn1.bias torch.Size([359])\n",
            "layer4.0.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([252])\n",
            "layer4.0.bn2.bias torch.Size([252])\n",
            "layer4.0.shortcut.0.weight torch.Size([252, 164, 1, 1])\n",
            "layer4.0.shortcut.1.weight torch.Size([252])\n",
            "layer4.0.shortcut.1.bias torch.Size([252])\n",
            "layer4.1.conv1.weight torch.Size([359, 252, 3, 3])\n",
            "layer4.1.bn1.weight torch.Size([359])\n",
            "layer4.1.bn1.bias torch.Size([359])\n",
            "layer4.1.conv2.weight torch.Size([252, 359, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([252])\n",
            "layer4.1.bn2.bias torch.Size([252])\n",
            "linear.weight torch.Size([10, 252])\n",
            "linear.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "def print_model_layers(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "print_model_layers(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3kWtBzVWg3Y"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "# ********* Hand-Set model parameters ***********\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
        "                       momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# ********* Hand-Set model parameters ***********\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "lr = 0.0008781984559717051\n",
        "\n",
        "momentum = 0.26582732909111395\n",
        "\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=lr,\n",
        "                       momentum = momentum)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# *********** model parameters found with Optuna ************** #\n",
        "\n",
        "\n",
        "# writing data to TensorBoard\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "writer.add_image('images', grid, 0)\n",
        "writer.add_graph(net, images)\n",
        "writer.close()\n",
        "\n",
        "# --------------------------------------- # \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "save_loss = {'train':[], 'test':[]}\n",
        "save_acc = {'train':[], 'test':[]}\n",
        "\n",
        "train_acc_array, train_loss_array = [], [] # for plotting\n",
        "val_acc_array, val_loss_array = [], [] # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIzJObnOWz2d"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch, model=net, train_loader=trainloader, optim=optimizer):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_acc = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optim.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_acc=100.*correct/total\n",
        "        progress_bar(batch_idx, len(train_loader), 'Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    train_acc_array.append(train_acc) # for plottting\n",
        "    train_loss_array.append(train_loss) # for plottting\n",
        "    writer.add_scalar('training loss', train_loss)\n",
        "    writer.add_scalar('training accuracy', train_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CHlPBF6uIhT"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch, model=net, validation_loader=val_loader): # validation\n",
        "   \n",
        "    global best_acc\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(validation_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(validation_loader), 'Valid Loss: %.3f | Valid Acc: %.3f%% (%d/%d)'\n",
        "                         % (valid_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    valid_acc = 100.*correct/total\n",
        "    if valid_acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net_state_dict': model.state_dict(),\n",
        "            'acc': valid_acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = valid_acc\n",
        "    val_acc_array.append(valid_acc) # for plottting\n",
        "    val_loss_array.append(valid_loss) # for plottting\n",
        "    writer.add_scalar('validation loss', valid_loss)\n",
        "    writer.add_scalar('validation accuracy', valid_acc)\n",
        "    return valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5i2dqetBgXp"
      },
      "outputs": [],
      "source": [
        "# Load the best model parameters (measured in terms of validation loss) and evaluate the loss/accuracy on the test set.\n",
        "def test(model=net):\n",
        "   \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "    model.load_state_dict(checkpoint['net_state_dict'])\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    best_acc = checkpoint['acc']\n",
        "    model.eval()\n",
        "    print(f'Best validation acc: {best_acc:.3f}% at Epoch {best_epoch}')\n",
        "    with torch.no_grad():\n",
        "          \n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyuhb-GrXzUo",
        "outputId": "9854b62d-39a7-41ef-9665-94bf96d39a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device  cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HcWh5aXzUq",
        "outputId": "784216fd-bad3-4fec-e328-439915c4a414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters before training is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJcMkrBzW7o7",
        "outputId": "27f61c7a-0bae-496a-a9b7-9637e1f1346d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 50ms | Tot: 28s665ms | Train Loss: 1.111 | Train Acc: 60.824% (27371/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 1.031 | Valid Acc: 63.080% (3154/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 48ms | Tot: 28s759ms | Train Loss: 0.947 | Train Acc: 66.471% (29912/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s22ms | Valid Loss: 1.005 | Valid Acc: 63.840% (3192/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.857 | Train Acc: 70.096% (31543/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.932 | Valid Acc: 67.060% (3353/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 50ms | Tot: 28s522ms | Train Loss: 0.774 | Train Acc: 72.878% (32795/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s14ms | Valid Loss: 0.810 | Valid Acc: 71.040% (3552/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 48ms | Tot: 28s418ms | Train Loss: 0.717 | Train Acc: 74.871% (33692/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s182ms | Valid Loss: 0.743 | Valid Acc: 74.080% (3704/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 51ms | Tot: 28s571ms | Train Loss: 0.674 | Train Acc: 76.378% (34370/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s13ms | Valid Loss: 0.792 | Valid Acc: 73.040% (3652/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.633 | Train Acc: 78.022% (35110/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s974ms | Valid Loss: 0.804 | Valid Acc: 72.920% (3646/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 49ms | Tot: 28s574ms | Train Loss: 0.600 | Train Acc: 79.091% (35591/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s28ms | Valid Loss: 0.687 | Valid Acc: 75.840% (3792/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 52ms | Tot: 28s506ms | Train Loss: 0.580 | Train Acc: 80.016% (36007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s9ms | Valid Loss: 0.685 | Valid Acc: 76.740% (3837/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.545 | Train Acc: 81.111% (36500/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s54ms | Valid Loss: 0.637 | Valid Acc: 78.360% (3918/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 50ms | Tot: 28s456ms | Train Loss: 0.521 | Train Acc: 81.704% (36767/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.684 | Valid Acc: 76.480% (3824/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 49ms | Tot: 28s505ms | Train Loss: 0.499 | Train Acc: 82.687% (37209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.602 | Valid Acc: 78.900% (3945/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 50ms | Tot: 28s536ms | Train Loss: 0.482 | Train Acc: 83.049% (37372/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.584 | Valid Acc: 79.780% (3989/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 49ms | Tot: 28s491ms | Train Loss: 0.471 | Train Acc: 83.607% (37623/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s988ms | Valid Loss: 0.609 | Valid Acc: 79.140% (3957/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 48ms | Tot: 28s447ms | Train Loss: 0.450 | Train Acc: 84.411% (37985/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s5ms | Valid Loss: 0.613 | Valid Acc: 78.460% (3923/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.435 | Train Acc: 84.836% (38176/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s38ms | Valid Loss: 0.577 | Valid Acc: 80.200% (4010/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 50ms | Tot: 28s473ms | Train Loss: 0.423 | Train Acc: 85.196% (38338/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s991ms | Valid Loss: 0.536 | Valid Acc: 81.340% (4067/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 50ms | Tot: 28s765ms | Train Loss: 0.408 | Train Acc: 85.740% (38583/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s4ms | Valid Loss: 0.539 | Valid Acc: 81.700% (4085/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 49ms | Tot: 28s482ms | Train Loss: 0.406 | Train Acc: 85.764% (38594/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s10ms | Valid Loss: 0.537 | Valid Acc: 81.480% (4074/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 52ms | Tot: 28s565ms | Train Loss: 0.388 | Train Acc: 86.364% (38864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.556 | Valid Acc: 81.540% (4077/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 20\n",
            " [======>]  Step: 50ms | Tot: 28s479ms | Train Loss: 0.372 | Train Acc: 86.860% (39087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.525 | Valid Acc: 82.720% (4136/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 21\n",
            " [======>]  Step: 53ms | Tot: 28s451ms | Train Loss: 0.366 | Train Acc: 87.129% (39208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s363ms | Valid Loss: 0.519 | Valid Acc: 82.360% (4118/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 22\n",
            " [======>]  Step: 51ms | Tot: 28s453ms | Train Loss: 0.359 | Train Acc: 87.496% (39373/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 13ms | Tot: 2s76ms | Valid Loss: 0.508 | Valid Acc: 82.600% (4130/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 23\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.353 | Train Acc: 87.642% (39439/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s989ms | Valid Loss: 0.530 | Valid Acc: 82.180% (4109/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 24\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.344 | Train Acc: 87.833% (39525/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s44ms | Valid Loss: 0.534 | Valid Acc: 81.860% (4093/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 25\n",
            " [======>]  Step: 49ms | Tot: 28s453ms | Train Loss: 0.340 | Train Acc: 88.120% (39654/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s981ms | Valid Loss: 0.537 | Valid Acc: 82.220% (4111/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 26\n",
            " [======>]  Step: 50ms | Tot: 28s569ms | Train Loss: 0.331 | Train Acc: 88.502% (39826/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s991ms | Valid Loss: 0.503 | Valid Acc: 82.940% (4147/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 27\n",
            " [======>]  Step: 49ms | Tot: 28s539ms | Train Loss: 0.319 | Train Acc: 88.809% (39964/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s972ms | Valid Loss: 0.488 | Valid Acc: 83.240% (4162/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 28\n",
            " [======>]  Step: 51ms | Tot: 28s526ms | Train Loss: 0.312 | Train Acc: 89.100% (40095/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s952ms | Valid Loss: 0.481 | Valid Acc: 84.220% (4211/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 29\n",
            " [======>]  Step: 50ms | Tot: 28s527ms | Train Loss: 0.307 | Train Acc: 89.258% (40166/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.486 | Valid Acc: 84.440% (4222/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 30\n",
            " [======>]  Step: 51ms | Tot: 28s444ms | Train Loss: 0.302 | Train Acc: 89.658% (40346/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s970ms | Valid Loss: 0.480 | Valid Acc: 83.540% (4177/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 31\n",
            " [======>]  Step: 51ms | Tot: 28s530ms | Train Loss: 0.295 | Train Acc: 89.702% (40366/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s969ms | Valid Loss: 0.460 | Valid Acc: 84.760% (4238/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 32\n",
            " [======>]  Step: 52ms | Tot: 28s478ms | Train Loss: 0.292 | Train Acc: 89.962% (40483/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s989ms | Valid Loss: 0.464 | Valid Acc: 85.220% (4261/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 33\n",
            " [======>]  Step: 51ms | Tot: 28s456ms | Train Loss: 0.283 | Train Acc: 90.127% (40557/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s996ms | Valid Loss: 0.467 | Valid Acc: 84.860% (4243/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 34\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.282 | Train Acc: 90.104% (40547/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s932ms | Valid Loss: 0.521 | Valid Acc: 84.020% (4201/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 35\n",
            " [======>]  Step: 52ms | Tot: 28s466ms | Train Loss: 0.276 | Train Acc: 90.360% (40662/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s24ms | Valid Loss: 0.493 | Valid Acc: 84.380% (4219/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 36\n",
            " [======>]  Step: 48ms | Tot: 28s541ms | Train Loss: 0.272 | Train Acc: 90.544% (40745/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s995ms | Valid Loss: 0.472 | Valid Acc: 84.360% (4218/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 37\n",
            " [======>]  Step: 52ms | Tot: 28s482ms | Train Loss: 0.263 | Train Acc: 90.896% (40903/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s972ms | Valid Loss: 0.469 | Valid Acc: 84.660% (4233/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 38\n",
            " [======>]  Step: 49ms | Tot: 28s391ms | Train Loss: 0.264 | Train Acc: 90.831% (40874/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s263ms | Valid Loss: 0.480 | Valid Acc: 84.480% (4224/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 39\n",
            " [======>]  Step: 50ms | Tot: 28s508ms | Train Loss: 0.259 | Train Acc: 90.858% (40886/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s962ms | Valid Loss: 0.476 | Valid Acc: 85.020% (4251/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 40\n",
            " [======>]  Step: 52ms | Tot: 28s546ms | Train Loss: 0.256 | Train Acc: 91.071% (40982/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s935ms | Valid Loss: 0.477 | Valid Acc: 84.580% (4229/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 41\n",
            " [======>]  Step: 51ms | Tot: 28s573ms | Train Loss: 0.245 | Train Acc: 91.404% (41132/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s963ms | Valid Loss: 0.447 | Valid Acc: 86.200% (4310/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 42\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.248 | Train Acc: 91.451% (41153/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s999ms | Valid Loss: 0.500 | Valid Acc: 85.340% (4267/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 43\n",
            " [======>]  Step: 54ms | Tot: 28s511ms | Train Loss: 0.245 | Train Acc: 91.331% (41099/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 2s295ms | Valid Loss: 0.477 | Valid Acc: 85.320% (4266/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 44\n",
            " [======>]  Step: 51ms | Tot: 28s468ms | Train Loss: 0.241 | Train Acc: 91.576% (41209/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s924ms | Valid Loss: 0.435 | Valid Acc: 85.440% (4272/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 45\n",
            " [======>]  Step: 50ms | Tot: 28s476ms | Train Loss: 0.235 | Train Acc: 91.836% (41326/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.475 | Valid Acc: 85.660% (4283/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 46\n",
            " [======>]  Step: 52ms | Tot: 28s576ms | Train Loss: 0.230 | Train Acc: 92.040% (41418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s971ms | Valid Loss: 0.439 | Valid Acc: 86.300% (4315/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 47\n",
            " [======>]  Step: 51ms | Tot: 28s477ms | Train Loss: 0.223 | Train Acc: 92.176% (41479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s960ms | Valid Loss: 0.453 | Valid Acc: 85.500% (4275/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 48\n",
            " [======>]  Step: 50ms | Tot: 28s576ms | Train Loss: 0.223 | Train Acc: 92.371% (41567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.432 | Valid Acc: 86.480% (4324/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 49\n",
            " [======>]  Step: 49ms | Tot: 28s480ms | Train Loss: 0.218 | Train Acc: 92.413% (41586/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s15ms | Valid Loss: 0.444 | Valid Acc: 86.060% (4303/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 50\n",
            " [======>]  Step: 51ms | Tot: 28s466ms | Train Loss: 0.217 | Train Acc: 92.320% (41544/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s973ms | Valid Loss: 0.451 | Valid Acc: 85.840% (4292/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 51\n",
            " [======>]  Step: 51ms | Tot: 28s525ms | Train Loss: 0.212 | Train Acc: 92.591% (41666/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s161ms | Valid Loss: 0.444 | Valid Acc: 86.180% (4309/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 52\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.215 | Train Acc: 92.513% (41631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s993ms | Valid Loss: 0.466 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 53\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.204 | Train Acc: 92.889% (41800/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.473 | Valid Acc: 86.520% (4326/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 54\n",
            " [======>]  Step: 52ms | Tot: 28s525ms | Train Loss: 0.207 | Train Acc: 92.693% (41712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.460 | Valid Acc: 85.900% (4295/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 55\n",
            " [======>]  Step: 50ms | Tot: 28s462ms | Train Loss: 0.206 | Train Acc: 92.784% (41753/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s51ms | Valid Loss: 0.455 | Valid Acc: 85.980% (4299/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 56\n",
            " [======>]  Step: 51ms | Tot: 28s540ms | Train Loss: 0.195 | Train Acc: 93.007% (41853/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s31ms | Valid Loss: 0.482 | Valid Acc: 85.420% (4271/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 57\n",
            " [======>]  Step: 51ms | Tot: 28s457ms | Train Loss: 0.196 | Train Acc: 93.393% (42027/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s998ms | Valid Loss: 0.470 | Valid Acc: 86.680% (4334/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 58\n",
            " [======>]  Step: 50ms | Tot: 28s578ms | Train Loss: 0.194 | Train Acc: 93.309% (41989/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s952ms | Valid Loss: 0.468 | Valid Acc: 86.320% (4316/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 59\n",
            " [======>]  Step: 50ms | Tot: 28s689ms | Train Loss: 0.193 | Train Acc: 93.324% (41996/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s999ms | Valid Loss: 0.473 | Valid Acc: 86.900% (4345/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 60\n",
            " [======>]  Step: 49ms | Tot: 28s470ms | Train Loss: 0.190 | Train Acc: 93.351% (42008/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s85ms | Valid Loss: 0.452 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 61\n",
            " [======>]  Step: 51ms | Tot: 28s524ms | Train Loss: 0.190 | Train Acc: 93.542% (42094/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s17ms | Valid Loss: 0.409 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 62\n",
            " [======>]  Step: 48ms | Tot: 28s463ms | Train Loss: 0.184 | Train Acc: 93.631% (42134/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s993ms | Valid Loss: 0.414 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 63\n",
            " [======>]  Step: 51ms | Tot: 28s744ms | Train Loss: 0.184 | Train Acc: 93.653% (42144/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s961ms | Valid Loss: 0.408 | Valid Acc: 87.560% (4378/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 64\n",
            " [======>]  Step: 52ms | Tot: 28s463ms | Train Loss: 0.180 | Train Acc: 93.756% (42190/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s928ms | Valid Loss: 0.413 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 65\n",
            " [======>]  Step: 51ms | Tot: 28s594ms | Train Loss: 0.180 | Train Acc: 93.851% (42233/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s240ms | Valid Loss: 0.434 | Valid Acc: 86.660% (4333/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 66\n",
            " [======>]  Step: 52ms | Tot: 28s465ms | Train Loss: 0.176 | Train Acc: 93.924% (42266/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s987ms | Valid Loss: 0.411 | Valid Acc: 87.740% (4387/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 67\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.177 | Train Acc: 93.918% (42263/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s32ms | Valid Loss: 0.417 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 68\n",
            " [======>]  Step: 51ms | Tot: 28s577ms | Train Loss: 0.172 | Train Acc: 93.971% (42287/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.466 | Valid Acc: 86.700% (4335/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 69\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.175 | Train Acc: 93.867% (42240/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s977ms | Valid Loss: 0.454 | Valid Acc: 86.980% (4349/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 70\n",
            " [======>]  Step: 51ms | Tot: 28s523ms | Train Loss: 0.166 | Train Acc: 94.107% (42348/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s963ms | Valid Loss: 0.437 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 71\n",
            " [======>]  Step: 51ms | Tot: 28s474ms | Train Loss: 0.167 | Train Acc: 94.164% (42374/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s992ms | Valid Loss: 0.444 | Valid Acc: 87.000% (4350/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 72\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.163 | Train Acc: 94.398% (42479/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s973ms | Valid Loss: 0.426 | Valid Acc: 87.620% (4381/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 73\n",
            " [======>]  Step: 52ms | Tot: 28s561ms | Train Loss: 0.163 | Train Acc: 94.242% (42409/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s978ms | Valid Loss: 0.434 | Valid Acc: 87.700% (4385/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 74\n",
            " [======>]  Step: 51ms | Tot: 28s568ms | Train Loss: 0.161 | Train Acc: 94.502% (42526/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s995ms | Valid Loss: 0.448 | Valid Acc: 86.860% (4343/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 75\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.163 | Train Acc: 94.367% (42465/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s958ms | Valid Loss: 0.430 | Valid Acc: 87.540% (4377/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 76\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.159 | Train Acc: 94.596% (42568/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s51ms | Valid Loss: 0.408 | Valid Acc: 87.660% (4383/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 77\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.155 | Train Acc: 94.616% (42577/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.429 | Valid Acc: 87.260% (4363/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 78\n",
            " [======>]  Step: 50ms | Tot: 28s531ms | Train Loss: 0.154 | Train Acc: 94.591% (42566/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s56ms | Valid Loss: 0.426 | Valid Acc: 87.300% (4365/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 79\n",
            " [======>]  Step: 51ms | Tot: 28s447ms | Train Loss: 0.158 | Train Acc: 94.369% (42466/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s21ms | Valid Loss: 0.455 | Valid Acc: 87.400% (4370/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 80\n",
            " [======>]  Step: 50ms | Tot: 28s534ms | Train Loss: 0.154 | Train Acc: 94.553% (42549/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s987ms | Valid Loss: 0.434 | Valid Acc: 88.500% (4425/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 81\n",
            " [======>]  Step: 52ms | Tot: 28s490ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s944ms | Valid Loss: 0.445 | Valid Acc: 87.140% (4357/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 82\n",
            " [======>]  Step: 51ms | Tot: 28s500ms | Train Loss: 0.150 | Train Acc: 94.778% (42650/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s963ms | Valid Loss: 0.416 | Valid Acc: 88.160% (4408/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 83\n",
            " [======>]  Step: 49ms | Tot: 28s553ms | Train Loss: 0.146 | Train Acc: 94.922% (42715/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s960ms | Valid Loss: 0.417 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 84\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.146 | Train Acc: 95.029% (42763/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s966ms | Valid Loss: 0.473 | Valid Acc: 87.600% (4380/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 85\n",
            " [======>]  Step: 51ms | Tot: 28s555ms | Train Loss: 0.144 | Train Acc: 94.998% (42749/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s973ms | Valid Loss: 0.431 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 86\n",
            " [======>]  Step: 50ms | Tot: 28s554ms | Train Loss: 0.145 | Train Acc: 94.984% (42743/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s937ms | Valid Loss: 0.441 | Valid Acc: 87.820% (4391/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 87\n",
            " [======>]  Step: 49ms | Tot: 28s520ms | Train Loss: 0.140 | Train Acc: 95.062% (42778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s54ms | Valid Loss: 0.406 | Valid Acc: 88.560% (4428/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 88\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.138 | Train Acc: 95.376% (42919/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s55ms | Valid Loss: 0.432 | Valid Acc: 87.780% (4389/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 89\n",
            " [======>]  Step: 52ms | Tot: 28s505ms | Train Loss: 0.140 | Train Acc: 95.207% (42843/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s988ms | Valid Loss: 0.447 | Valid Acc: 87.680% (4384/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 90\n",
            " [======>]  Step: 52ms | Tot: 28s566ms | Train Loss: 0.136 | Train Acc: 95.249% (42862/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s931ms | Valid Loss: 0.408 | Valid Acc: 88.440% (4422/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 91\n",
            " [======>]  Step: 51ms | Tot: 28s499ms | Train Loss: 0.140 | Train Acc: 95.231% (42854/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s971ms | Valid Loss: 0.399 | Valid Acc: 88.480% (4424/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 92\n",
            " [======>]  Step: 51ms | Tot: 28s529ms | Train Loss: 0.137 | Train Acc: 95.244% (42860/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s120ms | Valid Loss: 0.416 | Valid Acc: 88.040% (4402/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 93\n",
            " [======>]  Step: 49ms | Tot: 28s555ms | Train Loss: 0.134 | Train Acc: 95.398% (42929/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s943ms | Valid Loss: 0.413 | Valid Acc: 88.580% (4429/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            " [======>]  Step: 50ms | Tot: 28s528ms | Train Loss: 0.132 | Train Acc: 95.362% (42913/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s992ms | Valid Loss: 0.457 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 95\n",
            " [======>]  Step: 51ms | Tot: 28s572ms | Train Loss: 0.131 | Train Acc: 95.518% (42983/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s968ms | Valid Loss: 0.434 | Valid Acc: 88.100% (4405/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 96\n",
            " [======>]  Step: 52ms | Tot: 28s559ms | Train Loss: 0.132 | Train Acc: 95.422% (42940/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.431 | Valid Acc: 88.320% (4416/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 97\n",
            " [======>]  Step: 50ms | Tot: 28s503ms | Train Loss: 0.134 | Train Acc: 95.409% (42934/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s173ms | Valid Loss: 0.400 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 98\n",
            " [======>]  Step: 49ms | Tot: 28s578ms | Train Loss: 0.130 | Train Acc: 95.571% (43007/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s8ms | Valid Loss: 0.419 | Valid Acc: 87.960% (4398/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 99\n",
            " [======>]  Step: 51ms | Tot: 28s502ms | Train Loss: 0.131 | Train Acc: 95.609% (43024/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s968ms | Valid Loss: 0.382 | Valid Acc: 88.300% (4415/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 100\n",
            " [======>]  Step: 50ms | Tot: 28s563ms | Train Loss: 0.127 | Train Acc: 95.644% (43040/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s981ms | Valid Loss: 0.427 | Valid Acc: 88.140% (4407/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 101\n",
            " [======>]  Step: 51ms | Tot: 28s486ms | Train Loss: 0.126 | Train Acc: 95.702% (43066/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s968ms | Valid Loss: 0.399 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 102\n",
            " [======>]  Step: 52ms | Tot: 28s589ms | Train Loss: 0.123 | Train Acc: 95.749% (43087/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s990ms | Valid Loss: 0.426 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 103\n",
            " [======>]  Step: 53ms | Tot: 28s495ms | Train Loss: 0.123 | Train Acc: 95.769% (43096/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s7ms | Valid Loss: 0.429 | Valid Acc: 88.680% (4434/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 104\n",
            " [======>]  Step: 49ms | Tot: 28s538ms | Train Loss: 0.123 | Train Acc: 95.753% (43089/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.418 | Valid Acc: 88.620% (4431/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 105\n",
            " [======>]  Step: 48ms | Tot: 28s571ms | Train Loss: 0.120 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s980ms | Valid Loss: 0.381 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 106\n",
            " [======>]  Step: 50ms | Tot: 28s472ms | Train Loss: 0.121 | Train Acc: 95.733% (43080/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.438 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 107\n",
            " [======>]  Step: 47ms | Tot: 28s553ms | Train Loss: 0.118 | Train Acc: 95.993% (43197/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s960ms | Valid Loss: 0.389 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 108\n",
            " [======>]  Step: 50ms | Tot: 28s483ms | Train Loss: 0.118 | Train Acc: 95.929% (43168/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.413 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 109\n",
            " [======>]  Step: 49ms | Tot: 28s519ms | Train Loss: 0.116 | Train Acc: 95.982% (43192/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s78ms | Valid Loss: 0.403 | Valid Acc: 89.220% (4461/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 110\n",
            " [======>]  Step: 48ms | Tot: 28s528ms | Train Loss: 0.117 | Train Acc: 95.891% (43151/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.434 | Valid Acc: 88.400% (4420/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 111\n",
            " [======>]  Step: 52ms | Tot: 28s518ms | Train Loss: 0.114 | Train Acc: 96.084% (43238/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.415 | Valid Acc: 88.760% (4438/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 112\n",
            " [======>]  Step: 52ms | Tot: 28s603ms | Train Loss: 0.112 | Train Acc: 96.204% (43292/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s40ms | Valid Loss: 0.425 | Valid Acc: 88.420% (4421/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 113\n",
            " [======>]  Step: 50ms | Tot: 28s519ms | Train Loss: 0.113 | Train Acc: 96.067% (43230/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 2s1ms | Valid Loss: 0.374 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 114\n",
            " [======>]  Step: 51ms | Tot: 28s561ms | Train Loss: 0.115 | Train Acc: 96.011% (43205/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 6ms | Tot: 1s947ms | Valid Loss: 0.380 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 115\n",
            " [======>]  Step: 48ms | Tot: 28s488ms | Train Loss: 0.115 | Train Acc: 96.018% (43208/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s18ms | Valid Loss: 0.390 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 116\n",
            " [======>]  Step: 51ms | Tot: 28s482ms | Train Loss: 0.106 | Train Acc: 96.309% (43339/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s954ms | Valid Loss: 0.436 | Valid Acc: 88.780% (4439/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 117\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.106 | Train Acc: 96.313% (43341/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s924ms | Valid Loss: 0.413 | Valid Acc: 89.080% (4454/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 118\n",
            " [======>]  Step: 51ms | Tot: 28s515ms | Train Loss: 0.108 | Train Acc: 96.276% (43324/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s916ms | Valid Loss: 0.403 | Valid Acc: 89.280% (4464/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 119\n",
            " [======>]  Step: 52ms | Tot: 28s535ms | Train Loss: 0.105 | Train Acc: 96.344% (43355/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s941ms | Valid Loss: 0.405 | Valid Acc: 89.100% (4455/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 120\n",
            " [======>]  Step: 53ms | Tot: 28s484ms | Train Loss: 0.108 | Train Acc: 96.233% (43305/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s964ms | Valid Loss: 0.401 | Valid Acc: 89.320% (4466/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 121\n",
            " [======>]  Step: 50ms | Tot: 28s582ms | Train Loss: 0.111 | Train Acc: 96.249% (43312/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s315ms | Valid Loss: 0.391 | Valid Acc: 89.040% (4452/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 122\n",
            " [======>]  Step: 52ms | Tot: 28s512ms | Train Loss: 0.106 | Train Acc: 96.304% (43337/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s4ms | Valid Loss: 0.437 | Valid Acc: 89.000% (4450/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 123\n",
            " [======>]  Step: 49ms | Tot: 28s593ms | Train Loss: 0.105 | Train Acc: 96.351% (43358/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.400 | Valid Acc: 89.200% (4460/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 124\n",
            " [======>]  Step: 50ms | Tot: 28s593ms | Train Loss: 0.101 | Train Acc: 96.422% (43390/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s984ms | Valid Loss: 0.418 | Valid Acc: 88.860% (4443/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 125\n",
            " [======>]  Step: 51ms | Tot: 28s681ms | Train Loss: 0.099 | Train Acc: 96.484% (43418/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s57ms | Valid Loss: 0.401 | Valid Acc: 89.260% (4463/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 126\n",
            " [======>]  Step: 51ms | Tot: 28s538ms | Train Loss: 0.097 | Train Acc: 96.684% (43508/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s6ms | Valid Loss: 0.387 | Valid Acc: 89.480% (4474/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 127\n",
            " [======>]  Step: 50ms | Tot: 28s532ms | Train Loss: 0.101 | Train Acc: 96.467% (43410/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s979ms | Valid Loss: 0.420 | Valid Acc: 89.180% (4459/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 128\n",
            " [======>]  Step: 51ms | Tot: 28s492ms | Train Loss: 0.102 | Train Acc: 96.411% (43385/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s984ms | Valid Loss: 0.397 | Valid Acc: 88.900% (4445/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 129\n",
            " [======>]  Step: 51ms | Tot: 28s463ms | Train Loss: 0.095 | Train Acc: 96.707% (43518/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s968ms | Valid Loss: 0.415 | Valid Acc: 89.340% (4467/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 130\n",
            " [======>]  Step: 49ms | Tot: 28s533ms | Train Loss: 0.100 | Train Acc: 96.516% (43432/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s962ms | Valid Loss: 0.400 | Valid Acc: 89.440% (4472/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 131\n",
            " [======>]  Step: 47ms | Tot: 28s492ms | Train Loss: 0.099 | Train Acc: 96.509% (43429/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s931ms | Valid Loss: 0.394 | Valid Acc: 89.720% (4486/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 132\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.094 | Train Acc: 96.807% (43563/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s530ms | Valid Loss: 0.392 | Valid Acc: 89.560% (4478/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 133\n",
            " [======>]  Step: 52ms | Tot: 28s461ms | Train Loss: 0.099 | Train Acc: 96.627% (43482/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s949ms | Valid Loss: 0.390 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 134\n",
            " [======>]  Step: 52ms | Tot: 28s521ms | Train Loss: 0.092 | Train Acc: 96.756% (43540/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s967ms | Valid Loss: 0.432 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 135\n",
            " [======>]  Step: 49ms | Tot: 28s511ms | Train Loss: 0.094 | Train Acc: 96.736% (43531/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s904ms | Valid Loss: 0.398 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 136\n",
            " [======>]  Step: 50ms | Tot: 28s524ms | Train Loss: 0.088 | Train Acc: 96.947% (43626/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s960ms | Valid Loss: 0.410 | Valid Acc: 89.700% (4485/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 137\n",
            " [======>]  Step: 51ms | Tot: 28s489ms | Train Loss: 0.094 | Train Acc: 96.784% (43553/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s897ms | Valid Loss: 0.403 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 138\n",
            " [======>]  Step: 51ms | Tot: 28s481ms | Train Loss: 0.094 | Train Acc: 96.816% (43567/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s213ms | Valid Loss: 0.386 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 139\n",
            " [======>]  Step: 51ms | Tot: 28s478ms | Train Loss: 0.091 | Train Acc: 96.878% (43595/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s929ms | Valid Loss: 0.411 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 140\n",
            " [======>]  Step: 50ms | Tot: 28s489ms | Train Loss: 0.088 | Train Acc: 96.958% (43631/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s947ms | Valid Loss: 0.389 | Valid Acc: 89.580% (4479/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 141\n",
            " [======>]  Step: 48ms | Tot: 28s538ms | Train Loss: 0.091 | Train Acc: 96.767% (43545/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s928ms | Valid Loss: 0.397 | Valid Acc: 89.360% (4468/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 142\n",
            " [======>]  Step: 50ms | Tot: 28s492ms | Train Loss: 0.091 | Train Acc: 96.822% (43570/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s11ms | Valid Loss: 0.389 | Valid Acc: 89.960% (4498/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 143\n",
            " [======>]  Step: 51ms | Tot: 28s467ms | Train Loss: 0.090 | Train Acc: 96.927% (43617/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s939ms | Valid Loss: 0.388 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 144\n",
            " [======>]  Step: 49ms | Tot: 28s689ms | Train Loss: 0.087 | Train Acc: 96.962% (43633/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s936ms | Valid Loss: 0.375 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 145\n",
            " [======>]  Step: 50ms | Tot: 28s637ms | Train Loss: 0.091 | Train Acc: 96.916% (43612/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s939ms | Valid Loss: 0.391 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 146\n",
            " [======>]  Step: 49ms | Tot: 28s666ms | Train Loss: 0.089 | Train Acc: 96.933% (43620/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.398 | Valid Acc: 89.660% (4483/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 147\n",
            " [======>]  Step: 49ms | Tot: 28s587ms | Train Loss: 0.089 | Train Acc: 96.856% (43585/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s27ms | Valid Loss: 0.382 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 148\n",
            " [======>]  Step: 49ms | Tot: 28s623ms | Train Loss: 0.086 | Train Acc: 96.978% (43640/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s940ms | Valid Loss: 0.409 | Valid Acc: 89.500% (4475/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 149\n",
            " [======>]  Step: 50ms | Tot: 28s595ms | Train Loss: 0.086 | Train Acc: 97.042% (43669/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s908ms | Valid Loss: 0.367 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 150\n",
            " [======>]  Step: 51ms | Tot: 28s510ms | Train Loss: 0.088 | Train Acc: 96.944% (43625/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s918ms | Valid Loss: 0.403 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 151\n",
            " [======>]  Step: 49ms | Tot: 28s462ms | Train Loss: 0.084 | Train Acc: 97.120% (43704/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s935ms | Valid Loss: 0.411 | Valid Acc: 89.540% (4477/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 152\n",
            " [======>]  Step: 50ms | Tot: 28s491ms | Train Loss: 0.088 | Train Acc: 96.989% (43645/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s977ms | Valid Loss: 0.379 | Valid Acc: 90.100% (4505/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 153\n",
            " [======>]  Step: 50ms | Tot: 28s481ms | Train Loss: 0.083 | Train Acc: 97.064% (43679/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.397 | Valid Acc: 89.420% (4471/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 154\n",
            " [======>]  Step: 51ms | Tot: 28s501ms | Train Loss: 0.085 | Train Acc: 97.098% (43694/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.406 | Valid Acc: 89.840% (4492/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 155\n",
            " [======>]  Step: 50ms | Tot: 28s512ms | Train Loss: 0.082 | Train Acc: 97.180% (43731/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s937ms | Valid Loss: 0.414 | Valid Acc: 90.180% (4509/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 156\n",
            " [======>]  Step: 49ms | Tot: 28s490ms | Train Loss: 0.085 | Train Acc: 97.007% (43653/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 12ms | Tot: 1s948ms | Valid Loss: 0.368 | Valid Acc: 90.440% (4522/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 157\n",
            " [======>]  Step: 49ms | Tot: 28s477ms | Train Loss: 0.085 | Train Acc: 97.051% (43673/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.394 | Valid Acc: 90.220% (4511/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 158\n",
            " [======>]  Step: 47ms | Tot: 28s500ms | Train Loss: 0.083 | Train Acc: 97.082% (43687/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s922ms | Valid Loss: 0.411 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 159\n",
            " [======>]  Step: 50ms | Tot: 28s535ms | Train Loss: 0.083 | Train Acc: 97.138% (43712/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s988ms | Valid Loss: 0.416 | Valid Acc: 90.140% (4507/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 160\n",
            " [======>]  Step: 51ms | Tot: 28s552ms | Train Loss: 0.085 | Train Acc: 97.118% (43703/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s911ms | Valid Loss: 0.421 | Valid Acc: 90.080% (4504/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 161\n",
            " [======>]  Step: 49ms | Tot: 28s492ms | Train Loss: 0.081 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s912ms | Valid Loss: 0.379 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 162\n",
            " [======>]  Step: 51ms | Tot: 28s553ms | Train Loss: 0.083 | Train Acc: 97.076% (43684/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s2ms | Valid Loss: 0.375 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 163\n",
            " [======>]  Step: 49ms | Tot: 28s501ms | Train Loss: 0.079 | Train Acc: 97.129% (43708/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s945ms | Valid Loss: 0.380 | Valid Acc: 90.380% (4519/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 164\n",
            " [======>]  Step: 50ms | Tot: 28s464ms | Train Loss: 0.079 | Train Acc: 97.327% (43797/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s929ms | Valid Loss: 0.392 | Valid Acc: 89.880% (4494/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 165\n",
            " [======>]  Step: 50ms | Tot: 28s506ms | Train Loss: 0.082 | Train Acc: 97.216% (43747/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s932ms | Valid Loss: 0.373 | Valid Acc: 90.560% (4528/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 166\n",
            " [======>]  Step: 51ms | Tot: 28s534ms | Train Loss: 0.082 | Train Acc: 97.080% (43686/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s957ms | Valid Loss: 0.419 | Valid Acc: 89.920% (4496/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 167\n",
            " [======>]  Step: 49ms | Tot: 28s507ms | Train Loss: 0.078 | Train Acc: 97.289% (43780/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s997ms | Valid Loss: 0.385 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 168\n",
            " [======>]  Step: 50ms | Tot: 28s480ms | Train Loss: 0.078 | Train Acc: 97.280% (43776/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s912ms | Valid Loss: 0.386 | Valid Acc: 89.780% (4489/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 169\n",
            " [======>]  Step: 51ms | Tot: 28s556ms | Train Loss: 0.080 | Train Acc: 97.202% (43741/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s938ms | Valid Loss: 0.371 | Valid Acc: 90.360% (4518/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 170\n",
            " [======>]  Step: 52ms | Tot: 28s723ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s985ms | Valid Loss: 0.364 | Valid Acc: 90.700% (4535/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 171\n",
            " [======>]  Step: 49ms | Tot: 28s748ms | Train Loss: 0.080 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.392 | Valid Acc: 90.020% (4501/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 172\n",
            " [======>]  Step: 52ms | Tot: 28s792ms | Train Loss: 0.079 | Train Acc: 97.307% (43788/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s999ms | Valid Loss: 0.366 | Valid Acc: 90.540% (4527/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 173\n",
            " [======>]  Step: 49ms | Tot: 28s701ms | Train Loss: 0.078 | Train Acc: 97.200% (43740/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s4ms | Valid Loss: 0.389 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 174\n",
            " [======>]  Step: 51ms | Tot: 28s685ms | Train Loss: 0.080 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.369 | Valid Acc: 90.460% (4523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 175\n",
            " [======>]  Step: 52ms | Tot: 28s693ms | Train Loss: 0.078 | Train Acc: 97.278% (43775/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 0.404 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 176\n",
            " [======>]  Step: 52ms | Tot: 28s797ms | Train Loss: 0.076 | Train Acc: 97.398% (43829/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 1s950ms | Valid Loss: 0.367 | Valid Acc: 90.740% (4537/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 177\n",
            " [======>]  Step: 51ms | Tot: 28s666ms | Train Loss: 0.077 | Train Acc: 97.367% (43815/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s11ms | Valid Loss: 0.380 | Valid Acc: 90.520% (4526/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 178\n",
            " [======>]  Step: 50ms | Tot: 28s650ms | Train Loss: 0.076 | Train Acc: 97.351% (43808/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s39ms | Valid Loss: 0.374 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 179\n",
            " [======>]  Step: 52ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s27ms | Valid Loss: 0.389 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 180\n",
            " [======>]  Step: 51ms | Tot: 28s595ms | Train Loss: 0.078 | Train Acc: 97.222% (43750/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s29ms | Valid Loss: 0.407 | Valid Acc: 90.760% (4538/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 181\n",
            " [======>]  Step: 53ms | Tot: 28s799ms | Train Loss: 0.075 | Train Acc: 97.378% (43820/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s946ms | Valid Loss: 0.391 | Valid Acc: 90.340% (4517/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 182\n",
            " [======>]  Step: 51ms | Tot: 28s714ms | Train Loss: 0.074 | Train Acc: 97.364% (43814/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s3ms | Valid Loss: 0.353 | Valid Acc: 90.880% (4544/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 183\n",
            " [======>]  Step: 48ms | Tot: 28s670ms | Train Loss: 0.076 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s964ms | Valid Loss: 0.406 | Valid Acc: 89.940% (4497/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 184\n",
            " [======>]  Step: 52ms | Tot: 28s714ms | Train Loss: 0.077 | Train Acc: 97.338% (43802/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s63ms | Valid Loss: 0.381 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 185\n",
            " [======>]  Step: 49ms | Tot: 28s678ms | Train Loss: 0.077 | Train Acc: 97.344% (43805/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s940ms | Valid Loss: 0.349 | Valid Acc: 91.180% (4559/5000)\b\b\b\b 40/40 \n",
            "Saving..\n",
            "\n",
            "Epoch: 186\n",
            " [======>]  Step: 50ms | Tot: 28s714ms | Train Loss: 0.076 | Train Acc: 97.416% (43837/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s45ms | Valid Loss: 0.397 | Valid Acc: 90.400% (4520/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 187\n",
            " [======>]  Step: 52ms | Tot: 28s770ms | Train Loss: 0.079 | Train Acc: 97.271% (43772/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 2s19ms | Valid Loss: 0.419 | Valid Acc: 90.120% (4506/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 188\n",
            " [======>]  Step: 50ms | Tot: 28s669ms | Train Loss: 0.079 | Train Acc: 97.304% (43787/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s983ms | Valid Loss: 0.356 | Valid Acc: 90.860% (4543/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 189\n",
            " [======>]  Step: 51ms | Tot: 28s679ms | Train Loss: 0.078 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 9ms | Tot: 2s8ms | Valid Loss: 0.388 | Valid Acc: 90.240% (4512/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 190\n",
            " [======>]  Step: 52ms | Tot: 28s718ms | Train Loss: 0.074 | Train Acc: 97.353% (43809/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s60ms | Valid Loss: 0.382 | Valid Acc: 90.000% (4500/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 191\n",
            " [======>]  Step: 50ms | Tot: 28s720ms | Train Loss: 0.076 | Train Acc: 97.482% (43867/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s987ms | Valid Loss: 0.358 | Valid Acc: 90.260% (4513/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 192\n",
            " [======>]  Step: 50ms | Tot: 28s706ms | Train Loss: 0.075 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 1s974ms | Valid Loss: 0.364 | Valid Acc: 90.600% (4530/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 193\n",
            " [======>]  Step: 47ms | Tot: 28s697ms | Train Loss: 0.079 | Train Acc: 97.287% (43779/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 11ms | Tot: 2s17ms | Valid Loss: 0.405 | Valid Acc: 89.980% (4499/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 194\n",
            " [======>]  Step: 50ms | Tot: 28s760ms | Train Loss: 0.079 | Train Acc: 97.284% (43778/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s35ms | Valid Loss: 0.384 | Valid Acc: 90.040% (4502/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 195\n",
            " [======>]  Step: 47ms | Tot: 28s685ms | Train Loss: 0.078 | Train Acc: 97.347% (43806/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s995ms | Valid Loss: 0.376 | Valid Acc: 90.320% (4516/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 196\n",
            " [======>]  Step: 51ms | Tot: 28s671ms | Train Loss: 0.077 | Train Acc: 97.273% (43773/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 7ms | Tot: 1s963ms | Valid Loss: 0.345 | Valid Acc: 91.020% (4551/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 197\n",
            " [======>]  Step: 51ms | Tot: 28s817ms | Train Loss: 0.075 | Train Acc: 97.476% (43864/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.370 | Valid Acc: 90.200% (4510/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 198\n",
            " [======>]  Step: 52ms | Tot: 28s707ms | Train Loss: 0.076 | Train Acc: 97.313% (43791/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 8ms | Tot: 1s962ms | Valid Loss: 0.363 | Valid Acc: 90.780% (4539/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 199\n",
            " [======>]  Step: 50ms | Tot: 28s719ms | Train Loss: 0.075 | Train Acc: 97.329% (43798/45000)\b\b\b\b 352/352 \n",
            " [======>]  Step: 10ms | Tot: 2s13ms | Valid Loss: 0.381 | Valid Acc: 90.160% (4508/5000)\b\b\b\b 40/40 \n",
            "---------------------------------------- Testing Model... ----------------------------------------\n",
            "Best validation acc: 91.180% at Epoch 185\n",
            " [======>]  Step: 21ms | Tot: 2s360ms | Test Loss: 0.348 | Test Acc: 93.820% (9382/10000)\b\b\b\b 100/100 \n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 200\n",
        "\n",
        "print(\"Training the model for \", NUM_EPOCHS)\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "    scheduler.step()\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "\n",
        "print('---------------------------------------- Testing Model... ----------------------------------------')\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9l3iSKXzUs",
        "outputId": "b8c1f4be-717f-434e-9fce-be69987cb5c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters  4.5 million\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of parameters after the training is \")\n",
        "print_params(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z_TwWP4Xkca",
        "outputId": "4f984e49-30b1-4465-9d01-eba30dbbdcf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[24.788888888888888,\n",
              " 38.593333333333334,\n",
              " 51.28,\n",
              " 10.171830484330485,\n",
              " 10.211894586894587,\n",
              " 10.249732905982906,\n",
              " 10.1696047008547,\n",
              " 10.122863247863247,\n",
              " 10.27199074074074,\n",
              " 10.225249287749287,\n",
              " 10.243055555555555,\n",
              " 10.145121082621083,\n",
              " 10.109508547008547,\n",
              " 9.866071428571429,\n",
              " 10.0,\n",
              " 10.071428571428571,\n",
              " 9.908482142857142,\n",
              " 9.977678571428571,\n",
              " 9.964285714285714,\n",
              " 9.959821428571429,\n",
              " 9.890625,\n",
              " 9.991071428571429,\n",
              " 9.915178571428571,\n",
              " 9.452902421652421,\n",
              " 9.428418803418804,\n",
              " 9.437321937321938,\n",
              " 9.41951566951567,\n",
              " 9.339387464387464,\n",
              " 9.486289173789174,\n",
              " 9.524127492877493,\n",
              " 9.51522435897436,\n",
              " 9.346064814814815,\n",
              " 9.479611823361823,\n",
              " 10.024928774928775,\n",
              " 9.991542022792023,\n",
              " 10.011574074074074,\n",
              " 10.009348290598291,\n",
              " 60.824444444444445,\n",
              " 66.47111111111111,\n",
              " 70.09555555555555,\n",
              " 72.87777777777778,\n",
              " 74.8711111111111,\n",
              " 76.37777777777778,\n",
              " 78.02222222222223,\n",
              " 79.0911111111111,\n",
              " 80.01555555555555,\n",
              " 81.11111111111111,\n",
              " 81.70444444444445,\n",
              " 82.68666666666667,\n",
              " 83.04888888888888,\n",
              " 83.60666666666667,\n",
              " 84.41111111111111,\n",
              " 84.83555555555556,\n",
              " 85.19555555555556,\n",
              " 85.74,\n",
              " 85.76444444444445,\n",
              " 86.36444444444444,\n",
              " 86.86,\n",
              " 87.1288888888889,\n",
              " 87.49555555555555,\n",
              " 87.64222222222222,\n",
              " 87.83333333333333,\n",
              " 88.12,\n",
              " 88.50222222222222,\n",
              " 88.80888888888889,\n",
              " 89.1,\n",
              " 89.25777777777778,\n",
              " 89.65777777777778,\n",
              " 89.70222222222222,\n",
              " 89.96222222222222,\n",
              " 90.12666666666667,\n",
              " 90.10444444444444,\n",
              " 90.36,\n",
              " 90.54444444444445,\n",
              " 90.89555555555556,\n",
              " 90.83111111111111,\n",
              " 90.85777777777778,\n",
              " 91.07111111111111,\n",
              " 91.40444444444445,\n",
              " 91.45111111111112,\n",
              " 91.33111111111111,\n",
              " 91.57555555555555,\n",
              " 91.83555555555556,\n",
              " 92.04,\n",
              " 92.17555555555556,\n",
              " 92.3711111111111,\n",
              " 92.41333333333333,\n",
              " 92.32,\n",
              " 92.5911111111111,\n",
              " 92.51333333333334,\n",
              " 92.88888888888889,\n",
              " 92.69333333333333,\n",
              " 92.78444444444445,\n",
              " 93.00666666666666,\n",
              " 93.39333333333333,\n",
              " 93.30888888888889,\n",
              " 93.32444444444444,\n",
              " 93.35111111111111,\n",
              " 93.54222222222222,\n",
              " 93.63111111111111,\n",
              " 93.65333333333334,\n",
              " 93.75555555555556,\n",
              " 93.85111111111111,\n",
              " 93.92444444444445,\n",
              " 93.91777777777777,\n",
              " 93.97111111111111,\n",
              " 93.86666666666666,\n",
              " 94.10666666666667,\n",
              " 94.16444444444444,\n",
              " 94.39777777777778,\n",
              " 94.24222222222222,\n",
              " 94.50222222222222,\n",
              " 94.36666666666666,\n",
              " 94.59555555555555,\n",
              " 94.61555555555556,\n",
              " 94.5911111111111,\n",
              " 94.36888888888889,\n",
              " 94.55333333333333,\n",
              " 94.77777777777777,\n",
              " 94.77777777777777,\n",
              " 94.92222222222222,\n",
              " 95.02888888888889,\n",
              " 94.99777777777778,\n",
              " 94.98444444444445,\n",
              " 95.06222222222222,\n",
              " 95.37555555555555,\n",
              " 95.20666666666666,\n",
              " 95.24888888888889,\n",
              " 95.2311111111111,\n",
              " 95.24444444444444,\n",
              " 95.39777777777778,\n",
              " 95.36222222222223,\n",
              " 95.51777777777778,\n",
              " 95.42222222222222,\n",
              " 95.4088888888889,\n",
              " 95.57111111111111,\n",
              " 95.60888888888888,\n",
              " 95.64444444444445,\n",
              " 95.70222222222222,\n",
              " 95.74888888888889,\n",
              " 95.7688888888889,\n",
              " 95.75333333333333,\n",
              " 95.89111111111112,\n",
              " 95.73333333333333,\n",
              " 95.99333333333334,\n",
              " 95.92888888888889,\n",
              " 95.98222222222222,\n",
              " 95.89111111111112,\n",
              " 96.08444444444444,\n",
              " 96.20444444444445,\n",
              " 96.06666666666666,\n",
              " 96.0111111111111,\n",
              " 96.01777777777778,\n",
              " 96.30888888888889,\n",
              " 96.31333333333333,\n",
              " 96.27555555555556,\n",
              " 96.34444444444445,\n",
              " 96.23333333333333,\n",
              " 96.24888888888889,\n",
              " 96.30444444444444,\n",
              " 96.35111111111111,\n",
              " 96.42222222222222,\n",
              " 96.48444444444445,\n",
              " 96.68444444444444,\n",
              " 96.46666666666667,\n",
              " 96.41111111111111,\n",
              " 96.70666666666666,\n",
              " 96.51555555555555,\n",
              " 96.50888888888889,\n",
              " 96.80666666666667,\n",
              " 96.62666666666667,\n",
              " 96.75555555555556,\n",
              " 96.73555555555555,\n",
              " 96.94666666666667,\n",
              " 96.78444444444445,\n",
              " 96.81555555555556,\n",
              " 96.87777777777778,\n",
              " 96.95777777777778,\n",
              " 96.76666666666667,\n",
              " 96.82222222222222,\n",
              " 96.92666666666666,\n",
              " 96.96222222222222,\n",
              " 96.91555555555556,\n",
              " 96.93333333333334,\n",
              " 96.85555555555555,\n",
              " 96.97777777777777,\n",
              " 97.04222222222222,\n",
              " 96.94444444444444,\n",
              " 97.12,\n",
              " 96.9888888888889,\n",
              " 97.06444444444445,\n",
              " 97.09777777777778,\n",
              " 97.18,\n",
              " 97.00666666666666,\n",
              " 97.05111111111111,\n",
              " 97.08222222222223,\n",
              " 97.13777777777777,\n",
              " 97.11777777777777,\n",
              " 97.20222222222222,\n",
              " 97.07555555555555,\n",
              " 97.1288888888889,\n",
              " 97.32666666666667,\n",
              " 97.21555555555555,\n",
              " 97.08,\n",
              " 97.28888888888889,\n",
              " 97.28,\n",
              " 97.20222222222222,\n",
              " 97.27777777777777,\n",
              " 97.30444444444444,\n",
              " 97.30666666666667,\n",
              " 97.2,\n",
              " 97.22222222222223,\n",
              " 97.27777777777777,\n",
              " 97.39777777777778,\n",
              " 97.36666666666666,\n",
              " 97.35111111111111,\n",
              " 97.28444444444445,\n",
              " 97.22222222222223,\n",
              " 97.37777777777778,\n",
              " 97.36444444444444,\n",
              " 97.34666666666666,\n",
              " 97.33777777777777,\n",
              " 97.34444444444445,\n",
              " 97.41555555555556,\n",
              " 97.27111111111111,\n",
              " 97.30444444444444,\n",
              " 97.32888888888888,\n",
              " 97.35333333333334,\n",
              " 97.48222222222222,\n",
              " 97.31333333333333,\n",
              " 97.28666666666666,\n",
              " 97.28444444444445,\n",
              " 97.34666666666666,\n",
              " 97.27333333333333,\n",
              " 97.47555555555556,\n",
              " 97.31333333333333,\n",
              " 97.32888888888888]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_train_acc = max(train_acc_array)\n",
        "\n",
        "print(\"The highest training accuracy achieved is \", max_train_acc)\n",
        "\n",
        "max_val_acc = max(val_acc_array)\n",
        "\n",
        "print(\"The highest validation accuracy achieved is \", max_val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "JHKohhBDJRIP",
        "outputId": "73901168-8eda-4df3-bf12-69730b43b6d3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Plotting the result...\")\n",
        "train_loss_array2=[i/10 for i in train_loss_array]\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "ax = plt.axes()\n",
        "plt.subplot(121)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1), train_acc_array[37:])\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1),val_acc_array[37:])\n",
        "plt.title(\"Accuracy\", fontsize=60)\n",
        "plt.xlabel(\"Epochs\", fontsize=40)\n",
        "plt.ylabel(\"Percent Accuracy\", fontsize=40)\n",
        "plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"lower right\", fontsize=30)\n",
        "plt.xticks(fontsize=25)\n",
        "plt.yticks(fontsize=25)\n",
        "plt.subplot(122)\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),train_loss_array2[37:])\n",
        "plt.plot(np.arange(1,NUM_EPOCHS+1,dtype=int),val_loss_array[37:])\n",
        "plt.title(\"Loss\", fontsize=60)\n",
        "plt.xlabel(\"Epochs\", fontsize=40)\n",
        "plt.ylabel(\"Loss\", fontsize=40)\n",
        "plt.legend(['Train loss', 'Valid loss'], loc=\"upper right\", fontsize=30)\n",
        "plt.xticks(fontsize=25)\n",
        "plt.yticks(fontsize=25)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"pruning_curves.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jHEaEYOfK40"
      },
      "outputs": [],
      "source": [
        "def plot_test_result(num_epochs, train_acc, train_loss, val_acc, val_loss):\n",
        "  fig = plt.figure(figsize=(16,6))\n",
        "  plt.subplot(121)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), train_acc)\n",
        "  plt.plot(np.arange(1, num_epochs + 1), val_acc)\n",
        "  plt.title(\"Accuray\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend([\"Train Acc\",\"Valid Acc\"],loc = \"upper right\")\n",
        "\n",
        "  plt.subplot(122)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), train_loss)\n",
        "  plt.plot(np.arange(1, num_epochs + 1, dtype=int), val_loss)\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(['train loss', 'valid loss'], loc=\"upper right\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUPyXSy3yD6G"
      },
      "source": [
        "<h2>Automatic Hyperparameter Search using Optuna</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefZAQVvyCgU",
        "outputId": "fdc217da-1e40-4ea0-b726-f403e8c01bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.9.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.11.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.2)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing Optuna framework\")\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2MShrCMyLjz"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAKNVr4AyOPa"
      },
      "outputs": [],
      "source": [
        "# defining objective fucntion to be maximized by Optuna\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # trying different optimizers\n",
        "  optimizer_name_class_1 = trial.suggest_categorical(\"optimizer\", [\"SGD\",\n",
        "                                                                   \"RMSprop\"])\n",
        "\n",
        "  # optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "  #                                                                  \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_1 = getattr(optim, optimizer_name_class_1)(curr_model.parameters(),\n",
        "                                                     lr=lr, momentum=momentum)\n",
        "\n",
        "  # optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 128, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_1, T_max=200)\n",
        "\n",
        "  # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  # we will run the model for 200 epochs once the best parameters are \n",
        "  # discovered \n",
        "  NUM_EPOCHS = 20\n",
        "\n",
        "  for epoch in range(0, NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader, optim=optimizer_class_1)\n",
        "      accuracy = evaluate(epoch, model=curr_model, validation_loader=val_loader)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7S4oOdt1Rx4",
        "outputId": "44189fd5-1a11-4f61-9438-6cff2b4ae4b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 17:26:08,634]\u001b[0m A new study created in memory with name: resNet-18\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 152ms | Tot: 26s307ms | Train Loss: 2.876 | Train Acc: 14.353% (6430/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s872ms | Valid Loss: 2.263 | Valid Acc: 14.560% (728/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 149ms | Tot: 26s388ms | Train Loss: 2.053 | Train Acc: 19.752% (8849/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s743ms | Valid Loss: 2.090 | Valid Acc: 18.920% (946/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 148ms | Tot: 26s118ms | Train Loss: 1.937 | Train Acc: 26.750% (11984/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 2s285ms | Valid Loss: 1.912 | Valid Acc: 28.800% (1440/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 149ms | Tot: 26s391ms | Train Loss: 1.768 | Train Acc: 34.654% (15525/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s799ms | Valid Loss: 2.081 | Valid Acc: 31.260% (1563/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 147ms | Tot: 26s239ms | Train Loss: 1.600 | Train Acc: 41.308% (18506/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s763ms | Valid Loss: 1.567 | Valid Acc: 43.440% (2172/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 150ms | Tot: 26s123ms | Train Loss: 1.432 | Train Acc: 48.176% (21583/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 3s359ms | Valid Loss: 1.961 | Valid Acc: 41.020% (2051/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 148ms | Tot: 26s485ms | Train Loss: 1.277 | Train Acc: 54.433% (24386/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 35ms | Tot: 1s977ms | Valid Loss: 1.376 | Valid Acc: 51.520% (2576/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 149ms | Tot: 26s246ms | Train Loss: 1.158 | Train Acc: 58.993% (26429/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s828ms | Valid Loss: 1.265 | Valid Acc: 55.560% (2778/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 146ms | Tot: 26s177ms | Train Loss: 1.057 | Train Acc: 62.480% (27991/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 42ms | Tot: 1s761ms | Valid Loss: 1.171 | Valid Acc: 59.920% (2996/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 146ms | Tot: 26s24ms | Train Loss: 0.966 | Train Acc: 65.935% (29539/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s790ms | Valid Loss: 1.102 | Valid Acc: 61.320% (3066/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 146ms | Tot: 26s76ms | Train Loss: 0.901 | Train Acc: 68.498% (30687/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 36ms | Tot: 1s758ms | Valid Loss: 1.017 | Valid Acc: 64.880% (3244/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 146ms | Tot: 26s70ms | Train Loss: 0.852 | Train Acc: 70.000% (31360/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s798ms | Valid Loss: 1.075 | Valid Acc: 63.220% (3161/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 146ms | Tot: 26s101ms | Train Loss: 0.804 | Train Acc: 71.967% (32241/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s758ms | Valid Loss: 0.965 | Valid Acc: 66.120% (3306/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 146ms | Tot: 26s21ms | Train Loss: 0.765 | Train Acc: 73.522% (32938/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s922ms | Valid Loss: 1.370 | Valid Acc: 58.080% (2904/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 146ms | Tot: 26s90ms | Train Loss: 0.725 | Train Acc: 74.652% (33444/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s894ms | Valid Loss: 0.892 | Valid Acc: 70.120% (3506/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 147ms | Tot: 25s979ms | Train Loss: 0.711 | Train Acc: 75.406% (33782/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s872ms | Valid Loss: 0.822 | Valid Acc: 71.060% (3553/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 148ms | Tot: 26s12ms | Train Loss: 0.675 | Train Acc: 76.848% (34428/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 40ms | Tot: 1s863ms | Valid Loss: 0.955 | Valid Acc: 68.660% (3433/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 146ms | Tot: 26s59ms | Train Loss: 0.659 | Train Acc: 77.442% (34694/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 26ms | Tot: 1s868ms | Valid Loss: 0.778 | Valid Acc: 72.480% (3624/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 146ms | Tot: 26s17ms | Train Loss: 0.641 | Train Acc: 77.826% (34866/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s791ms | Valid Loss: 0.765 | Valid Acc: 74.560% (3728/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 146ms | Tot: 26s113ms | Train Loss: 0.623 | Train Acc: 78.525% (35179/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 26ms | Tot: 1s804ms | Valid Loss: 0.765 | Valid Acc: 74.080% (3704/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 17:35:49,435]\u001b[0m Trial 0 finished with value: 74.08 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.2, 'optimizer': 'RMSprop', 'momentum': 0.27825018865449946, 'lr': 0.03705955361405272, 'batch_size': 256}. Best is trial 0 with value: 74.08.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 149ms | Tot: 26s561ms | Train Loss: 2.031 | Train Acc: 24.038% (10769/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s727ms | Valid Loss: 1.871 | Valid Acc: 31.380% (1569/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 149ms | Tot: 26s719ms | Train Loss: 1.698 | Train Acc: 37.346% (16731/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s716ms | Valid Loss: 1.662 | Valid Acc: 39.920% (1996/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 151ms | Tot: 26s559ms | Train Loss: 1.444 | Train Acc: 47.817% (21422/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s790ms | Valid Loss: 1.477 | Valid Acc: 46.960% (2348/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 151ms | Tot: 26s604ms | Train Loss: 1.241 | Train Acc: 55.618% (24917/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s761ms | Valid Loss: 1.248 | Valid Acc: 56.160% (2808/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 154ms | Tot: 26s556ms | Train Loss: 1.079 | Train Acc: 61.413% (27513/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 26ms | Tot: 1s833ms | Valid Loss: 1.034 | Valid Acc: 63.680% (3184/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 151ms | Tot: 26s599ms | Train Loss: 0.931 | Train Acc: 67.150% (30083/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 32ms | Tot: 1s797ms | Valid Loss: 1.010 | Valid Acc: 65.320% (3266/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 149ms | Tot: 26s540ms | Train Loss: 0.821 | Train Acc: 71.259% (31924/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s732ms | Valid Loss: 0.836 | Valid Acc: 70.940% (3547/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 149ms | Tot: 26s572ms | Train Loss: 0.747 | Train Acc: 73.873% (33095/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s814ms | Valid Loss: 0.823 | Valid Acc: 72.160% (3608/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 150ms | Tot: 26s523ms | Train Loss: 0.691 | Train Acc: 75.797% (33957/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s824ms | Valid Loss: 0.808 | Valid Acc: 72.160% (3608/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 152ms | Tot: 26s589ms | Train Loss: 0.644 | Train Acc: 77.413% (34681/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s939ms | Valid Loss: 0.766 | Valid Acc: 73.640% (3682/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 149ms | Tot: 26s592ms | Train Loss: 0.596 | Train Acc: 79.493% (35613/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s746ms | Valid Loss: 0.714 | Valid Acc: 76.300% (3815/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 149ms | Tot: 26s533ms | Train Loss: 0.565 | Train Acc: 80.167% (35915/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 2s95ms | Valid Loss: 0.683 | Valid Acc: 76.520% (3826/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 150ms | Tot: 26s571ms | Train Loss: 0.540 | Train Acc: 81.219% (36386/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s820ms | Valid Loss: 0.584 | Valid Acc: 79.840% (3992/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 149ms | Tot: 26s497ms | Train Loss: 0.519 | Train Acc: 82.051% (36759/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s884ms | Valid Loss: 0.581 | Valid Acc: 80.400% (4020/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 148ms | Tot: 26s569ms | Train Loss: 0.487 | Train Acc: 83.190% (37269/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s775ms | Valid Loss: 0.558 | Valid Acc: 80.880% (4044/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 151ms | Tot: 26s533ms | Train Loss: 0.470 | Train Acc: 83.685% (37491/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s829ms | Valid Loss: 0.577 | Valid Acc: 79.600% (3980/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 148ms | Tot: 26s555ms | Train Loss: 0.451 | Train Acc: 84.277% (37756/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s854ms | Valid Loss: 0.561 | Valid Acc: 81.320% (4066/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 151ms | Tot: 26s503ms | Train Loss: 0.436 | Train Acc: 84.788% (37985/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s759ms | Valid Loss: 0.525 | Valid Acc: 81.680% (4084/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 148ms | Tot: 26s578ms | Train Loss: 0.421 | Train Acc: 85.471% (38291/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 57ms | Tot: 2s157ms | Valid Loss: 0.526 | Valid Acc: 83.260% (4163/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 151ms | Tot: 26s502ms | Train Loss: 0.401 | Train Acc: 86.065% (38557/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s856ms | Valid Loss: 0.553 | Valid Acc: 81.600% (4080/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 17:45:35,840]\u001b[0m Trial 1 finished with value: 81.6 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.2, 'optimizer': 'RMSprop', 'momentum': 0.876498817866124, 'lr': 0.0007834902289043906, 'batch_size': 256}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 107ms | Tot: 26s812ms | Train Loss: 9.752 | Train Acc: 10.067% (4523/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s824ms | Valid Loss: 2.381 | Valid Acc: 9.640% (482/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 109ms | Tot: 26s198ms | Train Loss: 2.317 | Train Acc: 9.920% (4457/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s844ms | Valid Loss: 2.345 | Valid Acc: 9.980% (499/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 112ms | Tot: 26s363ms | Train Loss: 2.318 | Train Acc: 9.920% (4457/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s861ms | Valid Loss: 2.350 | Valid Acc: 10.360% (518/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 109ms | Tot: 26s5ms | Train Loss: 2.318 | Train Acc: 10.107% (4541/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s860ms | Valid Loss: 2.324 | Valid Acc: 10.360% (518/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 110ms | Tot: 26s173ms | Train Loss: 2.319 | Train Acc: 10.009% (4497/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s881ms | Valid Loss: 2.320 | Valid Acc: 9.620% (481/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 109ms | Tot: 26s13ms | Train Loss: 2.316 | Train Acc: 9.896% (4446/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s906ms | Valid Loss: 2.315 | Valid Acc: 10.360% (518/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 109ms | Tot: 26s72ms | Train Loss: 2.317 | Train Acc: 9.756% (4383/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s980ms | Valid Loss: 2.311 | Valid Acc: 9.860% (493/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 109ms | Tot: 26s38ms | Train Loss: 2.317 | Train Acc: 9.896% (4446/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s870ms | Valid Loss: 2.322 | Valid Acc: 9.880% (494/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 110ms | Tot: 26s44ms | Train Loss: 2.318 | Train Acc: 10.029% (4506/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s912ms | Valid Loss: 2.326 | Valid Acc: 9.880% (494/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 109ms | Tot: 26s91ms | Train Loss: 2.316 | Train Acc: 9.903% (4449/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s859ms | Valid Loss: 2.320 | Valid Acc: 10.200% (510/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 108ms | Tot: 25s985ms | Train Loss: 2.318 | Train Acc: 9.969% (4479/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s868ms | Valid Loss: 2.319 | Valid Acc: 9.680% (484/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 108ms | Tot: 26s97ms | Train Loss: 2.317 | Train Acc: 10.061% (4520/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s896ms | Valid Loss: 2.320 | Valid Acc: 9.640% (482/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 111ms | Tot: 25s992ms | Train Loss: 2.317 | Train Acc: 10.136% (4554/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s887ms | Valid Loss: 2.326 | Valid Acc: 9.680% (484/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 111ms | Tot: 26s103ms | Train Loss: 2.316 | Train Acc: 9.987% (4487/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s841ms | Valid Loss: 2.314 | Valid Acc: 9.640% (482/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 108ms | Tot: 26s51ms | Train Loss: 2.319 | Train Acc: 10.116% (4545/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s883ms | Valid Loss: 2.311 | Valid Acc: 10.200% (510/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 107ms | Tot: 26s93ms | Train Loss: 2.316 | Train Acc: 9.825% (4414/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s890ms | Valid Loss: 2.318 | Valid Acc: 9.680% (484/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 110ms | Tot: 26s128ms | Train Loss: 2.316 | Train Acc: 10.130% (4551/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s865ms | Valid Loss: 2.306 | Valid Acc: 10.440% (522/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 109ms | Tot: 26s18ms | Train Loss: 2.317 | Train Acc: 10.132% (4552/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s854ms | Valid Loss: 2.326 | Valid Acc: 10.300% (515/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 109ms | Tot: 26s22ms | Train Loss: 2.316 | Train Acc: 10.323% (4638/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s873ms | Valid Loss: 2.323 | Valid Acc: 10.360% (518/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 110ms | Tot: 26s70ms | Train Loss: 2.317 | Train Acc: 10.012% (4498/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s810ms | Valid Loss: 2.307 | Valid Acc: 10.200% (510/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 17:55:11,248]\u001b[0m Trial 2 finished with value: 10.2 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'RMSprop', 'momentum': 0.7111298530061423, 'lr': 0.08934010704973969, 'batch_size': 192}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 115ms | Tot: 27s180ms | Train Loss: 1.865 | Train Acc: 30.740% (13811/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s872ms | Valid Loss: 1.839 | Valid Acc: 34.800% (1740/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 114ms | Tot: 27s202ms | Train Loss: 1.424 | Train Acc: 48.540% (21808/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s838ms | Valid Loss: 1.465 | Valid Acc: 47.500% (2375/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 115ms | Tot: 27s160ms | Train Loss: 1.171 | Train Acc: 58.218% (26156/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s822ms | Valid Loss: 1.138 | Valid Acc: 59.040% (2952/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 115ms | Tot: 27s270ms | Train Loss: 0.985 | Train Acc: 65.347% (29359/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s894ms | Valid Loss: 1.011 | Valid Acc: 63.480% (3174/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 115ms | Tot: 27s209ms | Train Loss: 0.891 | Train Acc: 68.372% (30718/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s839ms | Valid Loss: 1.010 | Valid Acc: 65.720% (3286/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 115ms | Tot: 27s264ms | Train Loss: 0.805 | Train Acc: 71.904% (32305/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 2s144ms | Valid Loss: 0.960 | Valid Acc: 66.760% (3338/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 115ms | Tot: 27s224ms | Train Loss: 0.750 | Train Acc: 73.825% (33168/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s821ms | Valid Loss: 0.814 | Valid Acc: 72.620% (3631/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 114ms | Tot: 27s290ms | Train Loss: 0.697 | Train Acc: 75.681% (34002/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 2s185ms | Valid Loss: 0.741 | Valid Acc: 75.820% (3791/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 115ms | Tot: 27s252ms | Train Loss: 0.664 | Train Acc: 76.801% (34505/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s874ms | Valid Loss: 0.772 | Valid Acc: 74.140% (3707/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 114ms | Tot: 27s214ms | Train Loss: 0.631 | Train Acc: 77.887% (34993/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 13ms | Tot: 2s196ms | Valid Loss: 0.729 | Valid Acc: 74.460% (3723/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 115ms | Tot: 27s244ms | Train Loss: 0.597 | Train Acc: 79.287% (35622/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s828ms | Valid Loss: 0.685 | Valid Acc: 76.440% (3822/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 114ms | Tot: 27s288ms | Train Loss: 0.569 | Train Acc: 80.224% (36043/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 2s291ms | Valid Loss: 0.704 | Valid Acc: 76.080% (3804/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 114ms | Tot: 27s246ms | Train Loss: 0.549 | Train Acc: 80.874% (36335/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s927ms | Valid Loss: 0.621 | Valid Acc: 78.260% (3913/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 116ms | Tot: 27s243ms | Train Loss: 0.524 | Train Acc: 81.686% (36700/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 2s244ms | Valid Loss: 0.634 | Valid Acc: 78.620% (3931/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 115ms | Tot: 27s191ms | Train Loss: 0.514 | Train Acc: 82.074% (36874/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s811ms | Valid Loss: 0.642 | Valid Acc: 77.320% (3866/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 114ms | Tot: 27s199ms | Train Loss: 0.491 | Train Acc: 83.006% (37293/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 15ms | Tot: 2s158ms | Valid Loss: 0.561 | Valid Acc: 80.840% (4042/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 117ms | Tot: 27s201ms | Train Loss: 0.474 | Train Acc: 83.449% (37492/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s839ms | Valid Loss: 0.600 | Valid Acc: 79.040% (3952/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 112ms | Tot: 27s244ms | Train Loss: 0.455 | Train Acc: 84.041% (37758/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 2s169ms | Valid Loss: 0.536 | Valid Acc: 81.380% (4069/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 115ms | Tot: 27s266ms | Train Loss: 0.448 | Train Acc: 84.348% (37896/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 13ms | Tot: 1s830ms | Valid Loss: 0.536 | Valid Acc: 81.840% (4092/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 115ms | Tot: 27s248ms | Train Loss: 0.432 | Train Acc: 84.836% (38115/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 2s146ms | Valid Loss: 0.567 | Valid Acc: 80.280% (4014/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:05:11,825]\u001b[0m Trial 3 finished with value: 80.28 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.1, 'optimizer': 'SGD', 'momentum': 0.9476183784592693, 'lr': 0.015770633845970158, 'batch_size': 192}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 150ms | Tot: 26s402ms | Train Loss: 2.300 | Train Acc: 12.321% (5520/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s838ms | Valid Loss: 2.283 | Valid Acc: 12.800% (640/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 150ms | Tot: 26s461ms | Train Loss: 2.265 | Train Acc: 14.850% (6653/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 2s72ms | Valid Loss: 2.248 | Valid Acc: 16.040% (802/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 149ms | Tot: 26s463ms | Train Loss: 2.234 | Train Acc: 16.913% (7577/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s745ms | Valid Loss: 2.217 | Valid Acc: 17.460% (873/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 148ms | Tot: 26s419ms | Train Loss: 2.202 | Train Acc: 18.355% (8223/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s807ms | Valid Loss: 2.190 | Valid Acc: 18.880% (944/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 148ms | Tot: 26s400ms | Train Loss: 2.168 | Train Acc: 19.850% (8893/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s719ms | Valid Loss: 2.152 | Valid Acc: 20.400% (1020/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 150ms | Tot: 26s400ms | Train Loss: 2.136 | Train Acc: 21.038% (9425/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s781ms | Valid Loss: 2.125 | Valid Acc: 21.700% (1085/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 149ms | Tot: 26s436ms | Train Loss: 2.102 | Train Acc: 22.614% (10131/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s757ms | Valid Loss: 2.096 | Valid Acc: 22.740% (1137/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 148ms | Tot: 26s422ms | Train Loss: 2.071 | Train Acc: 23.877% (10697/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s838ms | Valid Loss: 2.052 | Valid Acc: 24.360% (1218/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 150ms | Tot: 26s476ms | Train Loss: 2.036 | Train Acc: 24.848% (11132/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s791ms | Valid Loss: 2.030 | Valid Acc: 25.280% (1264/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 150ms | Tot: 26s730ms | Train Loss: 2.011 | Train Acc: 25.746% (11534/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 34ms | Tot: 2s345ms | Valid Loss: 1.997 | Valid Acc: 26.180% (1309/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 154ms | Tot: 27s928ms | Train Loss: 1.984 | Train Acc: 26.605% (11919/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 2s307ms | Valid Loss: 1.980 | Valid Acc: 26.440% (1322/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 148ms | Tot: 26s744ms | Train Loss: 1.960 | Train Acc: 27.408% (12279/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s960ms | Valid Loss: 1.955 | Valid Acc: 27.100% (1355/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 149ms | Tot: 26s605ms | Train Loss: 1.942 | Train Acc: 27.949% (12521/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s969ms | Valid Loss: 1.930 | Valid Acc: 28.800% (1440/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 148ms | Tot: 26s498ms | Train Loss: 1.921 | Train Acc: 28.632% (12827/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s763ms | Valid Loss: 1.922 | Valid Acc: 28.640% (1432/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 150ms | Tot: 27s52ms | Train Loss: 1.903 | Train Acc: 29.326% (13138/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s796ms | Valid Loss: 1.901 | Valid Acc: 28.820% (1441/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 146ms | Tot: 26s488ms | Train Loss: 1.889 | Train Acc: 29.643% (13280/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s765ms | Valid Loss: 1.883 | Valid Acc: 30.600% (1530/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 149ms | Tot: 26s585ms | Train Loss: 1.875 | Train Acc: 30.225% (13541/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 26ms | Tot: 1s796ms | Valid Loss: 1.873 | Valid Acc: 31.400% (1570/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 150ms | Tot: 26s456ms | Train Loss: 1.868 | Train Acc: 30.444% (13639/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s857ms | Valid Loss: 1.863 | Valid Acc: 30.260% (1513/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 151ms | Tot: 26s877ms | Train Loss: 1.851 | Train Acc: 31.121% (13942/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s790ms | Valid Loss: 1.834 | Valid Acc: 32.280% (1614/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 151ms | Tot: 26s548ms | Train Loss: 1.838 | Train Acc: 31.933% (14306/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s837ms | Valid Loss: 1.836 | Valid Acc: 32.020% (1601/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:15:00,841]\u001b[0m Trial 4 finished with value: 32.02 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.2, 'optimizer': 'SGD', 'momentum': 0.5093631153443452, 'lr': 0.00019236486028456414, 'batch_size': 256}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 150ms | Tot: 26s918ms | Train Loss: 2.280 | Train Acc: 15.522% (6954/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s776ms | Valid Loss: 2.222 | Valid Acc: 17.620% (881/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 155ms | Tot: 26s677ms | Train Loss: 2.147 | Train Acc: 21.310% (9547/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s833ms | Valid Loss: 2.085 | Valid Acc: 23.580% (1179/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 149ms | Tot: 26s677ms | Train Loss: 2.007 | Train Acc: 26.808% (12010/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s792ms | Valid Loss: 1.939 | Valid Acc: 27.520% (1376/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:16:29,453]\u001b[0m Trial 5 pruned. \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 79ms | Tot: 28s303ms | Train Loss: 2.201 | Train Acc: 20.339% (9138/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s944ms | Valid Loss: 2.023 | Valid Acc: 24.960% (1248/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 77ms | Tot: 28s365ms | Train Loss: 1.760 | Train Acc: 35.408% (15908/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s976ms | Valid Loss: 1.557 | Valid Acc: 43.340% (2167/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 82ms | Tot: 29s154ms | Train Loss: 1.407 | Train Acc: 49.321% (22159/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 13ms | Tot: 2s332ms | Valid Loss: 1.644 | Valid Acc: 45.960% (2298/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 78ms | Tot: 29s261ms | Train Loss: 1.185 | Train Acc: 57.784% (25961/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s943ms | Valid Loss: 1.273 | Valid Acc: 56.760% (2838/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 81ms | Tot: 28s275ms | Train Loss: 1.033 | Train Acc: 63.304% (28441/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s431ms | Valid Loss: 1.039 | Valid Acc: 62.760% (3138/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 78ms | Tot: 28s260ms | Train Loss: 0.930 | Train Acc: 67.550% (30349/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s16ms | Valid Loss: 0.985 | Valid Acc: 65.100% (3255/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 79ms | Tot: 28s956ms | Train Loss: 0.850 | Train Acc: 70.348% (31606/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 2s618ms | Valid Loss: 0.933 | Valid Acc: 68.240% (3412/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 77ms | Tot: 28s494ms | Train Loss: 0.793 | Train Acc: 72.211% (32443/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 2s414ms | Valid Loss: 0.882 | Valid Acc: 69.120% (3456/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 75ms | Tot: 28s481ms | Train Loss: 0.749 | Train Acc: 73.856% (33182/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s975ms | Valid Loss: 0.799 | Valid Acc: 72.980% (3649/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 78ms | Tot: 28s24ms | Train Loss: 0.712 | Train Acc: 75.274% (33819/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s973ms | Valid Loss: 0.773 | Valid Acc: 73.560% (3678/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 77ms | Tot: 28s290ms | Train Loss: 0.679 | Train Acc: 76.473% (34358/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s106ms | Valid Loss: 0.725 | Valid Acc: 75.100% (3755/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 81ms | Tot: 28s519ms | Train Loss: 0.649 | Train Acc: 77.540% (34837/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 16ms | Tot: 2s702ms | Valid Loss: 0.689 | Valid Acc: 76.660% (3833/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 77ms | Tot: 28s450ms | Train Loss: 0.628 | Train Acc: 78.105% (35091/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 2s568ms | Valid Loss: 0.713 | Valid Acc: 76.020% (3801/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 77ms | Tot: 28s299ms | Train Loss: 0.599 | Train Acc: 79.247% (35604/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 2s45ms | Valid Loss: 0.686 | Valid Acc: 76.260% (3813/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 75ms | Tot: 28s31ms | Train Loss: 0.585 | Train Acc: 79.930% (35911/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s970ms | Valid Loss: 0.710 | Valid Acc: 76.500% (3825/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 78ms | Tot: 28s11ms | Train Loss: 0.566 | Train Acc: 80.553% (36191/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s993ms | Valid Loss: 0.712 | Valid Acc: 76.100% (3805/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 77ms | Tot: 28s341ms | Train Loss: 0.550 | Train Acc: 80.876% (36336/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s983ms | Valid Loss: 0.613 | Valid Acc: 79.340% (3967/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 81ms | Tot: 28s33ms | Train Loss: 0.542 | Train Acc: 81.295% (36524/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s966ms | Valid Loss: 0.584 | Valid Acc: 80.560% (4028/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 78ms | Tot: 28s350ms | Train Loss: 0.521 | Train Acc: 81.918% (36804/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 2s74ms | Valid Loss: 0.590 | Valid Acc: 80.380% (4019/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 75ms | Tot: 28s85ms | Train Loss: 0.505 | Train Acc: 82.461% (37048/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s24ms | Valid Loss: 0.584 | Valid Acc: 80.700% (4035/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:26:54,208]\u001b[0m Trial 6 finished with value: 80.7 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.0, 'optimizer': 'RMSprop', 'momentum': 0.691539662345516, 'lr': 0.008955444489335542, 'batch_size': 128}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 112ms | Tot: 27s294ms | Train Loss: 1.842 | Train Acc: 31.775% (14276/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s969ms | Valid Loss: 1.780 | Valid Acc: 37.960% (1898/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 112ms | Tot: 27s194ms | Train Loss: 1.458 | Train Acc: 47.062% (21144/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s984ms | Valid Loss: 1.525 | Valid Acc: 47.300% (2365/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 114ms | Tot: 27s256ms | Train Loss: 1.256 | Train Acc: 55.346% (24866/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s950ms | Valid Loss: 1.254 | Valid Acc: 54.980% (2749/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 115ms | Tot: 27s225ms | Train Loss: 1.110 | Train Acc: 60.274% (27080/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s911ms | Valid Loss: 1.274 | Valid Acc: 56.360% (2818/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 115ms | Tot: 27s242ms | Train Loss: 1.007 | Train Acc: 64.336% (28905/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s928ms | Valid Loss: 1.288 | Valid Acc: 58.200% (2910/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 113ms | Tot: 27s214ms | Train Loss: 0.913 | Train Acc: 67.708% (30420/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 13ms | Tot: 2s608ms | Valid Loss: 0.939 | Valid Acc: 66.840% (3342/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 115ms | Tot: 27s418ms | Train Loss: 0.845 | Train Acc: 70.288% (31579/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s877ms | Valid Loss: 1.003 | Valid Acc: 66.340% (3317/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 115ms | Tot: 27s271ms | Train Loss: 0.805 | Train Acc: 71.710% (32218/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 15ms | Tot: 2s503ms | Valid Loss: 1.004 | Valid Acc: 65.040% (3252/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 114ms | Tot: 27s223ms | Train Loss: 0.755 | Train Acc: 73.438% (32994/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s906ms | Valid Loss: 0.867 | Valid Acc: 71.100% (3555/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 115ms | Tot: 27s318ms | Train Loss: 0.714 | Train Acc: 74.967% (33681/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s990ms | Valid Loss: 0.745 | Valid Acc: 73.960% (3698/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 115ms | Tot: 27s198ms | Train Loss: 0.681 | Train Acc: 76.189% (34230/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s835ms | Valid Loss: 0.735 | Valid Acc: 74.620% (3731/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 114ms | Tot: 27s242ms | Train Loss: 0.660 | Train Acc: 76.941% (34568/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s880ms | Valid Loss: 0.765 | Valid Acc: 74.000% (3700/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 112ms | Tot: 27s194ms | Train Loss: 0.624 | Train Acc: 78.203% (35135/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s905ms | Valid Loss: 0.679 | Valid Acc: 76.980% (3849/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 118ms | Tot: 27s316ms | Train Loss: 0.611 | Train Acc: 78.644% (35333/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 2s48ms | Valid Loss: 0.692 | Valid Acc: 75.780% (3789/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 114ms | Tot: 27s327ms | Train Loss: 0.590 | Train Acc: 79.647% (35784/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s855ms | Valid Loss: 0.726 | Valid Acc: 74.000% (3700/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 116ms | Tot: 27s300ms | Train Loss: 0.566 | Train Acc: 80.262% (36060/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s835ms | Valid Loss: 0.687 | Valid Acc: 76.060% (3803/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 115ms | Tot: 27s349ms | Train Loss: 0.552 | Train Acc: 80.921% (36356/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s861ms | Valid Loss: 0.683 | Valid Acc: 76.000% (3800/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 117ms | Tot: 27s279ms | Train Loss: 0.535 | Train Acc: 81.397% (36570/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s879ms | Valid Loss: 0.725 | Valid Acc: 75.080% (3754/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 116ms | Tot: 27s287ms | Train Loss: 0.519 | Train Acc: 82.154% (36910/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s849ms | Valid Loss: 0.595 | Valid Acc: 79.400% (3970/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 113ms | Tot: 27s248ms | Train Loss: 0.507 | Train Acc: 82.252% (36954/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s833ms | Valid Loss: 0.768 | Valid Acc: 75.320% (3766/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:36:55,206]\u001b[0m Trial 7 finished with value: 75.32 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.1, 'optimizer': 'SGD', 'momentum': 0.5209478103548258, 'lr': 0.012223134652644843, 'batch_size': 192}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 77ms | Tot: 28s170ms | Train Loss: 1.759 | Train Acc: 35.210% (15819/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 13ms | Tot: 1s935ms | Valid Loss: 1.620 | Valid Acc: 44.260% (2213/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 78ms | Tot: 28s241ms | Train Loss: 1.261 | Train Acc: 55.021% (24720/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s979ms | Valid Loss: 1.420 | Valid Acc: 52.680% (2634/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 80ms | Tot: 28s266ms | Train Loss: 1.028 | Train Acc: 63.593% (28571/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s999ms | Valid Loss: 1.220 | Valid Acc: 57.200% (2860/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 28s123ms | Train Loss: 0.889 | Train Acc: 68.892% (30952/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s970ms | Valid Loss: 0.855 | Valid Acc: 70.460% (3523/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 78ms | Tot: 28s187ms | Train Loss: 0.803 | Train Acc: 71.830% (32272/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s950ms | Valid Loss: 1.005 | Valid Acc: 66.460% (3323/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 80ms | Tot: 28s229ms | Train Loss: 0.741 | Train Acc: 74.383% (33419/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s398ms | Valid Loss: 0.835 | Valid Acc: 72.000% (3600/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 81ms | Tot: 28s259ms | Train Loss: 0.696 | Train Acc: 75.737% (34027/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 2s17ms | Valid Loss: 0.861 | Valid Acc: 70.280% (3514/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 79ms | Tot: 28s360ms | Train Loss: 0.656 | Train Acc: 77.166% (34669/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 2s222ms | Valid Loss: 0.899 | Valid Acc: 69.340% (3467/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 77ms | Tot: 28s566ms | Train Loss: 0.612 | Train Acc: 78.793% (35400/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s932ms | Valid Loss: 0.714 | Valid Acc: 75.840% (3792/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 77ms | Tot: 28s442ms | Train Loss: 0.587 | Train Acc: 79.383% (35665/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s957ms | Valid Loss: 0.704 | Valid Acc: 76.940% (3847/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 82ms | Tot: 28s387ms | Train Loss: 0.563 | Train Acc: 80.522% (36177/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s81ms | Valid Loss: 0.734 | Valid Acc: 74.840% (3742/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 80ms | Tot: 28s397ms | Train Loss: 0.536 | Train Acc: 81.261% (36509/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s946ms | Valid Loss: 0.630 | Valid Acc: 78.980% (3949/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 77ms | Tot: 28s288ms | Train Loss: 0.518 | Train Acc: 82.076% (36875/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s995ms | Valid Loss: 0.658 | Valid Acc: 77.440% (3872/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 79ms | Tot: 28s398ms | Train Loss: 0.501 | Train Acc: 82.592% (37107/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s993ms | Valid Loss: 0.651 | Valid Acc: 77.460% (3873/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 78ms | Tot: 28s271ms | Train Loss: 0.482 | Train Acc: 83.169% (37366/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 2s31ms | Valid Loss: 0.576 | Valid Acc: 80.100% (4005/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 79ms | Tot: 28s370ms | Train Loss: 0.471 | Train Acc: 83.583% (37552/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s975ms | Valid Loss: 0.559 | Valid Acc: 80.980% (4049/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 79ms | Tot: 28s398ms | Train Loss: 0.458 | Train Acc: 84.161% (37812/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s974ms | Valid Loss: 0.569 | Valid Acc: 80.260% (4013/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 77ms | Tot: 28s343ms | Train Loss: 0.442 | Train Acc: 84.464% (37948/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s954ms | Valid Loss: 0.533 | Valid Acc: 81.620% (4081/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 79ms | Tot: 28s371ms | Train Loss: 0.424 | Train Acc: 85.181% (38270/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s412ms | Valid Loss: 0.632 | Valid Acc: 78.440% (3922/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 76ms | Tot: 28s303ms | Train Loss: 0.414 | Train Acc: 85.452% (38392/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 2s36ms | Valid Loss: 0.575 | Valid Acc: 81.140% (4057/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:47:15,529]\u001b[0m Trial 8 finished with value: 81.14 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'SGD', 'momentum': 0.8513839372427039, 'lr': 0.019973362232791177, 'batch_size': 128}. Best is trial 1 with value: 81.6.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 78ms | Tot: 28s253ms | Train Loss: 2.523 | Train Acc: 14.207% (6383/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s991ms | Valid Loss: 2.148 | Valid Acc: 16.280% (814/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:47:46,661]\u001b[0m Trial 9 pruned. \u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 81.6\n",
            "Best hyperparameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.2, 'optimizer': 'RMSprop', 'momentum': 0.876498817866124, 'lr': 0.0007834902289043906, 'batch_size': 256}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18\")\n",
        "\n",
        "study.optimize(objective, n_trials = 10)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RphsqTa1uv_"
      },
      "outputs": [],
      "source": [
        "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "7FyHCQ1cHeZM",
        "outputId": "50c6f278-0a27-4e8f-becf-78dd2a6ffb3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4ac7909e-c1ea-4ee8-b7cd-8ac1f37f2a2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_dropout_rate</th>\n",
              "      <th>params_dropout_rate2</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_momentum</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74.08</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.037060</td>\n",
              "      <td>0.278250</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.60</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000783</td>\n",
              "      <td>0.876499</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.20</td>\n",
              "      <td>192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.089340</td>\n",
              "      <td>0.711130</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.28</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.015771</td>\n",
              "      <td>0.947618</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32.02</td>\n",
              "      <td>256</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.509363</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27.52</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>0.110993</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>80.70</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008955</td>\n",
              "      <td>0.691540</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>75.32</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.012223</td>\n",
              "      <td>0.520948</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>81.14</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.019973</td>\n",
              "      <td>0.851384</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>16.28</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.014143</td>\n",
              "      <td>0.890543</td>\n",
              "      <td>RMSprop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ac7909e-c1ea-4ee8-b7cd-8ac1f37f2a2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ac7909e-c1ea-4ee8-b7cd-8ac1f37f2a2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ac7909e-c1ea-4ee8-b7cd-8ac1f37f2a2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
              "0  74.08                256                  0.1                   0.2   \n",
              "1  81.60                256                  0.1                   0.2   \n",
              "2  10.20                192                  0.0                   0.1   \n",
              "3  80.28                192                  0.1                   0.1   \n",
              "4  32.02                256                  0.1                   0.2   \n",
              "5  27.52                256                  0.0                   0.0   \n",
              "6  80.70                128                  0.1                   0.0   \n",
              "7  75.32                192                  0.1                   0.1   \n",
              "8  81.14                128                  0.0                   0.1   \n",
              "9  16.28                128                  0.1                   0.2   \n",
              "\n",
              "   params_lr  params_momentum params_optimizer  \n",
              "0   0.037060         0.278250          RMSprop  \n",
              "1   0.000783         0.876499          RMSprop  \n",
              "2   0.089340         0.711130          RMSprop  \n",
              "3   0.015771         0.947618              SGD  \n",
              "4   0.000192         0.509363              SGD  \n",
              "5   0.001445         0.110993              SGD  \n",
              "6   0.008955         0.691540          RMSprop  \n",
              "7   0.012223         0.520948              SGD  \n",
              "8   0.019973         0.851384              SGD  \n",
              "9   0.014143         0.890543          RMSprop  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfILxanQHrkV"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path  \n",
        "filepath = Path('optuna_out.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tMVKiy5_1lQz",
        "outputId": "bb48cbb3-4fde-45a6-98d2-7fc13d8836cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ab5a7d25-63f5-473d-ac6d-13968f7089d8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ab5a7d25-63f5-473d-ac6d-13968f7089d8\")) {                    Plotly.newPlot(                        \"ab5a7d25-63f5-473d-ac6d-13968f7089d8\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,6,7,8],\"y\":[74.08,81.6,10.2,80.28,32.02,80.7,75.32,81.14],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,6,7,8],\"y\":[74.08,81.6,81.6,81.6,81.6,81.6,81.6,81.6],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ab5a7d25-63f5-473d-ac6d-13968f7089d8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt_hist = optuna.visualization.plot_optimization_history(study)\n",
        "\n",
        "opt_hist.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "opt_hist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ttCK-I3f1olz",
        "outputId": "ff7c2286-a53a-41a2-ad88-c760f14b2747"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"189d6b82-af81-433d-aedf-b64f23e8297e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"189d6b82-af81-433d-aedf-b64f23e8297e\")) {                    Plotly.newPlot(                        \"189d6b82-af81-433d-aedf-b64f23e8297e\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[121.6,128,192,256,262.4],\"y\":[0.0001415075803711087,0.00019236486028456414,0.0007834902289043906,0.008955444489335542,0.012223134652644843,0.015770633845970158,0.019973362232791177,0.03705955361405272,0.08934010704973969,0.1214485977737768],\"z\":[[null,null,null,null,null],[null,null,null,32.02,null],[null,null,null,81.6,null],[null,80.7,null,null,null],[null,null,75.32,null,null],[null,null,80.28,null,null],[null,81.14,null,null,null],[null,null,null,74.08,null],[null,null,10.2,null,null],[null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[256,256,192,192,256,128,192,128],\"y\":[0.03705955361405272,0.0007834902289043906,0.08934010704973969,0.015770633845970158,0.00019236486028456414,0.008955444489335542,0.012223134652644843,0.019973362232791177],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"batch_size\"},\"range\":[121.6,262.4]},\"yaxis\":{\"title\":{\"text\":\"lr\"},\"range\":[-3.849220294944181,-0.9156074951250235],\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('189d6b82-af81-433d-aedf-b64f23e8297e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i2J9SpQJ1sy5",
        "outputId": "c5af82b4-5be4-45da-9286-dfc7c408cd40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"67786b2a-9f68-4db1-bcdc-86734855b664\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"67786b2a-9f68-4db1-bcdc-86734855b664\")) {                    Plotly.newPlot(                        \"67786b2a-9f68-4db1-bcdc-86734855b664\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"dropout_rate2 (FloatDistribution): 0.007105488217932512<extra></extra>\",\"optimizer (CategoricalDistribution): 0.01722957344971664<extra></extra>\",\"batch_size (IntDistribution): 0.039511436786190055<extra></extra>\",\"dropout_rate (FloatDistribution): 0.12902263063093208<extra></extra>\",\"momentum (FloatDistribution): 0.24677341783785225<extra></extra>\",\"lr (FloatDistribution): 0.5603574530773765<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"0.02\",\"0.04\",\"0.13\",\"0.25\",\"0.56\"],\"textposition\":\"outside\",\"x\":[0.007105488217932512,0.01722957344971664,0.039511436786190055,0.12902263063093208,0.24677341783785225,0.5603574530773765],\"y\":[\"dropout_rate2\",\"optimizer\",\"batch_size\",\"dropout_rate\",\"momentum\",\"lr\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('67786b2a-9f68-4db1-bcdc-86734855b664');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_importance_fig = optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "param_importance_fig.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "param_importance_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3tpr4KK2RVI",
        "outputId": "bd2bab54-10d9-4f42-bc3b-58dcb573249d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Number of finished trials:  10\n",
            "  Number of pruned trials:  2\n",
            "  Number of complete trials:  8\n"
          ]
        }
      ],
      "source": [
        "from optuna.trial import TrialState\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUoh2I8hGQhu"
      },
      "outputs": [],
      "source": [
        "# serialize the reult\n",
        "\n",
        "SERIALIZATION_DIR = \"\" \n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('study_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(study, f)\n",
        "\n",
        "with open('df_optuna_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj0rployJanz",
        "outputId": "208e6474-07ae-42ad-88c8-d4785e455796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best model is\n",
            "{'dropout_rate': 0.1, 'dropout_rate2': 0.2, 'optimizer': 'RMSprop', 'momentum': 0.876498817866124, 'lr': 0.0007834902289043906, 'batch_size': 256}\n"
          ]
        }
      ],
      "source": [
        "print(\"The best model is\")\n",
        "\n",
        "print(trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OntkPiXekwLR"
      },
      "outputs": [],
      "source": [
        "# searching for the best Hyperparameters using a different family of optimizers \n",
        "\n",
        "def objective_2(trial):\n",
        "\n",
        "  # generate a model\n",
        "  curr_model = ResNet18(trial).to(device)\n",
        "\n",
        "  prune_model(curr_model)\n",
        "\n",
        "  if device == 'cuda':\n",
        "    curr_model = torch.nn.DataParallel(curr_model)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "  # trying different optimizers\n",
        "\n",
        "  optimizer_name_class_2 = trial.suggest_categorical(\"optimizer\", [\"Adam\",\n",
        "                                                                   \"Adadelta\", \"Adagrad\", \"ASGD\"])\n",
        "  \n",
        "  momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "  optimizer_class_2 = getattr(optim, optimizer_name_class_2)(curr_model.parameters(),lr=lr)\n",
        "\n",
        "  curr_batch_size = trial.suggest_int(\"batch_size\", 128, 256, step=64)\n",
        "\n",
        "  # defining a loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_class_2, T_max=200)\n",
        "\n",
        "  val_size = 5000\n",
        "  train_size = len(trainset) - val_size\n",
        "\n",
        "  train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "  curr_trainloader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "  \n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=curr_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "  # run for 200 epochs once the best model is found \n",
        "  NUM_EPOCHS = 20\n",
        "\n",
        "  for epoch in range(0, NUM_EPOCHS):\n",
        "      scheduler.step()\n",
        "      train(epoch, model=curr_model, train_loader=curr_trainloader, optim=optimizer_class_2)\n",
        "      accuracy = evaluate(epoch, model=curr_model, validation_loader=val_loader)\n",
        "      trial.report(accuracy, epoch)\n",
        "\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTR21sA2lAnX",
        "outputId": "91a79207-a283-4be7-b9c3-e91215c889cd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:49:06,359]\u001b[0m A new study created in memory with name: resNet-18-Ada\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna with Ada family optimizers\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning:\n",
            "\n",
            "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [======>]  Step: 119ms | Tot: 27s813ms | Train Loss: 2.331 | Train Acc: 9.929% (4461/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s800ms | Valid Loss: 2.318 | Valid Acc: 10.940% (547/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 112ms | Tot: 27s53ms | Train Loss: 2.303 | Train Acc: 11.287% (5071/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 13ms | Tot: 1s849ms | Valid Loss: 2.295 | Valid Acc: 11.300% (565/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 115ms | Tot: 27s121ms | Train Loss: 2.287 | Train Acc: 12.805% (5753/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s755ms | Valid Loss: 2.275 | Valid Acc: 13.700% (685/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 114ms | Tot: 27s345ms | Train Loss: 2.272 | Train Acc: 14.428% (6482/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s780ms | Valid Loss: 2.260 | Valid Acc: 14.520% (726/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 113ms | Tot: 27s83ms | Train Loss: 2.254 | Train Acc: 15.556% (6989/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 14ms | Tot: 1s793ms | Valid Loss: 2.242 | Valid Acc: 16.260% (813/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 113ms | Tot: 27s169ms | Train Loss: 2.233 | Train Acc: 16.575% (7447/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s774ms | Valid Loss: 2.226 | Valid Acc: 17.580% (879/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 114ms | Tot: 27s191ms | Train Loss: 2.213 | Train Acc: 17.152% (7706/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s820ms | Valid Loss: 2.202 | Valid Acc: 17.600% (880/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 113ms | Tot: 27s151ms | Train Loss: 2.193 | Train Acc: 18.327% (8234/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s756ms | Valid Loss: 2.170 | Valid Acc: 17.800% (890/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 113ms | Tot: 27s265ms | Train Loss: 2.178 | Train Acc: 18.815% (8453/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s770ms | Valid Loss: 2.172 | Valid Acc: 18.940% (947/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 115ms | Tot: 27s164ms | Train Loss: 2.163 | Train Acc: 19.629% (8819/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s768ms | Valid Loss: 2.159 | Valid Acc: 19.700% (985/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 115ms | Tot: 27s398ms | Train Loss: 2.148 | Train Acc: 19.921% (8950/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s775ms | Valid Loss: 2.133 | Valid Acc: 19.700% (985/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 112ms | Tot: 27s197ms | Train Loss: 2.137 | Train Acc: 20.448% (9187/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s821ms | Valid Loss: 2.117 | Valid Acc: 20.420% (1021/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 113ms | Tot: 27s137ms | Train Loss: 2.121 | Train Acc: 21.250% (9547/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s839ms | Valid Loss: 2.107 | Valid Acc: 21.080% (1054/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 113ms | Tot: 27s204ms | Train Loss: 2.108 | Train Acc: 21.737% (9766/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s779ms | Valid Loss: 2.103 | Valid Acc: 22.200% (1110/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 112ms | Tot: 27s161ms | Train Loss: 2.100 | Train Acc: 22.035% (9900/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s813ms | Valid Loss: 2.092 | Valid Acc: 22.380% (1119/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 114ms | Tot: 27s278ms | Train Loss: 2.084 | Train Acc: 22.541% (10127/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 2s158ms | Valid Loss: 2.070 | Valid Acc: 23.780% (1189/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 114ms | Tot: 27s276ms | Train Loss: 2.074 | Train Acc: 22.716% (10206/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s785ms | Valid Loss: 2.056 | Valid Acc: 23.560% (1178/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 114ms | Tot: 27s225ms | Train Loss: 2.060 | Train Acc: 23.475% (10547/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s842ms | Valid Loss: 2.055 | Valid Acc: 23.260% (1163/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 112ms | Tot: 27s305ms | Train Loss: 2.045 | Train Acc: 24.145% (10848/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s763ms | Valid Loss: 2.026 | Valid Acc: 24.120% (1206/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 113ms | Tot: 27s86ms | Train Loss: 2.034 | Train Acc: 24.526% (11019/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s784ms | Valid Loss: 2.009 | Valid Acc: 24.720% (1236/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 18:59:02,835]\u001b[0m Trial 0 finished with value: 24.72 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.0, 'optimizer': 'ASGD', 'momentum': 0.43646225906119995, 'lr': 0.00012990117653064416, 'batch_size': 192}. Best is trial 0 with value: 24.72.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 119ms | Tot: 27s553ms | Train Loss: 2.310 | Train Acc: 13.660% (6137/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s810ms | Valid Loss: 2.223 | Valid Acc: 16.320% (816/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 118ms | Tot: 27s586ms | Train Loss: 2.160 | Train Acc: 18.547% (8333/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 2s102ms | Valid Loss: 2.107 | Valid Acc: 21.100% (1055/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 117ms | Tot: 27s601ms | Train Loss: 2.058 | Train Acc: 23.489% (10553/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s796ms | Valid Loss: 2.026 | Valid Acc: 25.380% (1269/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 116ms | Tot: 27s634ms | Train Loss: 1.983 | Train Acc: 26.887% (12080/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s817ms | Valid Loss: 1.955 | Valid Acc: 27.480% (1374/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 117ms | Tot: 27s546ms | Train Loss: 1.918 | Train Acc: 28.960% (13011/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s835ms | Valid Loss: 1.894 | Valid Acc: 29.800% (1490/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 115ms | Tot: 27s641ms | Train Loss: 1.875 | Train Acc: 30.725% (13804/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s821ms | Valid Loss: 1.860 | Valid Acc: 31.640% (1582/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 114ms | Tot: 27s601ms | Train Loss: 1.843 | Train Acc: 31.671% (14229/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s762ms | Valid Loss: 1.827 | Valid Acc: 32.420% (1621/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 116ms | Tot: 27s622ms | Train Loss: 1.808 | Train Acc: 33.175% (14905/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s786ms | Valid Loss: 1.780 | Valid Acc: 33.500% (1675/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 116ms | Tot: 27s568ms | Train Loss: 1.787 | Train Acc: 33.754% (15165/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s758ms | Valid Loss: 1.771 | Valid Acc: 34.420% (1721/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 118ms | Tot: 27s647ms | Train Loss: 1.762 | Train Acc: 35.036% (15741/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s772ms | Valid Loss: 1.746 | Valid Acc: 35.960% (1798/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 117ms | Tot: 27s589ms | Train Loss: 1.739 | Train Acc: 35.806% (16087/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s786ms | Valid Loss: 1.730 | Valid Acc: 36.560% (1828/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 117ms | Tot: 27s797ms | Train Loss: 1.716 | Train Acc: 36.623% (16454/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s802ms | Valid Loss: 1.728 | Valid Acc: 37.740% (1887/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 117ms | Tot: 27s524ms | Train Loss: 1.697 | Train Acc: 37.373% (16791/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s925ms | Valid Loss: 1.690 | Valid Acc: 37.160% (1858/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 115ms | Tot: 27s674ms | Train Loss: 1.676 | Train Acc: 38.192% (17159/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s874ms | Valid Loss: 1.637 | Valid Acc: 39.160% (1958/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 114ms | Tot: 27s644ms | Train Loss: 1.656 | Train Acc: 39.094% (17564/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s829ms | Valid Loss: 1.633 | Valid Acc: 39.900% (1995/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 116ms | Tot: 27s604ms | Train Loss: 1.638 | Train Acc: 40.162% (18044/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s869ms | Valid Loss: 1.635 | Valid Acc: 40.040% (2002/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 115ms | Tot: 27s580ms | Train Loss: 1.621 | Train Acc: 40.607% (18244/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s814ms | Valid Loss: 1.627 | Valid Acc: 40.080% (2004/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 115ms | Tot: 27s604ms | Train Loss: 1.602 | Train Acc: 41.524% (18656/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s825ms | Valid Loss: 1.594 | Valid Acc: 41.360% (2068/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 116ms | Tot: 27s845ms | Train Loss: 1.584 | Train Acc: 42.537% (19111/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s828ms | Valid Loss: 1.574 | Valid Acc: 43.020% (2151/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 116ms | Tot: 27s622ms | Train Loss: 1.567 | Train Acc: 42.902% (19275/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s831ms | Valid Loss: 1.560 | Valid Acc: 42.140% (2107/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 19:09:07,466]\u001b[0m Trial 1 finished with value: 42.14 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.2, 'optimizer': 'Adadelta', 'momentum': 0.3165705710390335, 'lr': 0.0015005930007701857, 'batch_size': 192}. Best is trial 1 with value: 42.14.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 77ms | Tot: 28s184ms | Train Loss: 2.271 | Train Acc: 14.134% (6350/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s972ms | Valid Loss: 2.218 | Valid Acc: 16.900% (845/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 76ms | Tot: 28s55ms | Train Loss: 2.143 | Train Acc: 20.836% (9361/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s916ms | Valid Loss: 2.058 | Valid Acc: 24.620% (1231/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 76ms | Tot: 28s96ms | Train Loss: 2.007 | Train Acc: 25.434% (11427/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s937ms | Valid Loss: 1.950 | Valid Acc: 27.420% (1371/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 77ms | Tot: 28s1ms | Train Loss: 1.930 | Train Acc: 27.731% (12459/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s289ms | Valid Loss: 1.910 | Valid Acc: 28.320% (1416/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 76ms | Tot: 28s71ms | Train Loss: 1.875 | Train Acc: 29.852% (13412/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s921ms | Valid Loss: 1.876 | Valid Acc: 30.280% (1514/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 79ms | Tot: 28s332ms | Train Loss: 1.836 | Train Acc: 31.515% (14159/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s906ms | Valid Loss: 1.847 | Valid Acc: 31.040% (1552/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 77ms | Tot: 28s6ms | Train Loss: 1.798 | Train Acc: 32.922% (14791/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s876ms | Valid Loss: 1.791 | Valid Acc: 32.840% (1642/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 76ms | Tot: 28s97ms | Train Loss: 1.765 | Train Acc: 34.188% (15360/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s979ms | Valid Loss: 1.761 | Valid Acc: 34.700% (1735/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 78ms | Tot: 28s105ms | Train Loss: 1.728 | Train Acc: 35.938% (16146/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s936ms | Valid Loss: 1.742 | Valid Acc: 35.360% (1768/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 78ms | Tot: 28s133ms | Train Loss: 1.687 | Train Acc: 37.262% (16741/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s927ms | Valid Loss: 1.681 | Valid Acc: 37.800% (1890/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 78ms | Tot: 28s76ms | Train Loss: 1.653 | Train Acc: 38.653% (17366/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s940ms | Valid Loss: 1.656 | Valid Acc: 38.780% (1939/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 78ms | Tot: 28s124ms | Train Loss: 1.623 | Train Acc: 40.155% (18041/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s930ms | Valid Loss: 1.602 | Valid Acc: 40.420% (2021/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 78ms | Tot: 28s170ms | Train Loss: 1.594 | Train Acc: 41.295% (18553/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 2s361ms | Valid Loss: 1.578 | Valid Acc: 40.960% (2048/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 79ms | Tot: 28s92ms | Train Loss: 1.569 | Train Acc: 42.107% (18918/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s916ms | Valid Loss: 1.587 | Valid Acc: 42.000% (2100/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 80ms | Tot: 28s123ms | Train Loss: 1.544 | Train Acc: 43.472% (19531/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s835ms | Valid Loss: 1.541 | Valid Acc: 43.060% (2153/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 76ms | Tot: 28s162ms | Train Loss: 1.521 | Train Acc: 44.391% (19944/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s875ms | Valid Loss: 1.535 | Valid Acc: 44.000% (2200/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 77ms | Tot: 28s171ms | Train Loss: 1.501 | Train Acc: 44.992% (20214/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s889ms | Valid Loss: 1.514 | Valid Acc: 45.760% (2288/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 77ms | Tot: 28s63ms | Train Loss: 1.475 | Train Acc: 46.183% (20749/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s855ms | Valid Loss: 1.472 | Valid Acc: 46.560% (2328/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 77ms | Tot: 28s113ms | Train Loss: 1.451 | Train Acc: 47.293% (21248/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s885ms | Valid Loss: 1.419 | Valid Acc: 48.080% (2404/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 77ms | Tot: 28s70ms | Train Loss: 1.425 | Train Acc: 48.233% (21670/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s901ms | Valid Loss: 1.432 | Valid Acc: 47.340% (2367/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-22 19:19:21,748]\u001b[0m Trial 2 finished with value: 47.34 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.2, 'optimizer': 'ASGD', 'momentum': 0.3165519205471726, 'lr': 0.0007204095146147001, 'batch_size': 128}. Best is trial 2 with value: 47.34.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 115ms | Tot: 27s560ms | Train Loss: 1.997 | Train Acc: 25.757% (11572/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s804ms | Valid Loss: 1.882 | Valid Acc: 30.800% (1540/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 115ms | Tot: 27s573ms | Train Loss: 1.732 | Train Acc: 36.648% (16465/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s776ms | Valid Loss: 1.652 | Valid Acc: 39.280% (1964/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 114ms | Tot: 27s612ms | Train Loss: 1.585 | Train Acc: 42.357% (19030/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 2s | Valid Loss: 1.607 | Valid Acc: 42.580% (2129/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 118ms | Tot: 27s551ms | Train Loss: 1.483 | Train Acc: 46.120% (20721/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 2s311ms | Valid Loss: 1.483 | Valid Acc: 46.080% (2304/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 114ms | Tot: 27s571ms | Train Loss: 1.387 | Train Acc: 50.198% (22553/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s826ms | Valid Loss: 1.408 | Valid Acc: 48.460% (2423/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 116ms | Tot: 27s588ms | Train Loss: 1.310 | Train Acc: 52.880% (23758/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s846ms | Valid Loss: 1.366 | Valid Acc: 50.200% (2510/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 115ms | Tot: 27s599ms | Train Loss: 1.248 | Train Acc: 55.133% (24770/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s880ms | Valid Loss: 1.230 | Valid Acc: 55.500% (2775/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 115ms | Tot: 27s579ms | Train Loss: 1.207 | Train Acc: 56.938% (25581/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s859ms | Valid Loss: 1.276 | Valid Acc: 56.140% (2807/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 116ms | Tot: 27s554ms | Train Loss: 1.156 | Train Acc: 58.932% (26477/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 7ms | Tot: 1s779ms | Valid Loss: 1.168 | Valid Acc: 57.760% (2888/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 115ms | Tot: 27s624ms | Train Loss: 1.111 | Train Acc: 60.728% (27284/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s834ms | Valid Loss: 1.109 | Valid Acc: 61.060% (3053/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 118ms | Tot: 27s627ms | Train Loss: 1.068 | Train Acc: 61.852% (27789/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s845ms | Valid Loss: 1.086 | Valid Acc: 61.960% (3098/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 117ms | Tot: 27s573ms | Train Loss: 1.027 | Train Acc: 63.849% (28686/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s810ms | Valid Loss: 1.064 | Valid Acc: 62.680% (3134/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 117ms | Tot: 27s579ms | Train Loss: 0.989 | Train Acc: 65.040% (29221/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s795ms | Valid Loss: 1.046 | Valid Acc: 62.860% (3143/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 118ms | Tot: 27s645ms | Train Loss: 0.955 | Train Acc: 66.311% (29792/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s765ms | Valid Loss: 1.013 | Valid Acc: 64.220% (3211/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 118ms | Tot: 27s626ms | Train Loss: 0.930 | Train Acc: 67.448% (30303/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 2s93ms | Valid Loss: 0.985 | Valid Acc: 65.340% (3267/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 118ms | Tot: 27s586ms | Train Loss: 0.901 | Train Acc: 68.665% (30850/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s743ms | Valid Loss: 0.948 | Valid Acc: 66.540% (3327/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 116ms | Tot: 27s654ms | Train Loss: 0.879 | Train Acc: 69.251% (31113/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s797ms | Valid Loss: 0.906 | Valid Acc: 67.820% (3391/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 116ms | Tot: 27s647ms | Train Loss: 0.859 | Train Acc: 69.885% (31398/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s800ms | Valid Loss: 0.938 | Valid Acc: 67.260% (3363/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 117ms | Tot: 27s665ms | Train Loss: 0.835 | Train Acc: 70.695% (31762/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s789ms | Valid Loss: 0.952 | Valid Acc: 67.340% (3367/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 118ms | Tot: 27s673ms | Train Loss: 0.820 | Train Acc: 71.270% (32020/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s788ms | Valid Loss: 0.895 | Valid Acc: 68.800% (3440/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:29:26,603]\u001b[0m Trial 3 finished with value: 68.8 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'Adadelta', 'momentum': 0.6801655383816134, 'lr': 0.012640385834303648, 'batch_size': 192}. Best is trial 3 with value: 68.8.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 149ms | Tot: 26s414ms | Train Loss: 2.046 | Train Acc: 23.933% (10722/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s701ms | Valid Loss: 2.042 | Valid Acc: 25.000% (1250/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 147ms | Tot: 26s380ms | Train Loss: 1.793 | Train Acc: 33.545% (15028/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 2s35ms | Valid Loss: 1.744 | Valid Acc: 35.180% (1759/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 149ms | Tot: 26s450ms | Train Loss: 1.662 | Train Acc: 38.522% (17258/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s748ms | Valid Loss: 1.623 | Valid Acc: 40.900% (2045/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 150ms | Tot: 26s436ms | Train Loss: 1.545 | Train Acc: 43.806% (19625/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s707ms | Valid Loss: 1.705 | Valid Acc: 39.160% (1958/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 148ms | Tot: 26s379ms | Train Loss: 1.437 | Train Acc: 47.866% (21444/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s701ms | Valid Loss: 1.501 | Valid Acc: 45.960% (2298/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 146ms | Tot: 26s417ms | Train Loss: 1.345 | Train Acc: 51.719% (23170/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 35ms | Tot: 1s627ms | Valid Loss: 1.405 | Valid Acc: 50.200% (2510/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 148ms | Tot: 26s430ms | Train Loss: 1.263 | Train Acc: 54.835% (24566/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s662ms | Valid Loss: 1.423 | Valid Acc: 49.820% (2491/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 150ms | Tot: 26s434ms | Train Loss: 1.184 | Train Acc: 57.757% (25875/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s756ms | Valid Loss: 1.215 | Valid Acc: 56.900% (2845/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 148ms | Tot: 26s455ms | Train Loss: 1.127 | Train Acc: 59.953% (26859/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 32ms | Tot: 1s703ms | Valid Loss: 1.161 | Valid Acc: 58.620% (2931/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 149ms | Tot: 26s450ms | Train Loss: 1.072 | Train Acc: 62.029% (27789/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s701ms | Valid Loss: 1.116 | Valid Acc: 59.900% (2995/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 149ms | Tot: 26s435ms | Train Loss: 1.013 | Train Acc: 64.118% (28725/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s738ms | Valid Loss: 1.047 | Valid Acc: 62.780% (3139/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 148ms | Tot: 26s416ms | Train Loss: 0.978 | Train Acc: 65.496% (29342/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s682ms | Valid Loss: 1.101 | Valid Acc: 61.020% (3051/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 151ms | Tot: 26s495ms | Train Loss: 0.942 | Train Acc: 66.888% (29966/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s732ms | Valid Loss: 0.964 | Valid Acc: 65.000% (3250/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 149ms | Tot: 26s472ms | Train Loss: 0.891 | Train Acc: 68.799% (30822/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s704ms | Valid Loss: 0.933 | Valid Acc: 67.240% (3362/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 149ms | Tot: 26s406ms | Train Loss: 0.872 | Train Acc: 69.145% (30977/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s657ms | Valid Loss: 0.922 | Valid Acc: 67.460% (3373/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 150ms | Tot: 26s476ms | Train Loss: 0.837 | Train Acc: 70.518% (31592/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 32ms | Tot: 1s747ms | Valid Loss: 0.947 | Valid Acc: 66.860% (3343/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 148ms | Tot: 26s372ms | Train Loss: 0.826 | Train Acc: 71.045% (31828/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 26ms | Tot: 1s693ms | Valid Loss: 0.882 | Valid Acc: 68.940% (3447/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 151ms | Tot: 26s464ms | Train Loss: 0.794 | Train Acc: 72.147% (32322/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s802ms | Valid Loss: 0.874 | Valid Acc: 69.360% (3468/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 148ms | Tot: 26s416ms | Train Loss: 0.768 | Train Acc: 73.321% (32848/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s776ms | Valid Loss: 0.877 | Valid Acc: 69.420% (3471/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 147ms | Tot: 26s420ms | Train Loss: 0.753 | Train Acc: 73.337% (32855/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s784ms | Valid Loss: 0.806 | Valid Acc: 71.780% (3589/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:39:08,125]\u001b[0m Trial 4 finished with value: 71.78 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'ASGD', 'momentum': 0.7017481988849308, 'lr': 0.008475752955081241, 'batch_size': 256}. Best is trial 4 with value: 71.78.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 117ms | Tot: 27s455ms | Train Loss: 1.983 | Train Acc: 25.824% (11602/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s983ms | Valid Loss: 1.787 | Valid Acc: 34.120% (1706/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 113ms | Tot: 27s489ms | Train Loss: 1.624 | Train Acc: 40.505% (18198/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s835ms | Valid Loss: 1.504 | Valid Acc: 45.080% (2254/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 113ms | Tot: 27s454ms | Train Loss: 1.353 | Train Acc: 51.629% (23196/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 12ms | Tot: 1s776ms | Valid Loss: 1.273 | Valid Acc: 53.540% (2677/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 113ms | Tot: 27s426ms | Train Loss: 1.163 | Train Acc: 58.774% (26406/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s813ms | Valid Loss: 1.239 | Valid Acc: 57.520% (2876/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 117ms | Tot: 27s523ms | Train Loss: 1.035 | Train Acc: 63.270% (28426/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s823ms | Valid Loss: 1.198 | Valid Acc: 59.060% (2953/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 113ms | Tot: 27s406ms | Train Loss: 0.926 | Train Acc: 67.239% (30209/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s797ms | Valid Loss: 0.937 | Valid Acc: 66.560% (3328/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 115ms | Tot: 27s377ms | Train Loss: 0.839 | Train Acc: 70.555% (31699/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s835ms | Valid Loss: 0.934 | Valid Acc: 67.660% (3383/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 114ms | Tot: 27s414ms | Train Loss: 0.774 | Train Acc: 72.943% (32772/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s768ms | Valid Loss: 0.854 | Valid Acc: 70.080% (3504/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 114ms | Tot: 27s505ms | Train Loss: 0.717 | Train Acc: 74.878% (33641/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s840ms | Valid Loss: 0.765 | Valid Acc: 73.400% (3670/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 114ms | Tot: 27s396ms | Train Loss: 0.666 | Train Acc: 76.700% (34460/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 10ms | Tot: 1s825ms | Valid Loss: 0.716 | Valid Acc: 74.520% (3726/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 113ms | Tot: 27s364ms | Train Loss: 0.635 | Train Acc: 77.998% (35043/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s783ms | Valid Loss: 0.698 | Valid Acc: 74.680% (3734/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 117ms | Tot: 27s466ms | Train Loss: 0.594 | Train Acc: 79.420% (35682/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s804ms | Valid Loss: 0.712 | Valid Acc: 76.620% (3831/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 116ms | Tot: 27s430ms | Train Loss: 0.572 | Train Acc: 80.012% (35948/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s826ms | Valid Loss: 0.635 | Valid Acc: 76.760% (3838/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 117ms | Tot: 27s459ms | Train Loss: 0.541 | Train Acc: 81.168% (36467/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s804ms | Valid Loss: 0.609 | Valid Acc: 78.320% (3916/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 114ms | Tot: 27s353ms | Train Loss: 0.524 | Train Acc: 81.706% (36709/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s773ms | Valid Loss: 0.634 | Valid Acc: 78.200% (3910/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 116ms | Tot: 27s520ms | Train Loss: 0.504 | Train Acc: 82.545% (37086/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 8ms | Tot: 1s805ms | Valid Loss: 0.577 | Valid Acc: 80.400% (4020/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 115ms | Tot: 27s424ms | Train Loss: 0.481 | Train Acc: 83.182% (37372/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s834ms | Valid Loss: 0.652 | Valid Acc: 77.520% (3876/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 115ms | Tot: 27s490ms | Train Loss: 0.469 | Train Acc: 83.727% (37617/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s828ms | Valid Loss: 0.601 | Valid Acc: 79.440% (3972/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 115ms | Tot: 27s453ms | Train Loss: 0.447 | Train Acc: 84.482% (37956/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 9ms | Tot: 1s778ms | Valid Loss: 0.569 | Valid Acc: 81.100% (4055/5000)\b\b\b\b 27/27 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 115ms | Tot: 27s448ms | Train Loss: 0.433 | Train Acc: 84.996% (38187/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 11ms | Tot: 1s853ms | Valid Loss: 0.556 | Valid Acc: 80.860% (4043/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:49:08,912]\u001b[0m Trial 5 finished with value: 80.86 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'Adam', 'momentum': 0.22674051007973173, 'lr': 0.007336913126137123, 'batch_size': 192}. Best is trial 5 with value: 80.86.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 114ms | Tot: 27s187ms | Train Loss: 2.333 | Train Acc: 11.213% (5038/44928)\b\b\b\b 234/234 \n",
            " [======>]  Step: 14ms | Tot: 2s330ms | Valid Loss: 2.313 | Valid Acc: 11.480% (574/5000)\b\b\b\b 27/27 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:49:39,382]\u001b[0m Trial 6 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 152ms | Tot: 26s620ms | Train Loss: 1.731 | Train Acc: 36.174% (16206/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s715ms | Valid Loss: 1.576 | Valid Acc: 42.960% (2148/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 151ms | Tot: 26s757ms | Train Loss: 1.315 | Train Acc: 52.701% (23610/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s692ms | Valid Loss: 1.265 | Valid Acc: 53.140% (2657/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 150ms | Tot: 26s656ms | Train Loss: 1.092 | Train Acc: 61.464% (27536/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s780ms | Valid Loss: 1.075 | Valid Acc: 62.260% (3113/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 150ms | Tot: 26s700ms | Train Loss: 0.944 | Train Acc: 66.761% (29909/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s759ms | Valid Loss: 1.168 | Valid Acc: 59.240% (2962/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 147ms | Tot: 26s660ms | Train Loss: 0.845 | Train Acc: 70.382% (31531/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s754ms | Valid Loss: 0.822 | Valid Acc: 70.980% (3549/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 152ms | Tot: 26s715ms | Train Loss: 0.764 | Train Acc: 73.404% (32885/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s729ms | Valid Loss: 0.818 | Valid Acc: 71.120% (3556/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 151ms | Tot: 26s693ms | Train Loss: 0.726 | Train Acc: 74.895% (33553/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s697ms | Valid Loss: 0.829 | Valid Acc: 71.080% (3554/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 153ms | Tot: 26s717ms | Train Loss: 0.670 | Train Acc: 76.730% (34375/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s739ms | Valid Loss: 0.768 | Valid Acc: 73.120% (3656/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 151ms | Tot: 26s629ms | Train Loss: 0.642 | Train Acc: 77.904% (34901/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 31ms | Tot: 1s836ms | Valid Loss: 0.740 | Valid Acc: 74.700% (3735/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 152ms | Tot: 26s696ms | Train Loss: 0.613 | Train Acc: 78.558% (35194/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 30ms | Tot: 1s696ms | Valid Loss: 0.734 | Valid Acc: 75.400% (3770/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 152ms | Tot: 26s678ms | Train Loss: 0.585 | Train Acc: 79.783% (35743/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 27ms | Tot: 1s705ms | Valid Loss: 0.643 | Valid Acc: 77.440% (3872/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 150ms | Tot: 26s643ms | Train Loss: 0.557 | Train Acc: 80.766% (36183/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s675ms | Valid Loss: 0.650 | Valid Acc: 77.600% (3880/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 151ms | Tot: 26s665ms | Train Loss: 0.545 | Train Acc: 81.062% (36316/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s708ms | Valid Loss: 0.629 | Valid Acc: 78.340% (3917/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 150ms | Tot: 26s656ms | Train Loss: 0.524 | Train Acc: 81.761% (36629/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s858ms | Valid Loss: 0.680 | Valid Acc: 77.300% (3865/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 152ms | Tot: 26s730ms | Train Loss: 0.498 | Train Acc: 82.895% (37137/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s785ms | Valid Loss: 0.576 | Valid Acc: 80.040% (4002/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 152ms | Tot: 26s646ms | Train Loss: 0.484 | Train Acc: 83.087% (37223/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s750ms | Valid Loss: 0.689 | Valid Acc: 77.240% (3862/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 149ms | Tot: 26s744ms | Train Loss: 0.466 | Train Acc: 83.857% (37568/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s720ms | Valid Loss: 0.669 | Valid Acc: 77.540% (3877/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 151ms | Tot: 26s689ms | Train Loss: 0.462 | Train Acc: 84.067% (37662/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s724ms | Valid Loss: 0.582 | Valid Acc: 79.640% (3982/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 152ms | Tot: 26s745ms | Train Loss: 0.443 | Train Acc: 84.565% (37885/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 28ms | Tot: 1s733ms | Valid Loss: 0.595 | Valid Acc: 80.200% (4010/5000)\b\b\b\b 20/20 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 151ms | Tot: 26s689ms | Train Loss: 0.428 | Train Acc: 84.931% (38049/44800)\b\b\b\b 175/175 \n",
            " [======>]  Step: 29ms | Tot: 1s795ms | Valid Loss: 0.564 | Valid Acc: 80.780% (4039/5000)\b\b\b\b 20/20 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:59:26,250]\u001b[0m Trial 7 finished with value: 80.78 and parameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'Adam', 'momentum': 0.9049935042662269, 'lr': 0.00024090739388859145, 'batch_size': 256}. Best is trial 5 with value: 80.86.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 80ms | Tot: 28s723ms | Train Loss: 2.035 | Train Acc: 24.176% (10862/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s925ms | Valid Loss: 1.838 | Valid Acc: 31.380% (1569/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 79ms | Tot: 28s847ms | Train Loss: 1.773 | Train Acc: 34.382% (15447/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s885ms | Valid Loss: 1.679 | Valid Acc: 37.520% (1876/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 78ms | Tot: 28s683ms | Train Loss: 1.657 | Train Acc: 39.087% (17561/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s871ms | Valid Loss: 1.596 | Valid Acc: 43.040% (2152/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 79ms | Tot: 28s864ms | Train Loss: 1.552 | Train Acc: 43.752% (19657/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s923ms | Valid Loss: 1.507 | Valid Acc: 45.080% (2254/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 79ms | Tot: 28s679ms | Train Loss: 1.471 | Train Acc: 46.882% (21063/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 2s169ms | Valid Loss: 1.451 | Valid Acc: 47.500% (2375/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 78ms | Tot: 28s723ms | Train Loss: 1.397 | Train Acc: 49.610% (22289/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s905ms | Valid Loss: 1.342 | Valid Acc: 51.180% (2559/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 78ms | Tot: 28s891ms | Train Loss: 1.348 | Train Acc: 51.652% (23206/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 1s978ms | Valid Loss: 1.363 | Valid Acc: 50.640% (2532/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 79ms | Tot: 28s729ms | Train Loss: 1.298 | Train Acc: 53.530% (24050/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s980ms | Valid Loss: 1.274 | Valid Acc: 54.200% (2710/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 20:03:37,413]\u001b[0m Trial 8 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [======>]  Step: 81ms | Tot: 28s203ms | Train Loss: 2.098 | Train Acc: 22.923% (10299/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 7ms | Tot: 1s960ms | Valid Loss: 2.041 | Valid Acc: 25.420% (1271/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 1\n",
            " [======>]  Step: 81ms | Tot: 28s225ms | Train Loss: 1.762 | Train Acc: 34.758% (15616/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s911ms | Valid Loss: 1.675 | Valid Acc: 39.520% (1976/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 2\n",
            " [======>]  Step: 80ms | Tot: 28s287ms | Train Loss: 1.567 | Train Acc: 42.437% (19066/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s926ms | Valid Loss: 1.528 | Valid Acc: 43.960% (2198/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 3\n",
            " [======>]  Step: 80ms | Tot: 28s377ms | Train Loss: 1.398 | Train Acc: 49.501% (22240/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s897ms | Valid Loss: 1.340 | Valid Acc: 52.620% (2631/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 4\n",
            " [======>]  Step: 79ms | Tot: 28s293ms | Train Loss: 1.264 | Train Acc: 54.785% (24614/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s865ms | Valid Loss: 1.292 | Valid Acc: 55.200% (2760/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 5\n",
            " [======>]  Step: 76ms | Tot: 28s395ms | Train Loss: 1.161 | Train Acc: 58.614% (26334/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s890ms | Valid Loss: 1.109 | Valid Acc: 60.220% (3011/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 6\n",
            " [======>]  Step: 78ms | Tot: 28s327ms | Train Loss: 1.080 | Train Acc: 61.416% (27593/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s884ms | Valid Loss: 1.119 | Valid Acc: 60.400% (3020/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 7\n",
            " [======>]  Step: 78ms | Tot: 28s398ms | Train Loss: 1.009 | Train Acc: 64.136% (28815/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s892ms | Valid Loss: 1.027 | Valid Acc: 63.060% (3153/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 8\n",
            " [======>]  Step: 80ms | Tot: 28s292ms | Train Loss: 0.955 | Train Acc: 66.175% (29731/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s914ms | Valid Loss: 1.000 | Valid Acc: 65.780% (3289/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 9\n",
            " [======>]  Step: 79ms | Tot: 28s322ms | Train Loss: 0.891 | Train Acc: 68.496% (30774/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 12ms | Tot: 1s956ms | Valid Loss: 0.902 | Valid Acc: 67.420% (3371/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 10\n",
            " [======>]  Step: 78ms | Tot: 28s328ms | Train Loss: 0.835 | Train Acc: 70.366% (31614/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s923ms | Valid Loss: 0.819 | Valid Acc: 70.960% (3548/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 11\n",
            " [======>]  Step: 81ms | Tot: 28s344ms | Train Loss: 0.789 | Train Acc: 72.300% (32483/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s942ms | Valid Loss: 0.847 | Valid Acc: 70.360% (3518/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 12\n",
            " [======>]  Step: 77ms | Tot: 28s344ms | Train Loss: 0.754 | Train Acc: 73.435% (32993/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s907ms | Valid Loss: 0.762 | Valid Acc: 73.100% (3655/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 13\n",
            " [======>]  Step: 76ms | Tot: 28s330ms | Train Loss: 0.723 | Train Acc: 74.370% (33413/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 14ms | Tot: 2s177ms | Valid Loss: 0.804 | Valid Acc: 72.660% (3633/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 14\n",
            " [======>]  Step: 78ms | Tot: 28s378ms | Train Loss: 0.691 | Train Acc: 75.663% (33994/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s907ms | Valid Loss: 0.744 | Valid Acc: 74.300% (3715/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 15\n",
            " [======>]  Step: 78ms | Tot: 28s378ms | Train Loss: 0.670 | Train Acc: 76.469% (34356/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s867ms | Valid Loss: 0.777 | Valid Acc: 73.100% (3655/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 16\n",
            " [======>]  Step: 78ms | Tot: 28s428ms | Train Loss: 0.637 | Train Acc: 77.486% (34813/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 10ms | Tot: 1s927ms | Valid Loss: 0.707 | Valid Acc: 74.900% (3745/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 17\n",
            " [======>]  Step: 80ms | Tot: 28s408ms | Train Loss: 0.615 | Train Acc: 78.323% (35189/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 9ms | Tot: 1s932ms | Valid Loss: 0.663 | Valid Acc: 77.080% (3854/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 18\n",
            " [======>]  Step: 76ms | Tot: 28s394ms | Train Loss: 0.601 | Train Acc: 78.955% (35473/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 11ms | Tot: 1s924ms | Valid Loss: 0.630 | Valid Acc: 76.780% (3839/5000)\b\b\b\b 40/40 \n",
            "\n",
            "Epoch: 19\n",
            " [======>]  Step: 79ms | Tot: 28s405ms | Train Loss: 0.578 | Train Acc: 79.790% (35848/44928)\b\b\b\b 351/351 \n",
            " [======>]  Step: 8ms | Tot: 1s956ms | Valid Loss: 0.684 | Valid Acc: 76.660% (3833/5000)\b\b\b\b 40/40 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 20:13:55,678]\u001b[0m Trial 9 finished with value: 76.66 and parameters: {'dropout_rate': 0.1, 'dropout_rate2': 0.1, 'optimizer': 'Adagrad', 'momentum': 0.6994957155449719, 'lr': 0.06430301091426294, 'batch_size': 128}. Best is trial 5 with value: 80.86.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.86\n",
            "Best hyperparameters: {'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'Adam', 'momentum': 0.22674051007973173, 'lr': 0.007336913126137123, 'batch_size': 192}\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Optuna with Ada family optimizers\")\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), study_name=\"resNet-18-Ada\")\n",
        "\n",
        "study.optimize(objective_2, n_trials = 10)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)"
      ],
      "metadata": {
        "id": "lAhf_sJbBFsY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "aoSYEA21BMx5",
        "outputId": "16ddcfd8-90c4-4ce9-ffcd-6390a4f0a3d0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   value  params_batch_size  params_dropout_rate  params_dropout_rate2  \\\n",
              "0  24.72                192                  0.1                   0.0   \n",
              "1  42.14                192                  0.0                   0.2   \n",
              "2  47.34                128                  0.0                   0.2   \n",
              "3  68.80                192                  0.0                   0.1   \n",
              "4  71.78                256                  0.0                   0.1   \n",
              "5  80.86                192                  0.0                   0.1   \n",
              "6  11.48                192                  0.1                   0.2   \n",
              "7  80.78                256                  0.0                   0.1   \n",
              "8  54.20                128                  0.0                   0.0   \n",
              "9  76.66                128                  0.1                   0.1   \n",
              "\n",
              "   params_lr  params_momentum params_optimizer  \n",
              "0   0.000130         0.436462             ASGD  \n",
              "1   0.001501         0.316571         Adadelta  \n",
              "2   0.000720         0.316552             ASGD  \n",
              "3   0.012640         0.680166         Adadelta  \n",
              "4   0.008476         0.701748             ASGD  \n",
              "5   0.007337         0.226741             Adam  \n",
              "6   0.000176         0.417994             ASGD  \n",
              "7   0.000241         0.904994             Adam  \n",
              "8   0.007664         0.657834         Adadelta  \n",
              "9   0.064303         0.699496          Adagrad  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1df2af35-0457-44ef-a49b-9bd9322140dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_dropout_rate</th>\n",
              "      <th>params_dropout_rate2</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_momentum</th>\n",
              "      <th>params_optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.72</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.436462</td>\n",
              "      <td>ASGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42.14</td>\n",
              "      <td>192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.316571</td>\n",
              "      <td>Adadelta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47.34</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>0.316552</td>\n",
              "      <td>ASGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>68.80</td>\n",
              "      <td>192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.012640</td>\n",
              "      <td>0.680166</td>\n",
              "      <td>Adadelta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71.78</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.008476</td>\n",
              "      <td>0.701748</td>\n",
              "      <td>ASGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>80.86</td>\n",
              "      <td>192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.007337</td>\n",
              "      <td>0.226741</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11.48</td>\n",
              "      <td>192</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.417994</td>\n",
              "      <td>ASGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>80.78</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>0.904994</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>54.20</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007664</td>\n",
              "      <td>0.657834</td>\n",
              "      <td>Adadelta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>76.66</td>\n",
              "      <td>128</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.064303</td>\n",
              "      <td>0.699496</td>\n",
              "      <td>Adagrad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1df2af35-0457-44ef-a49b-9bd9322140dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1df2af35-0457-44ef-a49b-9bd9322140dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1df2af35-0457-44ef-a49b-9bd9322140dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path  \n",
        "filepath = Path('optuna_out_adam.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath) "
      ],
      "metadata": {
        "id": "rO1d8nXhBRHo"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_hist = optuna.visualization.plot_optimization_history(study)\n",
        "\n",
        "opt_hist.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "opt_hist.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LUwlIhUGBUm3",
        "outputId": "c8ce792e-843e-4ee3-8938-89bd0d2dbf53"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9caa866c-857e-4f53-9753-b2e6dc1ca39b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9caa866c-857e-4f53-9753-b2e6dc1ca39b\")) {                    Plotly.newPlot(                        \"9caa866c-857e-4f53-9753-b2e6dc1ca39b\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,7,9],\"y\":[24.72,42.14,47.34,68.8,71.78,80.86,80.78,76.66],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,7,9],\"y\":[24.72,42.14,47.34,68.8,71.78,80.86,80.86,80.86],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9caa866c-857e-4f53-9753-b2e6dc1ca39b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_contour(study, params=['batch_size', 'lr'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bHgQ9R9BBh19",
        "outputId": "44e88a7d-4721-4951-812a-6b551566769d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"39e33097-2315-4528-a533-a4bc0e592d95\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"39e33097-2315-4528-a533-a4bc0e592d95\")) {                    Plotly.newPlot(                        \"39e33097-2315-4528-a533-a4bc0e592d95\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[121.6,128,192,256,262.4],\"y\":[9.525376998531547e-05,0.00012990117653064416,0.00024090739388859145,0.0007204095146147001,0.0015005930007701857,0.007336913126137123,0.008475752955081241,0.012640385834303648,0.06430301091426294,0.0876924532594702],\"z\":[[null,null,null,null,null],[null,null,24.72,null,null],[null,null,null,80.78,null],[null,47.34,null,null,null],[null,null,42.14,null,null],[null,null,80.86,null,null],[null,null,null,71.78,null],[null,null,68.8,null,null],[null,76.66,null,null,null],[null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[192,192,128,192,256,192,256,128],\"y\":[0.00012990117653064416,0.0015005930007701857,0.0007204095146147001,0.012640385834303648,0.008475752955081241,0.007336913126137123,0.00024090739388859145,0.06430301091426294],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"batch_size\"},\"range\":[121.6,262.4]},\"yaxis\":{\"title\":{\"text\":\"lr\"},\"range\":[-4.021117826661073,-1.0570377800523656],\"type\":\"log\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('39e33097-2315-4528-a533-a4bc0e592d95');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_importance_fig = optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "param_importance_fig.update_layout(\n",
        "    yaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    xaxis=dict(\n",
        "        titlefont=dict(size=30),\n",
        "    ),\n",
        "\n",
        "    font=dict(\n",
        "        size = 30\n",
        "    )\n",
        ")\n",
        "\n",
        "param_importance_fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2wDuT1DDBm6_",
        "outputId": "e1c9ed9b-7fd1-4fc7-e059-2513ce41187c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"71e121fa-bd78-4e60-bdf3-906953bcb6b2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71e121fa-bd78-4e60-bdf3-906953bcb6b2\")) {                    Plotly.newPlot(                        \"71e121fa-bd78-4e60-bdf3-906953bcb6b2\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"batch_size (IntDistribution): 0.024336051804103812<extra></extra>\",\"dropout_rate (FloatDistribution): 0.03594791266412456<extra></extra>\",\"optimizer (CategoricalDistribution): 0.16397928690554622<extra></extra>\",\"momentum (FloatDistribution): 0.21629641764386953<extra></extra>\",\"lr (FloatDistribution): 0.2379570402226281<extra></extra>\",\"dropout_rate2 (FloatDistribution): 0.32148329075972776<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02\",\"0.04\",\"0.16\",\"0.22\",\"0.24\",\"0.32\"],\"textposition\":\"outside\",\"x\":[0.024336051804103812,0.03594791266412456,0.16397928690554622,0.21629641764386953,0.2379570402226281,0.32148329075972776],\"y\":[\"batch_size\",\"dropout_rate\",\"optimizer\",\"momentum\",\"lr\",\"dropout_rate2\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\",\"font\":{\"size\":30}}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\",\"font\":{\"size\":30}}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"size\":30}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('71e121fa-bd78-4e60-bdf3-906953bcb6b2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.trial import TrialState\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f_Kb2pyBxSl",
        "outputId": "6c09e6c8-361c-4b7c-ff07-20cb3f6f6d62"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Number of finished trials:  10\n",
            "  Number of pruned trials:  2\n",
            "  Number of complete trials:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize the reult\n",
        "\n",
        "SERIALIZATION_DIR = \"\" \n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('study_optuna_adam_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(study, f)\n",
        "\n",
        "with open('df_optuna_adam_nov_21.pickle', 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ],
      "metadata": {
        "id": "fnXzLuCoByaT"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best Adam model is\")\n",
        "\n",
        "print(trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwkypT-yB8_a",
        "outputId": "aee6850c-5c3f-4a55-c5a1-771e327b46c2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best Adam model is\n",
            "{'dropout_rate': 0.0, 'dropout_rate2': 0.1, 'optimizer': 'Adam', 'momentum': 0.22674051007973173, 'lr': 0.007336913126137123, 'batch_size': 192}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8OFkLJ5nQa"
      },
      "source": [
        "<h1>Model Visualization with Tensorboard</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odnt6T_i5mcA",
        "outputId": "fca4db79-ff96-4774-e1de-687c181bd165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.38.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.14.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVF5Rs1yg8-l"
      },
      "outputs": [],
      "source": [
        "# Run in shell: tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9M0JT27NZn",
        "outputId": "fa927eb0-3d81-4811-ab7c-630f16ac158d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 0.943s\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6l8H9BXcLp-",
        "outputId": "d567fcb6-1bcf-440b-e87e-0cca3e4723bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://legal-mails-turn-34-73-105-255.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!lt --port 6006"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a3dee7be8734ab99425179b2d0a37d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1346132be0c544bdb53d0985afeb9db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df2267cf8d54d74aaa803ab0a7f39d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4fd0e91c384433c9e4e86677551a5eb",
              "IPY_MODEL_75fb31bd9ee64e3c8fe52490f031d917",
              "IPY_MODEL_c411225fe7b9462bbbef20d707e9b184"
            ],
            "layout": "IPY_MODEL_ae4f75575c494f9aa028a84b27b35718"
          }
        },
        "75fb31bd9ee64e3c8fe52490f031d917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1346132be0c544bdb53d0985afeb9db0",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f2e2b1de884cfe875db6b983566fb3",
            "value": 170498071
          }
        },
        "91f2e2b1de884cfe875db6b983566fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4fd0e91c384433c9e4e86677551a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0361accc5944588b1f28e440421b32d",
            "placeholder": "",
            "style": "IPY_MODEL_0a3dee7be8734ab99425179b2d0a37d2",
            "value": "100%"
          }
        },
        "ae4f75575c494f9aa028a84b27b35718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b432d075aafa47cb8121b097d421733e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c411225fe7b9462bbbef20d707e9b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b432d075aafa47cb8121b097d421733e",
            "placeholder": "",
            "style": "IPY_MODEL_fcfc666db5a6422b95ae3115185ae4af",
            "value": " 170498071/170498071 [00:10&lt;00:00, 17177215.09it/s]"
          }
        },
        "f0361accc5944588b1f28e440421b32d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfc666db5a6422b95ae3115185ae4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}